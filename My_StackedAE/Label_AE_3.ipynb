{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE parameters\n",
    "num_inputs = 10\n",
    "neurons_hid1 = 5\n",
    "neurons_hid2 = 3\n",
    "neurons_hid3 = 1\n",
    "\n",
    "learning_rate = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PINV(PSEUDO-INVERSE) function\n",
    "def pinv(a, rcond=1e-15):\n",
    "    s, u, v = tf.svd(a)\n",
    "    # Ignore singular values close to zero to prevent numerical overflow\n",
    "    limit = rcond * tf.reduce_max(s)\n",
    "    non_zero = tf.greater(s, limit)\n",
    "\n",
    "    reciprocal = tf.where(non_zero, tf.reciprocal(s), tf.zeros(s.shape))\n",
    "    lhs = tf.matmul(v, tf.diag(reciprocal))\n",
    "    return tf.matmul(lhs, u, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSPOSE OR PINV\n",
    "tie_weight = tf.transpose #pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLACEHOLDER DEFINATION\n",
    "X = tf.placeholder(tf.float32, shape=[None, num_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WEIGHTS DEFINATION\n",
    "initializer = tf.variance_scaling_initializer()\n",
    "\n",
    "w1 = tf.Variable(initializer([num_inputs, neurons_hid1]), dtype=tf.float32)\n",
    "w1_ = tie_weight(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## WEIGHTS DEFINATION\n",
    "initializer = tf.variance_scaling_initializer()\n",
    "\n",
    "w1 = tf.Variable(initializer([num_inputs, neurons_hid1]), dtype=tf.float32)\n",
    "# w1 = tf.Variable(np.load('./save/weights/lw1.npy'))\n",
    "w1_ = tie_weight(w1)\n",
    "\n",
    "w2 = tf.Variable(initializer([neurons_hid1, neurons_hid2]), dtype=tf.float32)\n",
    "w2_ = tie_weight(w2)\n",
    "\n",
    "# LAYER MODELING OF :NN\n",
    "hid_layer1 = act_func(tf.matmul(X, w1))\n",
    "\n",
    "# hid_layer2 = act_func(tf.matmul(hid_layer1, w2))\n",
    "\n",
    "# hid_layer1_= act_func(tf.matmul(hid_layer2, w2_))\n",
    "output_layer = (tf.matmul(hid_layer1, w1_))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTIVATION FUNCTION  [ lambda X:X  <OR>  tf.nn.relu  ]\n",
    "act_func = lambda X:X #tf.nn.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAYER MODELING OF :NN\n",
    "hid_layer1 = act_func(tf.matmul(X, w1))\n",
    "output_layer = tf.matmul(hid_layer1, w1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS FUNCTIONS\n",
    "# loss = tf.reduce_mean(tf.square(output_layer - X))\n",
    "# loss = tf.reduce_mean(tf.abs(output_layer - X))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=X,logits=output_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss, var_list=[w1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATION\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Complete. Training Loss: 0.11045192927122116\n",
      "Epoch 1 Complete. Training Loss: 0.017541395500302315\n",
      "Epoch 2 Complete. Training Loss: 0.006896788254380226\n",
      "Epoch 3 Complete. Training Loss: 0.003574881237000227\n",
      "Epoch 4 Complete. Training Loss: 0.002191245788708329\n",
      "Epoch 5 Complete. Training Loss: 0.0014186359476298094\n",
      "Epoch 6 Complete. Training Loss: 0.0009893054375424981\n",
      "Epoch 7 Complete. Training Loss: 0.0007059051422402263\n",
      "Epoch 8 Complete. Training Loss: 0.0005221861647441983\n",
      "Epoch 9 Complete. Training Loss: 0.0003937579458579421\n",
      "Epoch 10 Complete. Training Loss: 0.0003019399009644985\n",
      "Epoch 11 Complete. Training Loss: 0.0002285156078869477\n",
      "Epoch 12 Complete. Training Loss: 0.00017933548951987177\n",
      "Epoch 13 Complete. Training Loss: 0.00013948955165687948\n",
      "Epoch 14 Complete. Training Loss: 0.00011204553447896615\n",
      "Epoch 15 Complete. Training Loss: 8.809883001958951e-05\n",
      "Epoch 16 Complete. Training Loss: 7.287469634320587e-05\n",
      "Epoch 17 Complete. Training Loss: 5.6167420552810654e-05\n",
      "Epoch 18 Complete. Training Loss: 4.6338729589479044e-05\n",
      "Epoch 19 Complete. Training Loss: 3.647894845926203e-05\n",
      "Epoch 20 Complete. Training Loss: 3.0095112379058264e-05\n",
      "Epoch 21 Complete. Training Loss: 2.4109383957693353e-05\n",
      "Epoch 22 Complete. Training Loss: 1.9662182239699177e-05\n",
      "Epoch 23 Complete. Training Loss: 1.6173387848539278e-05\n",
      "Epoch 24 Complete. Training Loss: 1.316856469202321e-05\n",
      "Epoch 25 Complete. Training Loss: 1.0920304703176953e-05\n",
      "Epoch 26 Complete. Training Loss: 8.680781320435926e-06\n",
      "Epoch 27 Complete. Training Loss: 7.196240403573029e-06\n",
      "Epoch 28 Complete. Training Loss: 5.922299351368565e-06\n",
      "Epoch 29 Complete. Training Loss: 4.7691546569694765e-06\n",
      "Epoch 30 Complete. Training Loss: 3.877472863678122e-06\n",
      "Epoch 31 Complete. Training Loss: 3.1669883355789352e-06\n",
      "Epoch 32 Complete. Training Loss: 2.614653340060613e-06\n",
      "Epoch 33 Complete. Training Loss: 2.164043735319865e-06\n",
      "Epoch 34 Complete. Training Loss: 1.7754221062205033e-06\n",
      "Epoch 35 Complete. Training Loss: 1.4440206541621592e-06\n",
      "Epoch 36 Complete. Training Loss: 1.1849396059915307e-06\n",
      "Epoch 37 Complete. Training Loss: 9.822840638662456e-07\n",
      "Epoch 38 Complete. Training Loss: 7.923441103230289e-07\n",
      "Epoch 39 Complete. Training Loss: 6.659823270638299e-07\n",
      "Epoch 40 Complete. Training Loss: 5.141893097970751e-07\n",
      "Epoch 41 Complete. Training Loss: 3.878274981161667e-07\n",
      "Epoch 42 Complete. Training Loss: 3.29017581179869e-07\n",
      "Epoch 43 Complete. Training Loss: 2.9643371135534835e-07\n",
      "Epoch 44 Complete. Training Loss: 2.18550312069965e-07\n",
      "Epoch 45 Complete. Training Loss: 1.589456957162838e-07\n",
      "Epoch 46 Complete. Training Loss: 1.311302071371756e-07\n",
      "Epoch 47 Complete. Training Loss: 9.139377965539097e-08\n",
      "Epoch 48 Complete. Training Loss: 9.298324243900424e-08\n",
      "Epoch 49 Complete. Training Loss: 8.4241221998127e-08\n",
      "Epoch 50 Complete. Training Loss: 7.629393650177008e-08\n",
      "Epoch 51 Complete. Training Loss: 0.0\n",
      "Epoch 52 Complete. Training Loss: 0.0\n",
      "Epoch 53 Complete. Training Loss: 1.7484028447256605e-08\n",
      "Epoch 54 Complete. Training Loss: 0.0\n",
      "Epoch 55 Complete. Training Loss: 1.1126199517264013e-08\n",
      "Epoch 56 Complete. Training Loss: 0.0\n",
      "Epoch 57 Complete. Training Loss: 0.0\n",
      "Epoch 58 Complete. Training Loss: 1.668929883180681e-08\n",
      "Epoch 59 Complete. Training Loss: 4.1325883159970545e-08\n",
      "Epoch 60 Complete. Training Loss: 0.0\n",
      "Epoch 61 Complete. Training Loss: 0.0\n",
      "Epoch 62 Complete. Training Loss: 0.0\n",
      "Epoch 63 Complete. Training Loss: 0.0\n",
      "Epoch 64 Complete. Training Loss: 1.192092824453539e-08\n",
      "Epoch 65 Complete. Training Loss: 0.0\n",
      "Epoch 66 Complete. Training Loss: 2.145767119543507e-08\n",
      "Epoch 67 Complete. Training Loss: 1.1126199517264013e-08\n",
      "Epoch 68 Complete. Training Loss: 0.0\n",
      "Epoch 69 Complete. Training Loss: 0.0\n",
      "Epoch 70 Complete. Training Loss: 0.0\n",
      "Epoch 71 Complete. Training Loss: 0.0\n",
      "Epoch 72 Complete. Training Loss: 0.0\n",
      "Epoch 73 Complete. Training Loss: 0.0\n",
      "Epoch 74 Complete. Training Loss: 0.0\n",
      "Epoch 75 Complete. Training Loss: 0.0\n",
      "Epoch 76 Complete. Training Loss: 0.0\n",
      "Epoch 77 Complete. Training Loss: 0.0\n",
      "Epoch 78 Complete. Training Loss: 0.0\n",
      "Epoch 79 Complete. Training Loss: 0.0\n",
      "Epoch 80 Complete. Training Loss: 0.0\n",
      "Epoch 81 Complete. Training Loss: 0.0\n",
      "Epoch 82 Complete. Training Loss: 0.0\n",
      "Epoch 83 Complete. Training Loss: 0.0\n",
      "Epoch 84 Complete. Training Loss: 0.0\n",
      "Epoch 85 Complete. Training Loss: 0.0\n",
      "Epoch 86 Complete. Training Loss: 0.0\n",
      "Epoch 87 Complete. Training Loss: 0.0\n",
      "Epoch 88 Complete. Training Loss: 0.0\n",
      "Epoch 89 Complete. Training Loss: 0.0\n",
      "Epoch 90 Complete. Training Loss: 0.0\n",
      "Epoch 91 Complete. Training Loss: 0.0\n",
      "Epoch 92 Complete. Training Loss: 0.0\n",
      "Epoch 93 Complete. Training Loss: 0.0\n",
      "Epoch 94 Complete. Training Loss: 0.0\n",
      "Epoch 95 Complete. Training Loss: 0.0\n",
      "Epoch 96 Complete. Training Loss: 0.0\n",
      "Epoch 97 Complete. Training Loss: 0.0\n",
      "Epoch 98 Complete. Training Loss: 0.0\n",
      "Epoch 99 Complete. Training Loss: 0.0\n",
      "Finished Training the Model\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "try:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # Epoch == Entire Training Set\n",
    "        for epoch in range(num_epochs):\n",
    "            num_batches = mnist.train.num_examples // batch_size\n",
    "\n",
    "            # 150 batch size\n",
    "            for iteration in range(num_batches):\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "                sess.run(train, feed_dict={X: y_batch})\n",
    "\n",
    "            training_loss = loss.eval(feed_dict={X: y_batch})   \n",
    "            print(\"Epoch {} Complete. Training Loss: {}\".format(epoch,training_loss))\n",
    "            saver.save(sess, \"./save/label_ae_3.ckpt\")\n",
    "            \n",
    "            \n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print('Keyboard Interrupted')\n",
    "finally:\n",
    "    print('Finished Training the Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save/label_ae_3.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_test_labels = 10\n",
    "start_point = 15\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess,\"./save/label_ae_3.ckpt\")\n",
    "    \n",
    "    results,compressed = sess.run([tf.nn.softmax(output_layer), hid_layer1],\n",
    "                                  feed_dict={X:mnist.test.labels[start_point:num_test_labels+start_point]})\n",
    "    weight1 = w1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ORIGINAL VS RECONSTRUCTED\n",
    "f, a = plt.subplots(2, num_test_labels, figsize=(20, 4))\n",
    "for i in range(start_point,num_test_labels+start_point):\n",
    "    j = i-start_point\n",
    "    a[0][j].imshow(np.reshape(mnist.test.labels[i], (10, 1)))\n",
    "    a[1][j].imshow(np.reshape(results[j], (10, 1)))\n",
    "    print(mnist.test.labels[i])\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    print(results[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.7071,  2.4307, -2.2346,  0.5107, -1.8471],\n",
       "       [ 1.8039, -2.4401, -0.9451, -2.7398, -1.1674],\n",
       "       [-1.7937,  2.4399,  0.9357,  2.7299,  1.1579],\n",
       "       [ 2.264 , -0.8663,  2.5567,  2.0596, -1.5852],\n",
       "       [-2.3048, -1.8807, -1.4455,  1.684 , -2.4051],\n",
       "       [-1.7042, -2.4218,  2.2298, -0.5078,  1.8432],\n",
       "       [-1.5418,  1.5675,  2.0579, -2.0793, -2.4424],\n",
       "       [ 2.3127,  1.8954,  1.4426, -1.6857,  2.4045],\n",
       "       [ 1.5455, -1.5576, -2.0646,  2.0822,  2.4382],\n",
       "       [-2.2585,  0.8757, -2.5591, -2.055 ,  1.5782]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5)\n"
     ]
    }
   ],
   "source": [
    "print(weight1.shape)\n",
    "np.save('./save/weights/lw1.npy',weight1)\n",
    "#wt1 = np.load('./save/weights/w1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
