{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e79740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2b919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dtnnlib as dtnn\n",
    "# import resnet_cifar\n",
    "\n",
    "from torchvision import datasets, transforms as T\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53af51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1602c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.5,],\n",
    "        std=[0.5,],\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/\", train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/\", train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "491fefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.data = train_dataset.data.view(-1, 28*28)\n",
    "# test_dataset.data = test_dataset.data.view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6807321",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f12e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd705fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0879c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47582925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuman/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103909e2",
   "metadata": {},
   "source": [
    "## Any function as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9551d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionDT(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, func, inv_temp=0.):\n",
    "        '''\n",
    "        func [input_dim -> 1]\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.func = func\n",
    "        \n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.centers = torch.randn(num_centers, input_dim)/3.\n",
    "        self.centers = nn.Parameter(self.centers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = x.unsqueeze(1) - self.centers.unsqueeze(0)\n",
    "        dists = self.func(z).squeeze(-1)\n",
    "        dists = -dists*torch.exp(self.inv_temp)\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e1d6fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuman/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from classes import DistanceRegressor, ConvexNN\n",
    "from nflib.flows import SequentialFlow, ActNorm\n",
    "import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4fc66",
   "metadata": {},
   "source": [
    "## Merge all models into single and benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffba015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(h = 5, device='cpu'):\n",
    "    I = 784\n",
    "    layer1 = {\n",
    "        \"l_0.5\":dtnn.DistanceTransform(I, h, p=0.5, bias=False),\n",
    "        \"l_1\":dtnn.DistanceTransform(I, h, p=1, bias=False),\n",
    "        \"l_2\":dtnn.DistanceTransform(I, h, bias=False),\n",
    "        \"l_inf\":dtnn.DistanceTransform(I, h, p=20, bias=False),\n",
    "        \"stereo\":dtnn.StereographicTransform(I, h, bias=False),\n",
    "        \"linear\":nn.Linear(I, h, bias=False)\n",
    "    }\n",
    "    net_dict = {}\n",
    "    for key in layer1:\n",
    "        net = nn.Sequential(\n",
    "            layer1[key],\n",
    "            nn.BatchNorm1d(h),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(h, 10),\n",
    "            )\n",
    "        net_dict[key] = net.to(device)\n",
    "    return net_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14541096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_func(h = 500, func_h=500, device='cpu'):\n",
    "    layer1 = {\n",
    "        \"convex\":ConvexNN([784, func_h, 1]),\n",
    "        \"invex\":nn.Sequential(\n",
    "                    ActNorm(784),\n",
    "                    irf.ResidualFlow(784, [func_h], activation=irf.LeakyReLU),\n",
    "                    ActNorm(784),\n",
    "                    DistanceRegressor(784),\n",
    "                    ),\n",
    "        \"ordinary\":nn.Sequential(\n",
    "                    ActNorm(784),\n",
    "                    irf.ResidualFlow(784, [func_h], activation=irf.LeakyReLU),\n",
    "                    ActNorm(784),\n",
    "                    DistanceRegressor(784),\n",
    "                    ),\n",
    "    }\n",
    "    irf.remove_spectral_norm_model(layer1[\"ordinary\"])\n",
    "\n",
    "    net_dict = {}\n",
    "    for key in layer1:\n",
    "        net = nn.Sequential(\n",
    "            FunctionDT(784, h, layer1[key]),\n",
    "            nn.BatchNorm1d(h),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(h, 10),\n",
    "            )\n",
    "        net_dict[key] = net.to(device)\n",
    "    return net_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eaa0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7bd80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch, model, model_name):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e46396d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3b156a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "729c0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"./outputs/00.2_exp_acc_dict.json\"\n",
    "\n",
    "with open(data_file, 'r') as f:\n",
    "    exp_acc_vals = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9165645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5': {'l_0.5': 67.05,\n",
       "  'l_1': 70.7,\n",
       "  'l_2': 78.15,\n",
       "  'l_inf': 79.52,\n",
       "  'stereo': 82.19,\n",
       "  'linear': 82.74,\n",
       "  'convex': 79.49,\n",
       "  'invex': 88.26,\n",
       "  'ordinary': 83.55},\n",
       " '10': {'l_0.5': 72.08,\n",
       "  'l_1': 77.91,\n",
       "  'l_2': 82.35,\n",
       "  'l_inf': 83.98,\n",
       "  'stereo': 84.73,\n",
       "  'linear': 84.89,\n",
       "  'convex': 78.99,\n",
       "  'invex': 88.41,\n",
       "  'ordinary': 81.69},\n",
       " '20': {'l_0.5': 75.54,\n",
       "  'l_1': 80.08,\n",
       "  'l_2': 83.82,\n",
       "  'l_inf': 85.17,\n",
       "  'stereo': 85.86,\n",
       "  'linear': 86.27,\n",
       "  'convex': 81.03}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43a09998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['l_0.5', 'l_1', 'l_2', 'l_inf', 'stereo', 'linear', 'convex', 'invex', 'ordinary'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = [5, 10, 20, 100, 500]\n",
    "net_keys = {**get_models(1), **get_models_func(1)}.keys()\n",
    "net_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0a5332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 []\n",
      "10 []\n",
      "20 ['invex', 'ordinary']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20, 100, 500]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H_ = [h for h in H if str(h) not in exp_acc_vals.keys()]\n",
    "H_ = []\n",
    "for h in H:\n",
    "    if str(h) in exp_acc_vals.keys():\n",
    "        NET_KEYS = [k for k in net_keys if k not in list(exp_acc_vals[str(h)].keys())]\n",
    "        print(h, NET_KEYS)\n",
    "        if len(NET_KEYS) > 0:\n",
    "            H_.append(h)\n",
    "    else:\n",
    "        H_.append(h)\n",
    "\n",
    "H_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b88503e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h = 20\n",
    "# NET_KEYS = list(net_keys)\n",
    "# if str(h) in exp_acc_vals.keys():\n",
    "#     NET_KEYS = [k for k in net_keys if k not in list(exp_acc_vals[str(h)].keys())[:-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d318560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NET_KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5948b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str(h) in exp_acc_vals.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bea674cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "_________________________\n",
      "Experimenting for invex ; h:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:23<00:00, 52.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 0 Loss: 1.770 | Acc: 40.348 24209/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 135.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.345 | Acc: 58.690 5869/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 1 Loss: 1.086 | Acc: 69.578 41747/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 139.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 1 Loss: 0.885 | Acc: 74.460 7446/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 2 Loss: 0.797 | Acc: 75.828 45497/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 133.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 2 Loss: 0.720 | Acc: 77.360 7736/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 3 Loss: 0.666 | Acc: 78.945 47367/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 137.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 3 Loss: 0.827 | Acc: 71.600 7160/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 4 Loss: 0.594 | Acc: 80.893 48536/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 135.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 4 Loss: 0.731 | Acc: 75.570 7557/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 52.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 5 Loss: 0.544 | Acc: 82.083 49250/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 152.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 5 Loss: 0.577 | Acc: 81.250 8125/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 6 Loss: 0.514 | Acc: 82.732 49639/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 137.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 6 Loss: 0.531 | Acc: 82.020 8202/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 7 Loss: 0.487 | Acc: 83.523 50114/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 138.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 7 Loss: 0.497 | Acc: 82.450 8245/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 8 Loss: 0.467 | Acc: 84.142 50485/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 136.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 8 Loss: 0.516 | Acc: 81.710 8171/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 9 Loss: 0.451 | Acc: 84.530 50718/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 135.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 9 Loss: 0.496 | Acc: 82.990 8299/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 10 Loss: 0.437 | Acc: 85.030 51018/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 136.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 10 Loss: 0.523 | Acc: 81.050 8105/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 11 Loss: 0.425 | Acc: 85.188 51113/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 134.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 11 Loss: 0.459 | Acc: 83.740 8374/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 52.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 12 Loss: 0.415 | Acc: 85.630 51378/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 158.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 12 Loss: 0.482 | Acc: 82.650 8265/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 13 Loss: 0.405 | Acc: 85.815 51489/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 134.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 13 Loss: 0.513 | Acc: 82.040 8204/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 14 Loss: 0.394 | Acc: 86.252 51751/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 136.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 14 Loss: 0.427 | Acc: 85.420 8542/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 15 Loss: 0.386 | Acc: 86.468 51881/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 138.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 15 Loss: 0.457 | Acc: 83.380 8338/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 16 Loss: 0.380 | Acc: 86.708 52025/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 139.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 16 Loss: 0.442 | Acc: 84.690 8469/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 17 Loss: 0.372 | Acc: 86.987 52192/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 136.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 17 Loss: 0.444 | Acc: 84.720 8472/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 18 Loss: 0.364 | Acc: 87.183 52310/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 133.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 18 Loss: 0.450 | Acc: 84.450 8445/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████▋                     | 688/1200 [00:07<00:05, 91.22it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m best_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m---> 22\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     test(epoch, net, model_name)\n\u001b[1;32m     24\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, model, optimizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for h in H_:\n",
    "    net_dict = {**get_models(h), **get_models_func(h)}\n",
    "    acc_dict = {}\n",
    "    NET_KEYS = list(net_keys)\n",
    "    \n",
    "    if str(h) in exp_acc_vals.keys():\n",
    "        acc_dict = exp_acc_vals[str(h)]\n",
    "        NET_KEYS = [k for k in net_keys if k not in list(exp_acc_vals[str(h)].keys())]\n",
    "        pass\n",
    "                    \n",
    "    for key in NET_KEYS:\n",
    "        print(\"_________________________\")\n",
    "        print(f\"Experimenting for {key} ; h:{h}\")\n",
    "        net = net_dict[key].to(device)\n",
    "        \n",
    "        model_name = f\"00.2_fmnist_{key}_h{h}\"\n",
    "        \n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "        best_acc = -1\n",
    "        for epoch in range(EPOCHS):\n",
    "            train(epoch, net, optimizer)\n",
    "            test(epoch, net, model_name)\n",
    "            scheduler.step()\n",
    "        acc_dict[key] = float(best_acc)\n",
    "        exp_acc_vals[str(h)] = acc_dict\n",
    "        \n",
    "        ## Save it in the file.\n",
    "        with open(data_file, \"w\") as f:\n",
    "            json.dump(exp_acc_vals, f, indent=3)\n",
    "        \n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d3d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde0a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12e500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net[0].centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals = \\\n",
    "{'5': {'l_0.5': 67.05,\n",
    "  'l_1': 70.7,\n",
    "  'l_2': 78.15,\n",
    "  'l_inf': 79.52,\n",
    "  'stereo': 82.19,\n",
    "  'linear': 82.74,\n",
    "  'convex': 79.49,\n",
    "  'invex': 88.26,\n",
    "  'ordinary': 83.55},\n",
    " '10': {'l_0.5': 72.08,\n",
    "  'l_1': 77.91,\n",
    "  'l_2': 82.35,\n",
    "  'l_inf': 83.98,\n",
    "  'stereo': 84.73,\n",
    "  'linear': 84.89,\n",
    "  'convex': 78.99,\n",
    "  'invex': 88.41,\n",
    "  'ordinary': 81.69}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29edc1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"./outputs/00.2_exp_acc_dict.json\"\n",
    "with open(data_file, \"w\") as f:\n",
    "    json.dump(exp_acc_vals, f, indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d4245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open(data_file, 'r') as f:\n",
    "    exp_acc_vals = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff8ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf363e92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
