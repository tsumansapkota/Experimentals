{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms as T\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm\n",
    "# from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtnnlib as dtnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.5,],\n",
    "        std=[0.5,],\n",
    "    ),\n",
    "])\n",
    "\n",
    "# train_dataset = datasets.FashionMNIST(root=\"../../../_Datasets/\", train=True, download=True, transform=mnist_transform)\n",
    "# test_dataset = datasets.FashionMNIST(root=\"../../../_Datasets/\", train=False, download=True, transform=mnist_transform)\n",
    "train_dataset = datasets.MNIST(root=\"../../../_Datasets/\", train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = datasets.MNIST(root=\"../../../_Datasets/\", train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Layer epsilon Softmax MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceTransform_Epsilon(dtnn.DistanceTransformBase):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, p=2, bias=False, epsilon=0.1):\n",
    "        super().__init__(input_dim, num_centers, p=2)\n",
    "        \n",
    "        nc = num_centers\n",
    "        if epsilon is not None:\n",
    "            nc += 1\n",
    "        self.scaler = nn.Parameter(torch.log(torch.ones(1, 1)*1))\n",
    "        self.bias = nn.Parameter(torch.ones(1, nc)*0) if bias else None\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dists = super().forward(x)\n",
    "        \n",
    "        if self.epsilon is not None:\n",
    "            dists = torch.cat([dists, torch.ones(len(x), 1, dtype=x.dtype)*self.epsilon], dim=1)\n",
    "        \n",
    "        ### normalize similar to UMAP\n",
    "        dists = dists/torch.sqrt(dists.var(dim=1, keepdim=True)+1e-9)\n",
    "        \n",
    "        ## scale the dists\n",
    "#         dists = torch.exp(-dists + self.scaler)\n",
    "        dists = 1-dists*torch.exp(self.scaler)\n",
    "    \n",
    "        if self.bias is not None: dists = dists+self.bias\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTeSM(DistanceTransform_Epsilon):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, epsilon=1.0):\n",
    "        super().__init__(input_dim, output_dim, bias=True, epsilon=epsilon)\n",
    "        \n",
    "        self.scale_shift = dtnn.ScaleShift(-1, scaler_init=3, shifter_init=0, scaler_const=True, shifter_const=True)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xo = super().forward(x)\n",
    "        xo = self.scale_shift(xo)\n",
    "        xo = self.softmax(xo)\n",
    "        return xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTeSM(2, 5, 0.1)(torch.randn(1, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalMLP_epsilonsoftmax(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim0, hidden_dim1, output_dim, epsilon=1.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer0 = DTeSM(input_dim, hidden_dim0, epsilon=epsilon)\n",
    "        \n",
    "        if epsilon is not None:\n",
    "            hidden_dim0 += 1\n",
    "        \n",
    "        self.layer1 = DTeSM(hidden_dim0, hidden_dim1, epsilon=epsilon)\n",
    "        \n",
    "        if epsilon is not None:\n",
    "            hidden_dim1 += 1\n",
    "        \n",
    "#         self.activ = dtnn.OneActiv(hdim, mode='relu', beta_init=np.log(1.2))\n",
    "#         self.activ = nn.ReLU()\n",
    "\n",
    "        self.layer2 = nn.Linear(hidden_dim1, output_dim)\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xo = self.layer0(x)\n",
    "        xo = self.layer1(xo)\n",
    "        xo = self.layer2(xo)\n",
    "        return xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = 200\n",
    "h1 = 60\n",
    "model = LocalMLP_epsilonsoftmax(784, h0, h1, 10, epsilon=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocalMLP_epsilonsoftmax(\n",
       "  (layer0): DTeSM(\n",
       "    (scale_shift): ScaleShift()\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (layer1): DTeSM(\n",
       "    (scale_shift): ScaleShift()\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (layer2): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xx.reshape(-1, 28*28)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_training_samples(N):\n",
    "    new_center = []\n",
    "    new_labels = []\n",
    "    count = 0\n",
    "    for i, (xx, yy) in enumerate(train_loader):\n",
    "        xx = xx.reshape(xx.shape[0], -1)\n",
    "        if count+xx.shape[0] < N:\n",
    "            new_center.append(xx)\n",
    "            new_labels.append(yy)\n",
    "            count += xx.shape[0]\n",
    "        elif count >= N:\n",
    "            break\n",
    "        else:\n",
    "            new_center.append(xx[:N-count])\n",
    "            new_labels.append(yy[:N-count])\n",
    "            count = N\n",
    "            break\n",
    "\n",
    "    new_center = torch.cat(new_center, dim=0)\n",
    "    new_labels = torch.cat(new_labels, dim=0)\n",
    "    \n",
    "    weights = torch.zeros(len(new_labels), 10)\n",
    "    for i in range(len(new_labels)):\n",
    "        weights[i, new_labels[i]] = 1.\n",
    "    \n",
    "    return new_center.to(device), weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]]),\n",
       " tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_training_samples(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0, _ = get_random_training_samples(h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first layer\n",
    "model.layer0.centers.data = c0.to(model.layer0.centers.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, v1 = get_random_training_samples(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## second layer\n",
    "model.layer1.centers.data = model.layer0(c1.to(device))\n",
    "model.layer2.weight.data = v1.t().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "        \n",
    "        ### Train with random image and \"10\" as class\n",
    "#         inputs = torch.cat([inputs, torch.rand(batch_size//10, 28*28, dtype=inputs.dtype).to(device)*2-1], dim=0)\n",
    "#         targets = torch.cat([targets, torch.ones(batch_size//10, dtype=targets.dtype).to(device)*10], dim=0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch, model):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    acc = 100.*correct/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocalMLP_epsilonsoftmax(\n",
       "  (layer0): DTeSM(\n",
       "    (scale_shift): ScaleShift()\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (layer1): DTeSM(\n",
       "    (scale_shift): ScaleShift()\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (layer2): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 2.122 | Acc: 34.080 3408/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34.08"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = test(0, model)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training - evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "# EPOCHS = 10\n",
    "EPOCHS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, p2 = [], []\n",
    "for p in model.named_parameters():\n",
    "    if p[0].endswith(\".centers\"):\n",
    "        p1.append(p[1])\n",
    "    else:\n",
    "        p2.append(p[1])\n",
    "\n",
    "params = [\n",
    "    {\"params\": p1, \"lr\": learning_rate*0.03}, ## default - to change little from data point\n",
    "#     {\"params\": p1},\n",
    "    {\"params\": p2},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "best_acc = -1\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch, model, optimizer)\n",
    "    test(epoch, model)\n",
    "    scheduler.step()\n",
    "    \n",
    "\"\"\"\n",
    "Note: It trains to about 95% on MNIST\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Noisy Selection (Type 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TYPE 1: DT>eSM>DT>eSM>V\n",
    "Type 2:  /DT>eSM>S\\\n",
    "        X---------+\\>eSM>V\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new centers to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1) initialize the models with data0, data1\n",
    "2) to add neurons to dt0, calculate respective activation with data1 and initialize the dt1\n",
    "    - for dt1, input dim increase and output dim stay same ;\n",
    "    - the hidden activation changes slightly..\n",
    "    \n",
    "3) to add neurons to dt1, same as 2 layer addition..\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = 200\n",
    "h1 = 60\n",
    "model = LocalMLP_epsilonsoftmax(784, h0, h1, 10, epsilon=None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_search0 = 30\n",
    "N_search1 = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0, _ = get_random_training_samples(h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer0.centers.data = c0.to(model.layer0.centers.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, v1 = get_random_training_samples(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer1.centers.data = model.layer0(c1.to(device))\n",
    "model.layer2.weight.data = v1.t().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 2.125 | Acc: 34.100 3410/10000\n"
     ]
    }
   ],
   "source": [
    "test_acc = test(0, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize to take the new_activation info of centers in layer 1..\n",
    "### The activation distribution changes due to entangled(softmax and normalization in DTeSM)\n",
    "def add_neurons_to_layer0(model, centers0, old_centers1): ## the parameters should not change\n",
    "    \n",
    "    ########## LAYER 0 ############\n",
    "    c0 = torch.cat((model.layer0.centers.data, centers0), dim=0)\n",
    "    s0 = torch.cat([model.layer0.bias.data, torch.ones(1, len(centers0))*0], dim=1)\n",
    "\n",
    "    model.layer0.centers.data = c0\n",
    "    model.layer0.bias.data = s0\n",
    "\n",
    "#     v = torch.cat((model.layer1.weight.data, values.t()), dim=1)\n",
    "#     model.layer1.weight.data = v\n",
    "\n",
    "    ########## LAYER 1 ############\n",
    "#     c1 = torch.cat((model.layer1.centers.data, model.layer0(centers1)), dim=0) ## initial: add center activation1\n",
    "#     all_centers = torch.cat([old_centers1, centers1], dim=0)\n",
    "#     c1 = model.layer0(all_centers) ## initial: add center activation1\n",
    "    \n",
    "    model.layer1.centers.data = model.layer0(old_centers1)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neurons_to_layer1(model, centers1, values1, old_centers1):\n",
    "    all_centers = torch.cat([old_centers1, centers1], dim=0)\n",
    "    \n",
    "#     c1 = torch.cat((model.layer1.centers.data, model.layer0(centers1)), dim=0)\n",
    "    c1 = model.layer0(all_centers)\n",
    "    s1 = torch.cat([model.layer1.bias.data, torch.ones(1, len(centers1))*0], dim=1)\n",
    "    v = torch.cat((model.layer2.weight.data, values1.t()), dim=1)\n",
    "\n",
    "    model.layer1.centers.data = c1\n",
    "    model.layer1.bias.data = s1\n",
    "    model.layer2.weight.data = v\n",
    "    \n",
    "    return all_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 784]), torch.Size([60, 200]), torch.Size([10, 60]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer0.centers.data.shape, model.layer1.centers.data.shape, model.layer2.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "_c0 = get_random_training_samples(N_search0)[0]\n",
    "add_neurons_to_layer0(model, _c0, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([230, 784]), torch.Size([60, 230]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer0.centers.data.shape, model.layer1.centers.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 2.142 | Acc: 34.170 3417/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34.17, 34.1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc2 = test(0, model)\n",
    "test_acc2, test_acc ### ?? why does adding new centers to layer0 reduce the accuracy ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add neurons to second layer\n",
    "_c1, _v1 = get_random_training_samples(N_search1)\n",
    "c1 = add_neurons_to_layer1(model, _c1, _v1, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([70, 230]), torch.Size([10, 70]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer1.centers.data.shape, model.layer2.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 2.128 | Acc: 37.350 3735/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37.35, 34.17, 34.1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc3 = test(0, model)\n",
    "test_acc3, test_acc2, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdsadsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Neuron Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_keys = [model.layer0, model.layer1]\n",
    "outputs = {k.softmax:None for k in layer_keys}\n",
    "gradients = {k.softmax:None for k in layer_keys}\n",
    "\n",
    "def capture_outputs(module, inp, out):\n",
    "    global outputs\n",
    "    outputs[module] = out.data.cpu()\n",
    "\n",
    "def capture_gradients(module, gradi, grado):\n",
    "    global gradients\n",
    "    gradients[module] = grado[0].data.cpu()\n",
    "        \n",
    "forw_hooks = [k.softmax.register_forward_hook(capture_outputs) for k in layer_keys]\n",
    "back_hooks = [k.softmax.register_backward_hook(capture_gradients) for k in layer_keys]\n",
    "\n",
    "def remove_hook():\n",
    "    for hook in forw_hooks+back_hooks:\n",
    "        hook.remove()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Softmax(dim=-1): tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " Softmax(dim=-1): tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance = {k.softmax:torch.zeros(k.centers.shape[0]) for k in layer_keys}\n",
    "significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device).view(-1, 28*28), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yout = model(xx)\n",
    "yout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer0.centers \t torch.Size([230, 784])\n",
      "layer0.scaler \t torch.Size([1, 1])\n",
      "layer0.bias \t torch.Size([1, 230])\n",
      "layer1.centers \t torch.Size([70, 230])\n",
      "layer1.scaler \t torch.Size([1, 1])\n",
      "layer1.bias \t torch.Size([1, 70])\n",
      "layer2.weight \t torch.Size([10, 70])\n",
      "layer2.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(n,\"\\t\" ,p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def none_grad():\n",
    "    for p in model.parameters():\n",
    "        p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "none_grad()\n",
    "yout.register_hook(lambda grad: grad/torch.norm(grad, dim=1, keepdim=True))\n",
    "\n",
    "# grad = torch.randn_like(yout)\n",
    "# ### grad = grad/torch.norm(grad, dim=1, keepdim=True)\n",
    "# yout.backward(gradient=grad, retain_graph=False)\n",
    "\n",
    "criterion(yout, yy).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_hook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Softmax(dim=-1): tensor([[2.4899e-06, 2.3023e-06, 5.2259e-07,  ..., 4.7741e-05, 5.2200e-07,\n",
       "          4.7811e-05],\n",
       "         [2.3233e-05, 7.4446e-04, 2.2435e-05,  ..., 3.5531e-06, 3.5619e-05,\n",
       "          3.5813e-06],\n",
       "         [1.4479e-06, 1.8525e-03, 6.4492e-04,  ..., 5.3255e-07, 2.3857e-05,\n",
       "          5.5373e-07],\n",
       "         ...,\n",
       "         [6.2687e-08, 1.1864e-05, 2.0976e-05,  ..., 4.2574e-07, 4.6926e-05,\n",
       "          7.9913e-08],\n",
       "         [5.5233e-06, 1.8968e-04, 7.4183e-06,  ..., 3.4797e-07, 3.3399e-06,\n",
       "          1.8670e-06],\n",
       "         [4.2201e-06, 5.5846e-05, 4.3116e-06,  ..., 8.1915e-07, 1.6886e-05,\n",
       "          4.7456e-07]]),\n",
       " Softmax(dim=-1): tensor([[2.8351e-04, 4.2182e-02, 5.4159e-03,  ..., 3.3260e-02, 3.5072e-03,\n",
       "          7.1325e-06],\n",
       "         [1.3547e-04, 2.7466e-02, 2.0285e-03,  ..., 1.6792e-02, 3.7371e-03,\n",
       "          6.7511e-06],\n",
       "         [2.6094e-04, 7.5014e-02, 5.0708e-03,  ..., 3.5155e-02, 3.5860e-03,\n",
       "          7.4689e-06],\n",
       "         ...,\n",
       "         [5.4296e-05, 6.3891e-03, 8.8972e-04,  ..., 4.7153e-03, 5.9543e-04,\n",
       "          1.4815e-06],\n",
       "         [1.8081e-04, 3.4162e-02, 3.0263e-03,  ..., 2.1035e-02, 3.1323e-03,\n",
       "          6.6145e-06],\n",
       "         [2.6666e-04, 3.8875e-02, 4.2127e-03,  ..., 3.0777e-02, 2.8026e-03,\n",
       "          7.3886e-06]])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Softmax(dim=-1): tensor([[ 0.0024,  0.0278,  0.0051,  ...,  0.0099,  0.0051, -0.0318],\n",
       "         [ 0.0029,  0.0091,  0.0037,  ...,  0.0072,  0.0112,  0.0094],\n",
       "         [ 0.0017, -0.0048,  0.0004,  ...,  0.0019,  0.0022,  0.0029],\n",
       "         ...,\n",
       "         [-0.0009, -0.0065, -0.0022,  ...,  0.1011, -0.0034, -0.0014],\n",
       "         [ 0.0048,  0.0249,  0.0032,  ...,  0.0058,  0.0060,  0.0077],\n",
       "         [ 0.0049, -0.0034,  0.0040,  ...,  0.0083,  0.0080,  0.0097]]),\n",
       " Softmax(dim=-1): tensor([[ 0.0957,  0.1036,  0.0915,  ...,  0.1036,  0.1059, -0.9484],\n",
       "         [ 0.0956,  0.0996,  0.0919,  ...,  0.0996,  0.1213,  0.1111],\n",
       "         [ 0.0942,  0.1063,  0.0900,  ...,  0.1063,  0.1043,  0.1068],\n",
       "         ...,\n",
       "         [ 0.2094,  0.0853,  0.0847,  ...,  0.0853,  0.0962,  0.0880],\n",
       "         [ 0.0952,  0.1004,  0.0915,  ...,  0.1004, -0.9483,  0.1118],\n",
       "         [ 0.0954,  0.1034,  0.0913,  ...,  0.1034,  0.1053,  0.1073]])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Softmax(dim=-1): tensor([5.6532e-11, 3.3266e-06, 4.2823e-09, 2.2322e-09, 2.9051e-04, 1.1509e-04,\n",
       "         1.4978e-06, 3.7347e-11, 1.1044e-02, 2.1369e-09, 1.6987e-06, 3.3429e-05,\n",
       "         7.6518e-04, 3.8205e-13, 7.3085e-13, 2.8390e-06, 2.6013e-05, 9.4760e-05,\n",
       "         6.0915e-07, 1.0419e-06, 3.1605e-07, 2.8982e-04, 2.3022e-06, 7.3204e-03,\n",
       "         8.0414e-14, 9.5337e-05, 1.5766e-15, 7.0277e-09, 5.5522e-04, 6.0955e-06,\n",
       "         8.2217e-09, 1.9732e-07, 6.0610e-06, 1.2988e-05, 4.6072e-05, 2.7052e-06,\n",
       "         1.3531e-05, 2.4826e-04, 3.3082e-05, 4.2930e-06, 1.1780e-03, 1.3351e-04,\n",
       "         1.4145e-06, 1.4505e-05, 1.1940e-08, 1.7981e-05, 1.5006e-06, 2.8295e-08,\n",
       "         3.5961e-03, 5.0773e-11, 1.0946e-10, 1.5564e-07, 1.5216e-09, 1.0105e-06,\n",
       "         4.7658e-05, 1.6055e-10, 1.0869e-06, 2.4086e-04, 8.5829e-08, 4.8694e-08,\n",
       "         1.5200e-12, 7.0120e-07, 4.0739e-02, 1.2976e-06, 8.8634e-02, 2.6272e-04,\n",
       "         2.1589e-07, 2.6546e-07, 1.8784e-07, 2.1555e-08, 4.1859e-10, 2.8555e-08,\n",
       "         1.0263e-07, 3.9491e-05, 2.1849e-07, 5.1938e-04, 6.2434e-05, 2.1534e-07,\n",
       "         1.2097e-06, 1.7260e-08, 1.3870e-05, 7.7143e-06, 8.5444e-06, 9.6806e-09,\n",
       "         2.1906e-09, 8.2180e-07, 7.5960e-03, 1.2233e-03, 1.4110e-05, 8.9862e-04,\n",
       "         5.3130e-05, 3.8648e-04, 6.4434e-01, 2.4193e+00, 3.5020e-05, 4.0114e-03,\n",
       "         2.6655e-10, 4.1495e-08, 3.0826e-10, 8.1158e-09, 6.3761e-08, 1.3308e-06,\n",
       "         1.3657e-04, 2.0618e-06, 7.4850e-08, 1.4280e-07, 1.0348e-11, 4.3913e-05,\n",
       "         2.5392e-04, 5.5716e-07, 3.2830e-07, 2.0962e-04, 6.5790e-06, 2.3133e-06,\n",
       "         1.8538e-05, 4.4513e-06, 6.6474e-07, 4.0091e-01, 3.3491e-05, 6.2452e-07,\n",
       "         1.4908e-06, 1.2823e-05, 8.4172e-01, 8.3251e-04, 3.5925e-04, 1.2650e-06,\n",
       "         6.8184e-05, 4.8595e-10, 3.5649e-06, 1.7923e-09, 8.1388e-08, 1.3163e-10,\n",
       "         4.2254e-05, 3.2026e-12, 6.2008e-04, 1.9431e-06, 1.1380e-03, 2.9793e-12,\n",
       "         9.9180e-06, 3.1932e-02, 6.1942e-05, 1.5245e-03, 3.0653e-07, 1.9995e-06,\n",
       "         2.8135e-10, 2.4417e-10, 5.8642e-06, 7.9525e-11, 9.9395e-08, 2.1573e-04,\n",
       "         2.0281e-05, 1.2384e-10, 1.8660e-09, 1.0598e-08, 5.8716e-13, 7.7845e-10,\n",
       "         2.1591e-06, 7.0154e-05, 1.9364e-06, 8.6170e-02, 4.2583e-05, 1.0469e-04,\n",
       "         2.1323e-10, 2.1671e-05, 1.7175e-08, 5.4051e-05, 3.6248e-04, 8.9713e-09,\n",
       "         8.6238e-11, 3.8114e-05, 1.4893e-05, 5.6100e-16, 8.7788e-06, 2.3891e-04,\n",
       "         6.4518e-05, 2.0158e-04, 1.2701e-07, 2.9855e-02, 1.4603e-06, 6.5794e-09,\n",
       "         3.3638e-04, 3.7776e-13, 1.3735e-07, 9.7551e-09, 2.0130e-03, 5.6373e-06,\n",
       "         6.3589e-08, 3.6450e-08, 9.8509e-06, 5.3770e-06, 2.1133e-09, 1.9898e-06,\n",
       "         6.9815e-12, 2.3022e-05, 9.7056e-09, 6.4815e-09, 4.3641e-08, 2.9626e-10,\n",
       "         1.9306e-04, 1.0775e-06, 8.3472e-05, 6.7368e-02, 1.5360e-03, 1.9205e-07,\n",
       "         5.3862e-12, 3.2349e-03, 4.8513e-03, 1.6052e-03, 1.0082e-17, 2.8295e-10,\n",
       "         6.7556e-09, 1.3490e-05, 2.5737e-07, 6.0388e-11, 7.6652e-06, 2.7050e-05,\n",
       "         9.9603e-08, 1.8173e-03, 1.7040e-05, 1.2878e-05, 3.8024e-08, 1.7201e-07,\n",
       "         2.3804e-07, 6.7067e-08, 1.3439e-07, 3.1158e-07, 1.6071e-06, 6.7568e-08,\n",
       "         7.9193e-08, 1.9696e-05]),\n",
       " Softmax(dim=-1): tensor([2.6467e-07, 5.5060e-03, 1.2868e-01, 6.8771e-07, 1.0864e-03, 1.2085e-10,\n",
       "         4.2683e-05, 1.1804e-06, 5.8105e-02, 2.8327e-02, 2.8922e-02, 9.7035e-10,\n",
       "         8.8150e-05, 1.5573e-01, 4.6422e-02, 6.1215e-04, 3.8394e-05, 1.1963e-05,\n",
       "         1.0247e-02, 4.2362e-04, 7.4653e-05, 1.2727e-02, 9.1494e-02, 1.6480e-02,\n",
       "         1.4703e-06, 6.9952e-03, 3.8586e-02, 5.7419e-08, 9.0770e-04, 3.2253e-10,\n",
       "         4.7179e-08, 1.8227e-05, 8.9963e-01, 4.0128e-02, 5.5277e-03, 1.0583e-04,\n",
       "         7.0056e-03, 3.4435e-02, 9.4761e-02, 5.7952e-05, 1.6414e-03, 1.3977e-03,\n",
       "         3.7238e-03, 1.1075e-03, 6.0489e-02, 3.0650e-07, 3.6848e-03, 4.4654e-10,\n",
       "         1.3612e-03, 6.2900e-02, 1.7328e-01, 3.8623e-04, 1.9325e-09, 3.7764e-10,\n",
       "         1.9599e-02, 7.2034e-03, 4.9119e-07, 3.8623e-02, 7.7134e-10, 5.4802e-03,\n",
       "         8.9977e-01, 4.2033e-08, 7.1738e-04, 1.8099e-03, 5.2523e-09, 3.3865e-02,\n",
       "         6.3131e-07, 2.7540e-03, 3.8366e-05, 6.6365e-01])}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for k in layer_keys:\n",
    "        lk = k.softmax\n",
    "#         print(outputs[lk])\n",
    "#         print(gradients[lk])\n",
    "#         print(significance[lk])\n",
    "        significance[lk] += torch.sum((outputs[lk]*gradients[lk])**2, dim=0)\n",
    "significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = significance[layer_keys[0].softmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.topk(sig, k=h0, sorted=True, largest=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 93, 122,  92, 117,  64, 159, 201,  62, 139, 177,   8,  86,  23, 206,\n",
       "         95,  48, 205, 184, 217, 207, 202, 141,  87,  40, 136,  89, 123,  12,\n",
       "        134,  28,  75,  91, 166, 124, 180,   4,  21,  65, 108,  37,  57, 173,\n",
       "        149, 111, 175, 198, 102,  41,   5, 161,  25,  17, 200, 157, 126, 174,\n",
       "         76, 140, 165,  90,  54,  34, 107, 160, 132,  73, 169,  94, 118,  11,\n",
       "         38, 215,  16, 193, 163, 150, 229, 114,  45, 218, 170,  43,  88,  80,\n",
       "         36, 211,  33, 219, 121, 138, 188, 172,  82,  81, 214, 112,  29,  32,\n",
       "        146, 185, 189, 115,  39, 128,   1,  15,  35, 113,  22, 156, 103, 143,\n",
       "        191, 135, 158,  10, 226,  46,   6, 120, 178,  42, 101,  63, 125,  78,\n",
       "         56, 199,  19,  53,  85,  61, 116, 119,  18, 109, 110,  20, 225, 142,\n",
       "         67, 212, 222,  74,  66,  77,  31, 203,  68, 221,  51, 105, 182, 224,\n",
       "        176,  72, 216, 148,  58, 130, 228, 104, 227, 223, 100, 186,  59, 196,\n",
       "         97, 220, 187,  71,  47,  69,  79, 164,  44, 153, 183, 194,  83, 167,\n",
       "         30,  99,  27, 210, 179, 195,   2,   3,  84,   9, 190, 152, 129,  52,\n",
       "        155, 127,  70,  98])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_idx = torch.topk(sig, k=h0, sorted=True)[1]\n",
    "topk_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_neurons_from_layer1(model, importance, num_prune, old_centers1):\n",
    "    N = model.layer1.centers.shape[0]\n",
    "    topk_idx = torch.topk(importance, k=N-num_prune, largest=True)[1]\n",
    "    \n",
    "    c = model.layer1.centers.data[topk_idx]\n",
    "    v = model.layer2.weight.data[:,topk_idx]\n",
    "    s = model.layer1.bias.data[:,topk_idx]\n",
    "    model.layer1.centers.data = c\n",
    "    model.layer2.weight.data = v\n",
    "    model.layer1.bias.data = s\n",
    "    \n",
    "    return old_centers1[topk_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_neurons_from_layer0(model, importance, num_prune, old_centers1):\n",
    "    N = model.layer0.centers.shape[0]\n",
    "    topk_idx = torch.topk(importance, k=N-num_prune, largest=True)[1]\n",
    "    \n",
    "    c = model.layer0.centers.data[topk_idx]\n",
    "    s = model.layer0.bias.data[:,topk_idx]\n",
    "    model.layer0.centers.data = c\n",
    "    model.layer0.bias.data = s\n",
    "    \n",
    "    model.layer1.centers.data = model.layer0(old_centers1)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = remove_neurons_from_layer1(model, significance[layer_keys[1].softmax], N_search1, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 784])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([230, 784]), torch.Size([60, 230]), torch.Size([10, 60]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer0.centers.data.shape, model.layer1.centers.data.shape, model.layer2.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 2.127 | Acc: 38.590 3859/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38.59, 37.35, 34.17, 34.1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc4 = test(0, model)\n",
    "\n",
    "test_acc4, test_acc3, test_acc2, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_neurons_from_layer0(model, significance[layer_keys[0].softmax], N_search0, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 784]), torch.Size([60, 200]), torch.Size([10, 60]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer0.centers.data.shape, model.layer1.centers.data.shape, model.layer2.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 2.126 | Acc: 39.740 3974/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39.74, 38.59, 37.35, 34.17, 34.1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc5 = test(0, model)\n",
    "test_acc5, test_acc4, test_acc3, test_acc2, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdasd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-efb445db9a2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masdasd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'asdasd' is not defined"
     ]
    }
   ],
   "source": [
    "asdasd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do this in Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "_c0 = get_random_training_samples(N_search0)[0]\n",
    "add_neurons_to_layer0(model, _c0, c1)\n",
    "\n",
    "_c1, _v1 = get_random_training_samples(N_search1)\n",
    "c1 = add_neurons_to_layer1(model, _c1, _v1, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance = {k.softmax:torch.zeros(k.centers.shape[0]) for k in layer_keys}\n",
    "\n",
    "forw_hooks = [k.softmax.register_forward_hook(capture_outputs) for k in layer_keys]\n",
    "back_hooks = [k.softmax.register_backward_hook(capture_gradients) for k in layer_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx = xx.to(device).view(-1, 28*28)\n",
    "    yout = model(xx)\n",
    "    \n",
    "    none_grad()\n",
    "#     yout.register_hook(lambda grad: grad/torch.norm(grad, dim=1, keepdim=True))\n",
    "    \n",
    "#     grad = torch.randn_like(yout)\n",
    "#     ### grad = grad/torch.norm(grad, dim=1, keepdim=True)\n",
    "#     yout.backward(gradient=grad)\n",
    "    \n",
    "    criterion(yout, yy).backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for k in layer_keys:\n",
    "            lk = k.softmax\n",
    "            significance[lk] += torch.sum((outputs[lk]*gradients[lk])**2, dim=0)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_hook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = remove_neurons_from_layer1(model, significance[layer_keys[1].softmax], N_search1, c1) ## anything can be done first\n",
    "remove_neurons_from_layer0(model, significance[layer_keys[0].softmax], N_search0, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 2.092 | Acc: 51.450 5145/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51.45"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(0, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdasd  ### ^^ expected test_acc2 > test_acc3 > test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize for multiple steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.936 | Acc: 54.470 5447/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54.47"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = 100\n",
    "h1 = 100\n",
    "N_search0 = 30\n",
    "N_search1 = 30\n",
    "model = LocalMLP_epsilonsoftmax(784, h0, h1, 10, epsilon=None).to(device)\n",
    "\n",
    "### Initialization\n",
    "c0, _ = get_random_training_samples(h0)\n",
    "model.layer0.centers.data = c0.to(model.layer0.centers.device)\n",
    "\n",
    "c1, v1 = get_random_training_samples(h1)\n",
    "model.layer1.centers.data = model.layer0(c1.to(device))\n",
    "model.layer2.weight.data = v1.t().to(device)\n",
    "\n",
    "test(0, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_keys = [model.layer0, model.layer1]\n",
    "outputs = {k.softmax:None for k in layer_keys}\n",
    "gradients = {k.softmax:None for k in layer_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding and Pruning for STEP: 0\n",
      "[Test] 0 Loss: 1.836 | Acc: 65.830 6583/10000\n",
      "Adding and Pruning for STEP: 1\n",
      "[Test] 0 Loss: 1.796 | Acc: 69.800 6980/10000\n",
      "Adding and Pruning for STEP: 2\n",
      "[Test] 0 Loss: 1.770 | Acc: 72.940 7294/10000\n",
      "Adding and Pruning for STEP: 3\n",
      "[Test] 0 Loss: 1.789 | Acc: 70.890 7089/10000\n",
      "Adding and Pruning for STEP: 4\n",
      "[Test] 0 Loss: 1.776 | Acc: 72.750 7275/10000\n",
      "Adding and Pruning for STEP: 5\n",
      "[Test] 0 Loss: 1.761 | Acc: 72.630 7263/10000\n",
      "Adding and Pruning for STEP: 6\n",
      "[Test] 0 Loss: 1.754 | Acc: 74.610 7461/10000\n",
      "Adding and Pruning for STEP: 7\n",
      "[Test] 0 Loss: 1.742 | Acc: 75.040 7504/10000\n",
      "Adding and Pruning for STEP: 8\n",
      "[Test] 0 Loss: 1.746 | Acc: 74.750 7475/10000\n",
      "Adding and Pruning for STEP: 9\n",
      "[Test] 0 Loss: 1.749 | Acc: 74.690 7469/10000\n"
     ]
    }
   ],
   "source": [
    "## Run multiple times for convergence\n",
    "STEPS = 10\n",
    "for s in range(STEPS):\n",
    "    print(f\"Adding and Pruning for STEP: {s}\")\n",
    "    _c0 = get_random_training_samples(N_search0)[0]\n",
    "    add_neurons_to_layer0(model, _c0, c1)\n",
    "\n",
    "    _c1, _v1 = get_random_training_samples(N_search1)\n",
    "    c1 = add_neurons_to_layer1(model, _c1, _v1, c1)\n",
    "    #############################\n",
    "    significance = {k.softmax:torch.zeros(k.centers.shape[0]) for k in layer_keys}\n",
    "\n",
    "    forw_hooks = [k.softmax.register_forward_hook(capture_outputs) for k in layer_keys]\n",
    "    back_hooks = [k.softmax.register_backward_hook(capture_gradients) for k in layer_keys]\n",
    "    #############################\n",
    "    \n",
    "    for xx, yy in train_loader:\n",
    "        xx = xx.to(device).view(-1, 28*28)\n",
    "        yout = model(xx)\n",
    "\n",
    "        none_grad()\n",
    "#         yout.register_hook(lambda grad: grad/torch.norm(grad, dim=1, keepdim=True))\n",
    "        ####################################\n",
    "#         grad = torch.randn_like(yout)\n",
    "#         ### grad = grad/torch.norm(grad, dim=1, keepdim=True)\n",
    "#         yout.backward(gradient=grad)\n",
    "        ###################################\n",
    "        criterion(yout, yy).backward()\n",
    "        with torch.no_grad():\n",
    "            for k in layer_keys:\n",
    "                lk = k.softmax\n",
    "                significance[lk] += torch.sum((outputs[lk]*gradients[lk])**2, dim=0)\n",
    "    \n",
    "    remove_hook()\n",
    "    c1 = remove_neurons_from_layer1(model, significance[layer_keys[1].softmax], N_search1, c1)\n",
    "    remove_neurons_from_layer0(model, significance[layer_keys[0].softmax], N_search0, c1)\n",
    "    test_acc = test(0, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
