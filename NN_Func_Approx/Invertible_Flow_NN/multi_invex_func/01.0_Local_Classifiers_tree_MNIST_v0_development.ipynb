{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nflib\n",
    "from nflib.flows import SequentialFlow, NormalizingFlow, ActNorm, AffineConstantFlow\n",
    "import nflib.coupling_flows as icf\n",
    "import nflib.inn_flow as inn\n",
    "import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import distributions\n",
    "from torch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mylibrary.datasets as datasets\n",
    "import mylibrary.nnlib as tnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.FashionMNIST()\n",
    "# mnist.download_mnist()\n",
    "# mnist.save_mnist()\n",
    "train_data, train_label_, test_data, test_label_ = mnist.load()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "# train_label = tnn.Logits.index_to_logit(train_label_)\n",
    "train_size = len(train_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting data to pytorch format\n",
    "train_data = torch.Tensor(train_data)\n",
    "test_data = torch.Tensor(test_data)\n",
    "train_label = torch.LongTensor(train_label_)\n",
    "test_label = torch.LongTensor(test_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        \n",
    "#         self.label = mask.type(torch.float32).reshape(-1,1)\n",
    "        self._shuffle_data_()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _shuffle_data_(self):\n",
    "        randidx = random.sample(range(len(self.data)), k=len(self.data))\n",
    "        self.data = self.data[randidx]\n",
    "        self.label = self.label[randidx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, lbl = self.data[idx], self.label[idx]\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subset_Dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, index):\n",
    "        self.dataset = dataset\n",
    "        self.index = index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.index[idx]\n",
    "        img, lbl = self.dataset[idx]\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The classifiers store all the data in INDEX FORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST_Dataset(train_data, train_label)\n",
    "test_dataset = MNIST_Dataset(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([8, 0, 6]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[[0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_SoftKMeans(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.centers = nn.Parameter(torch.rand(num_sets, input_dim)*2-1)\n",
    "        \n",
    "#         self.cls_weight = nn.Parameter(torch.ones(num_sets, output_dim)/output_dim)\n",
    "        init_val = torch.randn(num_sets, output_dim)*0.01\n",
    "        for ns in range(num_sets):\n",
    "            init_val[ns, ns%output_dim] = 2.\n",
    "#             init_val[ns, 0] = 2. ### initialize same class in all clusters\n",
    "\n",
    "        self.cls_weight = nn.Parameter(init_val)\n",
    "\n",
    "        self.cls_confidence = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "        self.cls_weight.data = torch.abs(self.cls_weight.data)/self.cls_weight.data.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        x = x[:, :self.input_dim]\n",
    "        dists = torch.cdist(x, self.centers)\n",
    "        dists = dists/np.sqrt(self.input_dim) ### correction to make diagonal of unit square 1 in nD space\n",
    "        \n",
    "        if hard:\n",
    "            x = torch.softmax(-dists*1e5, dim=1)\n",
    "        else:\n",
    "            x = torch.softmax(-dists*self.inv_temp, dim=1)\n",
    "        self.cls_confidence = x\n",
    "#         c = torch.softmax(self.cls_weight, dim=1)\n",
    "        c = self.cls_weight\n",
    "        return x@c ## since both are normalized, it is also normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ClassifierTree:\n",
    "    \n",
    "#     def __init__(self, train_data, test_data, device):\n",
    "#         self.depthwise_classifiers = []\n",
    "        \n",
    "#         self.train_data = train_data\n",
    "#         self.test_data = test_data\n",
    "#         self.device = device\n",
    "#         pass\n",
    "    \n",
    "#     def create_new_depth(self, x, hidden_dims):\n",
    "#         output_dim = 10\n",
    "#         num_classifier = 10\n",
    "#         if len(self.depthwise_classifiers) == 0:\n",
    "#             classifier = LocalClassifier(784, hidden_dims, output_dim, num_classifier, self.device)\n",
    "\n",
    "#             ### to initialize to all classes\n",
    "#             init_val = torch.randn(num_sets, output_dim)*0.01\n",
    "#             for ns in range(num_sets):\n",
    "#                 init_val[ns, ns%output_dim] = 2.\n",
    "\n",
    "#             classifier.classifier.cls_weight.data = init_val\n",
    "            \n",
    "#         else:\n",
    "#             for \n",
    "    \n",
    "    \n",
    "#     def inference_forward(self, x): ## inference for one data\n",
    "#         x = torch.unsqueeze(0)\n",
    "#         classifier_indx = 0 ## in first depth, there is only single classifier.\n",
    "#         for i in range(len(self.depthwise_classifiers)):\n",
    "#             classifier = self.depthwise_classifiers[i][classifier_indx]\n",
    "#             classifier_indx = classifier.inference_forward(x)[0]\n",
    "#             if i < len(self.depthwise_classifiers):\n",
    "#                 if self.depthwise_classifiers[i+1][classifier_indx] is not None:\n",
    "#                     continue\n",
    "#             return classifier.prediction_stat[classifier_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierTree:\n",
    "    \n",
    "    def __init__(self, train_data, test_data, device):\n",
    "        self.root = LocalClassifier(device)\n",
    "        self.root.create_network_0(784, [784], 10, 10)\n",
    "        \n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.device = device\n",
    "        pass\n",
    "    \n",
    "    def display_stats(self):\n",
    "        indexing = \"0\"\n",
    "        self.root.display_stats(indexing)\n",
    "        acc, tot = self.root.get_correct_train()\n",
    "        train_acc = acc/tot\n",
    "        acc, tot = self.root.get_correct_test()\n",
    "        test_acc = acc/tot\n",
    "        print(f\"Final Accuracy is Train: {train_acc :.5f} Test: {test_acc :.5f}\")\n",
    "            \n",
    "    def get_parent_node(self, index_list:list):\n",
    "        parent = self.root\n",
    "        index_list = index_list[1:]\n",
    "        for idx in index_list[:-1]:\n",
    "            parent = parent.children[idx]\n",
    "        return parent\n",
    "    \n",
    "    def get_node(self, index_list:list):\n",
    "        parent = self.root\n",
    "        index_list = index_list[1:]\n",
    "        for idx in index_list[:-1]:\n",
    "            parent = parent.children[idx]\n",
    "        child = parent.children[index_list[-1]]\n",
    "        return child\n",
    "    \n",
    "    \n",
    "    def get_all_child_index(self):\n",
    "        child_list = []\n",
    "        self.root.get_all_index([0], child_list)\n",
    "        return child_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "    def __init__(self):\n",
    "        self.pred = None\n",
    "        self.classes = None\n",
    "        self.num_correct = None\n",
    "        self.train_indices = None\n",
    "        self.test_indices = None\n",
    "        self.test_correct = None\n",
    "        \n",
    "    def display_stats(self, indexing):\n",
    "        print(f\"[{indexing}] : Train -> {self.num_correct/len(self.train_indices) :.4f}\", end=\" \")\n",
    "        \n",
    "        if len(self.test_indices)>0:\n",
    "            test_acc = self.test_correct/len(self.test_indices)\n",
    "        else:\n",
    "            test_acc = -1\n",
    "        print(f\"Test -> {test_acc :.4f}, NUM: {len(self.train_indices)}, classes: {self.pred}:{self.classes}\")\n",
    "\n",
    "    def get_correct_train(self):\n",
    "        return self.num_correct, len(self.train_indices)\n",
    "    \n",
    "    def get_correct_test(self):\n",
    "        return self.test_correct, len(self.test_indices)\n",
    "    \n",
    "    def get_all_index(self, indexing, indx_lst):\n",
    "        indx_lst.append(indexing)\n",
    "                \n",
    "        \n",
    "    \n",
    "\n",
    "class LocalClassifier:\n",
    "    \n",
    "    def __init__(self, device):\n",
    "        self.model = None\n",
    "        self.classifier = None\n",
    "        self.device = device\n",
    "        \n",
    "        ### for training purposes\n",
    "        self.train_loader = None\n",
    "        self.test_loader = None\n",
    "        self.optimizer = None\n",
    "        self.frozen = False\n",
    "        self.criterion = None\n",
    "        \n",
    "        ### after freazing the model, record stats\n",
    "        self.children = []\n",
    "    \n",
    "    def create_network_0(self, input_dim, hidden_dims:list, output_dims, num_classifiers):\n",
    "        actf = irf.Swish\n",
    "        flows = []\n",
    "        flows.append(ActNorm(input_dim))\n",
    "        for i in range(len(hidden_dims)):\n",
    "            if isinstance(hidden_dims[i], list):\n",
    "                hdi = hidden_dims[i]\n",
    "            else:\n",
    "                hdi = [hidden_dims[i]]\n",
    "            flows.append(irf.ResidualFlow(input_dim, hdi, activation=actf))\n",
    "            flows.append(ActNorm(input_dim))\n",
    "        \n",
    "        invertible = SequentialFlow(flows)\n",
    "        self.model = invertible.to(device)\n",
    "        \n",
    "        classifier = ConnectedClassifier_SoftKMeans(784, num_classifiers, output_dims)\n",
    "        self.classifier = classifier.to(device)\n",
    "        \n",
    "    def create_train_loader_1(self, train_dataset, index, batch_size):\n",
    "        dataset = Subset_Dataset(train_dataset, index)\n",
    "        print(f\"Train Dataset Num: {len(index)}\")\n",
    "        self.train_loader = data.DataLoader(dataset=dataset,\n",
    "                                            num_workers=4, \n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True)\n",
    "    \n",
    "    def create_test_loader_2(self, test_dataset, index, batch_size):\n",
    "        dataset = Subset_Dataset(test_dataset, index)\n",
    "        print(f\"Test Dataset Num: {len(index)}\")\n",
    "        self.test_loader = data.DataLoader(dataset=dataset,\n",
    "                                            num_workers=4, \n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=False)\n",
    "        \n",
    "    def create_optimizer_3(self, lr):\n",
    "        self.optimizer = optim.Adam(list(self.model.parameters())+list(self.classifier.parameters()), \n",
    "                                    lr=lr, weight_decay=1e-15)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        \n",
    "    def train_classifier_4(self, epochs, ):\n",
    "        if self.frozen:\n",
    "            raise ValueError(\"This classifier is frozen. Training it might cause errors in childern classifiers\")\n",
    "            \n",
    "    ############# TRAINING FUNCTIONALITY BELOW ####################    \n",
    "\n",
    "        index = 0\n",
    "        train_accs, test_accs = [], []\n",
    "        for epoch in range(epochs):\n",
    "            train_acc = 0\n",
    "            train_count = 0\n",
    "            for xx, yy in tqdm(self.train_loader):\n",
    "                xx, yy = xx.to(device), yy.to(device)\n",
    "#                 print(xx)\n",
    "                yout = self.model(xx)\n",
    "#                 print(yout, torch.count_nonzero(torch.isnan(yout)))\n",
    "                yout = self.classifier(yout)    \n",
    "#                 print(yout, torch.count_nonzero(torch.isnan(yout)))\n",
    "                loss = self.criterion(yout, yy)\n",
    "#                 print(loss)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "#                 losses.append(float(loss))\n",
    "\n",
    "                outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "                correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "                train_acc += correct\n",
    "                train_count += len(outputs)\n",
    "\n",
    "            train_accs.append(float(train_acc)/train_count*100)\n",
    "            train_acc = 0\n",
    "            train_count = 0\n",
    "\n",
    "            print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "            test_count = 0\n",
    "            test_acc = 0\n",
    "            for xx, yy in tqdm(self.test_loader):\n",
    "                xx, yy = xx.to(device), yy.to(device)\n",
    "                with torch.no_grad():\n",
    "                    yout = self.classifier(self.model(xx))    \n",
    "                outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "                correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "                test_acc += correct\n",
    "                test_count += len(xx)\n",
    "            test_accs.append(float(test_acc)/test_count*100)\n",
    "            print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "            print()\n",
    "\n",
    "        ### after each class index is finished training\n",
    "        print(f'\\t-> MAX Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}')\n",
    "        \n",
    "        \n",
    "    def freeze_and_compute_stats_5(self, MIN_POINTS):\n",
    "        assert MIN_POINTS > 0\n",
    "        if self.frozen:\n",
    "            raise ValueError(\"This classifier is frozen. The stat has already been calculated\")\n",
    "            \n",
    "        self.frozen = True\n",
    "        \n",
    "        ### delete optimizer, frees memory\n",
    "        del self.optimizer\n",
    "        ### take classifier to eval mode\n",
    "        self.model.eval()\n",
    "        self.classifier.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #### remove classifier with no data or few data.\n",
    "\n",
    "            set_count = torch.zeros(self.classifier.num_sets).to(device)\n",
    "            for xx, yy in tqdm(self.train_loader):\n",
    "                xx, yy = xx.to(device), yy.to(device)\n",
    "                with torch.no_grad():\n",
    "                    yout = self.classifier(self.model(xx), hard=True)\n",
    "\n",
    "                cls_indx = torch.argmax(self.classifier.cls_confidence, dim=1)\n",
    "                set_indx, count = torch.unique(cls_indx, return_counts=True) \n",
    "                set_count[set_indx] += count\n",
    "\n",
    "            #### find only the classifier having some data\n",
    "            classifier_index = []\n",
    "            classifier_count = []\n",
    "\n",
    "            for i, cnt in enumerate(set_count.type(torch.long).tolist()):\n",
    "    #             if cnt == 0: continue\n",
    "                if cnt < MIN_POINTS: continue\n",
    "\n",
    "                classifier_index.append(i)\n",
    "                classifier_count.append(int(cnt))\n",
    "\n",
    "            #### remove the classifier representing no data\n",
    "            #### OR representing data less than given N\n",
    "            print(f\"Keeping only N={len(classifier_index)}/{len(self.classifier.centers)} classifiers.\")\n",
    "            self.classifier.centers.data = self.classifier.centers.data[classifier_index]\n",
    "            self.classifier.cls_weight.data = self.classifier.cls_weight.data[classifier_index]\n",
    "            ### removed\n",
    "\n",
    "            ###### compute stats now, from pruned tree.\n",
    "            def get_Cs_Os_Ts(data_loader):\n",
    "                Cs = [] ## winning classifier\n",
    "                Os = [] ## output of winning classifier\n",
    "                Ts = [] ## target class\n",
    "\n",
    "                for xx, yy in tqdm(data_loader):\n",
    "                    Ts.append(yy)\n",
    "                    xx, yy = xx.to(device), yy.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        zz = self.model(xx)\n",
    "                        yout = self.classifier(zz, hard=True)\n",
    "                        Os.append(torch.argmax(yout, dim=1).data.cpu())\n",
    "\n",
    "                    cls_indx = torch.argmax(self.classifier.cls_confidence, dim=1)\n",
    "                    Cs.append(cls_indx)\n",
    "\n",
    "                Cs = torch.cat(Cs, dim=0)\n",
    "                Ts = torch.cat(Ts, dim=0)\n",
    "                Os = torch.cat(Os, dim=0)\n",
    "                return Cs, Ts, Os\n",
    "\n",
    "\n",
    "            unshuffled_data = data.DataLoader(dataset=self.train_loader.dataset,\n",
    "                                                num_workers=4, \n",
    "                                                batch_size=self.train_loader.batch_size, \n",
    "                                                shuffle=False)\n",
    "            Cs, Ts, Os = get_Cs_Os_Ts(unshuffled_data)\n",
    "            _Cs, _Ts, _ = get_Cs_Os_Ts(self.test_loader)\n",
    "\n",
    "            print(\"Hard inference on the data !\")\n",
    "            self.children = []\n",
    "            acc = 0\n",
    "            for cls_idx in range(len(self.classifier.centers)):\n",
    "                data_idx = torch.nonzero(Cs == cls_idx)\n",
    "                Ti = Ts[data_idx]\n",
    "\n",
    "                ### get prediction according to data\n",
    "                cls, count = torch.unique(Ti, return_counts=True, sorted=True)\n",
    "                pred = cls[torch.argmax(count)]\n",
    "                p = (Ti==pred).type(torch.float32).sum()\n",
    "                acc += p\n",
    "\n",
    "                child = LeafNode()\n",
    "                child.pred = int(pred)\n",
    "                child.classes = cls.tolist()\n",
    "                child.num_correct = int(p)\n",
    "                child.train_indices = data_idx.cpu().reshape(-1)\n",
    "                \n",
    "                test_idx = torch.nonzero(_Cs == cls_idx)\n",
    "                test_p = (_Ts[test_idx]==pred).type(torch.float32).sum()\n",
    "                child.test_indices = test_idx.cpu().reshape(-1)\n",
    "                child.test_correct = int(test_p)\n",
    "\n",
    "                self.children.append(child)\n",
    "\n",
    "                print(f\"idx: {cls_idx}\\tout: {int(pred)} \\t acc: {p/len(Ti)*100 :.3f} \\tclasses:{cls.tolist()}\")\n",
    "\n",
    "            print(f\"Accuracy: {float(acc)/len(Ts)}\")\n",
    "        \n",
    "        \n",
    "    def display_stats(self, indexing):\n",
    "        for i, c in enumerate(self.children):\n",
    "            c.display_stats(indexing+f\", {i}\")\n",
    "            \n",
    "    def get_all_index(self, indexing:list, indx_lst):\n",
    "        for i, c in enumerate(self.children):\n",
    "            c.get_all_index(indexing+[i], indx_lst)\n",
    "        pass\n",
    "\n",
    "    def get_correct_train(self):\n",
    "        a, b = 0, 0\n",
    "        for i, c in enumerate(self.children):\n",
    "            _a, _b = c.get_correct_train()\n",
    "            a+= _a\n",
    "            b+= _b\n",
    "        return a, b\n",
    "    \n",
    "    def get_correct_test(self):\n",
    "        a, b = 0, 0\n",
    "        for i, c in enumerate(self.children):\n",
    "            _a, _b = c.get_correct_test()\n",
    "            a+= _a\n",
    "            b+= _b\n",
    "        return a, b\n",
    "        \n",
    "    def inference_forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            zz = self.model(x)\n",
    "            yout = self.classifier(zz, hard=True)\n",
    "            return torch.argmax(classifier.cls_confidence, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ClassifierTree(train_dataset, test_dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.root.create_network_0(784, [784], 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Num: 60000\n"
     ]
    }
   ],
   "source": [
    "tree.root.create_train_loader_1(train_dataset, \n",
    "                                torch.arange(0, len(train_dataset), dtype=torch.long), \n",
    "                                50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Num: 10000\n"
     ]
    }
   ],
   "source": [
    "tree.root.create_test_loader_2(test_dataset, \n",
    "                               torch.arange(0, len(test_dataset), dtype=torch.long), \n",
    "                               50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.root.create_optimizer_3(lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(tree.root.classifier.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.root.model(torch.randn(10, 784).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:04<00:00, 267.31it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0:0,  Loss:2.227100133895874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 431.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:67.65%, Test Acc:68.96%\n",
      "\n",
      "\t-> MAX Train Acc 67.65 ; Test Acc 68.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tree.root.train_classifier_4(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdfsdfasdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.isinf(tree.root.model.flows[0].s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:01<00:00, 693.72it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping only N=10/10 classifiers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:01<00:00, 719.26it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 527.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard inference on the data !\n",
      "idx: 0\tout: 0 \t acc: 72.764 \tclasses:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "idx: 1\tout: 1 \t acc: 90.466 \tclasses:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "idx: 2\tout: 2 \t acc: 54.914 \tclasses:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "idx: 3\tout: 3 \t acc: 70.162 \tclasses:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "idx: 4\tout: 4 \t acc: 52.369 \tclasses:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "idx: 5\tout: 5 \t acc: 66.358 \tclasses:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "idx: 6\tout: 6 \t acc: 69.266 \tclasses:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "idx: 7\tout: 7 \t acc: 70.514 \tclasses:[0, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "idx: 8\tout: 8 \t acc: 87.261 \tclasses:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "idx: 9\tout: 9 \t acc: 73.111 \tclasses:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Accuracy: 0.6995833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tree.root.freeze_and_compute_stats_5(MIN_POINTS=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] : Train -> 0.7276 Test -> 0.7121, NUM: 6385, classes: 0:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[0, 1] : Train -> 0.9047 Test -> 0.9049, NUM: 6251, classes: 1:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[0, 2] : Train -> 0.5491 Test -> 0.5439, NUM: 7204, classes: 2:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[0, 3] : Train -> 0.7016 Test -> 0.6900, NUM: 7142, classes: 3:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[0, 4] : Train -> 0.5237 Test -> 0.4956, NUM: 7367, classes: 4:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[0, 5] : Train -> 0.6636 Test -> 0.6917, NUM: 5291, classes: 5:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 6] : Train -> 0.6927 Test -> 0.6486, NUM: 872, classes: 6:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[0, 7] : Train -> 0.7051 Test -> 0.7077, NUM: 7244, classes: 7:[0, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 8] : Train -> 0.8726 Test -> 0.8446, NUM: 4765, classes: 8:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 9] : Train -> 0.7311 Test -> 0.7213, NUM: 7479, classes: 9:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Final Accuracy is Train: 0.69958 Test: 0.69010\n"
     ]
    }
   ],
   "source": [
    "tree.display_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = tree.get_node([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6385"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(node.train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 2],\n",
       " [0, 0, 3],\n",
       " [0, 0, 4],\n",
       " [0, 0, 5],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 4],\n",
       " [0, 5],\n",
       " [0, 6],\n",
       " [0, 7],\n",
       " [0, 8],\n",
       " [0, 9]]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.get_all_child_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdfsadf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-b4d6b660fffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masdfsadf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'asdfsadf' is not defined"
     ]
    }
   ],
   "source": [
    "asdfsadf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a node and train a new classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max incorrect: 3509, [0, 4], train for: 203\n"
     ]
    }
   ],
   "source": [
    "### make selecting index automatic\n",
    "###### for all child index analyse how much incorrect training examples are present\n",
    "\n",
    "### 1. train the cild with maximum incorrect ones.\n",
    "### 2. train the network for at least 30,000 steps:\n",
    "###     for a 5K dataset with 50 batch size, 100 steps in one epoch, so train for 300 epochs\n",
    "\n",
    "MIN_POINTS = 10\n",
    "batch_size = 50\n",
    "\n",
    "max_incorrect = 0\n",
    "max_inc_node = None\n",
    "train_epoch = None\n",
    "for ci in tree.get_all_child_index():\n",
    "    node = tree.get_node(ci)\n",
    "    num_data = len(node.train_indices)\n",
    "    if num_data < MIN_POINTS: continue\n",
    "        \n",
    "    incorrect = num_data - node.num_correct\n",
    "    if incorrect > max_incorrect:\n",
    "        max_incorrect = incorrect\n",
    "        max_inc_node = ci\n",
    "        steps_in_epoch = max(num_data/batch_size, 1)\n",
    "        train_epoch = int(30000/steps_in_epoch)\n",
    "        \n",
    "print(f\"Max incorrect: {max_incorrect}, {max_inc_node}, train for: {train_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indx = [0, 0]\n",
    "indx = max_inc_node\n",
    "parent = tree.get_parent_node(indx)\n",
    "node = tree.get_node(indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, [0, 1, 2, 3, 4, 5, 6, 8, 9])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node.train_indices, node.test_indices\n",
    "node.pred, node.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_node = LocalClassifier(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Num: 6385\n",
      "Test Dataset Num: 1063\n"
     ]
    }
   ],
   "source": [
    "### make classifier with only available classes\n",
    "avl_cls = node.classes\n",
    "num_cls = len(node.classes)\n",
    "output_dim = 10\n",
    "num_sets = num_cls*2\n",
    "init_val = torch.randn(num_sets, output_dim)*0.01\n",
    "for ns in range(num_sets):\n",
    "    init_val[ns, avl_cls[ns%num_cls]] = 2.\n",
    "\n",
    "alt_node.create_network_0(784, [784], output_dim, num_sets)\n",
    "alt_node.classifier.cls_weight.data = init_val.to(device)\n",
    "\n",
    "alt_node.create_train_loader_1(train_dataset, node.train_indices, batch_size=50)\n",
    "alt_node.create_test_loader_2(test_dataset, node.test_indices, batch_size=50)\n",
    "alt_node.create_optimizer_3(lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] : Train -> 0.7276 Test -> 0.7121, NUM: 6385, classes: 0:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "node.display_stats(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 206.30it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0:0,  Loss:2.2397239208221436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 144.51it/s]\n",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:69.49%, Test Acc:71.50%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 221.56it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1:0,  Loss:2.206883192062378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 144.99it/s]\n",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:73.08%, Test Acc:71.21%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 213.14it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2:0,  Loss:2.1750831604003906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 135.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:72.76%, Test Acc:71.21%\n",
      "\n",
      "\t-> MAX Train Acc 73.07752545027408 ; Test Acc 71.49576669802445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alt_node.train_classifier_4(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 438.08it/s]\n",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping only N=6/18 classifiers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 452.79it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 152.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard inference on the data !\n",
      "idx: 0\tout: 0 \t acc: 73.527 \tclasses:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "idx: 1\tout: 2 \t acc: 57.143 \tclasses:[0, 2, 6]\n",
      "idx: 2\tout: 6 \t acc: 62.963 \tclasses:[0, 2, 6, 8]\n",
      "idx: 3\tout: 0 \t acc: 73.400 \tclasses:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "idx: 4\tout: 2 \t acc: 66.667 \tclasses:[0, 2, 4, 5, 8]\n",
      "idx: 5\tout: 6 \t acc: 77.778 \tclasses:[0, 6]\n",
      "Accuracy: 0.7332811276429131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alt_node.freeze_and_compute_stats_5(MIN_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[, 0] : Train -> 0.7353 Test -> 0.6894, NUM: 2410, classes: 0:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[, 1] : Train -> 0.5714 Test -> 0.3333, NUM: 21, classes: 2:[0, 2, 6]\n",
      "[, 2] : Train -> 0.6296 Test -> 0.5000, NUM: 27, classes: 6:[0, 2, 6, 8]\n",
      "[, 3] : Train -> 0.7340 Test -> 0.7381, NUM: 3891, classes: 0:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[, 4] : Train -> 0.6667 Test -> 0.6667, NUM: 27, classes: 2:[0, 2, 4, 5, 8]\n",
      "[, 5] : Train -> 0.7778 Test -> -1.0000, NUM: 9, classes: 6:[0, 6]\n"
     ]
    }
   ],
   "source": [
    "alt_node.display_stats(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "### replace the leaf node with Local Classifier Node\n",
    "parent.children[indx[-1]] = alt_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0] : Train -> 0.7353 Test -> 0.6894, NUM: 2410, classes: 0:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[0, 0, 1] : Train -> 0.5714 Test -> 0.3333, NUM: 21, classes: 2:[0, 2, 6]\n",
      "[0, 0, 2] : Train -> 0.6296 Test -> 0.5000, NUM: 27, classes: 6:[0, 2, 6, 8]\n",
      "[0, 0, 3] : Train -> 0.7340 Test -> 0.7381, NUM: 3891, classes: 0:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[0, 0, 4] : Train -> 0.6667 Test -> 0.6667, NUM: 27, classes: 2:[0, 2, 4, 5, 8]\n",
      "[0, 0, 5] : Train -> 0.7778 Test -> -1.0000, NUM: 9, classes: 6:[0, 6]\n",
      "[0, 1] : Train -> 0.9047 Test -> 0.9049, NUM: 6251, classes: 1:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[0, 2] : Train -> 0.5491 Test -> 0.5439, NUM: 7204, classes: 2:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[0, 3] : Train -> 0.7016 Test -> 0.6900, NUM: 7142, classes: 3:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[0, 4] : Train -> 0.5237 Test -> 0.4956, NUM: 7367, classes: 4:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[0, 5] : Train -> 0.6636 Test -> 0.6917, NUM: 5291, classes: 5:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 6] : Train -> 0.6927 Test -> 0.6486, NUM: 872, classes: 6:[0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "[0, 7] : Train -> 0.7051 Test -> 0.7077, NUM: 7244, classes: 7:[0, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 8] : Train -> 0.8726 Test -> 0.8446, NUM: 4765, classes: 8:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 9] : Train -> 0.7311 Test -> 0.7213, NUM: 7479, classes: 9:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Final Accuracy is Train: 0.70018 Test: 0.69060\n"
     ]
    }
   ],
   "source": [
    "#### After modification status\n",
    "tree.display_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 0, 0, 0] : pred -> 0.9799, NUM: 546, classes: [0, 2, 4, 6]\n",
    "[0, 0, 0, 1] : pred -> 0.9983, NUM: 606, classes: [1, 2]\n",
    "[0, 0, 0, 2] : pred -> 0.9831, NUM: 592, classes: [0, 2, 4, 6]\n",
    "[0, 0, 0, 3] : pred -> 0.9788, NUM: 565, classes: [0, 1, 2, 3, 4, 6, 8]\n",
    "[0, 0, 0, 4] : pred -> 0.9744, NUM: 586, classes: [1, 2, 3, 4, 6]\n",
    "[0, 0, 0, 5] : pred -> 1.0000, NUM: 589, classes: [5]\n",
    "[0, 0, 0, 6] : pred -> 0.9898, NUM: 588, classes: [0, 1, 2, 4, 6]\n",
    "[0, 0, 0, 7] : pred -> 0.9877, NUM: 568, classes: [5, 7, 9]\n",
    "[0, 0, 0, 8] : pred -> 0.9966, NUM: 592, classes: [0, 8]\n",
    "[0, 0, 0, 9] : pred -> 0.9947, NUM: 565, classes: [5, 7, 9]\n",
    "[0, 0, 1, 0] : pred -> 0.9571, NUM: 163, classes: [0, 6]\n",
    "[0, 0, 1, 1] : pred -> 1.0000, NUM: 149, classes: [1]\n",
    "[0, 0, 1, 2] : pred -> 0.9940, NUM: 168, classes: [2, 4]\n",
    "[0, 0, 1, 3] : pred -> 0.9939, NUM: 164, classes: [3, 6]\n",
    "[0, 0, 1, 4] : pred -> 0.9827, NUM: 173, classes: [2, 4, 6]\n",
    "[0, 0, 1, 5] : pred -> 1.0000, NUM: 167, classes: [5]\n",
    "[0, 0, 1, 6] : pred -> 1.0000, NUM: 143, classes: [6]\n",
    "[0, 0, 1, 7] : pred -> 0.9934, NUM: 151, classes: [7, 8]\n",
    "[0, 0, 1, 8] : pred -> 0.9864, NUM: 147, classes: [0, 6, 8]\n",
    "[0, 0, 1, 9] : pred -> 0.9831, NUM: 177, classes: [7, 9]\n",
    "[0, 1] : pred -> 0.9888, NUM: 5898, classes: [0, 1, 2, 3, 4, 6, 8, 9]\n",
    "[0, 2, 0, 0] : pred -> 0.9571, NUM: 466, classes: [0, 1, 2, 4, 6, 8]\n",
    "[0, 2, 0, 1] : pred -> 1.0000, NUM: 476, classes: [1]\n",
    "[0, 2, 0, 2] : pred -> 0.9876, NUM: 483, classes: [2, 3, 4, 6]\n",
    "[0, 2, 0, 3] : pred -> 0.9912, NUM: 457, classes: [0, 3, 4, 6]\n",
    "[0, 2, 0, 4] : pred -> 0.9790, NUM: 477, classes: [2, 3, 4, 6]\n",
    "[0, 2, 0, 5] : pred -> 1.0000, NUM: 451, classes: [5]\n",
    "[0, 2, 0, 6] : pred -> 0.9956, NUM: 456, classes: [2, 4, 6]\n",
    "[0, 2, 0, 7] : pred -> 0.9886, NUM: 440, classes: [5, 7, 8, 9]\n",
    "[0, 2, 0, 8] : pred -> 0.9883, NUM: 426, classes: [0, 6, 8]\n",
    "[0, 2, 0, 9] : pred -> 0.9918, NUM: 490, classes: [5, 7, 9]\n",
    "[0, 2, 1] : pred -> 0.8632, NUM: 541, classes: [0, 1, 3, 4, 5, 6]\n",
    "[0, 2, 2] : pred -> 0.8750, NUM: 8, classes: [0, 4]\n",
    "[0, 2, 3] : pred -> 0.8986, NUM: 138, classes: [0, 1, 3, 4, 6, 8]\n",
    "[0, 2, 4] : pred -> 0.8000, NUM: 5, classes: [0, 4]\n",
    "[0, 3, 0] : pred -> 0.9524, NUM: 210, classes: [0, 1, 2, 6, 8]\n",
    "[0, 3, 1] : pred -> 1.0000, NUM: 7, classes: [2]\n",
    "[0, 3, 2] : pred -> 0.9417, NUM: 5988, classes: [0, 1, 2, 3, 4, 5, 6, 8]\n",
    "[0, 3, 3, 0] : pred -> 0.9672, NUM: 61, classes: [0, 6]\n",
    "[0, 3, 3, 1] : pred -> 1.0000, NUM: 56, classes: [1]\n",
    "[0, 3, 3, 2] : pred -> 1.0000, NUM: 43, classes: [2]\n",
    "[0, 3, 3, 3] : pred -> 0.9583, NUM: 48, classes: [3, 4, 6]\n",
    "[0, 3, 3, 4] : pred -> 0.9811, NUM: 53, classes: [2, 4]\n",
    "[0, 3, 3, 5] : pred -> 1.0000, NUM: 44, classes: [5]\n",
    "[0, 3, 3, 6] : pred -> 0.9796, NUM: 49, classes: [0, 6]\n",
    "[0, 3, 3, 7] : pred -> 1.0000, NUM: 53, classes: [7]\n",
    "[0, 3, 3, 8] : pred -> 1.0000, NUM: 48, classes: [8]\n",
    "[0, 3, 3, 9] : pred -> 1.0000, NUM: 53, classes: [9]\n",
    "[0, 4, 0, 0] : pred -> 1.0000, NUM: 103, classes: [0]\n",
    "[0, 4, 0, 1] : pred -> 1.0000, NUM: 117, classes: [1]\n",
    "[0, 4, 0, 2] : pred -> 0.9910, NUM: 111, classes: [2, 6]\n",
    "[0, 4, 0, 3] : pred -> 1.0000, NUM: 112, classes: [3]\n",
    "[0, 4, 0, 4] : pred -> 1.0000, NUM: 117, classes: [4]\n",
    "[0, 4, 0, 5] : pred -> 1.0000, NUM: 110, classes: [5]\n",
    "[0, 4, 0, 6] : pred -> 1.0000, NUM: 119, classes: [6]\n",
    "[0, 4, 0, 7] : pred -> 0.9831, NUM: 118, classes: [5, 7, 9]\n",
    "[0, 4, 0, 8] : pred -> 1.0000, NUM: 103, classes: [8]\n",
    "[0, 4, 0, 9] : pred -> 1.0000, NUM: 124, classes: [9]\n",
    "[0, 4, 1, 0] : pred -> 0.9752, NUM: 483, classes: [0, 2, 6]\n",
    "[0, 4, 1, 1] : pred -> 0.9981, NUM: 520, classes: [1, 3]\n",
    "[0, 4, 1, 2] : pred -> 0.9693, NUM: 521, classes: [0, 2, 4, 6, 8]\n",
    "[0, 4, 1, 3] : pred -> 0.9838, NUM: 493, classes: [1, 2, 3, 4, 6]\n",
    "[0, 4, 1, 4] : pred -> 0.9745, NUM: 510, classes: [0, 2, 3, 4, 6]\n",
    "[0, 4, 1, 5] : pred -> 1.0000, NUM: 497, classes: [5]\n",
    "[0, 4, 1, 6] : pred -> 0.9917, NUM: 482, classes: [0, 2, 3, 4, 6]\n",
    "[0, 4, 1, 7] : pred -> 0.9874, NUM: 476, classes: [5, 7, 9]\n",
    "[0, 4, 1, 8] : pred -> 0.9939, NUM: 493, classes: [0, 6, 8]\n",
    "[0, 4, 1, 9] : pred -> 0.9941, NUM: 511, classes: [7, 9]\n",
    "[0, 5] : pred -> 0.9624, NUM: 5902, classes: [0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
    "[0, 6, 0] : pred -> 0.9314, NUM: 452, classes: [0, 1, 2, 3, 4, 8]\n",
    "[0, 6, 1, 0] : pred -> 0.9726, NUM: 401, classes: [0, 2, 6]\n",
    "[0, 6, 1, 1] : pred -> 1.0000, NUM: 403, classes: [1]\n",
    "[0, 6, 1, 2] : pred -> 0.9851, NUM: 404, classes: [1, 2, 3, 4, 6]\n",
    "[0, 6, 1, 3] : pred -> 0.9814, NUM: 376, classes: [1, 2, 3, 4, 6]\n",
    "[0, 6, 1, 4] : pred -> 0.9754, NUM: 407, classes: [2, 3, 4, 6]\n",
    "[0, 6, 1, 5] : pred -> 1.0000, NUM: 396, classes: [5]\n",
    "[0, 6, 1, 6] : pred -> 0.9897, NUM: 388, classes: [2, 4, 6, 8]\n",
    "[0, 6, 1, 7] : pred -> 0.9923, NUM: 391, classes: [5, 7, 8, 9]\n",
    "[0, 6, 1, 8] : pred -> 0.9972, NUM: 362, classes: [7, 8]\n",
    "[0, 6, 1, 9] : pred -> 0.9910, NUM: 444, classes: [5, 7, 9]\n",
    "[0, 6, 2] : pred -> 1.0000, NUM: 11, classes: [8]\n",
    "[0, 7, 0] : pred -> 1.0000, NUM: 100, classes: [5]\n",
    "[0, 7, 1] : pred -> 0.9763, NUM: 5877, classes: [5, 7, 8, 9]\n",
    "[0, 7, 2] : pred -> 0.7500, NUM: 8, classes: [6, 8]\n",
    "[0, 7, 3] : pred -> 0.9838, NUM: 308, classes: [5, 9]\n",
    "[0, 8] : pred -> 0.9482, NUM: 6123, classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 9] : pred -> 0.9605, NUM: 5803, classes: [0, 1, 4, 5, 6, 7, 8, 9]\n",
    "Final Accuracy is : 0.97130"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
