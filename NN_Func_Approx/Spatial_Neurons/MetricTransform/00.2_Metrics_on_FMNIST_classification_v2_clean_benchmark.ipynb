{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e79740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2b919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dtnnlib as dtnn\n",
    "# import resnet_cifar\n",
    "\n",
    "from torchvision import datasets, transforms as T\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53af51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys, random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1602c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.5,],\n",
    "        std=[0.5,],\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/\", train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/\", train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "491fefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.data = train_dataset.data.view(-1, 28*28)\n",
    "# test_dataset.data = test_dataset.data.view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6807321",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f12e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd705fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0879c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47582925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuman/All_Files/Program_Files/miniconda/envs/myenv/lib/python3.9/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103909e2",
   "metadata": {},
   "source": [
    "## Any function as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9551d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionDT(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, func, inv_temp=0.):\n",
    "        '''\n",
    "        func [input_dim -> 1]\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.func = func\n",
    "        \n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.centers = torch.randn(num_centers, input_dim)/3.\n",
    "        self.centers = nn.Parameter(self.centers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = x.unsqueeze(1) - self.centers.unsqueeze(0)\n",
    "        dists = self.func(z).squeeze(-1)\n",
    "        dists = -dists*torch.exp(self.inv_temp)\n",
    "        \n",
    "        ## COmment out (un-normalized)\n",
    "#         dists = dists-dists.mean(dim=1, keepdim=True)\n",
    "#         dists = dists/dists.std(dim=1, keepdim=True)\n",
    "\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e1d6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes import DistanceRegressor, ConvexNN\n",
    "from nflib.flows import SequentialFlow, ActNorm\n",
    "import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4fc66",
   "metadata": {},
   "source": [
    "## Merge all models into single and benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffba015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_keys = [\"l_0.5\", \"l_1\", \"l_2\", \"l_20\", \"stereo\", \"linear\",]\n",
    "def get_models(h = 5, key='linear'):\n",
    "    I = 784\n",
    "    layer1 = None\n",
    "    if key == \"l_0.5\":\n",
    "        layer1 = dtnn.DistanceTransform(I, h, p=0.5, bias=False)\n",
    "    elif key == \"l_1\":\n",
    "        layer1 = dtnn.DistanceTransform(I, h, p=1, bias=False)\n",
    "    elif key == \"l_2\":\n",
    "        layer1 = dtnn.DistanceTransform(I, h, bias=False)\n",
    "    elif key == \"l_20\":\n",
    "        layer1 = dtnn.DistanceTransform(I, h, p=20, bias=False)\n",
    "    elif key == \"stereo\":\n",
    "        layer1 = dtnn.StereographicTransform(I, h, bias=False)\n",
    "    elif key == \"linear\":\n",
    "        layer1 = nn.Linear(I, h, bias=False)\n",
    "    else:\n",
    "        raise KeyError()\n",
    "        \n",
    "    net = nn.Sequential(\n",
    "        layer1,\n",
    "#         nn.BatchNorm1d(h),\n",
    "        nn.LayerNorm(h),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(h, 10),\n",
    "        )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14541096",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_func_keys = [\"convex\", \"invex\", \"ordinary\"]\n",
    "\n",
    "def get_models_func(h = 500, func_h=500, key='ordinary'):\n",
    "#     I = 784\n",
    "    layer1 = None\n",
    "    if key == \"convex\":\n",
    "        layer1 = ConvexNN([784, func_h, 1])\n",
    "    elif key == \"invex\":\n",
    "        layer1 = nn.Sequential(\n",
    "                    ActNorm(784),\n",
    "                    irf.ResidualFlow(784, [func_h], activation=irf.LeakyReLU),\n",
    "                    ActNorm(784),\n",
    "                    DistanceRegressor(784),\n",
    "                    )\n",
    "    elif key == \"ordinary\":\n",
    "        layer1 = nn.Sequential(\n",
    "                    ActNorm(784),\n",
    "                    irf.ResidualFlow(784, [func_h], activation=irf.LeakyReLU),\n",
    "                    ActNorm(784),\n",
    "#                     DistanceRegressor(784),\n",
    "                    nn.Linear(784, 1),\n",
    "                    )\n",
    "        irf.remove_spectral_norm_model(layer1)\n",
    "    else:\n",
    "        raise KeyError()\n",
    "        \n",
    "    net = nn.Sequential(\n",
    "        FunctionDT(784, h, layer1),\n",
    "        nn.BatchNorm1d(h),\n",
    "#         nn.LayerNorm(h),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(h, 10),\n",
    "        )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eaa0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "#     for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "#     print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7bd80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch, model, model_name):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "#     print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "#         print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "#         if not os.path.isdir('models'):\n",
    "#             os.mkdir('models')\n",
    "#         torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e46396d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0feb854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['l_0.5', 'l_1', 'l_2', 'l_20', 'stereo', 'linear'],\n",
       " ['convex', 'invex', 'ordinary'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H = [5, 10, 20, 100, 500]\n",
    "H = [10, 20, 100, 500]\n",
    "\n",
    "models_keys, models_func_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69f1a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir outputs/00.2_exp_acc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88818039",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals = {}\n",
    "# # Opening JSON file\n",
    "with open(\"./outputs/00.2_exp_acc_data_v2.json\", 'r') as f:\n",
    "    exp_acc_vals = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1d8225a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5': {'l_0.5': [71.49, 73.15, 73.99, 73.01, 72.52, 72.96, 74.34, 73.66],\n",
       "  'l_1': [75.74, 75.33, 77.31, 76.17, 75.78, 77.11, 77.49, 76.82],\n",
       "  'l_2': [76.58, 77.89, 78.05, 77.67, 76.98, 78.75, 78.94, 78.06],\n",
       "  'l_20': [79.2, 79.7, 79.59, 78.49, 78.59, 78.85, 78.64, 75.73],\n",
       "  'stereo': [81.37, 80.73, 80.81, 81.9, 81.09, 80.2, 81.34, 81.82],\n",
       "  'linear': [81.22, 81.54, 81.04, 81.06, 81.5, 81.14, 80.99, 81.5],\n",
       "  'convex': [77.49, 68.88, 78.08, 80.34, 78.26, 80.63, 81.74, 66.97],\n",
       "  'invex': [88.48, 87.3, 86.87, 87.48, 88.06, 85.9, 87.63, 87.67],\n",
       "  'ordinary': [82.05, 85.56, 85.61, 83.84, 83.62, 82.49, 82.51, 83.6]},\n",
       " '10': {'l_0.5': [77.87, 77.97, 78.2, 78.28, 77.56, 78.15, 78.32, 77.96],\n",
       "  'l_1': [81.37, 81.15, 81.51, 81.42, 81.05, 81.0, 81.71, 81.46],\n",
       "  'l_2': [82.3, 82.67, 82.32, 82.42, 81.88, 82.45, 82.64, 82.5],\n",
       "  'l_20': [82.7, 82.4, 82.17, 82.97, 82.9, 82.09, 82.59, 81.31],\n",
       "  'stereo': [84.94, 85.31, 85.15, 85.31, 84.9, 84.75, 84.63, 85.19],\n",
       "  'linear': [84.43, 84.91, 84.94, 85.11, 84.97, 84.91, 85.49, 84.97],\n",
       "  'convex': [69.71, 77.79, 77.44, 76.42, 72.46, 74.74, 79.18, 76.23]}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea674cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for l_0.5 ; h:10\n",
      "_________________________\n",
      "Experimenting for l_1 ; h:10\n",
      "_________________________\n",
      "Experimenting for l_2 ; h:10\n",
      "_________________________\n",
      "Experimenting for l_20 ; h:10\n",
      "_________________________\n",
      "Experimenting for stereo ; h:10\n",
      "_________________________\n",
      "Experimenting for linear ; h:10\n",
      "_________________________\n",
      "Experimenting for convex ; h:10\n",
      "_________________________\n",
      "Experimenting for invex ; h:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [47:23<00:00, 355.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for ordinary ; h:10\n",
      "_________________________\n",
      "Experimenting for l_0.5 ; h:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [32:36<00:00, 244.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for l_1 ; h:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [33:26<00:00, 250.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for l_2 ; h:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [34:39<00:00, 259.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for l_20 ; h:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [33:29<00:00, 251.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for stereo ; h:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [34:16<00:00, 257.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for linear ; h:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [31:08<00:00, 233.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for convex ; h:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [38:08<00:00, 286.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for invex ; h:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [54:24<00:00, 408.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for ordinary ; h:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                               | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████▊                                               | 1/8 [05:27<38:10, 327.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|█████████████▌                                        | 2/8 [10:54<32:44, 327.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|████████████████████▎                                 | 3/8 [16:20<27:14, 326.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████                           | 4/8 [21:47<21:47, 326.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████▊                    | 5/8 [27:15<16:21, 327.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████▌             | 6/8 [32:43<10:54, 327.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|███████████████████████████████████████████████▎      | 7/8 [38:09<05:26, 326.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [43:36<00:00, 327.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for l_0.5 ; h:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [33:18<00:00, 249.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for l_1 ; h:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [33:45<00:00, 253.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for l_2 ; h:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [34:38<00:00, 259.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for l_20 ; h:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [33:49<00:00, 253.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for stereo ; h:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [34:17<00:00, 257.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for linear ; h:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [31:01<00:00, 232.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for convex ; h:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [50:45<00:00, 380.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for invex ; h:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 8/8 [1:49:39<00:00, 822.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for ordinary ; h:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                               | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████▌                                             | 1/8 [12:48<1:29:40, 768.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|█████████████                                       | 2/8 [25:37<1:16:53, 768.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████▌                                | 3/8 [38:26<1:04:03, 768.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████                           | 4/8 [51:14<51:13, 768.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|████████████████████████████████▌                   | 5/8 [1:04:00<38:22, 767.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████             | 6/8 [1:16:46<25:34, 767.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|█████████████████████████████████████████████▌      | 7/8 [1:29:31<12:46, 766.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=784, out_features=1, bias=True)\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 8/8 [1:42:18<00:00, 767.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for l_0.5 ; h:500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 8/8 [44:02<00:00, 330.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for l_1 ; h:500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████▊                                               | 1/8 [04:38<32:26, 278.04s/it]"
     ]
    }
   ],
   "source": [
    "# data_file = \"./outputs/00.2_exp_acc_dict_v2.json\"\n",
    "SEEDS = [147, 258, 369, 741, 852, 963, 159, 357]\n",
    "\n",
    "for h in H:\n",
    "    acc_dict = {}\n",
    "    \n",
    "    for key, func_idx in zip(models_keys+models_func_keys, [0]*len(models_keys)+[1]*len(models_func_keys)):\n",
    "        acc_dict[key] = []\n",
    "        print(\"_________________________\")\n",
    "        print(f\"Experimenting for {key} ; h:{h}\")\n",
    "        \n",
    "        if h == 10 and key != \"invex\": continue\n",
    "\n",
    "        for seed in tqdm(SEEDS):\n",
    "            model_name = f\"00.2_fmnist_{key}_h{h}_s{seed}\"\n",
    "            \n",
    "            torch.manual_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "            train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "            test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            if func_idx == 0:\n",
    "                net = get_models(h, key=key).to(device)\n",
    "            else:\n",
    "                net = get_models_func(h, key=key).to(device)\n",
    "            \n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "            best_acc = -1\n",
    "            for epoch in range(EPOCHS):\n",
    "                train(epoch, net, optimizer)\n",
    "                test(epoch, net, model_name)\n",
    "                scheduler.step()\n",
    "            acc_dict[key] += [float(best_acc)] ## add to the list\n",
    "        \n",
    "        exp_acc_vals[str(h)] = acc_dict\n",
    "        \n",
    "        ## Save it in the file.\n",
    "        with open(f\"./outputs/00.2_exp_acc_data_v2.json\", \"w\") as f:\n",
    "            json.dump(exp_acc_vals, f, indent=3)\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da496a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_acc_vals = \\\n",
    "# {'5': {'l_0.5': 67.05,\n",
    "#   'l_1': 70.7,\n",
    "#   'l_2': 78.15,\n",
    "#   'l_inf': 79.52,\n",
    "#   'stereo': 82.19,\n",
    "#   'linear': 82.74,\n",
    "#   'convex': 79.49,\n",
    "#   'invex': 88.26,\n",
    "#   'ordinary': 83.55},\n",
    "#  '10': {'l_0.5': 72.08,\n",
    "#   'l_1': 77.91,\n",
    "#   'l_2': 82.35,\n",
    "#   'l_inf': 83.98,\n",
    "#   'stereo': 84.73,\n",
    "#   'linear': 84.89,\n",
    "#   'convex': 78.99,\n",
    "#   'invex': 88.41,\n",
    "#   'ordinary': 81.69}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee48e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file = \"./outputs/00.2_exp_acc_dict.json\"\n",
    "# with open(data_file, \"w\") as f:\n",
    "#     json.dump(exp_acc_vals, f, indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf858b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Opening JSON file\n",
    "# with open(data_file, 'r') as f:\n",
    "#     exp_acc_vals = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd77393",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae651c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
