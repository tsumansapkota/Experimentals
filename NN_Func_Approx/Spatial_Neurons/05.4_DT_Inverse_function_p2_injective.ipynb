{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mylibrary.datasets as datasets\n",
    "import mylibrary.nnlib as tnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.FashionMNIST()\n",
    "# mnist.download_mnist()\n",
    "# mnist.save_mnist()\n",
    "train_data, train_label_, test_data, test_label_ = mnist.load()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "# train_label = tnn.Logits.index_to_logit(train_label_)\n",
    "train_size = len(train_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting data to pytorch format\n",
    "train_data = torch.Tensor(train_data)\n",
    "test_data = torch.Tensor(test_data)\n",
    "train_label = torch.LongTensor(train_label_)\n",
    "test_label = torch.LongTensor(test_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         print(idx)\n",
    "        img, lbl = self.data[idx], self.label[idx]\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST_Dataset(train_data, train_label)\n",
    "test_dataset = MNIST_Dataset(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                    num_workers=4, \n",
    "                                    batch_size=batch_size, \n",
    "                                    shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                    num_workers=1, \n",
    "                                    batch_size=batch_size, \n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceTransform(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, p=2):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.p = p\n",
    "        \n",
    "        self.centers = torch.randn(num_centers, input_dim)/3.\n",
    "#         self.centers = torch.rand(num_centers, input_dim)\n",
    "        self.centers = nn.Parameter(self.centers)\n",
    "        self.inv_params = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        dists = torch.cdist(x, self.centers, p=self.p)\n",
    "        \n",
    "        ### normalize similar to UMAP\n",
    "#         dists = dists-dists.min(dim=1, keepdim=True)[0]\n",
    "#         dists = dists-dists.mean(dim=1, keepdim=True)\n",
    "#         dists = dists/dists.std(dim=1, keepdim=True)\n",
    "\n",
    "        return dists\n",
    "    \n",
    "    def set_centroid_to_data_randomly(self, data_loader):\n",
    "        indices = np.random.permutation(len(data_loader.dataset.data))[:self.centers.shape[0]]\n",
    "        self.centers.data = data_loader.dataset.data[indices].to(self.centers.device)\n",
    "        self.centers.data += torch.randn_like(self.centers)*0.01\n",
    "        pass\n",
    "    \n",
    "    def set_centroid_to_data_maxdist(self, data_loader):\n",
    "        ## sample N points\n",
    "        N = self.centers.shape[0]\n",
    "        new_center = torch.empty_like(self.centers)\n",
    "        min_dists = torch.empty(N)\n",
    "        count = 0\n",
    "        for i, (xx, _) in enumerate(tqdm(data_loader)):\n",
    "            if count < N:\n",
    "                if N-count < batch_size:\n",
    "                    #### final fillup\n",
    "                    new_center[count:count+N-count] = xx[:N-count]\n",
    "                    xx = xx[N-count:]\n",
    "                    dists = torch.cdist(new_center, new_center)+torch.eye(N)*1e5\n",
    "                    min_dists = dists.min(dim=0)[0]\n",
    "                    count = N\n",
    "\n",
    "                else:#### fill the center\n",
    "                    new_center[count:count+len(xx)] = xx\n",
    "                    count += len(xx)\n",
    "                    continue\n",
    "\n",
    "            ammd = min_dists.argmin()\n",
    "            for i, x in enumerate(xx):\n",
    "                dists = torch.norm(new_center-x, dim=1)\n",
    "                md = dists.min()\n",
    "                if md > min_dists[ammd]:\n",
    "                    min_dists[ammd] = md\n",
    "                    new_center[ammd] = x\n",
    "                    ammd = min_dists.argmin()\n",
    "        self.centers.data = new_center.to(self.centers.device)\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def set_centroid_to_data(self, data_loader):\n",
    "        new_center = self.centers.data.clone()\n",
    "        min_dists = torch.ones(self.centers.shape[0])*1e9\n",
    "\n",
    "        for xx, _ in data_loader:\n",
    "\n",
    "            dists = torch.cdist(xx, self.centers.data)\n",
    "            ### min dist of each center to the data points\n",
    "            min_d, arg_md = dists.min(dim=0)\n",
    "\n",
    "            ### dont allow same point to be assigned as closest to multiple centroid\n",
    "            occupied = []\n",
    "            for i in np.random.permutation(len(arg_md)):\n",
    "        #     for i, ind in enumerate(arg_md):\n",
    "                ind = arg_md[i]\n",
    "                if ind in occupied:\n",
    "                    min_d[i] = min_dists[i]\n",
    "                    arg_md[i] = -1\n",
    "                else:\n",
    "                    occupied.append(ind)\n",
    "\n",
    "            ### the index of centroids that have new min_dist\n",
    "            idx = torch.nonzero(min_d<min_dists).reshape(-1)\n",
    "\n",
    "            ### assign new_center to the nearest data point\n",
    "            new_center[idx] = xx[arg_md[idx]]\n",
    "            min_dists[idx] = min_d[idx]\n",
    "            \n",
    "        self.centers.data = new_center.to(self.centers.device)\n",
    "        pass\n",
    "    \n",
    "    def compute_inverse_matrix(self):\n",
    "        A = 2*(self.centers.data[1:]-self.centers.data[:-1])\n",
    "        \n",
    "        c2 = self.centers.data**2\n",
    "        Z = (c2[:-1]-c2[1:]).sum(dim=1, keepdim=True)\n",
    "        \n",
    "        invA = torch.pinverse(A)\n",
    "        \n",
    "        self.inv_params = (invA, Z)\n",
    "        \n",
    "    def inverse(self, dists):\n",
    "        assert invA is not None\n",
    "        \n",
    "        d2 = dists**2\n",
    "        D = d2[:, :-1]-d2[:, 1:]\n",
    "\n",
    "        invA, Z = self.inv_params\n",
    "        xrec = torch.matmul(invA, D.t()-Z).t()\n",
    "        return xrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA(object):\n",
    "\n",
    "    def __init__(self, momentum=0.1, mu=None):\n",
    "        self.mu = mu\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.mu is None:\n",
    "            self.mu = x\n",
    "        self.mu = self.momentum*self.mu + (1.0 - self.momentum)*x\n",
    "        return self.mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse function programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(test_loader.dataset.data))[:50]\n",
    "xx, yy = test_loader.dataset[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistanceTransform()"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DistanceTransform(784, 100, p=2)\n",
    "dt.set_centroid_to_data_randomly(train_loader)\n",
    "dt.centers.data += torch.randn_like(dt.centers)*0.01\n",
    "# dt.set_centroid_to_data_maxdist(train_loader)\n",
    "dt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = dt(xx.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.5916, 14.8464, 12.0628,  ..., 14.2910, 10.2527, 10.1579],\n",
       "        [10.7364, 13.2698, 13.9123,  ..., 11.5001,  7.7839, 11.9286],\n",
       "        [11.4181, 14.1490, 14.1074,  ..., 10.7497, 10.9852, 13.3369],\n",
       "        ...,\n",
       "        [ 8.9270, 14.7898, 10.8822,  ..., 16.5947, 13.2267,  7.6776],\n",
       "        [ 6.8252, 11.9767, 11.7552,  ...,  8.3982,  8.5702,  9.9942],\n",
       "        [10.9388, 14.7640, 13.7783,  ..., 11.6463,  7.0056, 13.3259]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### compute the inverse matrix/vector parameters\n",
    "\n",
    "A = 2*(dt.centers.data[1:]-dt.centers.data[:-1])\n",
    "d2 = dists**2\n",
    "D = d2[:, :-1]-d2[:, 1:]\n",
    "\n",
    "c2 = dt.centers.data**2\n",
    "Z = (c2[:-1]-c2[1:]).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([99, 784]), torch.Size([50, 99]), torch.Size([99, 1]))"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, D.shape, Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A, D, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0095, -0.0044,  0.0062,  ...,  0.0118, -0.0093, -0.0083],\n",
       "        [ 0.0075, -0.0107, -0.0056,  ...,  0.0195,  0.0135,  0.0021],\n",
       "        [ 0.0177,  0.0097, -0.0089,  ..., -0.0375, -0.0463,  0.0087],\n",
       "        ...,\n",
       "        [-0.0009,  0.0039, -0.0035,  ...,  0.0077,  0.0319, -0.0022],\n",
       "        [ 0.0043,  0.0057, -0.0102,  ...,  0.0199,  0.0187,  0.0052],\n",
       "        [-0.0102,  0.0109, -0.0024,  ..., -0.0380,  0.0076, -0.0036]],\n",
       "       device='cuda:0', grad_fn=<TBackward>)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invA = torch.pinverse(A)\n",
    "xrec = torch.matmul(invA, D.t()-Z).t()\n",
    "xrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclose = torch.isclose(xrec.data.cpu(), xx, atol=1e-3)\n",
    "iclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not close tensor(38653)\n"
     ]
    }
   ],
   "source": [
    "print(\"Not close\", torch.numel(xx)-torch.count_nonzero(iclose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQLUlEQVR4nO3db2zd1X3H8c/nOtcxJClJgGQpRC1NWQesAiYrnUQ1UaFWwKSFqupUHrBMQksfFK2V+mCIPSgPUbe264OpUjpQ08GoKgEiWlFXFCEhVoEwKIPQrIWyFEJCki5NExJsX9vfPfBlcoLvOc79/e4fc94vKbJ9j69/X374c3+2v79zjiNCAD74GoMuAEB/EHagEIQdKARhBwpB2IFCrOjnwUa9Msa0qp+HHAqXf/Kd5PhM5F5znRnvvqMSma+dG8+ZSzy/kan797MXJMen9tNJOtekTms6phY96ZXCbvtmSd+VNCLpXyLivtTnj2mVPuWbqhxyWfqHf382OX5sNv0COJt5MRjx3HnX9J7JaCbHW1HtejAdIx3HxtxKPvcnv7s2OX5g67td1fRB9lzs6TjW9Y/xtkck/bOkWyRdLel221d3+/UA9FaV39m3SnotIl6PiGlJP5K0rZ6yANStStgvk/Tmgo8Pth87i+0dtidsT7Q0VeFwAKqoEvbF/gjwvr+YRMTOiBiPiPGmVlY4HIAqqoT9oKTNCz6+XNKhauUA6JUqYX9e0pW2r7A9KulLknbXUxaAunXdV4mIGdt3SfoPzbfeHoiIV2qrbBlZ8ZHNyfFLG88kx1uRbiGNZPrRDXcezz13MtEak6TZin32VGtvci7d9vvC+onk+D9t/ExyfPbI0eR4aSo1USPiCUlP1FQLgB7idlmgEIQdKARhBwpB2IFCEHagEIQdKERf57N/UP3PHek++4jTvepTc2PJ8bWNdB9+LhJfP9Mmb1Xss89WuF6cifTt058cfTs5fvyzH0uOX/QgffaFuLIDhSDsQCEIO1AIwg4UgrADhSDsQCFovdVg6hPp1tiJzOKvTc8kx3Ptr9Q01twU15zc81uZlW9zK8hWceIvTifHL3qwZ4delriyA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCPrsNfjzq/Ylx3PLNTc9mxyv0mfPPbeR2QE212fPT4HtPL4mM3X3VGap6c0Xn0iO42xc2YFCEHagEIQdKARhBwpB2IFCEHagEIQdKAR99hpsHjueHM/N+Z7LjOfMJrZsrjidPatqHz5lMtLfntesPZwc39/1kT+YKoXd9gFJpyTNSpqJiPE6igJQvzqu7J+JiN/W8HUA9BC/swOFqBr2kPQz2y/Y3rHYJ9jeYXvC9kRLUxUPB6BbVX+MvyEiDtneIOlJ2/8dEU8v/ISI2ClppyR9yOt7/OciAJ1UurJHxKH226OSHpO0tY6iANSv67DbXmV7zXvvS/qcpPRcTwADU+XH+I2SHvP8dsQrJP1bRPy0lqqWmVyffOPIdHL8NzMXJsdbmX7zmkbnr39qbjT53Nxc+pwqffScaaXXAdgydiw5vl/r6ixn2es67BHxuqRra6wFQA/RegMKQdiBQhB2oBCEHSgEYQcKwRTXGmxs/j45nm4gLWUp6fRrcmqp6slIL8d8YaPalsqTmXsic7Wn5FqaFza4/fp8cGUHCkHYgUIQdqAQhB0oBGEHCkHYgUIQdqAQ9NlrsHbkTHI814tuZbZ0HlF6W+XT0Xkaa67PnlsKepidmVs56BKWFa7sQCEIO1AIwg4UgrADhSDsQCEIO1AIwg4Ugj57DU7OjiXHRzKrLeeWis5peqbjWCPTo1/TSM+lPzGXri3fp+98/Nw9AHK6dpwfruxAIQg7UAjCDhSCsAOFIOxAIQg7UAjCDhSCPnsNfjW5KTm+bfWbyfFGxX5ylbXZM53uJRy7d1s251Q9b6XJfpfYfsD2Udv7Fjy23vaTtl9tv2UjbGDILeWS8ANJN5/z2N2S9kTElZL2tD8GMMSyYY+IpyUdP+fhbZJ2td/fJem2essCULduf9nbGBGHJan9dkOnT7S9w/aE7YmW2JsLGJSe/zU+InZGxHhEjDfFAoHAoHQb9iO2N0lS++3R+koC0Avdhn23pO3t97dLeryecgD0SrbPbvthSTdKusT2QUnfkHSfpB/bvlPSG5K+2Msih93rpy9Jjo9dmpsTXq1fnJ0Xnjq2033y3Hz1Kj3+kUyffDazP3vV81aabNgj4vYOQzfVXAuAHuJ2WaAQhB0oBGEHCkHYgUIQdqAQTHGtwWsn0q23I7Pp24RntbrS8XMtqkpfu+IU1lR77FSkl+Aecys5zpbN54crO1AIwg4UgrADhSDsQCEIO1AIwg4UgrADhaDPXoPJVvo0jmWmkebkpnLOJV6zc73qDSOrkuOHZtL3CIwqveXztEaS4ym9vH+gRJxNoBCEHSgEYQcKQdiBQhB2oBCEHSgEYQcKQZ+9BqcOr6n0/LlcPznTpp+Ozr3sK5v/m3zu7tMdd+6SJG1pvpscn8302U/PjXYcyy1Tnbp/QGLL5vPFlR0oBGEHCkHYgUIQdqAQhB0oBGEHCkHYgULQZ69BYyr9mrnS6fHs2uyZPnxqy+YtzfSa9Lf8PL3b9jfHH0mOXzv6dnL8xNwFyfGU1P0DUn6uPs6WvbLbfsD2Udv7Fjx2r+23bO9t/7u1t2UCqGopP8b/QNLNizz+nYi4rv3viXrLAlC3bNgj4mlJx/tQC4AeqvIHurtsv9T+MX9dp0+yvcP2hO2JltLrmQHonW7D/j1JWyRdJ+mwpG91+sSI2BkR4xEx3hQb8QGD0lXYI+JIRMxGxJyk70vaWm9ZAOrWVdhtb1rw4ecl7ev0uQCGQ7bPbvthSTdKusT2QUnfkHSj7eskhaQDkr7cuxKHX2My3SdvRXredW5ed06VfvOKV9Lrxp+8Pr2H+mTmHoDUf1vVLnnT6bn0OFs27BFx+yIP39+DWgD0ELfLAoUg7EAhCDtQCMIOFIKwA4VgimsNRqYz45kprLklkVuZqZ5VrHkj3fY7PpueIru2ka79SKI7lpvaO5I5L7Ncq84LZwsoBGEHCkHYgUIQdqAQhB0oBGEHCkHYgULQZ69Bo5VZCjoju2VzD60+mL5J4PFD1ybHt//RL5Lj2WWyE3JTf8ecucEBZ+HKDhSCsAOFIOxAIQg7UAjCDhSCsAOFIOxAIeiz1yAyreRWxaWie6n5n+kl/3/5WrrPvu6aC5Pjrej8LdZUeinoucy16OIV7yTHcTau7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCMIOFII+ew1mx6r10avM+a4qpqaS443JateDhjqv/Z5bFz63Xv7axpnkuJujHceiVd5c+Oz/SdubbT9le7/tV2x/tf34ettP2n61/XZd78sF0K2lvGzPSPp6RFwl6U8lfcX21ZLulrQnIq6UtKf9MYAhlQ17RByOiBfb75+StF/SZZK2SdrV/rRdkm7rUY0AanBev5DZ/qik6yU9J2ljRByW5l8QJG3o8JwdtidsT7SU/v0QQO8sOey2V0t6RNLXIuLkUp8XETsjYjwixpta2U2NAGqwpLDbbmo+6A9FxKPth4/Y3tQe3yTpaG9KBFCHbOvNtiXdL2l/RHx7wdBuSdsl3dd++3hPKlwGZtakW0i5V9TcksnTmRZUroVVRWOqWlswVdtsxSW01zTS7bPG2os6H/vYsUrHXo6W0me/QdIdkl62vbf92D2aD/mPbd8p6Q1JX+xJhQBqkQ17RDwjdbzr46Z6ywHQK9wuCxSCsAOFIOxAIQg7UAjCDhSCKa41aKxP93tzXfCqU1xzSzJXseLdarVNRrPjWK7u3P0HzcyZjcsu7TxYYJ+dKztQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Wgz94HVeezNxut5HhuyeUq5lZUWyZ7zOnak8fOzHcfzczjf/fDqzqOrdzbTUXLG1d2oBCEHSgEYQcKQdiBQhB2oBCEHSgEYQcKQZ+9Bo1G79Ztl/J99FyfvoqRquvGJ2qrPI8/8/QzGzp/e5e4NxFXdqAQhB0oBGEHCkHYgUIQdqAQhB0oBGEHCrGU/dk3S/qhpD/Q/BLoOyPiu7bvlfQ3kt5bgPueiHiiV4UOs+boTHK8FdX64Ll9zFOrrz872f18ckla+bv0+FSkv/5krO441nT6vDUy68K3Mqd15oL0eGmWclPNjKSvR8SLttdIesH2k+2x70TEP/auPAB1Wcr+7IclHW6/f8r2fkmX9bowAPU6r9/ZbX9U0vWSnms/dJftl2w/YHtdh+fssD1he6KlqWrVAujaksNue7WkRyR9LSJOSvqepC2SrtP8lf9biz0vInZGxHhEjDeLvCMZGA5LCrvtpuaD/lBEPCpJEXEkImYjYk7S9yVt7V2ZAKrKht22Jd0vaX9EfHvB45sWfNrnJe2rvzwAdVnKX+NvkHSHpJdt720/do+k221fJykkHZD05R7UtyxEpOdablrRuf0kScfmzlQ6/vpG5xbW5ZljV7XSnbdklqS1jc7/bdNKT91d5fRW2Fua6f+2kx/v3JtLbOb8gbWUv8Y/Iy068bjInjqwXHEHHVAIwg4UgrADhSDsQCEIO1AIwg4UwlFx+uX5+JDXx6d8U9+ONyx+/dD1yfFbP5G+H+lEKz1X89kDV3Qc+/CDo8nnrvzJ88nxnLcevSY5/rdXPdVx7A9H304+97kzW5LjO/d+Ojn+8b/a23mwj9/3/fRc7NHJOL7ojR9c2YFCEHagEIQdKARhBwpB2IFCEHagEIQdKERf++y2j0n6zYKHLpH0274VcH6GtbZhrUuitm7VWdtHImLR6fp9Dfv7Dm5PRMT4wApIGNbahrUuidq61a/a+DEeKARhBwox6LDvHPDxU4a1tmGtS6K2bvWltoH+zg6gfwZ9ZQfQJ4QdKMRAwm77Ztu/tP2a7bsHUUMntg/Yftn2XtsTA67lAdtHbe9b8Nh620/afrX9dtE99gZU272232qfu722bx1QbZttP2V7v+1XbH+1/fhAz12irr6ct77/zm57RNKvJH1W0kFJz0u6PSJ+0ddCOrB9QNJ4RAz8BgzbfybpHUk/jIg/bj/2TUnHI+K+9gvluoj4uyGp7V5J7wx6G+/2bkWbFm4zLuk2SX+tAZ67RF1/qT6ct0Fc2bdKei0iXo+IaUk/krRtAHUMvYh4WtLxcx7eJmlX+/1dmv9m6bsOtQ2FiDgcES+23z8l6b1txgd67hJ19cUgwn6ZpDcXfHxQw7Xfe0j6me0XbO8YdDGL2BgRh6X5bx5JGwZcz7my23j30znbjA/Nuetm+/OqBhH2xdbHGqb+3w0R8SeSbpH0lfaPq1iaJW3j3S+LbDM+FLrd/ryqQYT9oKTNCz6+XNKhAdSxqIg41H57VNJjGr6tqI+8t4Nu++3RAdfz/4ZpG+/FthnXEJy7QW5/PoiwPy/pSttX2B6V9CVJuwdQx/vYXtX+w4lsr5L0OQ3fVtS7JW1vv79d0uMDrOUsw7KNd6dtxjXgczfw7c8jou//JN2q+b/I/1rS3w+ihg51fUzSf7X/vTLo2iQ9rPkf61qa/4noTkkXS9oj6dX22/VDVNu/SnpZ0kuaD9amAdX2ac3/aviSpL3tf7cO+twl6urLeeN2WaAQ3EEHFIKwA4Ug7EAhCDtQCMIOFIKwA4Ug7EAh/g9w5OL1D8a/iAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xrec.data[i].cpu().reshape(28,28))\n",
    "plt.show()\n",
    "plt.imshow(xx.data[i].cpu().reshape(28,28))\n",
    "plt.show()\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For 2D / ND case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = 2000\n",
    "xx = torch.rand(5, nd)*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1988, -0.4898, -0.6683,  ..., -0.2005,  0.2330, -0.1519],\n",
       "        [ 0.3749, -0.1628,  0.9782,  ...,  0.8401,  0.8104, -0.2827],\n",
       "        [ 0.4490,  0.5505, -0.2476,  ..., -0.9750, -0.8364,  0.2310],\n",
       "        [-0.1796, -0.3950, -0.0871,  ..., -0.3676,  0.3723,  0.0281],\n",
       "        [ 0.7756,  0.0282,  0.9532,  ..., -0.9717, -0.0792, -0.1150]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DistanceTransform(nd, nd+1, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = dt(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[29.8885, 29.7697, 29.8857,  ..., 30.2374, 30.0821, 29.6521],\n",
       "        [29.4673, 28.8991, 29.5707,  ..., 29.1595, 29.4923, 29.5889],\n",
       "        [29.9323, 29.8873, 30.0217,  ..., 29.7485, 29.7305, 29.7226],\n",
       "        [29.9579, 29.9379, 30.0357,  ..., 30.3834, 29.8568, 30.3314],\n",
       "        [29.1380, 29.9084, 29.8060,  ..., 29.8752, 29.5153, 30.9829]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### compute the inverse matrix/vector parameters\n",
    "\n",
    "A = 2*(dt.centers.data[1:]-dt.centers.data[:-1])\n",
    "d2 = dists**2\n",
    "D = d2[:, :-1]-d2[:, 1:]\n",
    "\n",
    "c2 = dt.centers.data**2\n",
    "Z = (c2[:-1]-c2[1:]).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 2000]), torch.Size([5, 2000]), torch.Size([2000, 1]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, D.shape, Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A, D, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1990, -0.4897, -0.6685,  ..., -0.2003,  0.2331, -0.1516],\n",
       "        [ 0.3756, -0.1626,  0.9786,  ...,  0.8403,  0.8103, -0.2823],\n",
       "        [ 0.4490,  0.5508, -0.2476,  ..., -0.9744, -0.8365,  0.2312],\n",
       "        [-0.1796, -0.3949, -0.0869,  ..., -0.3672,  0.3715,  0.0283],\n",
       "        [ 0.7754,  0.0282,  0.9530,  ..., -0.9715, -0.0794, -0.1151]],\n",
       "       grad_fn=<TBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invA = torch.pinverse(A)\n",
    "xrec = torch.matmul(invA, D.t()-Z).t()\n",
    "xrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1988, -0.4898, -0.6683,  ..., -0.2005,  0.2330, -0.1519],\n",
       "        [ 0.3749, -0.1628,  0.9782,  ...,  0.8401,  0.8104, -0.2827],\n",
       "        [ 0.4490,  0.5505, -0.2476,  ..., -0.9750, -0.8364,  0.2310],\n",
       "        [-0.1796, -0.3950, -0.0871,  ..., -0.3676,  0.3723,  0.0281],\n",
       "        [ 0.7756,  0.0282,  0.9532,  ..., -0.9717, -0.0792, -0.1150]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclose = torch.isclose(xrec.data, xx, atol=1e-3)\n",
    "iclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not close tensor(319)\n"
     ]
    }
   ],
   "source": [
    "print(\"Not close\", torch.numel(xx)-torch.count_nonzero(iclose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x2 and 5x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-8bf0619b9c4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x2 and 5x2)"
     ]
    }
   ],
   "source": [
    "A@xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
