{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os, sys, pathlib, random, time, pickle, copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nflib\n",
    "from nflib.flows import SequentialFlow, NormalizingFlow, ActNorm, ActNorm2D, AffineConstantFlow\n",
    "import nflib.coupling_flows as icf\n",
    "import nflib.inn_flow as inn\n",
    "import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(size=32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(\n",
    "#         mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "#         std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "#     ),\n",
    "# ])\n",
    "\n",
    "# cifar_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(\n",
    "#         mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "#         std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "#     ),\n",
    "# ])\n",
    "\n",
    "# train_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=True, download=True, transform=cifar_train)\n",
    "# test_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=False, download=True, transform=cifar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_train = transforms.Compose([\n",
    "    transforms.RandomCrop(size=32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5071, 0.4865, 0.4409],\n",
    "        std=[0.2009, 0.1984, 0.2023],\n",
    "    ),\n",
    "])\n",
    "\n",
    "cifar_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5071, 0.4865, 0.4409],\n",
    "        std=[0.2009, 0.1984, 0.2023],\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root=\"../../../../../_Datasets/cifar100/\", train=True, download=True, transform=cifar_train)\n",
    "test_dataset = datasets.CIFAR100(root=\"../../../../../_Datasets/cifar100/\", train=False, download=True, transform=cifar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 32, 32])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "actf = irf.Swish\n",
    "flows = [\n",
    "#     ActNorm2D(3),\n",
    "    nn.BatchNorm2d(3),\n",
    "    irf.ConvResidualFlow(3, [32, 32], kernels=5, activation=actf),\n",
    "    irf.InvertiblePooling(2),\n",
    "#     ActNorm2D(12),\n",
    "    nn.BatchNorm2d(12),\n",
    "    irf.ConvResidualFlow(12, [64, 64], kernels=5, activation=actf),\n",
    "#     ActNorm2D(12),\n",
    "    nn.BatchNorm2d(12),\n",
    "    irf.ConvResidualFlow(12, [64, 64], kernels=5, activation=actf),\n",
    "    irf.InvertiblePooling(2),\n",
    "#     ActNorm2D(48),\n",
    "    nn.BatchNorm2d(48),\n",
    "    irf.ConvResidualFlow(48, [128, 128], kernels=5, activation=actf),\n",
    "#     ActNorm2D(48),\n",
    "    nn.BatchNorm2d(48),\n",
    "    irf.ConvResidualFlow(48, [128, 128], kernels=5, activation=actf),\n",
    "    irf.InvertiblePooling(2),\n",
    "#     ActNorm2D(192),\n",
    "    nn.BatchNorm2d(192),\n",
    "    irf.ConvResidualFlow(192, [256, 256], kernels=5, activation=actf),\n",
    "#     ActNorm2D(192),\n",
    "    nn.BatchNorm2d(192),\n",
    "    irf.ConvResidualFlow(192, [256, 256], kernels=5, activation=actf),\n",
    "    nn.BatchNorm2d(192),\n",
    "    irf.Flatten(img_size=(192, 4, 4)),\n",
    "#     ActNorm(3072),\n",
    "#     nn.BatchNorm1d(3072),\n",
    "#     nn.Linear(3072, 3072, bias=False),\n",
    "    nn.BatchNorm1d(3072),\n",
    "        ]\n",
    "\n",
    "# backbone = SequentialFlow(flows)\n",
    "backbone = nn.Sequential(*flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): ConvResidualFlow(\n",
       "    (resblock): ModuleList(\n",
       "      (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): Swish()\n",
       "      (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): Swish()\n",
       "      (4): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (2): InvertiblePooling()\n",
       "  (3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): ConvResidualFlow(\n",
       "    (resblock): ModuleList(\n",
       "      (0): Conv2d(12, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): Swish()\n",
       "      (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): Swish()\n",
       "      (4): Conv2d(64, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (5): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ConvResidualFlow(\n",
       "    (resblock): ModuleList(\n",
       "      (0): Conv2d(12, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): Swish()\n",
       "      (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): Swish()\n",
       "      (4): Conv2d(64, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (7): InvertiblePooling()\n",
       "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): ConvResidualFlow(\n",
       "    (resblock): ModuleList(\n",
       "      (0): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): Swish()\n",
       "      (2): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): Swish()\n",
       "      (4): Conv2d(128, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (10): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): ConvResidualFlow(\n",
       "    (resblock): ModuleList(\n",
       "      (0): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): Swish()\n",
       "      (2): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): Swish()\n",
       "      (4): Conv2d(128, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (12): InvertiblePooling()\n",
       "  (13): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ConvResidualFlow(\n",
       "    (resblock): ModuleList(\n",
       "      (0): Conv2d(192, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): Swish()\n",
       "      (2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): Swish()\n",
       "      (4): Conv2d(256, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (15): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): ConvResidualFlow(\n",
       "    (resblock): ModuleList(\n",
       "      (0): Conv2d(192, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): Swish()\n",
       "      (2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): Swish()\n",
       "      (4): Conv2d(256, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (17): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): Flatten()\n",
       "  (19): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone(xx.to(device)).shape, 32*32*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  9947519\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in backbone.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(module):\n",
    "    child = list(module.children())\n",
    "    if len(child) == 0:\n",
    "        return [module]\n",
    "    children = []\n",
    "    for ch in child:\n",
    "        grand_ch = get_children(ch)\n",
    "        children+=grand_ch\n",
    "    return children\n",
    "\n",
    "def remove_spectral_norm(model):\n",
    "    for child in get_children(model):\n",
    "        if hasattr(child, 'weight'):\n",
    "            print(\"Yes\", child)\n",
    "            try:\n",
    "                nn.utils.remove_spectral_norm(child)\n",
    "                print(\"Success\")\n",
    "            except:\n",
    "                print(\"Failed\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Failed\n",
      "Yes Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Failed\n",
      "Yes Conv2d(12, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(64, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Failed\n",
      "Yes Conv2d(12, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(64, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Failed\n",
      "Yes Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(128, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Failed\n",
      "Yes Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(128, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Failed\n",
      "Yes Conv2d(192, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(256, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Failed\n",
      "Yes Conv2d(192, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes Conv2d(256, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Success\n",
      "Yes BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Failed\n",
      "Yes BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Failed\n"
     ]
    }
   ],
   "source": [
    "remove_spectral_norm(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32]) torch.Size([128, 3072])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    tt = backbone(xx.to(device))\n",
    "    print(xx.shape, tt.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_Linear(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.linear = nn.Linear(input_dim, num_sets)\n",
    "#         self.linear.bias.data *= 0\n",
    "#         self.linear.weight.data *= 0.1\n",
    "#         self.cls_weight = nn.Parameter(torch.randn(num_sets, output_dim)/output_dim)\n",
    "\n",
    "        init_val = torch.randn(num_sets, output_dim)\n",
    "        for ns in range(num_sets):\n",
    "            init_val[ns, ns%output_dim] = 5\n",
    "        self.cls_weight = nn.Parameter(init_val)\n",
    "        \n",
    "        self.cls_confidence = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "#         self.cls_weight.data = torch.abs(self.cls_weight.data/self.cls_weight.data.sum(dim=1, keepdim=True))\n",
    "        \n",
    "        x = self.linear(x)*torch.exp(self.inv_temp)\n",
    "        if hard:\n",
    "            x = torch.softmax(x*1e5, dim=1)\n",
    "        else:\n",
    "            x = torch.softmax(x, dim=1)\n",
    "#             x = torch.softmax(x*self.inv_temp, dim=1)\n",
    "        self.cls_confidence = x\n",
    "#         c = torch.softmax(self.cls_weight, dim=1)\n",
    "        c = self.cls_weight\n",
    "        return x@c ## since both are normalized, it is also normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_SoftKMeans(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.centers = nn.Parameter(torch.rand(num_sets, input_dim)*2-1)\n",
    "        \n",
    "#         self.cls_weight = nn.Parameter(torch.ones(num_sets, output_dim)/output_dim)\n",
    "\n",
    "        init_val = torch.randn(num_sets, output_dim)\n",
    "        for ns in range(num_sets):\n",
    "            init_val[ns, ns%output_dim] = 5\n",
    "        self.cls_weight = nn.Parameter(init_val)\n",
    "\n",
    "        self.cls_confidence = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "#         self.cls_weight.data = torch.abs(self.cls_weight.data/self.cls_weight.data.sum(dim=1, keepdim=True))\n",
    "        \n",
    "        dists = torch.cdist(x, self.centers)\n",
    "        ### correction to make diagonal of unit square 1 in nD space\n",
    "        dists = dists/np.sqrt(self.input_dim)\n",
    "        dists = dists*torch.exp(self.inv_temp)\n",
    "#         dists = dists/self.input_dim\n",
    "#         dists = dists/dists.norm(dim=1, keepdim=True)\n",
    "        if hard:\n",
    "            x = torch.softmax(-dists*1e5, dim=1)\n",
    "        else:\n",
    "            x = torch.softmax(-dists, dim=1)\n",
    "#             x = torch.softmax(-dists*self.inv_temp, dim=1)\n",
    "        self.cls_confidence = x\n",
    "#         c = torch.softmax(self.cls_weight, dim=1)\n",
    "        c = self.cls_weight\n",
    "        return x@c ## since both are normalized, it is also normalized\n",
    "#         return torch.softmax(x@self.cls_weight, dim=1)\n",
    "\n",
    "    def set_centroid_to_data_randomly(self, data_loader, model):\n",
    "        num_centers = self.centers.shape[0]\n",
    "        xxs, yys = [], []\n",
    "        count = 0\n",
    "        for xx, yy in data_loader:\n",
    "            yout = model(xx.to(device)).data.cpu()\n",
    "            xxs.append(yout)\n",
    "            yys.append(yy)\n",
    "            count += len(xx)\n",
    "            if count >= num_centers:\n",
    "                break\n",
    "        \n",
    "        yout = torch.cat(xxs, dim=0)\n",
    "        yy = torch.cat(yys, dim=0)\n",
    "        \n",
    "        yout = yout[:num_centers].to(self.centers.device)\n",
    "        yy = yy[:num_centers].to(self.centers.device)\n",
    "        \n",
    "        self.centers.data = yout\n",
    "        \n",
    "        init_val = torch.randn(self.num_sets, self.output_dim)#/self.output_dim\n",
    "        for ns in range(num_centers):\n",
    "            init_val[ns, yy[ns]] = 5.\n",
    "        self.cls_weight.data = init_val.to(self.cls_weight.device)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### for cifar 10\n",
    "# classifier = ConnectedClassifier_SoftKMeans(3072, 100, 10)\n",
    "# classifier = ConnectedClassifier_Linear(3072, 100, 10)\n",
    "\n",
    "#### for cifar 100\n",
    "# classifier = ConnectedClassifier_SoftKMeans(3072, 500, 100, inv_temp=0.8)\n",
    "classifier = ConnectedClassifier_Linear(3072, 500, 100, inv_temp=0)\n",
    "# classifier = ConnectedClassifier_Linear(3072, 500, 100, )\n",
    "\n",
    "#### for MLP based classification\n",
    "# classifier = nn.Sequential(nn.Linear(3072, 500), nn.SELU(), nn.Linear(500, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  9947519\n",
      "number of params:  1586501\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in backbone.parameters()))\n",
    "print(\"number of params: \", sum(p.numel() for p in classifier.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### debug linear classifier\n",
    "yout = classifier(torch.randn(10, 3072).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([-5.1136e-02, -3.9579e-02, -3.8149e-02, -3.8140e-02, -3.6784e-02,\n",
       "        -3.5998e-02, -3.3601e-02, -3.0321e-02, -2.8377e-02, -2.2965e-02,\n",
       "        -1.9536e-02, -1.7964e-02, -1.7334e-02, -1.4202e-02,  3.8575e-05,\n",
       "         1.0551e-03,  1.8266e-03,  3.8670e-03,  7.4088e-03,  7.6089e-03,\n",
       "         7.9190e-03,  7.9490e-03,  9.0643e-03,  9.1031e-03,  1.0729e-02,\n",
       "         1.6859e-02,  1.7508e-02,  1.7537e-02,  1.8479e-02,  1.8817e-02,\n",
       "         2.5470e-02,  2.6183e-02,  2.6191e-02,  2.6932e-02,  2.7852e-02,\n",
       "         3.1330e-02,  3.1937e-02,  3.4138e-02,  3.5556e-02,  3.5566e-02,\n",
       "         3.7072e-02,  4.0023e-02,  4.0107e-02,  4.1044e-02,  4.4740e-02,\n",
       "         4.7292e-02,  4.7450e-02,  4.9267e-02,  5.1015e-02,  5.1817e-02,\n",
       "         5.2204e-02,  5.2969e-02,  5.3234e-02,  5.4429e-02,  5.6425e-02,\n",
       "         5.7116e-02,  5.7443e-02,  5.8323e-02,  6.1053e-02,  6.1151e-02,\n",
       "         6.1378e-02,  6.1871e-02,  6.2040e-02,  6.2043e-02,  6.2455e-02,\n",
       "         6.2472e-02,  6.5861e-02,  6.7247e-02,  6.9726e-02,  7.0210e-02,\n",
       "         7.2516e-02,  7.3538e-02,  7.5189e-02,  7.5547e-02,  7.8014e-02,\n",
       "         7.9312e-02,  7.9920e-02,  8.0336e-02,  8.5460e-02,  9.2729e-02,\n",
       "         9.7630e-02,  1.0523e-01,  1.0588e-01,  1.0653e-01,  1.0731e-01,\n",
       "         1.1127e-01,  1.1353e-01,  1.1663e-01,  1.2261e-01,  1.2301e-01,\n",
       "         1.2512e-01,  1.2904e-01,  1.3639e-01,  1.3819e-01,  1.3869e-01,\n",
       "         1.4142e-01,  1.4882e-01,  1.4989e-01,  1.5649e-01,  1.6210e-01],\n",
       "       device='cuda:1', grad_fn=<SortBackward0>),\n",
       "indices=tensor([66, 58, 37,  4,  0, 31, 54, 34, 63, 19, 60, 44, 17, 69, 72, 90, 59, 78,\n",
       "        48, 53, 26, 65, 64,  1, 57, 27, 38, 10, 16, 52,  2, 75, 18, 92,  7, 79,\n",
       "        35, 70, 47, 85, 68, 97, 25, 28,  8, 33, 98, 29, 61, 46, 71, 81, 24, 62,\n",
       "         6, 22, 82, 96, 41, 87, 74, 77, 88, 95, 36, 12,  3, 91, 51, 11,  9, 42,\n",
       "        99,  5, 55, 30, 23, 32, 43, 80, 76, 50, 39, 86, 73, 20, 94, 89, 49, 15,\n",
       "        14, 21, 67, 13, 56, 93, 84, 83, 45, 40], device='cuda:1'))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "yout[i].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([0.0002, 0.0003, 0.0003, 0.0003, 0.0003, 0.0004, 0.0004, 0.0004, 0.0004,\n",
       "        0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0006,\n",
       "        0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
       "        0.0006, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "        0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0008, 0.0008,\n",
       "        0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
       "        0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008,\n",
       "        0.0008, 0.0008, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009,\n",
       "        0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009,\n",
       "        0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0010, 0.0010,\n",
       "        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
       "        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
       "        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
       "        0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011,\n",
       "        0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011,\n",
       "        0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011,\n",
       "        0.0011, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012,\n",
       "        0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012,\n",
       "        0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012,\n",
       "        0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013,\n",
       "        0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0014, 0.0014,\n",
       "        0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014,\n",
       "        0.0014, 0.0014, 0.0014, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n",
       "        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n",
       "        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n",
       "        0.0015, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016,\n",
       "        0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0017, 0.0017, 0.0017,\n",
       "        0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017,\n",
       "        0.0017, 0.0017, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018,\n",
       "        0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018,\n",
       "        0.0018, 0.0018, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019,\n",
       "        0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019,\n",
       "        0.0019, 0.0019, 0.0019, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
       "        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
       "        0.0020, 0.0020, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021,\n",
       "        0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021,\n",
       "        0.0022, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022,\n",
       "        0.0022, 0.0022, 0.0022, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023,\n",
       "        0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023,\n",
       "        0.0023, 0.0023, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.0024,\n",
       "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
       "        0.0026, 0.0026, 0.0026, 0.0026, 0.0026, 0.0026, 0.0027, 0.0027, 0.0027,\n",
       "        0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0027, 0.0027,\n",
       "        0.0027, 0.0027, 0.0027, 0.0028, 0.0028, 0.0028, 0.0028, 0.0028, 0.0028,\n",
       "        0.0028, 0.0028, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0030, 0.0030,\n",
       "        0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0031, 0.0031, 0.0031,\n",
       "        0.0031, 0.0031, 0.0032, 0.0032, 0.0032, 0.0032, 0.0032, 0.0032, 0.0032,\n",
       "        0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0034, 0.0034, 0.0034, 0.0034,\n",
       "        0.0034, 0.0034, 0.0035, 0.0035, 0.0035, 0.0035, 0.0035, 0.0035, 0.0036,\n",
       "        0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0037, 0.0037, 0.0037, 0.0038,\n",
       "        0.0038, 0.0038, 0.0038, 0.0038, 0.0039, 0.0039, 0.0039, 0.0039, 0.0039,\n",
       "        0.0039, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0041, 0.0041, 0.0041,\n",
       "        0.0041, 0.0041, 0.0042, 0.0042, 0.0042, 0.0042, 0.0043, 0.0043, 0.0043,\n",
       "        0.0044, 0.0044, 0.0044, 0.0044, 0.0045, 0.0045, 0.0046, 0.0047, 0.0048,\n",
       "        0.0049, 0.0050, 0.0052, 0.0052, 0.0052, 0.0053, 0.0054, 0.0056, 0.0057,\n",
       "        0.0058, 0.0060, 0.0074, 0.0080, 0.0085], device='cuda:1',\n",
       "       grad_fn=<SortBackward0>),\n",
       "indices=tensor([318, 429, 252, 428, 254,  90, 258, 248, 385,  80, 324, 285, 141, 231,\n",
       "         70,  75, 441, 119, 482, 347, 406, 129, 353,  49, 171,  77, 372, 189,\n",
       "        472, 326, 483, 366, 183, 100,  57, 200,  51, 166, 360,  61, 361, 113,\n",
       "        331, 382, 431, 269,  35,  69,  72, 381, 417, 369, 351, 142, 178, 356,\n",
       "         25,  37, 473,  13, 259, 432, 222,  36, 424, 365, 304, 470, 150, 134,\n",
       "        401, 491, 225, 334, 236, 221,  38, 462, 290, 292, 437, 156, 190, 474,\n",
       "        405,  31, 267, 392, 404, 271, 250, 153, 112, 337,  99,  62,   5, 158,\n",
       "        398,  21,  71, 451, 240,  74, 176, 316, 103, 244, 386, 426, 414,  85,\n",
       "        111, 338, 165, 251, 301, 475, 229, 246, 163, 149, 362, 389, 210, 127,\n",
       "        440, 412, 448, 228, 110, 195, 376,  97, 357, 128,  34, 102,  15, 204,\n",
       "         73,  19,  46, 484, 328, 177, 174, 233, 342,  54,   1, 311,  96, 218,\n",
       "         39,  79, 330, 443, 492,  10, 410, 454, 439, 314, 160, 370, 397, 466,\n",
       "        202, 377, 355, 433,  60, 402, 253, 379,  44, 197, 216, 341, 313, 278,\n",
       "        133, 107, 239, 237, 478,  43, 115,  20, 447, 368, 384, 436,  28, 321,\n",
       "        117, 476, 363, 329,  81, 339, 179, 378, 146,  29, 348,  68,  45, 205,\n",
       "        109,  91, 449, 151,  27, 123, 227, 444, 352, 450, 456, 155,  83, 132,\n",
       "        407, 345,  24,  86, 388, 140, 319, 302, 358, 125,  95, 317, 169, 226,\n",
       "        497, 391, 241, 114, 327, 126, 124,  89,  78,  64, 422, 425, 247, 498,\n",
       "        394, 305, 435, 308,  59, 249,  63, 458, 299, 297, 203, 265, 364, 130,\n",
       "        198,  33, 191, 193, 199,  94, 420, 279, 315, 496, 416, 219, 277, 481,\n",
       "        415, 145, 281, 383,   6,  65, 194, 243, 332, 459, 201, 469,  93, 185,\n",
       "        188, 427, 284, 196, 223, 108, 144,  50, 101,  55, 147, 273, 143, 396,\n",
       "        403, 206,  98, 192,  41, 116, 471, 286, 423, 487, 245,  82, 371, 421,\n",
       "        276, 137, 154, 296, 105, 463, 413,  22,   4, 418, 121, 170, 490, 343,\n",
       "        152, 309, 486, 242,  88, 255,  66,  53, 275, 452, 104, 208, 468, 135,\n",
       "         42, 263, 354, 139, 393, 346, 460, 181, 264, 235, 106, 434, 280, 387,\n",
       "        395, 461,  48,  76, 234, 118, 120, 399, 344, 303, 182,   7, 274, 261,\n",
       "         47, 211, 136, 148, 442, 266, 494, 446, 480, 293, 409, 457, 295, 325,\n",
       "        217, 180, 164, 220, 207, 489, 257,  52, 430,  67,  92, 157,  87,   8,\n",
       "         26, 131, 187, 493,  16, 349, 374,   0, 289, 184, 283,  12, 320, 172,\n",
       "         30, 359, 350, 465, 455, 499, 232, 260, 212,  23, 298, 300, 373,  40,\n",
       "        294,  17, 400, 209, 333, 408,   9, 419, 175, 288, 162, 453, 340, 336,\n",
       "        390, 438, 159, 335,   2, 168, 312, 268, 306, 323, 367, 262, 167,  18,\n",
       "         14,   3, 173, 307, 495, 464, 488, 291, 256,  11, 322, 138, 445, 224,\n",
       "        161, 380, 272,  58, 310, 375, 282,  84, 230, 238, 479, 287, 270, 213,\n",
       "        477, 186, 467,  56, 215, 214, 411,  32, 485, 122], device='cuda:1'))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.cls_confidence[i].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.set_centroid_to_data_randomly(train_loader, backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(backbone, classifier).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  11534020\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## debugging to find the good classifier/output distribution.\n",
    "# model_name = 'c100_inv_v1'## using linear+500 units\n",
    "# model_name = 'c100_inv_v2' ## using dists+500 units\n",
    "# model_name = 'c100_inv_v3' ## using dists+3072 units\n",
    "# model_name = 'c100_inv_v4' ## using linear+3072+unnormalized output units\n",
    "# model_name = 'c100_inv_v5' ## using dists+500+unnormalized output units\n",
    "\n",
    "# model_name = 'c100_inv_v6' ## using linear+500+unnormalized output units\n",
    "model_name = 'c100_ord_v6' ## using linear+500+unnormalized output units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'c10_inv_v0'\n",
    "# model_name = 'c10_ord_v0'\n",
    "# model_name = 'c100_inv_v0'\n",
    "# model_name = 'c100_ord_v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1,\n",
    "#                       momentum=0.9, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) ## lr=0.0001\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('./models'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:38<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 0 Loss: 4.490 | Acc: 4.420 2210/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 4.363 | Acc: 7.490 749/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:38<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 1 Loss: 4.342 | Acc: 7.664 3832/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 1 Loss: 4.261 | Acc: 9.720 972/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:38<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 2 Loss: 4.267 | Acc: 9.412 4706/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 2 Loss: 4.198 | Acc: 11.460 1146/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 3 Loss: 4.210 | Acc: 10.912 5456/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 3 Loss: 4.153 | Acc: 12.590 1259/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 4 Loss: 4.163 | Acc: 12.230 6115/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 4 Loss: 4.104 | Acc: 13.910 1391/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 5 Loss: 4.125 | Acc: 13.208 6604/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 5 Loss: 4.071 | Acc: 14.720 1472/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 6 Loss: 4.095 | Acc: 14.020 7010/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 6 Loss: 4.043 | Acc: 15.480 1548/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 7 Loss: 4.059 | Acc: 14.656 7328/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 7 Loss: 4.015 | Acc: 15.800 1580/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 8 Loss: 4.037 | Acc: 15.100 7550/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 8 Loss: 3.998 | Acc: 16.440 1644/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 9 Loss: 4.008 | Acc: 16.026 8013/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 9 Loss: 3.974 | Acc: 16.970 1697/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 10 Loss: 3.988 | Acc: 16.310 8155/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 10 Loss: 3.959 | Acc: 17.310 1731/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 11 Loss: 3.965 | Acc: 16.696 8348/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 11 Loss: 3.938 | Acc: 17.860 1786/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 12 Loss: 3.942 | Acc: 17.144 8572/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 12 Loss: 3.922 | Acc: 18.150 1815/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 13 Loss: 3.928 | Acc: 17.462 8731/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 13 Loss: 3.907 | Acc: 18.370 1837/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 14 Loss: 3.902 | Acc: 17.974 8987/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 14 Loss: 3.897 | Acc: 18.750 1875/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 15 Loss: 3.885 | Acc: 18.348 9174/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 15 Loss: 3.885 | Acc: 18.760 1876/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 16 Loss: 3.873 | Acc: 18.526 9263/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 16 Loss: 3.881 | Acc: 18.840 1884/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 17 Loss: 3.851 | Acc: 19.182 9591/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 17 Loss: 3.867 | Acc: 19.100 1910/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 18 Loss: 3.836 | Acc: 19.338 9669/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 18 Loss: 3.851 | Acc: 19.540 1954/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 19 Loss: 3.816 | Acc: 19.834 9917/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 19 Loss: 3.831 | Acc: 20.020 2002/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 20 Loss: 3.799 | Acc: 20.184 10092/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 20 Loss: 3.827 | Acc: 19.890 1989/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 21 Loss: 3.782 | Acc: 20.418 10209/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 21 Loss: 3.820 | Acc: 20.030 2003/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 22 Loss: 3.767 | Acc: 20.886 10443/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 22 Loss: 3.815 | Acc: 19.910 1991/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 23 Loss: 3.759 | Acc: 21.020 10510/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 23 Loss: 3.796 | Acc: 20.480 2048/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 24 Loss: 3.738 | Acc: 21.296 10648/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 24 Loss: 3.788 | Acc: 20.390 2039/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 25 Loss: 3.731 | Acc: 21.532 10766/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 25 Loss: 3.782 | Acc: 20.630 2063/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 26 Loss: 3.715 | Acc: 21.712 10856/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 26 Loss: 3.772 | Acc: 20.930 2093/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 27 Loss: 3.694 | Acc: 22.302 11151/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 27 Loss: 3.762 | Acc: 20.840 2084/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 28 Loss: 3.681 | Acc: 22.468 11234/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 28 Loss: 3.751 | Acc: 21.120 2112/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 29 Loss: 3.668 | Acc: 22.826 11413/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 29 Loss: 3.747 | Acc: 21.270 2127/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 30 Loss: 3.659 | Acc: 22.982 11491/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 30 Loss: 3.743 | Acc: 21.260 2126/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 31 Loss: 3.645 | Acc: 23.376 11688/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 31 Loss: 3.737 | Acc: 21.080 2108/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 32 Loss: 3.633 | Acc: 23.282 11641/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 32 Loss: 3.732 | Acc: 21.840 2184/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 33 Loss: 3.617 | Acc: 23.778 11889/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 33 Loss: 3.726 | Acc: 21.500 2150/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 34 Loss: 3.601 | Acc: 23.996 11998/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 34 Loss: 3.714 | Acc: 21.840 2184/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 35 Loss: 3.593 | Acc: 24.250 12125/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 35 Loss: 3.713 | Acc: 22.130 2213/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 36 Loss: 3.577 | Acc: 24.476 12238/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 36 Loss: 3.689 | Acc: 22.570 2257/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 37 Loss: 3.562 | Acc: 24.966 12483/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 37 Loss: 3.694 | Acc: 22.350 2235/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 38 Loss: 3.554 | Acc: 24.986 12493/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 38 Loss: 3.688 | Acc: 22.700 2270/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 39 Loss: 3.545 | Acc: 25.160 12580/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 39 Loss: 3.694 | Acc: 21.970 2197/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 40 Loss: 3.529 | Acc: 25.454 12727/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 40 Loss: 3.685 | Acc: 22.520 2252/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 41 Loss: 3.525 | Acc: 25.618 12809/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 41 Loss: 3.682 | Acc: 22.670 2267/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 42 Loss: 3.505 | Acc: 25.918 12959/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 42 Loss: 3.664 | Acc: 23.190 2319/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:39<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 43 Loss: 3.495 | Acc: 26.254 13127/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 43 Loss: 3.667 | Acc: 22.730 2273/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████▉    | 360/391 [00:36<00:03,  9.93it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Train the whole damn thing\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, start_epoch\u001b[38;5;241m+\u001b[39mEPOCHS): \u001b[38;5;66;03m## for 200 epochs\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     test(epoch)\n\u001b[1;32m      6\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 18\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Train the whole damn thing\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+EPOCHS): ## for 200 epochs\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.25"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(810)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## C10\n",
    "\n",
    "#### non-inv nn with MLP classifier: 85.73 Acc ; using no-spectral init\n",
    "#### non-inv nn with connected classifier:   Acc ; using no-spectral init\n",
    "#### inv nn with connected classifier: 84.25 Acc ; spectral normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## C100\n",
    "#### inv nn with MLP classifier: 59.3 Acc ;\n",
    "#### non-inv nn with MLP classifier: 54.67 Acc ;\n",
    "\n",
    "#### inv nn + ConnectedDist: 30.03 Acc; -> v2\n",
    "#### inv nn + ConnectedLin: 48.79 Acc; -> v1\n",
    "\n",
    "#### inv nn + ConnectedLin-3072: 46.82 Acc; v3\n",
    "#### inv nn + ConnectedLin-3072-unnormalized: 55.54 Acc / 54.97 (Hard); v4\n",
    "\n",
    "#### inv nn + ConnectedLin-500-unnormalized: 57.25 Acc / 56.83 (Hard); v6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.3377], device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.inv_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57.25, 160)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "best_acc = checkpoint['acc']\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "best_acc, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone, classifier = model[0], model[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard test accuracy with count per classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 26.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Test Acc:56.83%\n",
      "[98, 0, 1, 20, 77, 0, 3, 2, 0, 1, 48, 12, 79, 0, 0, 94, 14, 0, 4, 10, 0, 21, 1, 98, 94, 13, 72, 56, 72, 15, 0, 0, 0, 1, 2, 7, 86, 0, 0, 0, 4, 0, 1, 0, 3, 67, 4, 42, 1, 0, 1, 82, 0, 107, 0, 31, 0, 0, 90, 102, 1, 1, 6, 0, 10, 43, 4, 0, 105, 2, 86, 102, 21, 0, 0, 0, 1, 0, 25, 80, 1, 1, 2, 8, 61, 0, 0, 0, 3, 101, 1, 8, 82, 49, 1, 0, 0, 6, 1, 66, 6, 2, 1, 1, 20, 1, 0, 0, 66, 77, 3, 2, 1, 83, 0, 3, 2, 0, 8, 0, 2, 0, 57, 8, 0, 24, 3, 0, 4, 56, 0, 3, 5, 66, 81, 0, 8, 92, 102, 16, 5, 1, 10, 0, 50, 0, 0, 48, 110, 0, 4, 5, 0, 3, 0, 26, 0, 6, 4, 12, 0, 13, 90, 54, 0, 1, 48, 3, 0, 0, 0, 0, 28, 3, 14, 0, 108, 1, 2, 0, 82, 9, 0, 1, 1, 6, 4, 0, 0, 12, 98, 45, 2, 3, 0, 38, 0, 63, 3, 1, 0, 1, 1, 9, 5, 87, 0, 0, 0, 1, 29, 3, 0, 9, 8, 1, 75, 0, 0, 0, 11, 0, 2, 0, 6, 3, 0, 1, 20, 0, 80, 3, 56, 6, 18, 8, 0, 3, 0, 1, 4, 84, 0, 0, 4, 9, 0, 7, 1, 85, 86, 7, 95, 0, 2, 1, 97, 4, 1, 0, 94, 0, 0, 14, 3, 72, 2, 0, 0, 94, 3, 0, 41, 10, 73, 102, 18, 0, 9, 2, 20, 1, 0, 93, 25, 0, 5, 42, 74, 1, 1, 53, 0, 7, 0, 0, 0, 42, 1, 2, 1, 85, 107, 66, 0, 4, 95, 81, 0, 5, 0, 0, 7, 4, 1, 1, 1, 0, 83, 0, 90, 86, 34, 2, 1, 50, 5, 12, 3, 8, 14, 82, 7, 9, 1, 0, 0, 0, 0, 90, 10, 1, 2, 4, 3, 0, 10, 0, 2, 0, 7, 9, 21, 0, 99, 47, 0, 2, 0, 2, 0, 0, 0, 0, 66, 1, 8, 39, 1, 0, 8, 0, 35, 72, 0, 0, 3, 32, 3, 4, 0, 95, 101, 5, 8, 0, 0, 69, 0, 1, 6, 9, 20, 1, 0, 63, 99, 0, 0, 5, 0, 6, 1, 5, 3, 1, 7, 29, 28, 12, 6, 72, 21, 0, 68, 7, 1, 91, 2, 84, 1, 0, 5, 0, 0, 3, 12, 0, 0, 0, 3, 1, 31, 0, 0, 88, 9, 1, 6, 1, 75, 0, 76, 87, 40, 4, 76, 0, 4, 0, 1, 0, 0, 0, 0, 11, 2, 77, 0, 0, 2, 82, 13, 7, 1, 15, 51, 55, 0, 5, 0, 0, 0, 0, 0, 0, 2, 66, 69, 11, 1, 0, 0, 3, 0, 90, 82, 0, 0, 1, 0, 6, 2, 41, 106, 15, 0, 5, 91, 40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "test_acc = 0\n",
    "set_count = torch.zeros(classifier.num_sets).to(device)\n",
    "model.eval()\n",
    "for xx, yy in tqdm(test_loader):\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    with torch.no_grad():\n",
    "        yout = classifier(backbone(xx), hard=True)\n",
    "        set_indx, count = torch.unique(torch.argmax(classifier.cls_confidence, dim=1), return_counts=True) \n",
    "        set_count[set_indx] += count\n",
    "    outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "    test_acc += correct\n",
    "    test_count += len(xx)\n",
    "\n",
    "print(f'Hard Test Acc:{float(test_acc)/test_count*100:.2f}%')\n",
    "print(set_count.type(torch.long).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Classifiers that enclose any data\n",
    "torch.count_nonzero(set_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard train accuracy with count per classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:29<00:00, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Train Acc:91.31%\n",
      "[0, 0, 0, 0, 4452, 25, 4597, 0, 4948, 0, 0, 0, 0, 162, 0, 0, 0, 0, 0, 4909, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5013, 4926, 0, 56, 0, 5022, 4125, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 0, 5073, 38, 4, 158, 0, 0, 0, 0, 0, 60, 9, 84, 0, 0, 119, 4967, 0, 25, 0, 0, 0, 0, 0, 0, 0, 0, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 284, 0, 0, 0, 0, 0, 888, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "test_acc = 0\n",
    "set_count = torch.zeros(classifier.num_sets).to(device)\n",
    "for xx, yy in tqdm(train_loader):\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    with torch.no_grad():\n",
    "        yout = classifier(backbone(xx), hard=True)\n",
    "        set_indx, count = torch.unique(torch.argmax(classifier.cls_confidence, dim=1), return_counts=True) \n",
    "        set_count[set_indx] += count\n",
    "    outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "    test_acc += correct\n",
    "    test_count += len(xx)\n",
    "\n",
    "print(f'Hard Train Acc:{float(test_acc)/test_count*100:.2f}%')\n",
    "print(set_count.type(torch.long).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26, device='cuda:1')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Classifiers that enclose any data\n",
    "torch.count_nonzero(set_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 3, 7, 9, 5, 0, 2, 3, 3, 3, 7, 7, 5, 3, 5, 6, 3, 1, 8, 7, 3, 1, 5, 2,\n",
       "        3, 3, 3, 1, 6, 2, 1, 1, 5, 6, 9, 9, 2, 3, 4, 8, 3, 9, 8, 3, 5, 9, 9, 8,\n",
       "        3, 2, 2, 1, 8, 8, 8, 0, 6, 7, 2, 3, 5, 7, 0, 9, 1, 0, 6, 6, 5, 4, 1, 1,\n",
       "        9, 8, 2, 5, 1, 1, 7, 7, 8, 9, 2, 2, 9, 0, 9, 5, 4, 3, 3, 1, 5, 1, 5, 4,\n",
       "        5, 9, 8, 5], device='cuda:1')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### classifier with class representation\n",
    "torch.argmax(classifier.cls_weight, dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.4"
=======
   "version": "3.9.7"
>>>>>>> c4048bcce8322b266da868c682dfb6916eb49e64
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
