{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairWeight(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        assert input_dim%2 == 0, \"Input dim must be even number\"\n",
    "        self.weight = torch.eye(2).unsqueeze(0).repeat_interleave(input_dim//2, dim=0)\n",
    "        self.weight = nn.Parameter(self.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, dim = x.shape[0], x.shape[1]\n",
    "        x = x.view(bs, -1, 2).transpose(0,1)\n",
    "        x = torch.bmm(x, self.weight)\n",
    "        x = x.transpose(1,0).reshape(bs, -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairW = PairWeight(784).to(device)\n",
    "pairW_s = torch.jit.script(pairW)\n",
    "\n",
    "x = torch.randn(1000, 784).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2235, -0.6298,  0.9451,  ..., -0.2658, -1.2232,  1.2944],\n",
       "        [-0.1163,  1.3137, -0.3774,  ..., -1.4213, -0.1092, -1.4871],\n",
       "        [-1.2374,  0.2737,  0.6669,  ..., -0.2756, -1.0252,  0.6792],\n",
       "        ...,\n",
       "        [-0.4211, -1.9955, -2.0891,  ..., -0.8854,  1.2063,  1.6415],\n",
       "        [-0.5472, -0.5235, -0.1416,  ...,  0.9046, -0.0857, -0.6555],\n",
       "        [-0.5857, -0.3508,  2.0595,  ...,  0.3208, -0.7738,  0.7363]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairW(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing my custom cuda code for bmm2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bmm2x2_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMM2x2Function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, weights):\n",
    "        outputs = bmm2x2_cuda.forward(inputs, weights)\n",
    "        ctx.save_for_backward(inputs, weights)\n",
    "        return outputs[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        inputs, weights = ctx.saved_tensors\n",
    "#         del_input, del_weights = bmm2x2_cuda.backward(\n",
    "#             grad_output.contiguous(), \n",
    "#             grad_cell.contiguous(), \n",
    "#             grad_output.contiguous())\n",
    "        del_input, del_weights = bmm2x2_cuda.backward(\n",
    "            inputs, \n",
    "            weights, \n",
    "            grad_output)\n",
    "    \n",
    "        return del_input, del_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairWeight2(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        assert input_dim%2 == 0, \"Input dim must be even number\"\n",
    "        self.weight = torch.eye(2).unsqueeze(0).repeat_interleave(input_dim//2, dim=0)\n",
    "        self.weight = nn.Parameter(self.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, dim = x.shape[0], x.shape[1]\n",
    "        x = x.view(bs, -1, 2)\n",
    "        x = BMM2x2Function.apply(x, self.weight)\n",
    "        x = x.view(bs, -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmm2x2_cuda.forward(torch.randn(10, 2, 2).to(device), torch.randn(10,2,2).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairW2 = PairWeight2(784).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2235, -0.6298,  0.9451,  ..., -0.2658, -1.2232,  1.2944],\n",
       "        [-0.1163,  1.3137, -0.3774,  ..., -1.4213, -0.1092, -1.4871],\n",
       "        [-1.2374,  0.2737,  0.6669,  ..., -0.2756, -1.0252,  0.6792],\n",
       "        ...,\n",
       "        [-0.4211, -1.9955, -2.0891,  ..., -0.8854,  1.2063,  1.6415],\n",
       "        [-0.5472, -0.5235, -0.1416,  ...,  0.9046, -0.0857, -0.6555],\n",
       "        [-0.5857, -0.3508,  2.0595,  ...,  0.3208, -0.7738,  0.7363]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairW2(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create sparse matrix row and col\n",
    "N = 784\n",
    "B = 100\n",
    "indices = []\n",
    "for i in range(0, N, 2):\n",
    "    indices.extend([(i,i), (i,i+1), (i+1,i), (i+1,i+1)])\n",
    "indices = np.array(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1568, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = torch.eye(2).unsqueeze(0).repeat_interleave(N//2, dim=0).reshape(-1)\n",
    "# vals = torch.randn(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sW = torch.sparse_coo_tensor(indices.T, vals, size=(N, N)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[  0,   0,   1,  ..., 782, 783, 783],\n",
       "                       [  0,   1,   0,  ..., 783, 782, 783]]),\n",
       "       values=tensor([1., 0., 0.,  ..., 0., 0., 1.]),\n",
       "       device='cuda:0', size=(784, 784), nnz=1568, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(B, N).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt, xt = sW.t(), X.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit (wt@xt).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, dim = X.shape[0], X.shape[1]\n",
    "x = X.view(bs, -1, 2)#.transpose(0,1).contiguous()\n",
    "\n",
    "w = torch.eye(2).unsqueeze(0).repeat_interleave(N//2, dim=0)#.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([392, 2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(device)\n",
    "w = w.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([392, 2, 2]), torch.Size([100, 392, 2]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit BMM2x2Function.apply(x, w).view(bs, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit torch.bmm(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = torch.randn(B, N).to(device)\n",
    "_w = torch.randn(N, N).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit torch.mm(_x, _w)reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## x -> (100, 784) w -> sparse or dense ##########\n",
    "\n",
    "### sparse mm -> 626 µs ± 1.35 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "### BMM2x2 -> 77.7 µs ± 12.4 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "### BMM2x2+contiguous -> 150 µs ± 9.8 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "### BMM2x2+reshape -> 80 µs ± 6.22 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "### torch bmm -> 1.11 ms ± 570 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "### dense mm -> 754 µs ± 283 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "\n",
    "########## x -> (100, 7840)\n",
    "## sparse mm -> 6.1 ms ± 29.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "## BMM2x2 -> 804 µs ± 56.1 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "## Dense -> 70.7 ms ± 3.61 ms per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "\n",
    "\n",
    "########## x -> (1000, 784)\n",
    "## sparse mm -> 3.57 ms ± 80.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "## BMM2x2 -> 801 µs ± 63 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "## Dense -> 4.44 ms ± 2.39 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3629, -0.5071, -0.9541,  ..., -1.2122, -1.5663, -0.4602],\n",
       "        [-0.2374, -0.4753,  1.2988,  ..., -0.8158,  0.7913,  0.1759],\n",
       "        [-0.1011, -1.4976,  0.1732,  ...,  0.6395, -0.5420,  0.5178],\n",
       "        ...,\n",
       "        [-0.0517,  0.0322,  0.0651,  ...,  0.2235, -0.5103,  0.0496],\n",
       "        [-0.4108,  0.6535,  0.2936,  ..., -1.0167, -0.0673,  0.0679],\n",
       "        [ 2.1288,  2.1379, -0.3316,  ...,  1.2718,  0.0641, -0.5905]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ansA = (wt@xt).t()\n",
    "ansA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 784])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ansA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3629, -0.5071, -0.9541,  ..., -1.2122, -1.5663, -0.4602],\n",
       "        [-0.2374, -0.4753,  1.2988,  ..., -0.8158,  0.7913,  0.1759],\n",
       "        [-0.1011, -1.4976,  0.1732,  ...,  0.6395, -0.5420,  0.5178],\n",
       "        ...,\n",
       "        [-0.0517,  0.0322,  0.0651,  ...,  0.2235, -0.5103,  0.0496],\n",
       "        [-0.4108,  0.6535,  0.2936,  ..., -1.0167, -0.0673,  0.0679],\n",
       "        [ 2.1288,  2.1379, -0.3316,  ...,  1.2718,  0.0641, -0.5905]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ansB = BMM2x2Function.apply(x, w).view(bs, -1)\n",
    "ansB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ansB[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ansC = torch.bmm(x, w).transpose(1,0).reshape(bs, -1)\n",
    "# ansC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ansC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3629, -0.5071],\n",
       "         [-0.9541,  0.3553],\n",
       "         [-0.9223, -0.0636],\n",
       "         ...,\n",
       "         [ 0.0351, -0.1227],\n",
       "         [ 0.9231, -1.2122],\n",
       "         [-1.5663, -0.4602]],\n",
       "\n",
       "        [[-0.2374, -0.4753],\n",
       "         [ 1.2988, -1.0792],\n",
       "         [ 0.8484, -2.0350],\n",
       "         ...,\n",
       "         [-0.6424, -0.1664],\n",
       "         [-0.3492, -0.8158],\n",
       "         [ 0.7913,  0.1759]],\n",
       "\n",
       "        [[-0.1011, -1.4976],\n",
       "         [ 0.1732, -0.1137],\n",
       "         [ 1.2251, -0.6367],\n",
       "         ...,\n",
       "         [-1.1096, -0.2325],\n",
       "         [ 0.0678,  0.6395],\n",
       "         [-0.5420,  0.5178]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0517,  0.0322],\n",
       "         [ 0.0651,  0.4915],\n",
       "         [ 2.8140,  1.5796],\n",
       "         ...,\n",
       "         [ 0.6711,  0.4032],\n",
       "         [-1.0173,  0.2235],\n",
       "         [-0.5103,  0.0496]],\n",
       "\n",
       "        [[-0.4108,  0.6535],\n",
       "         [ 0.2936,  0.4095],\n",
       "         [-0.7818, -0.3301],\n",
       "         ...,\n",
       "         [ 1.1950, -0.6354],\n",
       "         [-1.2095, -1.0167],\n",
       "         [-0.0673,  0.0679]],\n",
       "\n",
       "        [[ 2.1288,  2.1379],\n",
       "         [-0.3316, -1.7284],\n",
       "         [-0.3347, -1.9654],\n",
       "         ...,\n",
       "         [-1.1492,  1.8395],\n",
       "         [-1.5587,  1.2718],\n",
       "         [ 0.0641, -0.5905]]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing indices of Bx2x2 array\n",
    "_w = torch.arange(10*2*2).reshape(10,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3]],\n",
       "\n",
       "        [[ 4,  5],\n",
       "         [ 6,  7]],\n",
       "\n",
       "        [[ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15]],\n",
       "\n",
       "        [[16, 17],\n",
       "         [18, 19]],\n",
       "\n",
       "        [[20, 21],\n",
       "         [22, 23]],\n",
       "\n",
       "        [[24, 25],\n",
       "         [26, 27]],\n",
       "\n",
       "        [[28, 29],\n",
       "         [30, 31]],\n",
       "\n",
       "        [[32, 33],\n",
       "         [34, 35]],\n",
       "\n",
       "        [[36, 37],\n",
       "         [38, 39]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_t = sW.to_dense()\n",
    "_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(784., device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(_t == torch.eye(784).to(device)).type(torch.long).sum().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn_like(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Backward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.requires_grad = True\n",
    "w.requires_grad = True\n",
    "\n",
    "x.grad = None\n",
    "w.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3629, -0.5071],\n",
       "         [-0.9541,  0.3553],\n",
       "         [-0.9223, -0.0636],\n",
       "         ...,\n",
       "         [ 0.0351, -0.1227],\n",
       "         [ 0.9231, -1.2122],\n",
       "         [-1.5663, -0.4602]],\n",
       "\n",
       "        [[-0.2374, -0.4753],\n",
       "         [ 1.2988, -1.0792],\n",
       "         [ 0.8484, -2.0350],\n",
       "         ...,\n",
       "         [-0.6424, -0.1664],\n",
       "         [-0.3492, -0.8158],\n",
       "         [ 0.7913,  0.1759]],\n",
       "\n",
       "        [[-0.1011, -1.4976],\n",
       "         [ 0.1732, -0.1137],\n",
       "         [ 1.2251, -0.6367],\n",
       "         ...,\n",
       "         [-1.1096, -0.2325],\n",
       "         [ 0.0678,  0.6395],\n",
       "         [-0.5420,  0.5178]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0517,  0.0322],\n",
       "         [ 0.0651,  0.4915],\n",
       "         [ 2.8140,  1.5796],\n",
       "         ...,\n",
       "         [ 0.6711,  0.4032],\n",
       "         [-1.0173,  0.2235],\n",
       "         [-0.5103,  0.0496]],\n",
       "\n",
       "        [[-0.4108,  0.6535],\n",
       "         [ 0.2936,  0.4095],\n",
       "         [-0.7818, -0.3301],\n",
       "         ...,\n",
       "         [ 1.1950, -0.6354],\n",
       "         [-1.2095, -1.0167],\n",
       "         [-0.0673,  0.0679]],\n",
       "\n",
       "        [[ 2.1288,  2.1379],\n",
       "         [-0.3316, -1.7284],\n",
       "         [-0.3347, -1.9654],\n",
       "         ...,\n",
       "         [-1.1492,  1.8395],\n",
       "         [-1.5587,  1.2718],\n",
       "         [ 0.0641, -0.5905]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = BMM2x2Function.apply(x, w).view(bs, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0022e-04, -1.0022e-04],\n",
       "         [-2.2904e-05, -2.2904e-05]],\n",
       "\n",
       "        [[ 4.1111e-04,  4.1111e-04],\n",
       "         [-8.4858e-05, -8.4858e-05]],\n",
       "\n",
       "        [[ 5.6670e-05,  5.6670e-05],\n",
       "         [-8.6980e-06, -8.6980e-06]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 7.5286e-05,  7.5286e-05],\n",
       "         [ 7.4401e-06,  7.4401e-06]],\n",
       "\n",
       "        [[-1.0035e-04, -1.0035e-04],\n",
       "         [ 2.0920e-05,  2.0920e-05]],\n",
       "\n",
       "        [[-1.6806e-04, -1.6806e-04],\n",
       "         [-3.2195e-05, -3.2195e-05]]], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.7387e-05, -6.3784e-06],\n",
       "         [-1.5906e-05, -4.1040e-05],\n",
       "         [ 4.5410e-05,  5.9082e-08],\n",
       "         ...,\n",
       "         [-3.2505e-05,  3.7755e-06],\n",
       "         [-4.7682e-06, -1.0622e-05],\n",
       "         [-2.4337e-06,  3.5021e-06]],\n",
       "\n",
       "        [[ 2.7387e-05, -6.3784e-06],\n",
       "         [-1.5906e-05, -4.1040e-05],\n",
       "         [ 4.5410e-05,  5.9082e-08],\n",
       "         ...,\n",
       "         [-3.2505e-05,  3.7755e-06],\n",
       "         [-4.7682e-06, -1.0622e-05],\n",
       "         [-2.4337e-06,  3.5021e-06]],\n",
       "\n",
       "        [[ 2.7387e-05, -6.3784e-06],\n",
       "         [-1.5906e-05, -4.1040e-05],\n",
       "         [ 4.5410e-05,  5.9082e-08],\n",
       "         ...,\n",
       "         [-3.2505e-05,  3.7755e-06],\n",
       "         [-4.7682e-06, -1.0622e-05],\n",
       "         [-2.4337e-06,  3.5021e-06]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.7387e-05, -6.3784e-06],\n",
       "         [-1.5906e-05, -4.1040e-05],\n",
       "         [ 4.5410e-05,  5.9082e-08],\n",
       "         ...,\n",
       "         [-3.2505e-05,  3.7755e-06],\n",
       "         [-4.7682e-06, -1.0622e-05],\n",
       "         [-2.4337e-06,  3.5021e-06]],\n",
       "\n",
       "        [[ 2.7387e-05, -6.3784e-06],\n",
       "         [-1.5906e-05, -4.1040e-05],\n",
       "         [ 4.5410e-05,  5.9082e-08],\n",
       "         ...,\n",
       "         [-3.2505e-05,  3.7755e-06],\n",
       "         [-4.7682e-06, -1.0622e-05],\n",
       "         [-2.4337e-06,  3.5021e-06]],\n",
       "\n",
       "        [[ 2.7387e-05, -6.3784e-06],\n",
       "         [-1.5906e-05, -4.1040e-05],\n",
       "         [ 4.5410e-05,  5.9082e-08],\n",
       "         ...,\n",
       "         [-3.2505e-05,  3.7755e-06],\n",
       "         [-4.7682e-06, -1.0622e-05],\n",
       "         [-2.4337e-06,  3.5021e-06]]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgrad = x.grad\n",
    "wgrad = w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test using bmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad = None\n",
    "w.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = torch.bmm(x.transpose(1,0), w).transpose(1,0).reshape(B, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1921e-07,  0.0000e+00,  0.0000e+00,  ..., -5.9605e-08,\n",
       "          2.9802e-08,  0.0000e+00],\n",
       "        [ 1.1176e-08,  0.0000e+00,  0.0000e+00,  ..., -3.7253e-09,\n",
       "          1.4901e-08,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  0.0000e+00, -5.9605e-08,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  2.9802e-08],\n",
       "        [-5.9605e-08, -2.9802e-08,  0.0000e+00,  ...,  2.9802e-08,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-1.1921e-07,  0.0000e+00,  0.0000e+00,  ..., -5.9605e-08,\n",
       "          0.0000e+00,  0.0000e+00]], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.7387e-05, -6.3784e-06],\n",
       "         [-1.5906e-05, -4.1040e-05],\n",
       "         [ 4.5410e-05,  5.9082e-08],\n",
       "         ...,\n",
       "         [-3.2505e-05,  3.7755e-06],\n",
       "         [-4.7682e-06, -1.0622e-05],\n",
       "         [-2.4337e-06,  3.5021e-06]],\n",
       "\n",
       "        [[ 2.7387e-05, -6.3784e-06],\n",
       "         [-1.5906e-05, -4.1040e-05],\n",
       "         [ 4.5410e-05,  5.9082e-08],\n",
       "         ...,\n",
       "         [-3.2505e-05,  3.7755e-06],\n",
       "         [-4.7682e-06, -1.0622e-05],\n",
       "         [-2.4337e-06,  3.5021e-06]],\n",
       "\n",
       "        [[ 2.7387e-05, -6.3784e-06],\n",
       "         [-1.5906e-05, -4.1040e-05],\n",
       "         [ 4.5410e-05,  5.9082e-08],\n",
       "         ...,\n",
       "         [-3.2505e-05,  3.7755e-06],\n",
       "         [-4.7682e-06, -1.0622e-05],\n",
       "         [-2.4337e-06,  3.5021e-06]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.7387e-05, -6.3784e-06],\n",
       "         [-1.5906e-05, -4.1040e-05],\n",
       "         [ 4.5410e-05,  5.9082e-08],\n",
       "         ...,\n",
       "         [-3.2505e-05,  3.7755e-06],\n",
       "         [-4.7682e-06, -1.0622e-05],\n",
       "         [-2.4337e-06,  3.5021e-06]],\n",
       "\n",
       "        [[ 2.7387e-05, -6.3784e-06],\n",
       "         [-1.5906e-05, -4.1040e-05],\n",
       "         [ 4.5410e-05,  5.9082e-08],\n",
       "         ...,\n",
       "         [-3.2505e-05,  3.7755e-06],\n",
       "         [-4.7682e-06, -1.0622e-05],\n",
       "         [-2.4337e-06,  3.5021e-06]],\n",
       "\n",
       "        [[ 2.7387e-05, -6.3784e-06],\n",
       "         [-1.5906e-05, -4.1040e-05],\n",
       "         [ 4.5410e-05,  5.9082e-08],\n",
       "         ...,\n",
       "         [-3.2505e-05,  3.7755e-06],\n",
       "         [-4.7682e-06, -1.0622e-05],\n",
       "         [-2.4337e-06,  3.5021e-06]]], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0022e-04, -1.0022e-04],\n",
       "         [-2.2904e-05, -2.2904e-05]],\n",
       "\n",
       "        [[ 4.1111e-04,  4.1111e-04],\n",
       "         [-8.4858e-05, -8.4858e-05]],\n",
       "\n",
       "        [[ 5.6670e-05,  5.6670e-05],\n",
       "         [-8.6980e-06, -8.6980e-06]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 7.5286e-05,  7.5286e-05],\n",
       "         [ 7.4401e-06,  7.4401e-06]],\n",
       "\n",
       "        [[-1.0035e-04, -1.0035e-04],\n",
       "         [ 2.0920e-05,  2.0920e-05]],\n",
       "\n",
       "        [[-1.6806e-04, -1.6806e-04],\n",
       "         [-3.2195e-05, -3.2195e-05]]], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_allclose(x.grad, xgrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_allclose(w.grad, wgrad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing the backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create sparse matrix row and col\n",
    "N = 784\n",
    "B = 1000\n",
    "indices = []\n",
    "for i in range(0, N, 2):\n",
    "    indices.extend([(i,i), (i,i+1), (i+1,i), (i+1,i+1)])\n",
    "indices = np.array(indices)\n",
    "vals = torch.eye(2).unsqueeze(0).repeat_interleave(N//2, dim=0).reshape(-1)\n",
    "sW = torch.sparse_coo_tensor(indices.T, vals, size=(N, N)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(B, N).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt, xt = sW.t(), X.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, dim = X.shape[0], X.shape[1]\n",
    "x = X.view(bs, -1, 2)#.transpose(0,1).contiguous()\n",
    "w = torch.eye(2).unsqueeze(0).repeat_interleave(N//2, dim=0)#.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt.requires_grad = True\n",
    "xt.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(device)\n",
    "w = w.to(device)\n",
    "w.requires_grad = True\n",
    "x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = torch.randn(B, N).to(device)\n",
    "_w = torch.randn(N, N).to(device)\n",
    "_w.requires_grad = True\n",
    "_x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now perform operation using each method, and then benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y0 = BMM2x2Function.apply(x, w).mean()\n",
    "_y1 = torch.bmm(x.transpose(1,0), w).mean()\n",
    "_y2 = torch.sparse.mm(wt,xt).t().mean()\n",
    "_y3 = torch.mm(_x, _w).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.43 ms ± 119 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _y0.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit _y1.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit _y2.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit _y3.backward(retain_graph=True)\n",
    "# %timeit -n 100 -r 7 _y3.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For N=784, B=1000 ###### sequentially -- bmm2x2, bmm, sparsemm, densemm\n",
    "# 4.75 ms ± 878 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "# 14.4 ms ± 2.44 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "# 6.54 ms ± 250 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# 10.1 ms ± 7.44 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "## BMM2x2 backward_v2\n",
    "# 2.43 ms ± 239 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "\n",
    "### for N=7840, B=100\n",
    "# 4.44 ms ± 502 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "# 19.8 ms ± 3.71 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "# 51 ms ± 745 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# 185 ms ± 66.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "## BMM2x2 backward_v2\n",
    "# 2.32 ms ± 84.4 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "\n",
    "### for N=784, B=100\n",
    "# 413 µs ± 120 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "# 2.12 ms ± 4.34 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "# 1.67 ms ± 87.1 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# 2.13 ms ± 745 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "## BMM2x2 backward_v2\n",
    "# 244 µs ± 75.6 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdfadsfsfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear grad check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://stats.stackexchange.com/questions/358786/mean-or-sum-of-gradients-for-weight-updates-in-sgd\n",
    "### sum or mean for gradient in sgd ?? Ans: Sum on grad, mean on loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = nn.Linear(20, 10, bias=False)\n",
    "x = torch.randn(5, 20)\n",
    "x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin(x).mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgrad = x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgrad = lin.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad = None\n",
    "lin.weight.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x@lin.weight.t()).mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad-xgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.weight.grad-wgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
