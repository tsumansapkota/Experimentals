{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-b22782e32495>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE parameters\n",
    "num_label = 10\n",
    "label_hid1 = 5\n",
    "label_hid2 = 3\n",
    "label_hid3 = 2\n",
    "label_hid4 = 1\n",
    "\n",
    "num_image = 784 # 28*28\n",
    "image_hid1 = 392\n",
    "image_hid2 = 196\n",
    "image_hid3 = 98\n",
    "image_hid4 = 49\n",
    "image_hid5 = 25\n",
    "image_hid6 = 12\n",
    "image_hid7 = 6\n",
    "image_hid8 = 3\n",
    "image_hid9 = 2\n",
    "image_hid10 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tie_weight = tf.transpose\n",
    "act_func = lambda X:X\n",
    "initializer = tf.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLACEHOLDER DEFINATION\n",
    "X = tf.placeholder(tf.float32, shape=[None, num_image])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, num_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Encoded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMAGE COMPRESSION\n",
    "wi1 = tf.Variable(np.load('../save/weights/w1.npy'))\n",
    "wi2 = tf.Variable(np.load('../save/weights/w2.npy'))\n",
    "wi3 = tf.Variable(np.load('../save/weights/w3.npy'))\n",
    "wi4 = tf.Variable(np.load('../save/weights/w4.npy'))\n",
    "wi5 = tf.Variable(np.load('../save/weights/w5.npy'))\n",
    "wi6 = tf.Variable(np.load('../save/weights/w6.npy'))\n",
    "wi7 = tf.Variable(np.load('../save/weights/w7.npy'))\n",
    "wi8 = tf.Variable(np.load('../save/weights/w8.npy'))\n",
    "wi9 = tf.Variable(np.load('../save/weights/w9.npy'))\n",
    "wi10 = tf.Variable(np.load('../save/weights/w10.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_layer1 = act_func(tf.matmul(X, wi1))\n",
    "img_layer2 = act_func(tf.matmul(img_layer1, wi2))\n",
    "img_layer3 = act_func(tf.matmul(img_layer2, wi3))\n",
    "img_layer4 = act_func(tf.matmul(img_layer3, wi4))\n",
    "img_layer5 = act_func(tf.matmul(img_layer4, wi5))\n",
    "img_layer6 = act_func(tf.matmul(img_layer5, wi6))\n",
    "img_layer7 = act_func(tf.matmul(img_layer6, wi7))\n",
    "img_layer8 = act_func(tf.matmul(img_layer7, wi8))\n",
    "img_layer9 = act_func(tf.matmul(img_layer8, wi9))\n",
    "img_layer10 = act_func(tf.matmul(img_layer9, wi10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LABEL DECOMPRESSION\n",
    "wl1 = tf.Variable(np.load('../save/weights/lw1.npy'))\n",
    "wl2 = tf.Variable(np.load('../save/weights/lw2.npy'))\n",
    "wl3 = tf.Variable(np.load('../save/weights/lw3.npy'))\n",
    "wl4 = tf.Variable(np.load('../save/weights/lw4.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_layer1 = act_func(tf.matmul(Y, wl1))\n",
    "lbl_layer2 = act_func(tf.matmul(lbl_layer1, wl2))\n",
    "lbl_layer3 = act_func(tf.matmul(lbl_layer2, wl3))\n",
    "lbl_layer4 = act_func(tf.matmul(lbl_layer3, wl4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Parameters for activation learning\n",
    "initializer = tf.random_normal_initializer()\n",
    "\n",
    "input_no = image_hid10\n",
    "output_no = label_hid4\n",
    "\n",
    "inpt = img_layer10\n",
    "yval = lbl_layer4\n",
    "\n",
    "\n",
    "W1 = tf.Variable(initializer([input_no,155]), dtype=tf.float32)\n",
    "b1 = tf.Variable(tf.zeros([155]), dtype=tf.float32)\n",
    "a1 = tf.nn.relu(tf.matmul(inpt, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(initializer([155, 31]), dtype=tf.float32)\n",
    "b2 = tf.Variable(tf.zeros([31]), dtype=tf.float32)\n",
    "a2 = tf.nn.relu(tf.matmul(a1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(initializer([31,output_no]), dtype=tf.float32)\n",
    "b3 = tf.Variable(tf.zeros([output_no]), dtype=tf.float32)\n",
    "a13 = tf.matmul(a2, W3) + b3\n",
    "\n",
    "output = a13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_14:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Encode-Decode Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_layer1 = tf.matmul(output,tf.transpose(wl4))\n",
    "out_layer2 = tf.matmul(out_layer1,tf.transpose(wl3))\n",
    "out_layer3 = tf.matmul(out_layer2,tf.transpose(wl2))\n",
    "out_layer4 = tf.matmul(out_layer3,tf.transpose(wl1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS FUNCTIONS\n",
    "loss = tf.reduce_mean(tf.square(output - yval))\n",
    "# loss = tf.reduce_mean(tf.abs(output_layer - X))\n",
    "# cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=yout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "learning_rate = 0.00001\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss, var_list=[W1, W2, W3, b1, b2, b3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATION\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Complete. Training Loss: 7226.271484375\n",
      "TEST ACCURACY: \n",
      "0.1118\n",
      "\n",
      "Epoch 1 Complete. Training Loss: 4983.7841796875\n",
      "TEST ACCURACY: \n",
      "0.1104\n",
      "\n",
      "Epoch 2 Complete. Training Loss: 2894.209228515625\n",
      "TEST ACCURACY: \n",
      "0.1071\n",
      "\n",
      "Epoch 3 Complete. Training Loss: 1996.41064453125\n",
      "TEST ACCURACY: \n",
      "0.1039\n",
      "\n",
      "Epoch 4 Complete. Training Loss: 1259.6514892578125\n",
      "TEST ACCURACY: \n",
      "0.0997\n",
      "\n",
      "Epoch 5 Complete. Training Loss: 681.1837768554688\n",
      "TEST ACCURACY: \n",
      "0.0941\n",
      "\n",
      "Epoch 6 Complete. Training Loss: 348.1495666503906\n",
      "TEST ACCURACY: \n",
      "0.0876\n",
      "\n",
      "Epoch 7 Complete. Training Loss: 162.28555297851562\n",
      "TEST ACCURACY: \n",
      "0.078\n",
      "\n",
      "Epoch 8 Complete. Training Loss: 71.76679229736328\n",
      "TEST ACCURACY: \n",
      "0.0702\n",
      "\n",
      "Epoch 9 Complete. Training Loss: 41.97008514404297\n",
      "TEST ACCURACY: \n",
      "0.0678\n",
      "\n",
      "Epoch 10 Complete. Training Loss: 33.8363037109375\n",
      "TEST ACCURACY: \n",
      "0.0874\n",
      "\n",
      "Epoch 11 Complete. Training Loss: 27.84778594970703\n",
      "TEST ACCURACY: \n",
      "0.1056\n",
      "\n",
      "Epoch 12 Complete. Training Loss: 29.237701416015625\n",
      "TEST ACCURACY: \n",
      "0.1143\n",
      "\n",
      "Epoch 13 Complete. Training Loss: 28.44270896911621\n",
      "TEST ACCURACY: \n",
      "0.1181\n",
      "\n",
      "Epoch 14 Complete. Training Loss: 28.217233657836914\n",
      "TEST ACCURACY: \n",
      "0.119\n",
      "\n",
      "Epoch 15 Complete. Training Loss: 35.342472076416016\n",
      "TEST ACCURACY: \n",
      "0.1199\n",
      "\n",
      "Epoch 16 Complete. Training Loss: 31.40998649597168\n",
      "TEST ACCURACY: \n",
      "0.1197\n",
      "\n",
      "Epoch 17 Complete. Training Loss: 29.9035701751709\n",
      "TEST ACCURACY: \n",
      "0.121\n",
      "\n",
      "Epoch 18 Complete. Training Loss: 26.844682693481445\n",
      "TEST ACCURACY: \n",
      "0.1219\n",
      "\n",
      "Epoch 19 Complete. Training Loss: 28.437406539916992\n",
      "TEST ACCURACY: \n",
      "0.1213\n",
      "\n",
      "Epoch 20 Complete. Training Loss: 27.692298889160156\n",
      "TEST ACCURACY: \n",
      "0.1233\n",
      "\n",
      "Epoch 21 Complete. Training Loss: 26.61131477355957\n",
      "TEST ACCURACY: \n",
      "0.1232\n",
      "\n",
      "Epoch 22 Complete. Training Loss: 24.988277435302734\n",
      "TEST ACCURACY: \n",
      "0.1237\n",
      "\n",
      "Epoch 23 Complete. Training Loss: 29.226959228515625\n",
      "TEST ACCURACY: \n",
      "0.125\n",
      "\n",
      "Epoch 24 Complete. Training Loss: 27.537933349609375\n",
      "TEST ACCURACY: \n",
      "0.1248\n",
      "\n",
      "Epoch 25 Complete. Training Loss: 27.66740608215332\n",
      "TEST ACCURACY: \n",
      "0.1266\n",
      "\n",
      "Epoch 26 Complete. Training Loss: 25.25800132751465\n",
      "TEST ACCURACY: \n",
      "0.1263\n",
      "\n",
      "Epoch 27 Complete. Training Loss: 28.055402755737305\n",
      "TEST ACCURACY: \n",
      "0.1265\n",
      "\n",
      "Epoch 28 Complete. Training Loss: 24.0112247467041\n",
      "TEST ACCURACY: \n",
      "0.1295\n",
      "\n",
      "Epoch 29 Complete. Training Loss: 23.755048751831055\n",
      "TEST ACCURACY: \n",
      "0.1348\n",
      "\n",
      "Epoch 30 Complete. Training Loss: 23.711027145385742\n",
      "TEST ACCURACY: \n",
      "0.1376\n",
      "\n",
      "Epoch 31 Complete. Training Loss: 22.85589599609375\n",
      "TEST ACCURACY: \n",
      "0.1509\n",
      "\n",
      "Epoch 32 Complete. Training Loss: 25.16161346435547\n",
      "TEST ACCURACY: \n",
      "0.1645\n",
      "\n",
      "Epoch 33 Complete. Training Loss: 24.67360496520996\n",
      "TEST ACCURACY: \n",
      "0.1722\n",
      "\n",
      "Epoch 34 Complete. Training Loss: 26.128934860229492\n",
      "TEST ACCURACY: \n",
      "0.1749\n",
      "\n",
      "Epoch 35 Complete. Training Loss: 24.659944534301758\n",
      "TEST ACCURACY: \n",
      "0.1769\n",
      "\n",
      "Epoch 36 Complete. Training Loss: 23.6184139251709\n",
      "TEST ACCURACY: \n",
      "0.1773\n",
      "\n",
      "Epoch 37 Complete. Training Loss: 25.830116271972656\n",
      "TEST ACCURACY: \n",
      "0.1758\n",
      "\n",
      "Epoch 38 Complete. Training Loss: 24.7630558013916\n",
      "TEST ACCURACY: \n",
      "0.1766\n",
      "\n",
      "Epoch 39 Complete. Training Loss: 26.026216506958008\n",
      "TEST ACCURACY: \n",
      "0.1774\n",
      "\n",
      "Epoch 40 Complete. Training Loss: 23.135108947753906\n",
      "TEST ACCURACY: \n",
      "0.1773\n",
      "\n",
      "Epoch 41 Complete. Training Loss: 23.519624710083008\n",
      "TEST ACCURACY: \n",
      "0.177\n",
      "\n",
      "Epoch 42 Complete. Training Loss: 22.786069869995117\n",
      "TEST ACCURACY: \n",
      "0.1773\n",
      "\n",
      "Epoch 43 Complete. Training Loss: 24.219379425048828\n",
      "TEST ACCURACY: \n",
      "0.1767\n",
      "\n",
      "Epoch 44 Complete. Training Loss: 25.558673858642578\n",
      "TEST ACCURACY: \n",
      "0.1769\n",
      "\n",
      "Epoch 45 Complete. Training Loss: 22.956514358520508\n",
      "TEST ACCURACY: \n",
      "0.1769\n",
      "\n",
      "Epoch 46 Complete. Training Loss: 25.847414016723633\n",
      "TEST ACCURACY: \n",
      "0.1771\n",
      "\n",
      "Epoch 47 Complete. Training Loss: 23.25659942626953\n",
      "TEST ACCURACY: \n",
      "0.1764\n",
      "\n",
      "Epoch 48 Complete. Training Loss: 24.379100799560547\n",
      "TEST ACCURACY: \n",
      "0.1769\n",
      "\n",
      "Epoch 49 Complete. Training Loss: 25.930498123168945\n",
      "TEST ACCURACY: \n",
      "0.1762\n",
      "\n",
      "Epoch 50 Complete. Training Loss: 24.319068908691406\n",
      "TEST ACCURACY: \n",
      "0.1767\n",
      "\n",
      "Epoch 51 Complete. Training Loss: 22.827831268310547\n",
      "TEST ACCURACY: \n",
      "0.1752\n",
      "\n",
      "Epoch 52 Complete. Training Loss: 24.117952346801758\n",
      "TEST ACCURACY: \n",
      "0.1766\n",
      "\n",
      "Epoch 53 Complete. Training Loss: 24.0507869720459\n",
      "TEST ACCURACY: \n",
      "0.1762\n",
      "\n",
      "Epoch 54 Complete. Training Loss: 23.7666072845459\n",
      "TEST ACCURACY: \n",
      "0.1753\n",
      "\n",
      "Epoch 55 Complete. Training Loss: 24.299564361572266\n",
      "TEST ACCURACY: \n",
      "0.1765\n",
      "\n",
      "Epoch 56 Complete. Training Loss: 23.714794158935547\n",
      "TEST ACCURACY: \n",
      "0.1763\n",
      "\n",
      "Epoch 57 Complete. Training Loss: 24.095352172851562\n",
      "TEST ACCURACY: \n",
      "0.1764\n",
      "\n",
      "Epoch 58 Complete. Training Loss: 23.7271785736084\n",
      "TEST ACCURACY: \n",
      "0.1753\n",
      "\n",
      "Epoch 59 Complete. Training Loss: 27.026004791259766\n",
      "TEST ACCURACY: \n",
      "0.1749\n",
      "\n",
      "Epoch 60 Complete. Training Loss: 24.7126522064209\n",
      "TEST ACCURACY: \n",
      "0.176\n",
      "\n",
      "Epoch 61 Complete. Training Loss: 21.263221740722656\n",
      "TEST ACCURACY: \n",
      "0.1754\n",
      "\n",
      "Epoch 62 Complete. Training Loss: 24.782217025756836\n",
      "TEST ACCURACY: \n",
      "0.1766\n",
      "\n",
      "Epoch 63 Complete. Training Loss: 21.978952407836914\n",
      "TEST ACCURACY: \n",
      "0.1763\n",
      "\n",
      "Epoch 64 Complete. Training Loss: 26.649572372436523\n",
      "TEST ACCURACY: \n",
      "0.1752\n",
      "\n",
      "Epoch 65 Complete. Training Loss: 25.315052032470703\n",
      "TEST ACCURACY: \n",
      "0.1756\n",
      "\n",
      "Epoch 66 Complete. Training Loss: 23.27486801147461\n",
      "TEST ACCURACY: \n",
      "0.1769\n",
      "\n",
      "Epoch 67 Complete. Training Loss: 24.241512298583984\n",
      "TEST ACCURACY: \n",
      "0.1763\n",
      "\n",
      "Epoch 68 Complete. Training Loss: 23.30596160888672\n",
      "TEST ACCURACY: \n",
      "0.1717\n",
      "\n",
      "Epoch 69 Complete. Training Loss: 24.20307731628418\n",
      "TEST ACCURACY: \n",
      "0.1751\n",
      "\n",
      "Epoch 70 Complete. Training Loss: 23.143007278442383\n",
      "TEST ACCURACY: \n",
      "0.1743\n",
      "\n",
      "Epoch 71 Complete. Training Loss: 26.462007522583008\n",
      "TEST ACCURACY: \n",
      "0.171\n",
      "\n",
      "Epoch 72 Complete. Training Loss: 25.45891761779785\n",
      "TEST ACCURACY: \n",
      "0.1718\n",
      "\n",
      "Epoch 73 Complete. Training Loss: 21.786975860595703\n",
      "TEST ACCURACY: \n",
      "0.1748\n",
      "\n",
      "Epoch 74 Complete. Training Loss: 25.601388931274414\n",
      "TEST ACCURACY: \n",
      "0.1751\n",
      "\n",
      "Epoch 75 Complete. Training Loss: 24.591630935668945\n",
      "TEST ACCURACY: \n",
      "0.1728\n",
      "\n",
      "Epoch 76 Complete. Training Loss: 23.20180892944336\n",
      "TEST ACCURACY: \n",
      "0.1727\n",
      "\n",
      "Epoch 77 Complete. Training Loss: 22.073265075683594\n",
      "TEST ACCURACY: \n",
      "0.1684\n",
      "\n",
      "Epoch 78 Complete. Training Loss: 25.230918884277344\n",
      "TEST ACCURACY: \n",
      "0.174\n",
      "\n",
      "Epoch 79 Complete. Training Loss: 27.502090454101562\n",
      "TEST ACCURACY: \n",
      "0.1726\n",
      "\n",
      "Epoch 80 Complete. Training Loss: 23.073213577270508\n",
      "TEST ACCURACY: \n",
      "0.1751\n",
      "\n",
      "Epoch 81 Complete. Training Loss: 22.694583892822266\n",
      "TEST ACCURACY: \n",
      "0.1732\n",
      "\n",
      "Epoch 82 Complete. Training Loss: 23.97149658203125\n",
      "TEST ACCURACY: \n",
      "0.1673\n",
      "\n",
      "Epoch 83 Complete. Training Loss: 20.944726943969727\n",
      "TEST ACCURACY: \n",
      "0.1733\n",
      "\n",
      "Epoch 84 Complete. Training Loss: 23.18885040283203\n",
      "TEST ACCURACY: \n",
      "0.1736\n",
      "\n",
      "Epoch 85 Complete. Training Loss: 21.84691047668457\n",
      "TEST ACCURACY: \n",
      "0.1736\n",
      "\n",
      "Epoch 86 Complete. Training Loss: 22.001367568969727\n",
      "TEST ACCURACY: \n",
      "0.1718\n",
      "\n",
      "Epoch 87 Complete. Training Loss: 22.183303833007812\n",
      "TEST ACCURACY: \n",
      "0.1716\n",
      "\n",
      "Epoch 88 Complete. Training Loss: 24.02228355407715\n",
      "TEST ACCURACY: \n",
      "0.174\n",
      "\n",
      "Epoch 89 Complete. Training Loss: 23.09696388244629\n",
      "TEST ACCURACY: \n",
      "0.1734\n",
      "\n",
      "Epoch 90 Complete. Training Loss: 26.408681869506836\n",
      "TEST ACCURACY: \n",
      "0.1694\n",
      "\n",
      "Epoch 91 Complete. Training Loss: 26.55417251586914\n",
      "TEST ACCURACY: \n",
      "0.1701\n",
      "\n",
      "Epoch 92 Complete. Training Loss: 25.910249710083008\n",
      "TEST ACCURACY: \n",
      "0.1747\n",
      "\n",
      "Epoch 93 Complete. Training Loss: 23.60085105895996\n",
      "TEST ACCURACY: \n",
      "0.1725\n",
      "\n",
      "Epoch 94 Complete. Training Loss: 23.679759979248047\n",
      "TEST ACCURACY: \n",
      "0.1729\n",
      "\n",
      "Epoch 95 Complete. Training Loss: 21.95778465270996\n",
      "TEST ACCURACY: \n",
      "0.172\n",
      "\n",
      "Epoch 96 Complete. Training Loss: 23.641780853271484\n",
      "TEST ACCURACY: \n",
      "0.1728\n",
      "\n",
      "Epoch 97 Complete. Training Loss: 25.520246505737305\n",
      "TEST ACCURACY: \n",
      "0.1716\n",
      "\n",
      "Epoch 98 Complete. Training Loss: 24.1101131439209\n",
      "TEST ACCURACY: \n",
      "0.1709\n",
      "\n",
      "Epoch 99 Complete. Training Loss: 22.152996063232422\n",
      "TEST ACCURACY: \n",
      "0.172\n",
      "\n",
      "Finished Training the Model\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "try:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # Epoch == Entire Training Set\n",
    "        for epoch in range(num_epochs):\n",
    "            num_batches = mnist.train.num_examples // batch_size\n",
    "\n",
    "            # 150 batch size\n",
    "            for iteration in range(num_batches):\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "                sess.run(train, feed_dict={X: X_batch, Y: y_batch})\n",
    "\n",
    "            training_loss = loss.eval(feed_dict={X: X_batch, Y: y_batch})   \n",
    "            print(\"Epoch {} Complete. Training Loss: {}\".format(epoch,training_loss))\n",
    "            saver.save(sess, \"../save/slearn_1-1.ckpt\")\n",
    "            \n",
    "            matches = tf.equal(tf.argmax(out_layer4, 1), tf.argmax(Y,1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "\n",
    "            print('TEST ACCURACY: ')\n",
    "            print (sess.run(acc, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n",
    "            print()\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print('Keyboard Interrupted')\n",
    "finally:\n",
    "    print('Finished Training the Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../save/slearn_1-1.ckpt\n",
      "TRAIN ACCURACY: \n",
      "0.17436364\n",
      "TEST ACCURACY: \n",
      "0.172\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_test_labels = 10\n",
    "start_point = 15\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess,\"../save/slearn_1-1.ckpt\")\n",
    "    \n",
    "    params = sess.run([W1, W2, W3, b1, b2, b3])\n",
    "    \n",
    "    matches = tf.equal(tf.argmax(out_layer4, 1), tf.argmax(Y,1))\n",
    "    acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "    \n",
    "    print('TRAIN ACCURACY: ')\n",
    "    print (sess.run(acc, feed_dict={X:mnist.train.images, Y:mnist.train.labels}))\n",
    "\n",
    "    print('TEST ACCURACY: ')\n",
    "    print (sess.run(acc, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-5.07876515e-01, -1.59362841e+00, -4.35799509e-01,\n",
       "          8.69601965e-01,  8.19871366e-01, -1.14273906e+00,\n",
       "         -4.26776499e-01, -8.14560831e-01,  3.19570750e-01,\n",
       "          7.27141082e-01,  9.13293719e-01, -5.39881997e-02,\n",
       "         -5.54646313e-01, -3.79515022e-01, -4.23279703e-02,\n",
       "         -3.11678201e-01, -5.26109934e-01, -1.71761656e+00,\n",
       "         -1.16177344e+00, -1.95540452e+00,  7.40523756e-01,\n",
       "          1.40820050e+00, -8.04819822e-01, -1.94492924e+00,\n",
       "          4.86408919e-01,  9.07569647e-01, -4.64092463e-01,\n",
       "         -3.83706652e-02,  5.47424138e-01,  7.80043185e-01,\n",
       "          9.75426674e-01, -1.14047194e+00,  6.92348421e-01,\n",
       "         -1.63689113e+00, -5.77038884e-01, -2.96159655e-01,\n",
       "          6.52402997e-01,  1.23922133e+00, -1.14363752e-01,\n",
       "          6.28867373e-02, -5.27672946e-01,  5.82940400e-01,\n",
       "          1.42208683e+00,  3.60395126e-02, -2.52230406e-01,\n",
       "          6.86351478e-01,  1.30035818e-01,  1.54322898e+00,\n",
       "         -1.71269083e+00, -4.10648108e-01, -7.04170346e-01,\n",
       "         -1.32973552e+00,  1.31737435e+00, -2.31757477e-01,\n",
       "          9.65948939e-01,  9.15265977e-01, -2.15823978e-01,\n",
       "         -1.29365408e+00,  2.22621158e-01,  5.05472243e-01,\n",
       "          3.66342783e-01,  1.16675928e-01, -1.65835965e+00,\n",
       "          6.16143763e-01, -1.31148171e+00, -5.24734735e-01,\n",
       "          1.51574314e+00, -7.19799459e-01, -2.79339314e-01,\n",
       "         -3.10989022e-01,  4.79917638e-02,  4.54780497e-02,\n",
       "          2.05337014e-02,  5.18292725e-01,  6.09398412e-04,\n",
       "         -1.01889275e-01, -1.41374636e-02,  4.19973671e-01,\n",
       "         -8.93821344e-02,  8.16804469e-01, -5.16923845e-01,\n",
       "          1.40710580e+00, -9.46513236e-01, -8.47847164e-02,\n",
       "          2.88977802e-01,  1.11565614e+00, -2.88480252e-01,\n",
       "          1.63599408e+00,  1.03311718e+00, -4.33440030e-01,\n",
       "         -1.67572486e+00,  7.80506909e-01, -4.76720035e-01,\n",
       "         -1.55156851e+00, -1.46082842e+00, -1.24248374e+00,\n",
       "          1.34305978e+00,  7.14197218e-01,  1.07761407e+00,\n",
       "          9.58852112e-01, -5.56896925e-01,  8.44206333e-01,\n",
       "         -6.45009220e-01, -3.36112715e-02, -9.95709538e-01,\n",
       "         -1.49473739e+00,  9.71756935e-01, -6.93754017e-01,\n",
       "         -5.92025399e-01,  9.09290075e-01,  8.49412680e-01,\n",
       "          5.51659763e-01,  2.87693948e-01,  4.01786231e-02,\n",
       "         -5.42627215e-01, -8.44289124e-01, -1.48650968e+00,\n",
       "          7.12036788e-01,  6.48721874e-01, -1.50983310e+00,\n",
       "         -3.02440934e-02,  1.28377691e-01,  8.43583584e-01,\n",
       "         -3.25030923e-01,  8.66741836e-01, -1.97639000e+00,\n",
       "         -4.43702698e-01, -4.42251652e-01, -4.85545397e-01,\n",
       "          2.66952491e+00, -5.14613748e-01, -1.31924197e-01,\n",
       "          1.30007148e+00,  1.25872624e+00,  9.96718347e-01,\n",
       "         -2.36196164e-02,  2.76684582e-01,  1.37843907e+00,\n",
       "         -9.15506840e-01, -6.34986162e-01,  5.61226189e-01,\n",
       "          6.21469498e-01, -1.00195932e+00, -1.61255980e+00,\n",
       "          6.09041639e-02, -8.71652365e-02, -3.02166939e-01,\n",
       "          1.53770244e+00, -7.25782752e-01, -2.24477619e-01,\n",
       "         -6.84278488e-01, -2.02649981e-01, -8.63256812e-01,\n",
       "         -1.41269553e+00,  7.34305859e-01]], dtype=float32),\n",
       " array([[-3.43758017e-01,  9.74843681e-01,  2.04264417e-01, ...,\n",
       "         -3.56298238e-01,  5.47966421e-01,  7.05329254e-02],\n",
       "        [-1.07825661e+00, -1.00154698e+00, -9.55121934e-01, ...,\n",
       "         -3.83470803e-01, -5.06413877e-02,  2.23273888e-01],\n",
       "        [ 1.78068166e-03, -1.36666253e-01,  3.84561956e-01, ...,\n",
       "         -1.18314154e-01, -1.35996774e-01, -1.19024277e+00],\n",
       "        ...,\n",
       "        [ 1.08234930e+00, -9.07124102e-01,  8.65804315e-01, ...,\n",
       "          2.13361219e-01, -1.16388679e+00, -1.70494363e-01],\n",
       "        [ 2.12898359e-01, -1.92946053e+00,  3.50093514e-01, ...,\n",
       "         -3.29266399e-01,  1.61049533e+00, -4.73751724e-01],\n",
       "        [ 8.17997634e-01,  6.29691303e-01, -1.70859742e+00, ...,\n",
       "         -1.64708161e+00, -2.50811785e-01, -2.15302005e-01]], dtype=float32),\n",
       " array([[ 1.3138815 ],\n",
       "        [ 0.7105163 ],\n",
       "        [ 1.2103083 ],\n",
       "        [-0.6358562 ],\n",
       "        [-0.37586457],\n",
       "        [-0.7143961 ],\n",
       "        [ 0.89834803],\n",
       "        [ 0.42702627],\n",
       "        [ 1.4784766 ],\n",
       "        [-0.9866635 ],\n",
       "        [ 0.10214151],\n",
       "        [ 0.48165596],\n",
       "        [ 0.59279466],\n",
       "        [-0.7689093 ],\n",
       "        [-1.6568387 ],\n",
       "        [ 0.6920335 ],\n",
       "        [ 0.42288217],\n",
       "        [-0.9580804 ],\n",
       "        [-0.06689759],\n",
       "        [ 0.24157073],\n",
       "        [ 0.20416307],\n",
       "        [ 0.756631  ],\n",
       "        [ 0.6496673 ],\n",
       "        [-0.419579  ],\n",
       "        [ 1.1624155 ],\n",
       "        [-1.1040868 ],\n",
       "        [-0.7812674 ],\n",
       "        [ 0.8674354 ],\n",
       "        [-0.03143279],\n",
       "        [-0.22894983],\n",
       "        [-0.82487667]], dtype=float32),\n",
       " array([ 7.69866398e-04, -2.78982241e-02,  4.59130630e-02,  6.05674274e-02,\n",
       "         9.12846103e-02, -2.26311088e-02,  7.64787721e-04,  2.82472018e-02,\n",
       "         1.67696670e-01,  4.19424102e-02,  3.90464067e-02,  3.94832902e-02,\n",
       "         1.07466824e-01,  9.66446251e-02,  5.78678586e-03,  5.16363000e-03,\n",
       "        -2.40877992e-03, -6.14706660e-03,  2.27049626e-02, -8.97734892e-03,\n",
       "         7.01196790e-02,  2.23597847e-02, -4.08825092e-03, -1.77484918e-02,\n",
       "         5.86164184e-02,  5.01590148e-02, -1.27389267e-01,  6.77611902e-02,\n",
       "         6.32487983e-02,  3.78993191e-02, -2.15006098e-02, -2.47597788e-02,\n",
       "         3.84088568e-02, -2.98064351e-02, -8.02602037e-04, -8.18879902e-02,\n",
       "         5.09649068e-02,  5.13727330e-02, -1.72863882e-02,  1.96870416e-01,\n",
       "        -9.96822491e-04,  6.56178640e-03,  2.16210801e-02,  1.33851752e-01,\n",
       "        -1.33113877e-04,  8.92437920e-02,  4.27219756e-02,  1.23800989e-02,\n",
       "         1.21170744e-01,  1.16205579e-02,  7.69765824e-02, -1.02817245e-01,\n",
       "         1.21767558e-02,  3.15876082e-02,  4.24049348e-02,  1.01357903e-02,\n",
       "        -5.44877946e-02, -1.09880798e-01, -2.78577041e-02,  3.92582342e-02,\n",
       "         3.10318340e-02,  6.45752903e-03, -6.80959411e-03,  2.89386418e-02,\n",
       "        -4.66227792e-02, -7.73900421e-03,  4.29978855e-02, -4.44206484e-02,\n",
       "         6.93297526e-03,  5.31346314e-02,  1.61459804e-01,  2.28461400e-02,\n",
       "         7.53336474e-02,  4.26190346e-02, -5.59605367e-04, -5.44050615e-03,\n",
       "        -5.45383021e-02, -1.96211264e-02,  2.53338125e-02,  2.66258791e-02,\n",
       "        -5.75994560e-03,  4.00239639e-02,  9.62149873e-02,  2.84869745e-02,\n",
       "         1.62378162e-01,  1.15167936e-02, -5.80647262e-03,  3.39060500e-02,\n",
       "         3.17222136e-03, -5.34184976e-03,  3.57575193e-02,  7.17559308e-02,\n",
       "         1.23211211e-02,  8.76135379e-03,  7.88026024e-03,  7.78196333e-03,\n",
       "         1.03013022e-02,  1.93947237e-02,  4.87587638e-02,  2.40054075e-02,\n",
       "        -1.18854664e-01, -2.11678352e-03, -8.96885831e-05, -4.13031578e-02,\n",
       "        -9.53196585e-02,  8.72884840e-02,  6.65181726e-02, -1.68125387e-02,\n",
       "         8.59647896e-03,  6.58082440e-02,  5.88400941e-03, -2.04782747e-03,\n",
       "        -2.66313944e-02,  1.36348769e-01,  4.60938551e-03,  5.80970980e-02,\n",
       "        -1.28660351e-01,  2.89565660e-02,  5.10540456e-02, -5.99518977e-02,\n",
       "        -1.08643407e-02, -1.31757064e-02,  1.73726529e-02, -1.80911273e-02,\n",
       "         1.98087674e-02,  4.19056863e-02,  5.43119153e-03, -4.49103341e-02,\n",
       "         8.55804048e-03,  5.01817316e-02,  1.12434449e-02,  3.73679139e-02,\n",
       "         3.21941040e-02,  1.85338128e-03,  2.00143885e-02,  1.41063914e-01,\n",
       "         2.03076050e-01,  5.47719039e-02, -5.31753525e-03,  1.08607970e-02,\n",
       "         6.46823421e-02,  7.76170269e-02, -1.31542692e-02, -6.98325112e-02,\n",
       "         1.90782011e-01,  1.88009173e-03,  1.08905748e-01, -1.66982075e-03,\n",
       "         5.60976826e-02,  1.38196605e-03,  4.15105186e-03, -1.07472390e-02,\n",
       "         5.46591496e-03, -1.07438820e-04,  1.09635219e-02], dtype=float32),\n",
       " array([-0.0061207 ,  0.04071682, -0.00380016,  0.00339436, -0.00060634,\n",
       "         0.        ,  0.05420148,  0.04477282, -0.00094658,  0.        ,\n",
       "         0.        ,  0.        ,  0.1413367 ,  0.00348956,  0.        ,\n",
       "        -0.0038057 , -0.00351003,  0.00044029,  0.00295571, -0.00387066,\n",
       "        -0.00366086, -0.00348826,  0.16873172,  0.00360798, -0.0042697 ,\n",
       "         0.00362627,  0.0075772 ,  0.17157307, -0.02102392,  0.00386986,\n",
       "        -0.03979213], dtype=float32),\n",
       " array([-0.00347137], dtype=float32)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(params)):\n",
    "    np.save('../save/weights/slearn_parms{}_1-1.npy'.format(i),params[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
