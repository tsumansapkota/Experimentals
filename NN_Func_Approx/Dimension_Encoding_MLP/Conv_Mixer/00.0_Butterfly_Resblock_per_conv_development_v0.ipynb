{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d5b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4efdacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets, transforms as T\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8122207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e01cfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet_mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1602c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train = T.Compose([\n",
    "    T.RandomCrop(size=32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "        std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "    ),\n",
    "])\n",
    "\n",
    "cifar_test = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "        std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=True, download=True, transform=cifar_train)\n",
    "test_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=False, download=True, transform=cifar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "491fefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.data = train_dataset.data.view(-1, 28*28)\n",
    "# test_dataset.data = test_dataset.data.view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6807321",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd705fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0879c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47582925",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4fc66",
   "metadata": {},
   "source": [
    "## Group-Butterfly for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b727fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = resnet_mixer.cifar_resnet20(mixer=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eaa0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7bd80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch, model, model_name):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e46396d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9ae3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "asfsdafwdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea674cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict = {}\n",
    "#     net = torch.compile(net)\n",
    "#     net = torch.compile(net, mode=\"reduce-overhead\")\n",
    "#     net = torch.compile(net, mode=\"max-autotune\")\n",
    "\n",
    "### e0 default cifar_resnet20 with 4,8,8 groups per block\n",
    "# model_name = f\"00.0_c10_butterfly_e0\"\n",
    "# net = resnet_mixer.cifar_resnet20(num_classes=10, mixer=True).to(device)\n",
    "\n",
    "### e0 32, 64, 128 cifar_resnet20 with 8,8,16 groups per block\n",
    "model_name = f\"00.0_c10_butterfly_e1\"\n",
    "net = resnet_mixer.cifar_resnet20(num_classes=10, mixer=True, planes=32, G=[8, 8, 16]).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "best_acc = -1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch, net, optimizer)\n",
    "    test(epoch, net, model_name)\n",
    "    scheduler.step()\n",
    "# acc_dict[key] = float(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d3d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4877776",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed263777",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "{'stereographic': 90.51}\n",
    "{'linear': 92.77}\n",
    "{'butterfly': 88.61}\n",
    "{'butterfly-in32': 91.68}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bcbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in resnet_mixer.cifar_resnet20(mixer=True).parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb4a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in resnet_mixer.cifar_resnet20(mixer=False).parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2699208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "43802/272474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in resnet_mixer.cifar_resnet20(mixer=True, planes=32, G=[8, 8, 16]).parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e32fe",
   "metadata": {},
   "source": [
    "## Computing the MACs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7199c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "for i in range(9):\n",
    "    print(\"MODEL INDEX: \", i)\n",
    "    if i==0:\n",
    "        ## hard core ignore\n",
    "        model = resnet_mixer.cifar_resnet20(mixer=False)\n",
    "    elif i == 1:\n",
    "        ### FOR ORIGINAL MIXER V1 -- Default values used\n",
    "        model = resnet_mixer.cifar_resnet20(mixer=True)\n",
    "    elif i == 2:\n",
    "        ### Larger plane creates smaller than original\n",
    "        model = resnet_mixer.cifar_resnet20(mixer=True, planes=32, G=[8, 8, 16])\n",
    "    elif i == 3:\n",
    "        ## Use filter wise conv in second conv of resblock\n",
    "        model = resnet_mixer.cifar_resnet20(mixer=True, G=[1, 1, 1])\n",
    "    elif i == 4:\n",
    "        ## Use filter wise conv in first conv of resblock\n",
    "        model = resnet_mixer.cifar_resnet20(mixer=True, G=[16, 32, 64])\n",
    "    else: \n",
    "        break\n",
    "        \n",
    "    macs, params = get_model_complexity_info(model, (3, 32, 32), as_strings=True,\n",
    "                                   print_per_layer_stat=False, verbose=False)\n",
    "\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf32f6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
