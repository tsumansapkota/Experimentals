{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c57c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### MODIFIED from \n",
    "## https://github.com/chenyaofo/CIFAR-pretrained-models\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Union, Tuple\n",
    "import numpy as np\n",
    "\n",
    "__all__ = ['CifarResNet', 'cifar_resnet20', 'cifar_resnet32', 'cifar_resnet44', 'cifar_resnet56']\n",
    "    \n",
    "\n",
    "class ChannelNorm2D(nn.Module):\n",
    "    \n",
    "    def __init__(self, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x-x.mean(dim=1, keepdim=True)\n",
    "        x = x/torch.sqrt(x.var(dim=1, keepdim=True)+self.eps)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, groups=groups, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1, groups=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, groups=groups, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        self.groups = groups\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride, self.groups)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "#         self.groups2 = planes//self.groups\n",
    "        self.conv2 = conv3x3(planes, planes, groups=self.groups)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)        \n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "#         B, C, H, W = out.shape\n",
    "#         out = out.view(B, C//self.groups2, self.groups2, H, W)\\\n",
    "#                     .transpose(1,2).contiguous()\\\n",
    "#                     .view(B, C, H, W)\n",
    "                      \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class SequentialMixer(nn.Module):\n",
    "    \n",
    "    def __init__(self, blocks, inplanes, group_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "        self.inplanes = inplanes\n",
    "        self.group_sz = group_size\n",
    "        self.groups = inplanes//group_size\n",
    "        \n",
    "        def log_base(a, base):\n",
    "            return np.log(a) / np.log(base)\n",
    "        \n",
    "        \n",
    "        ### total number of layers to complete mixing\n",
    "        self.num_layers = int(np.ceil(log_base(self.inplanes, base=self.group_sz)))\n",
    "        \n",
    "        self.gaps = []\n",
    "        for i in range(len(self.blocks)):\n",
    "            butterfly_layer_index = i%self.num_layers ## repeated index in blocks (for layers)\n",
    "\n",
    "            gap = self.group_sz**butterfly_layer_index\n",
    "            if gap*self.group_sz > self.inplanes:\n",
    "                gap = int(np.ceil(self.inplanes/self.group_sz))\n",
    "            self.gaps += [gap]\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, C, H, W = x.shape\n",
    "#         out = out.view(B, C//self.groups2, self.groups2, H, W)\\\n",
    "#                     .transpose(1,2).contiguous()\\\n",
    "#                     .view(B, C, H, W)\n",
    "\n",
    "        for gap, fn in zip(self.gaps, self.blocks):\n",
    "#         for i, fn in enumerate(self.blocks):\n",
    "#             butterfly_layer_index = i%self.num_layers\n",
    "#             gap = self.group_sz**butterfly_layer_index\n",
    "#             if gap*self.group_sz > self.inplanes:\n",
    "#                 gap = int(np.ceil(self.inplanes/self.group_sz))\n",
    "            \n",
    "            \n",
    "            \n",
    "            x = x.view(B, -1, self.group_sz, gap, H, W).transpose(2, 3).contiguous().view(B, -1, H, W)\n",
    "            x = fn(x)\n",
    "            _, _, H, W = x.shape\n",
    "            x = x.view(B, -1, gap, self.group_sz, H, W).transpose(2, 3).contiguous().view(B, -1, H, W)\n",
    "\n",
    "#         x = x.view(B, C, H, W)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class CifarResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=10, planes=16, group_sizes=None):\n",
    "        super(CifarResNet, self).__init__()\n",
    "        global conv3x3, conv1x1\n",
    "        \n",
    "        self.inplanes = planes\n",
    "        self.conv1 = conv3x3(3, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        if group_sizes is None:\n",
    "            group_sizes = [-1, -1, -1]\n",
    "                \n",
    "        self.layer1 = self._make_layer(block, planes, layers[0], group_sz=group_sizes[0])\n",
    "        self.layer2 = self._make_layer(block, planes*2, layers[1], stride=2, group_sz=group_sizes[1])\n",
    "        self.layer3 = self._make_layer(block, planes*4, layers[2], stride=2, group_sz=group_sizes[2])\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc = nn.Linear(planes*4 * block.expansion, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, group_sz=-1):\n",
    "        downsample = None\n",
    "        if group_sz <= 0:\n",
    "            groups = 1\n",
    "        else:\n",
    "            groups = self.inplanes//group_sz\n",
    "        \n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride, groups=groups),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, groups=groups))\n",
    "        \n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=groups))\n",
    "\n",
    "        return SequentialMixer(layers, self.inplanes, group_sz)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def cifar_resnet20(**kwargs):\n",
    "    model = CifarResNet(BasicBlock, [3, 3, 3], group_sizes=[4, 8, 8], **kwargs)\n",
    "    return model\n",
    "\n",
    "def cifar_resnet23(**kwargs):\n",
    "    model = CifarResNet(BasicBlock, [4, 4, 4], group_sizes=[4, 8, 8], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# def cifar_resnet32(**kwargs):\n",
    "#     model = CifarResNet(BasicBlock, [5, 5, 5], **kwargs)\n",
    "#     return model\n",
    "\n",
    "\n",
    "# def cifar_resnet44(**kwargs):\n",
    "#     model = CifarResNet(BasicBlock, [7, 7, 7], **kwargs)\n",
    "#     return model\n",
    "\n",
    "\n",
    "# def cifar_resnet56(**kwargs):\n",
    "#     model = CifarResNet(BasicBlock, [9, 9, 9], **kwargs)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d556ed9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CifarResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): SequentialMixer(\n",
       "    (blocks): ModuleList(\n",
       "      (0-2): 3 x BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): SequentialMixer(\n",
       "    (blocks): ModuleList(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), groups=2, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1-2): 2 x BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): SequentialMixer(\n",
       "    (blocks): ModuleList(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4, bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), groups=4, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1-2): 2 x BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cifar_resnet20()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72c260d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2257,  0.4249,  0.2232,  0.7458, -0.2010, -0.6317, -0.0889,  0.7805,\n",
       "          1.1233,  1.2063]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9cedba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58efabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1d5b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efdacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets, transforms as T\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8122207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e01cfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import resnet_mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1602c6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_train = T.Compose([\n",
    "    T.RandomCrop(size=32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "        std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "    ),\n",
    "])\n",
    "\n",
    "cifar_test = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "        std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=True, download=True, transform=cifar_train)\n",
    "test_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=False, download=True, transform=cifar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "491fefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.data = train_dataset.data.view(-1, 28*28)\n",
    "# test_dataset.data = test_dataset.data.view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6807321",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd705fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0879c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47582925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4fc66",
   "metadata": {},
   "source": [
    "## Group-Butterfly for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b727fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = resnet_mixer.cifar_resnet20(mixer=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eaa0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7bd80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch, model, model_name):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e46396d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bea674cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:16<00:00, 23.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 0 Loss: 1.537 | Acc: 42.884 21442/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 79/79 [00:00<00:00, 141.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.318 | Acc: 54.610 5461/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:06<00:00, 55.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 1 Loss: 1.078 | Acc: 61.322 30661/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 79/79 [00:00<00:00, 146.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 1 Loss: 1.214 | Acc: 58.990 5899/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:07<00:00, 55.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 2 Loss: 0.914 | Acc: 67.646 33823/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 79/79 [00:00<00:00, 145.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 2 Loss: 1.228 | Acc: 57.830 5783/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:07<00:00, 54.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 3 Loss: 0.805 | Acc: 71.770 35885/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 79/79 [00:00<00:00, 144.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 3 Loss: 0.992 | Acc: 66.000 6600/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:07<00:00, 53.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 4 Loss: 0.742 | Acc: 74.210 37105/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 79/79 [00:00<00:00, 140.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 4 Loss: 0.911 | Acc: 68.950 6895/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████▉                                       | 97/391 [00:02<00:06, 44.26it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m best_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     test(epoch, net, model_name)\n\u001b[1;32m     31\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[17], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, model, optimizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 18\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "acc_dict = {}\n",
    "#     net = torch.compile(net)\n",
    "#     net = torch.compile(net, mode=\"reduce-overhead\")\n",
    "#     net = torch.compile(net, mode=\"max-autotune\")\n",
    "\n",
    "\n",
    "# model_name = f\"00.0_c10_ordinary_e0\"\n",
    "# net = resnet_mixer.cifar_resnet20(num_classes=10, mixer=False).to(device)\n",
    "\n",
    "### e0 default cifar_resnet20 with 4,8,8 groups per block\n",
    "# model_name = f\"00.0_c10_butterfly_e0\"\n",
    "# net = resnet_mixer.cifar_resnet20(num_classes=10, mixer=True).to(device)\n",
    "\n",
    "### e0 32, 64, 128 cifar_resnet20 with 8,8,16 groups per block\n",
    "# model_name = f\"00.0_c10_butterfly_e1\"\n",
    "# net = resnet_mixer.cifar_resnet20(num_classes=10, mixer=True, planes=32, G=[8, 8, 16]).to(device)\n",
    "\n",
    "model_name = f\"00.1_c10_butterfly_block_e1\"\n",
    "net = CifarResNet(BasicBlock, [4, 4, 4], num_classes=10, planes=16, group_sizes=[4, 8, 8]).to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "best_acc = -1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch, net, optimizer)\n",
    "    test(epoch, net, model_name)\n",
    "    scheduler.step()\n",
    "# acc_dict[key] = float(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36d3d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "903d2506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.14"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4877776",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdasd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43masdasd\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asdasd' is not defined"
     ]
    }
   ],
   "source": [
    "asdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed263777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n{'stereographic': 90.51}\\n{'linear': 92.77}\\n{'butterfly': 88.61}\\n{'butterfly-in32': 91.68}\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "FOR RESNET 20\n",
    "{'stereographic': 90.51}\n",
    "{'linear': 92.77} ??? uses different settings ?!\n",
    "{'linear': 90.14} /!\\ using the same configs\n",
    "{'butterfly': 88.61}\n",
    "{'butterfly-in32': 91.68}\n",
    "{'block-butterfly': 90.61}\n",
    "\n",
    "RESNET 26 -- for even mixing in each resoultion\n",
    "{'block-butterfly[4,4,4]': 91.2}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63bcbc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43802"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in resnet_mixer.cifar_resnet20(mixer=True).parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcb4a0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130346"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in resnet_mixer.cifar_resnet20(mixer=False).parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2699208c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33604406732849496"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "43802/130346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fad78a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129578"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in resnet_mixer.cifar_resnet20(mixer=True, planes=32, G=[8, 8, 16]).parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e32fe",
   "metadata": {},
   "source": [
    "## Computing the MACs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7199c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INDEX:  0\n",
      "Computational complexity:       20.95 MMac\n",
      "Number of parameters:           130.35 k\n",
      "\n",
      "MODEL INDEX:  1\n",
      "Computational complexity:       8.97 MMac\n",
      "Number of parameters:           43.8 k  \n",
      "\n",
      "MODEL INDEX:  2\n",
      "Computational complexity:       25.24 MMac\n",
      "Number of parameters:           129.58 k\n",
      "\n",
      "MODEL INDEX:  3\n",
      "Computational complexity:       19.3 MMac\n",
      "Number of parameters:           112.15 k\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "for i in range(4):\n",
    "    if i==0:\n",
    "        ## hard core ignore\n",
    "        model = resnet_mixer.cifar_resnet20(mixer=False)\n",
    "    elif i == 1:\n",
    "        ### FOR ORIGINAL MIXER V1\n",
    "        model = resnet_mixer.cifar_resnet20(mixer=True)\n",
    "    elif i == 2:\n",
    "        model = resnet_mixer.cifar_resnet20(mixer=True, planes=32, G=[8, 8, 16])\n",
    "        \n",
    "    elif i == 3:\n",
    "#         model = CifarResNet(BasicBlock, [3, 3, 3], num_classes=10, group_sizes=[4, 8, 8])\n",
    "        model = CifarResNet(BasicBlock, [4, 4, 4], num_classes=10, planes=16, group_sizes=[4, 8, 8])\n",
    "#         model = CifarResNet(BasicBlock, [2, 2, 2], num_classes=10, planes=32, group_sizes=[8, 8, 16])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    macs, params = get_model_complexity_info(model, (3, 32, 32), as_strings=True,\n",
    "                                   print_per_layer_stat=False, verbose=False)\n",
    "\n",
    "    print(\"MODEL INDEX: \", i)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf32f6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
