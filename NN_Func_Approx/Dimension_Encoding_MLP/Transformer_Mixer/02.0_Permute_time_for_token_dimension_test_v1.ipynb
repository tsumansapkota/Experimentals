{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6287145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os, sys, pathlib, random, time, pickle, copy, json\n",
    "# from tqdm.autonotebook import tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0173cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcaa3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_lib import TransformerBlock, \\\n",
    "        Mixer_TransformerBlock_Encoder, \\\n",
    "        PositionalEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2e11b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45f6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "### add randomize patches for clear benefit\n",
    "class Mixer_ViT_Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_dim:tuple, patch_size:tuple, hidden_channel:int, num_blocks:int, num_classes:int, block_seq_size:int, block_mlp_size:int, forward_expansion:float=2.0, pos_emb=True, dropout:float=0.0, randomize_patch:bool=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_dim = image_dim ### must contain (C, H, W) or (H, W)\n",
    "        \n",
    "        ### find patch dim\n",
    "        d0 = int(image_dim[-2]/patch_size[0])\n",
    "        d1 = int(image_dim[-1]/patch_size[1])\n",
    "        assert d0*patch_size[0]==image_dim[-2], \"Image must be divisible into patch size\"\n",
    "        assert d1*patch_size[1]==image_dim[-1], \"Image must be divisible into patch size\"\n",
    "        \n",
    "#         self.d0, self.d1 = d0, d1 ### number of patches in each axis\n",
    "        __patch_size = patch_size[0]*patch_size[1]*image_dim[0] ## number of channels in each patch\n",
    "    \n",
    "        ### find channel dim\n",
    "        channel_size = d0*d1 ## number of patches\n",
    "        \n",
    "        ### after the number of channels are changed\n",
    "        init_dim = __patch_size\n",
    "        final_dim = hidden_channel\n",
    "        self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "        #### rescale the patches (patch wise image non preserving transform, unlike bilinear interpolation)\n",
    "        self.channel_change = nn.Linear(init_dim, final_dim)\n",
    "        print(f\"ViT Mixer : Channels per patch -> Initial:{init_dim} Final:{final_dim}\")\n",
    "        \n",
    "        \n",
    "        self.channel_dim = final_dim\n",
    "        self.patch_dim = channel_size\n",
    "        \n",
    "        self.transformer_blocks = []\n",
    "        \n",
    "        f = self.get_factors(self.channel_dim)\n",
    "        print(f)\n",
    "        fi = np.abs(np.array(f) - np.sqrt(self.channel_dim)).argmin()\n",
    "        \n",
    "        _n_heads = f[fi]\n",
    "        \n",
    "        ## number of dims per channel -> channel_dim\n",
    "#         print('Num patches:', self.patch_dim)\n",
    "        print(f'Sequence len: {self.patch_dim} ; Block size: {block_seq_size}')\n",
    "        print('Channel dim:', self.channel_dim, 'num heads:',_n_heads)\n",
    "            \n",
    "        \n",
    "        if block_seq_size is None or block_seq_size<2:\n",
    "            ### Find the block size for sequence:\n",
    "            block_seq_size = int(2**np.ceil(np.log2(np.sqrt(self.patch_dim))))\n",
    "            \n",
    "        print(f'MLP dim: {self.channel_dim} ; Block size: {block_mlp_size}')\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            L = Mixer_TransformerBlock_Encoder(self.patch_dim, block_seq_size, self.channel_dim, _n_heads, dropout, forward_expansion, nn.GELU, block_mlp_size)\n",
    "            self.transformer_blocks.append(L)\n",
    "        self.transformer_blocks = nn.Sequential(*self.transformer_blocks)\n",
    "        \n",
    "        self.linear = nn.Linear(self.patch_dim*self.channel_dim, num_classes)\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(self.channel_dim, dropout=0)\n",
    "        if not pos_emb:\n",
    "            self.positional_encoding = nn.Identity()\n",
    "            \n",
    "        self.randomize = None\n",
    "        if randomize_patch is not None:\n",
    "            self.randomize = torch.randperm(self.patch_dim)\n",
    "        \n",
    "        \n",
    "    def get_factors(self, n):\n",
    "        facts = []\n",
    "        for i in range(2, n+1):\n",
    "            if n%i == 0:\n",
    "                facts.append(i)\n",
    "        return facts\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = self.unfold(x).swapaxes(-1, -2)\n",
    "        x = self.channel_change(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        ## swap position of patches here\n",
    "        if self.randomize is not None:\n",
    "            x = x[..., self.randomize, :]\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.linear(x.view(bs, -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7094b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b0ac9f5-f1e2-4dba-a8e3-06bb4d5acac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a356db1-2fad-40ba-8186-7ca3c40ddd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3efe0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e27199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT Mixer : Channels per patch -> Initial:12 Final:64\n",
      "[2, 4, 8, 16, 32, 64]\n",
      "Sequence len: 256 ; Block size: 16\n",
      "Channel dim: 64 num heads: 8\n",
      "MLP dim: 64 ; Block size: None\n"
     ]
    }
   ],
   "source": [
    "model = Mixer_ViT_Classifier([3, 32, 32], [2, 2], 64, num_blocks=2, num_classes=10, \n",
    "                            block_seq_size=16, block_mlp_size=None, pos_emb=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f741268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1017ac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT Mixer : Channels per patch -> Initial:3 Final:64\n",
      "[2, 4, 8, 16, 32, 64]\n",
      "Sequence len: 1024 ; Block size: 32\n",
      "Channel dim: 64 num heads: 8\n",
      "MLP dim: 64 ; Block size: None\n"
     ]
    }
   ],
   "source": [
    "model = Mixer_ViT_Classifier([3, 32, 32], [1, 1], 64, num_blocks=2, num_classes=10, \n",
    "                            block_seq_size=32, block_mlp_size=None, pos_emb=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae575940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfold: 0\n",
      "channel_change: 256\n",
      "transformer_blocks: 133888\n",
      "linear: 655370\n",
      "positional_encoding: 0\n"
     ]
    }
   ],
   "source": [
    "# print(\"number of params: \", sum(p.numel() for p in model.parameters()))\n",
    "for name, m in model.named_children():\n",
    "#     print(name)\n",
    "    print(f\"{name}: {sum(p.numel() for p in m.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d642126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b258ea4-8037-457d-aea6-35e9e02d9be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  789514\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20622e",
   "metadata": {},
   "source": [
    "## Benchmark Memory and Time CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1faebb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvidia_smi\n",
    "\n",
    "MB = 1024*1024\n",
    "def get_memory_used():\n",
    "    nvidia_smi.nvmlInit()\n",
    "    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(1)\n",
    "    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "    val = info.used/MB\n",
    "    nvidia_smi.nvmlShutdown()\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1812db91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.1875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_memory_used()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb7fa91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "def get_memory_used(cuda_idx):\n",
    "    command = \"nvidia-smi --query-gpu=memory.used --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values[cuda_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30adc9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_memory_used(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c9ae24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 MiB', '2 MiB']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"nvidia-smi --query-gpu=memory.used --format=csv\"\n",
    "memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "memory_free_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47d9cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdfsadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7429fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "expansion_dict = {16:1024, 8:256, 4:128, 2:64, 1:64}\n",
    "def benchmark_memory(dataset:str, patch_size:int, num_layers:int, SEED:int, sparse_att:bool=False, sparse_mlp:bool=False, pos_emb:bool=False, cuda:int=0):\n",
    "    global expansion_dict\n",
    "    device = torch.device(f\"cuda:{cuda}\")\n",
    "    \n",
    "    if sparse_att:\n",
    "        assert num_layers%2 == 0, 'number of blocks on sparse transformer is (x2)/2 hence it must be even'\n",
    "        num_layers_ = num_layers//2\n",
    "    else:\n",
    "        num_layers_ = num_layers\n",
    "    \n",
    "    BS = 32\n",
    "    NC = -1\n",
    "    EPOCHS = 1\n",
    "    imsize = (3, 32, 32)\n",
    "    expansion = expansion_dict[patch_size]\n",
    "\n",
    "    \n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    ##### Data Transforms\n",
    "        \n",
    "    if dataset == 'cifar10':\n",
    "        NC = 10\n",
    "    elif dataset == 'cifar100':\n",
    "        NC = 100\n",
    "\n",
    "    ### Now create models\n",
    "    \n",
    "    seq_len = (imsize[-1]*imsize[-2])//(patch_size*patch_size)\n",
    "    mlp_dim = expansion\n",
    "    print(seq_len, mlp_dim)\n",
    "    \n",
    "    if sparse_att:\n",
    "        seq_len = int(2**np.ceil(np.log2(np.sqrt(seq_len))))\n",
    "    if sparse_mlp:\n",
    "        mlp_dim = int(2**np.ceil(np.log2(np.sqrt(expansion))))\n",
    "    \n",
    "    mem_begin = get_memory_used(cuda)\n",
    "    \n",
    "    torch.manual_seed(SEED)\n",
    "    model = Mixer_ViT_Classifier(imsize, \n",
    "                                 patch_size=[patch_size]*2, \n",
    "                                 hidden_channel=expansion, \n",
    "                                 num_blocks=num_layers_, \n",
    "                                 num_classes=NC, \n",
    "                                 block_seq_size=seq_len, \n",
    "                                 block_mlp_size=mlp_dim,\n",
    "                                 pos_emb=pos_emb).to(device)\n",
    "    \n",
    "    _x = torch.randn(BS, *imsize)#.to(device)\n",
    "    _y = torch.randint(10, (BS,))\n",
    "#     print(\"Output: \",vit_mixer(_x).shape)\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"number of params: \", num_params)\n",
    "    \n",
    "    _a, _b, _c = 'att', 'mlp', 'nPE'\n",
    "    if sparse_att: _a = 'sAtt'\n",
    "    if sparse_mlp: _b = 'sMlp'\n",
    "    if pos_emb: _c = 'PE'\n",
    "    model_name = f'01.3_ViT_train_{dataset}_patch{patch_size}_l{num_layers}_exp{expansion}_{_a}_{_b}_s{SEED}'\n",
    "    print(f\"Model Name: {model_name}\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "#     model.eval()\n",
    "    inputs, targets = _x.to(device), _y.to(device)\n",
    "    ### test time taken for multiple iterations\n",
    "    time_taken = []\n",
    "    for i in tqdm(range(50)):\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             start = time.time()\n",
    "#             outputs = model(inputs)\n",
    "#             start = time.time()-start\n",
    "            \n",
    "        start = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        start = time.time()-start\n",
    "        \n",
    "        time_taken.append(start)\n",
    "    train_time = np.mean(time_taken)\n",
    "        \n",
    "    mem_end = get_memory_used(cuda)\n",
    "    print(f\"mem begin: {mem_begin}  end: {mem_end}\")\n",
    "\n",
    "    model.eval()\n",
    "    time_taken = []\n",
    "    for i in range(50):\n",
    "        with torch.no_grad():\n",
    "            start = time.time()\n",
    "            outputs = model(inputs)\n",
    "            start = time.time()-start\n",
    "            time_taken.append(start)\n",
    "            \n",
    "    test_time = np.mean(time_taken)\n",
    "    \n",
    "    filename = f\"./output/bench_mem_retest_data.json\"\n",
    "    if not os.path.exists(filename):\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump({}, f, indent=0)\n",
    "            \n",
    "    with open(filename, 'r+') as f:\n",
    "#         with open(filename,'r+') as f:\n",
    "        file_data = json.load(f)\n",
    "        file_data[f\"{model_name}\"] = {'memory':mem_end-mem_begin, \n",
    "                                      'time_train':train_time, \n",
    "                                      'time_test':test_time,\n",
    "                                      'param':num_params}\n",
    "        f.seek(0)\n",
    "        json.dump(file_data, f, indent = 0)\n",
    "\n",
    "    del model, optimizer\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c0e54bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark_memory(dataset='cifar100', \n",
    "#                   patch_size=2, \n",
    "#                   num_layers=4, \n",
    "#                   SEED=147, \n",
    "#                   sparse_att=True, \n",
    "#                   sparse_mlp=False, \n",
    "#                   pos_emb=False,\n",
    "#                   cuda=0\n",
    "#                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "675693c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:4,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "64 64\n",
      "ViT Mixer : Channels per patch -> Initial:48 Final:64\n",
      "[2, 4, 8, 16, 32, 64]\n",
      "Sequence len: 64 ; Block size: 64\n",
      "Channel dim: 64 num heads: 8\n",
      "MLP dim: 64 ; Block size: 64\n",
      "number of params:  111050\n",
      "Model Name: 01.3_ViT_train_cifar10_patch4_l2_exp64_att_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 50/50 [00:00<00:00, 105.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 2  end: 348\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:4,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "64 64\n",
      "ViT Mixer : Channels per patch -> Initial:48 Final:64\n",
      "[2, 4, 8, 16, 32, 64]\n",
      "Sequence len: 64 ; Block size: 8\n",
      "Channel dim: 64 num heads: 8\n",
      "MLP dim: 64 ; Block size: 64\n",
      "number of params:  111050\n",
      "Model Name: 01.3_ViT_train_cifar10_patch4_l2_exp64_sAtt_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 50/50 [00:00<00:00, 180.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 310  end: 350\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:4,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "64 256\n",
      "ViT Mixer : Channels per patch -> Initial:48 Final:256\n",
      "[2, 4, 8, 16, 32, 64, 128, 256]\n",
      "Sequence len: 64 ; Block size: 64\n",
      "Channel dim: 256 num heads: 16\n",
      "MLP dim: 256 ; Block size: 256\n",
      "number of params:  1230602\n",
      "Model Name: 01.3_ViT_train_cifar10_patch4_l2_exp256_att_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 50/50 [00:00<00:00, 127.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 310  end: 432\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:4,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "64 256\n",
      "ViT Mixer : Channels per patch -> Initial:48 Final:256\n",
      "[2, 4, 8, 16, 32, 64, 128, 256]\n",
      "Sequence len: 64 ; Block size: 8\n",
      "Channel dim: 256 num heads: 16\n",
      "MLP dim: 256 ; Block size: 256\n",
      "number of params:  1230602\n",
      "Model Name: 01.3_ViT_train_cifar10_patch4_l2_exp256_sAtt_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 50/50 [00:00<00:00, 124.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 310  end: 398\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:4,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "64 1024\n",
      "ViT Mixer : Channels per patch -> Initial:48 Final:1024\n",
      "[2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
      "Sequence len: 64 ; Block size: 64\n",
      "Channel dim: 1024 num heads: 32\n",
      "MLP dim: 1024 ; Block size: 1024\n",
      "number of params:  17505290\n",
      "Model Name: 01.3_ViT_train_cifar10_patch4_l2_exp1024_att_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 50/50 [00:01<00:00, 27.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 310  end: 926\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:4,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "64 1024\n",
      "ViT Mixer : Channels per patch -> Initial:48 Final:1024\n",
      "[2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
      "Sequence len: 64 ; Block size: 8\n",
      "Channel dim: 1024 num heads: 32\n",
      "MLP dim: 1024 ; Block size: 1024\n",
      "number of params:  17505290\n",
      "Model Name: 01.3_ViT_train_cifar10_patch4_l2_exp1024_sAtt_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 50/50 [00:01<00:00, 26.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 310  end: 890\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:2,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "256 64\n",
      "ViT Mixer : Channels per patch -> Initial:12 Final:64\n",
      "[2, 4, 8, 16, 32, 64]\n",
      "Sequence len: 256 ; Block size: 256\n",
      "Channel dim: 64 num heads: 8\n",
      "MLP dim: 64 ; Block size: 64\n",
      "number of params:  231626\n",
      "Model Name: 01.3_ViT_train_cifar10_patch2_l2_exp64_att_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 50/50 [00:00<00:00, 66.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 310  end: 720\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:2,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "256 64\n",
      "ViT Mixer : Channels per patch -> Initial:12 Final:64\n",
      "[2, 4, 8, 16, 32, 64]\n",
      "Sequence len: 256 ; Block size: 16\n",
      "Channel dim: 64 num heads: 8\n",
      "MLP dim: 64 ; Block size: 64\n",
      "number of params:  231626\n",
      "Model Name: 01.3_ViT_train_cifar10_patch2_l2_exp64_sAtt_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 50/50 [00:00<00:00, 111.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 310  end: 396\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:2,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "256 256\n",
      "ViT Mixer : Channels per patch -> Initial:12 Final:256\n",
      "[2, 4, 8, 16, 32, 64, 128, 256]\n",
      "Sequence len: 256 ; Block size: 256\n",
      "Channel dim: 256 num heads: 16\n",
      "MLP dim: 256 ; Block size: 256\n",
      "number of params:  1712906\n",
      "Model Name: 01.3_ViT_train_cifar10_patch2_l2_exp256_att_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 50/50 [00:01<00:00, 30.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 310  end: 1158\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:2,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "256 256\n",
      "ViT Mixer : Channels per patch -> Initial:12 Final:256\n",
      "[2, 4, 8, 16, 32, 64, 128, 256]\n",
      "Sequence len: 256 ; Block size: 16\n",
      "Channel dim: 256 num heads: 16\n",
      "MLP dim: 256 ; Block size: 256\n",
      "number of params:  1712906\n",
      "Model Name: 01.3_ViT_train_cifar10_patch2_l2_exp256_sAtt_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 50/50 [00:01<00:00, 48.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 310  end: 682\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:2,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "256 1024\n",
      "ViT Mixer : Channels per patch -> Initial:12 Final:1024\n",
      "[2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
      "Sequence len: 256 ; Block size: 256\n",
      "Channel dim: 1024 num heads: 32\n",
      "MLP dim: 1024 ; Block size: 1024\n",
      "number of params:  19434506\n",
      "Model Name: 01.3_ViT_train_cifar10_patch2_l2_exp1024_att_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 310  end: 2634\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:2,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "256 1024\n",
      "ViT Mixer : Channels per patch -> Initial:12 Final:1024\n",
      "[2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
      "Sequence len: 256 ; Block size: 16\n",
      "Channel dim: 1024 num heads: 32\n",
      "MLP dim: 1024 ; Block size: 1024\n",
      "number of params:  19434506\n",
      "Model Name: 01.3_ViT_train_cifar10_patch2_l2_exp1024_sAtt_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 50/50 [00:06<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 310  end: 1626\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:1,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "1024 64\n",
      "ViT Mixer : Channels per patch -> Initial:3 Final:64\n",
      "[2, 4, 8, 16, 32, 64]\n",
      "Sequence len: 1024 ; Block size: 1024\n",
      "Channel dim: 64 num heads: 8\n",
      "MLP dim: 64 ; Block size: 64\n",
      "number of params:  722570\n",
      "Model Name: 01.3_ViT_train_cifar10_patch1_l2_exp64_att_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 310  end: 6518\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:1,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "1024 64\n",
      "ViT Mixer : Channels per patch -> Initial:3 Final:64\n",
      "[2, 4, 8, 16, 32, 64]\n",
      "Sequence len: 1024 ; Block size: 32\n",
      "Channel dim: 64 num heads: 8\n",
      "MLP dim: 64 ; Block size: 64\n",
      "number of params:  722570\n",
      "Model Name: 01.3_ViT_train_cifar10_patch1_l2_exp64_sAtt_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 50/50 [00:01<00:00, 38.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 310  end: 794\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:1,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "1024 256\n",
      "ViT Mixer : Channels per patch -> Initial:3 Final:256\n",
      "[2, 4, 8, 16, 32, 64, 128, 256]\n",
      "Sequence len: 1024 ; Block size: 1024\n",
      "Channel dim: 256 num heads: 16\n",
      "MLP dim: 256 ; Block size: 256\n",
      "number of params:  3676682\n",
      "Model Name: 01.3_ViT_train_cifar10_patch1_l2_exp256_att_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 10.91 GiB total capacity; 8.56 GiB already allocated; 411.00 MiB free; 10.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m expansion_dict[patch_size] \u001b[38;5;241m=\u001b[39m _expansion\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m    Experimenting on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Dataset \u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m    patch:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124m    seed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mbenchmark_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m          \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m          \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m          \u001b[49m\u001b[43mSEED\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m          \u001b[49m\u001b[43msparse_att\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_attention\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_mlp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_mlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m          \u001b[49m\u001b[43mpos_emb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcuda_idx\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mbenchmark_memory\u001b[0;34m(dataset, patch_size, num_layers, SEED, sparse_att, sparse_mlp, pos_emb, cuda)\u001b[0m\n\u001b[1;32m     82\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     83\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m---> 84\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     86\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 10.91 GiB total capacity; 8.56 GiB already allocated; 411.00 MiB free; 10.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "### Automate the benchmark\n",
    "###### for c10\n",
    "\n",
    "cuda_idx = 0\n",
    "seed = 147\n",
    "PE = False\n",
    "nlayers=2\n",
    "dataset='cifar10'\n",
    "nlayers = 2\n",
    "sparse_mlp = False\n",
    "for patch_size in [4, 2, 1]:\n",
    "    for _expansion in [64, 256, 1024]:\n",
    "        for sparse_attention in [False, True]:\n",
    "            expansion_dict[patch_size] = _expansion\n",
    "            print(f'''\n",
    "                Experimenting on {dataset} Dataset \n",
    "                patch:{patch_size},\n",
    "                sparse_att: {sparse_attention},\n",
    "                sparse_mlp: {sparse_mlp},\n",
    "                num_layers: {nlayers},\n",
    "                pos_embed: {PE},\n",
    "                seed: {seed}\n",
    "            ''')\n",
    "\n",
    "            benchmark_memory(dataset=dataset, \n",
    "                      patch_size=patch_size, \n",
    "                      num_layers=nlayers, \n",
    "                      SEED=seed, \n",
    "                      sparse_att=sparse_attention, sparse_mlp=sparse_mlp, \n",
    "                      pos_emb=PE,\n",
    "                      cuda=cuda_idx\n",
    "                     )\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed029069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
