{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-b22782e32495>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE parameters\n",
    "num_label = 10\n",
    "label_hid1 = 5\n",
    "label_hid2 = 3\n",
    "label_hid3 = 2\n",
    "label_hid4 = 1\n",
    "\n",
    "num_image = 784 # 28*28\n",
    "image_hid1 = 392\n",
    "image_hid2 = 196\n",
    "image_hid3 = 98\n",
    "image_hid4 = 49\n",
    "image_hid5 = 25\n",
    "image_hid6 = 12\n",
    "image_hid7 = 6\n",
    "image_hid8 = 3\n",
    "image_hid9 = 2\n",
    "image_hid10 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tie_weight = tf.transpose\n",
    "act_func = lambda X:X\n",
    "initializer = tf.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLACEHOLDER DEFINATION\n",
    "X = tf.placeholder(tf.float32, shape=[None, num_image])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, num_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Encoded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMAGE COMPRESSION\n",
    "wi1 = tf.Variable(np.load('../save/weights/w1.npy'))\n",
    "wi2 = tf.Variable(np.load('../save/weights/w2.npy'))\n",
    "wi3 = tf.Variable(np.load('../save/weights/w3.npy'))\n",
    "wi4 = tf.Variable(np.load('../save/weights/w4.npy'))\n",
    "wi5 = tf.Variable(np.load('../save/weights/w5.npy'))\n",
    "wi6 = tf.Variable(np.load('../save/weights/w6.npy'))\n",
    "wi7 = tf.Variable(np.load('../save/weights/w7.npy'))\n",
    "wi8 = tf.Variable(np.load('../save/weights/w8.npy'))\n",
    "wi9 = tf.Variable(np.load('../save/weights/w9.npy'))\n",
    "wi10 = tf.Variable(np.load('../save/weights/w10.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_layer1 = act_func(tf.matmul(X, wi1))\n",
    "img_layer2 = act_func(tf.matmul(img_layer1, wi2))\n",
    "img_layer3 = act_func(tf.matmul(img_layer2, wi3))\n",
    "img_layer4 = act_func(tf.matmul(img_layer3, wi4))\n",
    "img_layer5 = act_func(tf.matmul(img_layer4, wi5))\n",
    "img_layer6 = act_func(tf.matmul(img_layer5, wi6))\n",
    "img_layer7 = act_func(tf.matmul(img_layer6, wi7))\n",
    "img_layer8 = act_func(tf.matmul(img_layer7, wi8))\n",
    "img_layer9 = act_func(tf.matmul(img_layer8, wi9))\n",
    "img_layer10 = act_func(tf.matmul(img_layer9, wi10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LABEL DECOMPRESSION\n",
    "wl1 = tf.Variable(np.load('../save/weights/lw1.npy'))\n",
    "wl2 = tf.Variable(np.load('../save/weights/lw2.npy'))\n",
    "wl3 = tf.Variable(np.load('../save/weights/lw3.npy'))\n",
    "wl4 = tf.Variable(np.load('../save/weights/lw4.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_layer1 = act_func(tf.matmul(Y, wl1))\n",
    "lbl_layer2 = act_func(tf.matmul(lbl_layer1, wl2))\n",
    "lbl_layer3 = act_func(tf.matmul(lbl_layer2, wl3))\n",
    "lbl_layer4 = act_func(tf.matmul(lbl_layer3, wl4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Parameters for activation learning\n",
    "initializer = tf.random_uniform_initializer()\n",
    "\n",
    "input_no = image_hid9\n",
    "output_no = label_hid4\n",
    "\n",
    "inpt = img_layer9\n",
    "yval = lbl_layer4\n",
    "\n",
    "pW1 = tf.Variable(np.load('../save/weights/slearn_parms0_1-1.npy'))\n",
    "W1 = tf.Variable(tf.matmul(wi10,pW1))\n",
    "W2 = tf.Variable(np.load('../save/weights/slearn_parms1_1-1.npy'))\n",
    "W3 = tf.Variable(np.load('../save/weights/slearn_parms2_1-1.npy'))\n",
    "b1 = tf.Variable(np.load('../save/weights/slearn_parms3_1-1.npy'))\n",
    "b2 = tf.Variable(np.load('../save/weights/slearn_parms4_1-1.npy'))\n",
    "b3 = tf.Variable(np.load('../save/weights/slearn_parms5_1-1.npy'))\n",
    "\n",
    "a1 = tf.nn.relu(tf.matmul(inpt, W1) + b1)\n",
    "a2 = tf.nn.relu(tf.matmul(a1, W2) + b2)\n",
    "a13 = tf.matmul(a2, W3) + b3\n",
    "\n",
    "output = a13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a13' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-90198fe9249f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma13\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'a13' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Encode-Decode Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_layer1 = tf.matmul(output,tf.transpose(wl4))\n",
    "out_layer2 = tf.matmul(out_layer1,tf.transpose(wl3))\n",
    "out_layer3 = tf.matmul(out_layer2,tf.transpose(wl2))\n",
    "out_layer4 = tf.matmul(out_layer3,tf.transpose(wl1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS FUNCTIONS\n",
    "loss = tf.reduce_mean(tf.square(output - yval))\n",
    "# loss = tf.reduce_mean(tf.abs(output_layer - X))\n",
    "# cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=yout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "learning_rate = 0.0001\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss, var_list=[W1, W2, W3, b1, b2, b3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATION\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Complete. Training Loss: 22.296995162963867\n",
      "TEST ACCURACY: \n",
      "0.1768\n",
      "\n",
      "Epoch 1 Complete. Training Loss: 24.046171188354492\n",
      "TEST ACCURACY: \n",
      "0.1773\n",
      "\n",
      "Epoch 2 Complete. Training Loss: 27.181495666503906\n",
      "TEST ACCURACY: \n",
      "0.1783\n",
      "\n",
      "Epoch 3 Complete. Training Loss: 31.498865127563477\n",
      "TEST ACCURACY: \n",
      "0.1789\n",
      "\n",
      "Epoch 4 Complete. Training Loss: 24.456920623779297\n",
      "TEST ACCURACY: \n",
      "0.1804\n",
      "\n",
      "Epoch 5 Complete. Training Loss: 26.715288162231445\n",
      "TEST ACCURACY: \n",
      "0.1803\n",
      "\n",
      "Epoch 6 Complete. Training Loss: 21.27690887451172\n",
      "TEST ACCURACY: \n",
      "0.1811\n",
      "\n",
      "Epoch 7 Complete. Training Loss: 22.561717987060547\n",
      "TEST ACCURACY: \n",
      "0.1819\n",
      "\n",
      "Epoch 8 Complete. Training Loss: 25.325927734375\n",
      "TEST ACCURACY: \n",
      "0.1824\n",
      "\n",
      "Epoch 9 Complete. Training Loss: 24.958236694335938\n",
      "TEST ACCURACY: \n",
      "0.1842\n",
      "\n",
      "Epoch 10 Complete. Training Loss: 25.798141479492188\n",
      "TEST ACCURACY: \n",
      "0.1851\n",
      "\n",
      "Epoch 11 Complete. Training Loss: 25.497901916503906\n",
      "TEST ACCURACY: \n",
      "0.1848\n",
      "\n",
      "Epoch 12 Complete. Training Loss: 25.069204330444336\n",
      "TEST ACCURACY: \n",
      "0.1849\n",
      "\n",
      "Epoch 13 Complete. Training Loss: 32.210445404052734\n",
      "TEST ACCURACY: \n",
      "0.187\n",
      "\n",
      "Epoch 14 Complete. Training Loss: 20.22802734375\n",
      "TEST ACCURACY: \n",
      "0.1799\n",
      "\n",
      "Epoch 15 Complete. Training Loss: 20.455978393554688\n",
      "TEST ACCURACY: \n",
      "0.1809\n",
      "\n",
      "Epoch 16 Complete. Training Loss: 20.76604461669922\n",
      "TEST ACCURACY: \n",
      "0.1839\n",
      "\n",
      "Epoch 17 Complete. Training Loss: 28.224863052368164\n",
      "TEST ACCURACY: \n",
      "0.1858\n",
      "\n",
      "Epoch 18 Complete. Training Loss: 23.276857376098633\n",
      "TEST ACCURACY: \n",
      "0.1871\n",
      "\n",
      "Epoch 19 Complete. Training Loss: 19.13888931274414\n",
      "TEST ACCURACY: \n",
      "0.1867\n",
      "\n",
      "Epoch 20 Complete. Training Loss: 16.031715393066406\n",
      "TEST ACCURACY: \n",
      "0.1875\n",
      "\n",
      "Epoch 21 Complete. Training Loss: 15.867035865783691\n",
      "TEST ACCURACY: \n",
      "0.187\n",
      "\n",
      "Epoch 22 Complete. Training Loss: 13.022185325622559\n",
      "TEST ACCURACY: \n",
      "0.1881\n",
      "\n",
      "Epoch 23 Complete. Training Loss: 19.533309936523438\n",
      "TEST ACCURACY: \n",
      "0.1873\n",
      "\n",
      "Epoch 24 Complete. Training Loss: 10.848474502563477\n",
      "TEST ACCURACY: \n",
      "0.1875\n",
      "\n",
      "Epoch 25 Complete. Training Loss: 15.513989448547363\n",
      "TEST ACCURACY: \n",
      "0.1867\n",
      "\n",
      "Epoch 26 Complete. Training Loss: 18.47412872314453\n",
      "TEST ACCURACY: \n",
      "0.1879\n",
      "\n",
      "Epoch 27 Complete. Training Loss: 14.988140106201172\n",
      "TEST ACCURACY: \n",
      "0.187\n",
      "\n",
      "Epoch 28 Complete. Training Loss: 20.150230407714844\n",
      "TEST ACCURACY: \n",
      "0.1869\n",
      "\n",
      "Epoch 29 Complete. Training Loss: 24.366348266601562\n",
      "TEST ACCURACY: \n",
      "0.1868\n",
      "\n",
      "Epoch 30 Complete. Training Loss: 12.931063652038574\n",
      "TEST ACCURACY: \n",
      "0.1873\n",
      "\n",
      "Epoch 31 Complete. Training Loss: 22.38428497314453\n",
      "TEST ACCURACY: \n",
      "0.1868\n",
      "\n",
      "Epoch 32 Complete. Training Loss: 15.493454933166504\n",
      "TEST ACCURACY: \n",
      "0.1873\n",
      "\n",
      "Epoch 33 Complete. Training Loss: 21.82642364501953\n",
      "TEST ACCURACY: \n",
      "0.1867\n",
      "\n",
      "Epoch 34 Complete. Training Loss: 15.29583740234375\n",
      "TEST ACCURACY: \n",
      "0.1865\n",
      "\n",
      "Epoch 35 Complete. Training Loss: 16.031518936157227\n",
      "TEST ACCURACY: \n",
      "0.1873\n",
      "\n",
      "Epoch 36 Complete. Training Loss: 23.266075134277344\n",
      "TEST ACCURACY: \n",
      "0.1869\n",
      "\n",
      "Epoch 37 Complete. Training Loss: 14.609981536865234\n",
      "TEST ACCURACY: \n",
      "0.1874\n",
      "\n",
      "Epoch 38 Complete. Training Loss: 14.296780586242676\n",
      "TEST ACCURACY: \n",
      "0.1866\n",
      "\n",
      "Epoch 39 Complete. Training Loss: 15.212244033813477\n",
      "TEST ACCURACY: \n",
      "0.1869\n",
      "\n",
      "Epoch 40 Complete. Training Loss: 19.382244110107422\n",
      "TEST ACCURACY: \n",
      "0.1868\n",
      "\n",
      "Epoch 41 Complete. Training Loss: 19.174280166625977\n",
      "TEST ACCURACY: \n",
      "0.1869\n",
      "\n",
      "Epoch 42 Complete. Training Loss: 18.6085205078125\n",
      "TEST ACCURACY: \n",
      "0.187\n",
      "\n",
      "Epoch 43 Complete. Training Loss: 17.0800838470459\n",
      "TEST ACCURACY: \n",
      "0.1876\n",
      "\n",
      "Epoch 44 Complete. Training Loss: 19.539772033691406\n",
      "TEST ACCURACY: \n",
      "0.1866\n",
      "\n",
      "Epoch 45 Complete. Training Loss: 16.46881103515625\n",
      "TEST ACCURACY: \n",
      "0.1873\n",
      "\n",
      "Epoch 46 Complete. Training Loss: 19.73858070373535\n",
      "TEST ACCURACY: \n",
      "0.187\n",
      "\n",
      "Epoch 47 Complete. Training Loss: 12.92898178100586\n",
      "TEST ACCURACY: \n",
      "0.1868\n",
      "\n",
      "Epoch 48 Complete. Training Loss: 20.181230545043945\n",
      "TEST ACCURACY: \n",
      "0.1868\n",
      "\n",
      "Epoch 49 Complete. Training Loss: 17.075584411621094\n",
      "TEST ACCURACY: \n",
      "0.1882\n",
      "\n",
      "Epoch 50 Complete. Training Loss: 19.517189025878906\n",
      "TEST ACCURACY: \n",
      "0.1867\n",
      "\n",
      "Epoch 51 Complete. Training Loss: 17.411357879638672\n",
      "TEST ACCURACY: \n",
      "0.1867\n",
      "\n",
      "Epoch 52 Complete. Training Loss: 17.60808753967285\n",
      "TEST ACCURACY: \n",
      "0.187\n",
      "\n",
      "Epoch 53 Complete. Training Loss: 18.72339630126953\n",
      "TEST ACCURACY: \n",
      "0.1863\n",
      "\n",
      "Epoch 54 Complete. Training Loss: 17.606698989868164\n",
      "TEST ACCURACY: \n",
      "0.1869\n",
      "\n",
      "Epoch 55 Complete. Training Loss: 15.973710060119629\n",
      "TEST ACCURACY: \n",
      "0.1867\n",
      "\n",
      "Epoch 56 Complete. Training Loss: 17.856395721435547\n",
      "TEST ACCURACY: \n",
      "0.1867\n",
      "\n",
      "Epoch 57 Complete. Training Loss: 17.146099090576172\n",
      "TEST ACCURACY: \n",
      "0.1866\n",
      "\n",
      "Epoch 58 Complete. Training Loss: 19.340288162231445\n",
      "TEST ACCURACY: \n",
      "0.1866\n",
      "\n",
      "Epoch 59 Complete. Training Loss: 14.836923599243164\n",
      "TEST ACCURACY: \n",
      "0.1877\n",
      "\n",
      "Epoch 60 Complete. Training Loss: 18.7912654876709\n",
      "TEST ACCURACY: \n",
      "0.1869\n",
      "\n",
      "Epoch 61 Complete. Training Loss: 20.31645965576172\n",
      "TEST ACCURACY: \n",
      "0.1868\n",
      "\n",
      "Epoch 62 Complete. Training Loss: 16.419086456298828\n",
      "TEST ACCURACY: \n",
      "0.1871\n",
      "\n",
      "Epoch 63 Complete. Training Loss: 16.955036163330078\n",
      "TEST ACCURACY: \n",
      "0.1866\n",
      "\n",
      "Epoch 64 Complete. Training Loss: 15.998522758483887\n",
      "TEST ACCURACY: \n",
      "0.1869\n",
      "\n",
      "Epoch 65 Complete. Training Loss: 15.867276191711426\n",
      "TEST ACCURACY: \n",
      "0.1872\n",
      "\n",
      "Epoch 66 Complete. Training Loss: 17.256526947021484\n",
      "TEST ACCURACY: \n",
      "0.1868\n",
      "\n",
      "Epoch 67 Complete. Training Loss: 18.072582244873047\n",
      "TEST ACCURACY: \n",
      "0.1874\n",
      "\n",
      "Epoch 68 Complete. Training Loss: 16.298696517944336\n",
      "TEST ACCURACY: \n",
      "0.1871\n",
      "\n",
      "Epoch 69 Complete. Training Loss: 17.671058654785156\n",
      "TEST ACCURACY: \n",
      "0.1872\n",
      "\n",
      "Epoch 70 Complete. Training Loss: 19.814067840576172\n",
      "TEST ACCURACY: \n",
      "0.1868\n",
      "\n",
      "Epoch 71 Complete. Training Loss: 18.72593116760254\n",
      "TEST ACCURACY: \n",
      "0.1871\n",
      "\n",
      "Epoch 72 Complete. Training Loss: 17.3187313079834\n",
      "TEST ACCURACY: \n",
      "0.1874\n",
      "\n",
      "Epoch 73 Complete. Training Loss: 17.063777923583984\n",
      "TEST ACCURACY: \n",
      "0.1868\n",
      "\n",
      "Epoch 74 Complete. Training Loss: 24.219985961914062\n",
      "TEST ACCURACY: \n",
      "0.1866\n",
      "\n",
      "Epoch 75 Complete. Training Loss: 21.43570327758789\n",
      "TEST ACCURACY: \n",
      "0.1864\n",
      "\n",
      "Epoch 76 Complete. Training Loss: 17.44467544555664\n",
      "TEST ACCURACY: \n",
      "0.1869\n",
      "\n",
      "Epoch 77 Complete. Training Loss: 16.24009895324707\n",
      "TEST ACCURACY: \n",
      "0.1875\n",
      "\n",
      "Epoch 78 Complete. Training Loss: 11.980548858642578\n",
      "TEST ACCURACY: \n",
      "0.187\n",
      "\n",
      "Epoch 79 Complete. Training Loss: 13.106583595275879\n",
      "TEST ACCURACY: \n",
      "0.1866\n",
      "\n",
      "Epoch 80 Complete. Training Loss: 18.058917999267578\n",
      "TEST ACCURACY: \n",
      "0.1873\n",
      "\n",
      "Epoch 81 Complete. Training Loss: 16.14681053161621\n",
      "TEST ACCURACY: \n",
      "0.1872\n",
      "\n",
      "Epoch 82 Complete. Training Loss: 16.30042266845703\n",
      "TEST ACCURACY: \n",
      "0.187\n",
      "\n",
      "Epoch 83 Complete. Training Loss: 20.54659652709961\n",
      "TEST ACCURACY: \n",
      "0.1871\n",
      "\n",
      "Epoch 84 Complete. Training Loss: 17.749881744384766\n",
      "TEST ACCURACY: \n",
      "0.1873\n",
      "\n",
      "Epoch 85 Complete. Training Loss: 19.139375686645508\n",
      "TEST ACCURACY: \n",
      "0.1866\n",
      "\n",
      "Epoch 86 Complete. Training Loss: 13.149508476257324\n",
      "TEST ACCURACY: \n",
      "0.1865\n",
      "\n",
      "Epoch 87 Complete. Training Loss: 16.750959396362305\n",
      "TEST ACCURACY: \n",
      "0.1867\n",
      "\n",
      "Epoch 88 Complete. Training Loss: 20.801481246948242\n",
      "TEST ACCURACY: \n",
      "0.1871\n",
      "\n",
      "Epoch 89 Complete. Training Loss: 17.107465744018555\n",
      "TEST ACCURACY: \n",
      "0.187\n",
      "\n",
      "Epoch 90 Complete. Training Loss: 17.48323631286621\n",
      "TEST ACCURACY: \n",
      "0.1872\n",
      "\n",
      "Epoch 91 Complete. Training Loss: 15.168500900268555\n",
      "TEST ACCURACY: \n",
      "0.1872\n",
      "\n",
      "Epoch 92 Complete. Training Loss: 15.136052131652832\n",
      "TEST ACCURACY: \n",
      "0.1866\n",
      "\n",
      "Epoch 93 Complete. Training Loss: 16.316320419311523\n",
      "TEST ACCURACY: \n",
      "0.1861\n",
      "\n",
      "Epoch 94 Complete. Training Loss: 22.27967071533203\n",
      "TEST ACCURACY: \n",
      "0.1866\n",
      "\n",
      "Epoch 95 Complete. Training Loss: 14.757479667663574\n",
      "TEST ACCURACY: \n",
      "0.1873\n",
      "\n",
      "Epoch 96 Complete. Training Loss: 13.685747146606445\n",
      "TEST ACCURACY: \n",
      "0.1874\n",
      "\n",
      "Epoch 97 Complete. Training Loss: 21.15323257446289\n",
      "TEST ACCURACY: \n",
      "0.1863\n",
      "\n",
      "Epoch 98 Complete. Training Loss: 17.26211929321289\n",
      "TEST ACCURACY: \n",
      "0.187\n",
      "\n",
      "Epoch 99 Complete. Training Loss: 18.040422439575195\n",
      "TEST ACCURACY: \n",
      "0.1871\n",
      "\n",
      "Finished Training the Model\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "try:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # Epoch == Entire Training Set\n",
    "        for epoch in range(num_epochs):\n",
    "            num_batches = mnist.train.num_examples // batch_size\n",
    "\n",
    "            # 150 batch size\n",
    "            for iteration in range(num_batches):\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "                sess.run(train, feed_dict={X: X_batch, Y: y_batch})\n",
    "\n",
    "            training_loss = loss.eval(feed_dict={X: X_batch, Y: y_batch})   \n",
    "            print(\"Epoch {} Complete. Training Loss: {}\".format(epoch,training_loss))\n",
    "            saver.save(sess, \"../save/slearn_2-1.ckpt\")\n",
    "            \n",
    "            matches = tf.equal(tf.argmax(out_layer4, 1), tf.argmax(Y,1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "\n",
    "            print('TEST ACCURACY: ')\n",
    "            print (sess.run(acc, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n",
    "            print()\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print('Keyboard Interrupted')\n",
    "finally:\n",
    "    print('Finished Training the Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../save/slearn_2-1.ckpt\n",
      "TRAIN ACCURACY: \n",
      "0.18776363\n",
      "TEST ACCURACY: \n",
      "0.1871\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_test_labels = 10\n",
    "start_point = 15\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess,\"../save/slearn_2-1.ckpt\")\n",
    "    \n",
    "    params = sess.run([W1, W2, W3, b1, b2, b3])\n",
    "    \n",
    "    matches = tf.equal(tf.argmax(out_layer4, 1), tf.argmax(Y,1))\n",
    "    acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "    \n",
    "    print('TRAIN ACCURACY: ')\n",
    "    print (sess.run(acc, feed_dict={X:mnist.train.images, Y:mnist.train.labels}))\n",
    "\n",
    "    print('TEST ACCURACY: ')\n",
    "    print (sess.run(acc, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.47204027e-01, -1.63612232e-01, -7.89847821e-02,\n",
       "         -3.54875982e-01, -1.38225392e-01, -1.23432837e-01,\n",
       "         -1.67157084e-01, -1.62829198e-02, -1.15787296e-03,\n",
       "         -1.39118418e-01, -3.18070203e-01, -1.10288970e-01,\n",
       "         -3.19613591e-02, -1.62331983e-01, -5.58279939e-02,\n",
       "         -1.31763324e-01, -6.59467056e-02, -3.56064700e-02,\n",
       "         -3.52212995e-01, -4.30803783e-02, -1.23826161e-01,\n",
       "         -9.70576629e-02, -1.23359226e-01, -1.80440739e-01,\n",
       "         -1.11833684e-01, -9.85604227e-02, -2.80318856e-01,\n",
       "         -3.32584500e-01, -2.71379620e-01, -1.34534109e-02,\n",
       "         -1.56314582e-01, -1.74017325e-01, -8.31290409e-02,\n",
       "         -1.04702219e-01, -7.40552023e-02, -8.44248757e-03,\n",
       "         -5.52955829e-02, -3.79176140e-01, -1.73021987e-01,\n",
       "          2.18435246e-02, -3.24476585e-02, -1.05944194e-01,\n",
       "         -5.48586366e-04, -5.29333465e-02, -5.57320453e-02,\n",
       "         -1.68555632e-01, -2.45512798e-02, -5.84157184e-02,\n",
       "         -1.03683338e-01, -1.47968471e-01, -9.04036537e-02,\n",
       "         -1.60583958e-01, -3.05052727e-01,  2.57327646e-01,\n",
       "         -7.13439509e-02, -3.67458947e-02, -8.82331356e-02,\n",
       "         -9.72316489e-02, -1.57325760e-01, -3.90664428e-01,\n",
       "         -1.19881317e-01, -3.28041464e-01, -1.03455327e-01,\n",
       "         -1.22388311e-01, -1.23182312e-01, -1.44333243e-01,\n",
       "         -1.74962461e-01, -2.31111944e-01, -1.62783593e-01,\n",
       "         -1.59981668e-01, -2.86086857e-01, -1.79466233e-01,\n",
       "         -1.23949155e-01, -9.69644487e-02, -4.71536741e-02,\n",
       "         -9.44001041e-03, -9.78582948e-02, -1.68359756e-01,\n",
       "         -2.37568825e-01, -1.72158942e-01, -1.00157902e-01,\n",
       "         -6.88705295e-02, -3.35422218e-01, -9.86346528e-02,\n",
       "         -1.32756695e-01, -1.68518558e-01, -1.24485359e-01,\n",
       "         -8.64889473e-02, -9.75486562e-02, -1.28417507e-01,\n",
       "         -9.48934723e-03, -1.66137531e-01, -1.31608590e-01,\n",
       "         -5.69322929e-02, -3.58387291e-01, -8.99364054e-02,\n",
       "         -8.96228186e-04, -7.56929517e-02, -1.64611086e-01,\n",
       "         -3.58821511e-01, -3.08332145e-01, -5.98468296e-02,\n",
       "         -3.04358572e-01, -2.73921967e-01, -8.80588740e-02,\n",
       "         -3.84690911e-01, -3.37339312e-01, -1.35559723e-01,\n",
       "         -5.36645018e-02, -3.15765850e-02, -2.96706975e-01,\n",
       "         -6.65461719e-02, -8.85707512e-02, -7.01991767e-02,\n",
       "         -2.99653590e-01, -2.53077447e-01, -2.14924470e-01,\n",
       "         -3.51845831e-01, -4.21932250e-01, -9.68566164e-02,\n",
       "         -1.34591624e-01, -1.12940945e-01, -2.81757951e-01,\n",
       "         -3.65625739e-01, -9.09371972e-02, -2.03900151e-02,\n",
       "         -3.60966176e-01, -5.66721745e-02, -1.09533951e-01,\n",
       "         -3.34170938e-01, -8.02159756e-02, -7.17942044e-02,\n",
       "         -3.08958709e-01, -4.30003256e-02, -2.49403194e-02,\n",
       "         -3.44856799e-01, -8.76838043e-02, -6.68743327e-02,\n",
       "         -3.61145824e-01, -1.58325717e-01, -1.04356416e-01,\n",
       "         -1.04099996e-01, -9.49116796e-02, -2.68948585e-01,\n",
       "         -7.85288513e-02, -1.60234705e-01, -1.15117557e-01,\n",
       "         -1.13882996e-01, -3.13928097e-01, -1.63890168e-01,\n",
       "         -4.43675630e-02, -1.75640061e-02, -3.88302863e-01,\n",
       "         -5.15844151e-02, -1.67640358e-01],\n",
       "        [ 3.86695534e-01,  4.29798812e-01,  2.07487941e-01,\n",
       "          3.30445468e-01,  3.63109231e-01,  3.03328872e-01,\n",
       "          6.10846102e-01,  4.27741855e-02,  3.04165762e-03,\n",
       "          1.04480498e-01,  8.29673111e-01,  2.89722025e-01,\n",
       "          8.39604363e-02,  4.26435679e-01,  1.46656543e-01,\n",
       "          3.07556599e-01,  1.73237756e-01,  9.35359076e-02,\n",
       "          9.27816927e-01,  1.13169380e-01,  3.25283349e-01,\n",
       "          2.54964232e-01,  3.24056745e-01,  4.74006206e-01,\n",
       "          2.93779880e-01,  2.58911908e-01,  6.51916683e-01,\n",
       "          8.56952488e-01,  6.79048300e-01,  3.53412442e-02,\n",
       "          3.94797981e-01,  4.57132310e-01,  2.18374640e-01,\n",
       "          2.75045991e-01,  1.94538251e-01,  2.21778713e-02,\n",
       "          1.45257935e-01,  9.55086589e-01,  4.54517633e-01,\n",
       "          1.56972751e-01,  8.52379054e-02,  2.78308570e-01,\n",
       "          1.44110108e-03,  1.39052495e-01,  1.46404490e-01,\n",
       "          4.42784786e-01,  6.44946322e-02,  1.53454334e-01,\n",
       "          2.72369444e-01,  3.88703644e-01,  2.37484589e-01,\n",
       "          4.21843708e-01,  7.86952376e-01, -7.10264221e-02,\n",
       "          1.87415972e-01,  9.65290964e-02,  2.31782764e-01,\n",
       "          2.55421281e-01,  4.13284659e-01,  9.94970739e-01,\n",
       "          3.14920485e-01,  9.65690613e-01,  2.71770477e-01,\n",
       "          3.21506232e-01,  3.23592007e-01,  3.79154146e-01,\n",
       "          4.59615111e-01,  4.54358488e-01,  4.27622020e-01,\n",
       "          4.20261562e-01,  7.92598724e-01,  4.71446246e-01,\n",
       "          3.25606436e-01,  2.54719377e-01,  1.23869665e-01,\n",
       "          2.47983001e-02,  2.57067442e-01,  3.54685962e-01,\n",
       "          6.79189563e-01,  5.94867766e-01,  2.63108343e-01,\n",
       "          1.80918455e-01,  7.37922013e-01,  2.59106904e-01,\n",
       "          3.48743290e-01,  4.42687392e-01,  3.27015013e-01,\n",
       "          2.27200896e-01,  2.56254047e-01,  3.37344527e-01,\n",
       "          2.49279048e-02,  4.36432600e-01,  3.45727295e-01,\n",
       "          1.49557471e-01,  9.18174207e-01,  2.36257136e-01,\n",
       "          2.35433388e-03,  1.98840514e-01,  4.32422727e-01,\n",
       "          9.30697203e-01,  8.02907526e-01,  1.57213777e-01,\n",
       "          7.91159093e-01,  7.20878065e-01,  2.31325001e-01,\n",
       "          8.96449208e-01,  8.81911635e-01,  3.56106669e-01,\n",
       "          1.40973195e-01,  8.29496607e-02,  7.89770007e-01,\n",
       "          1.74812496e-01,  2.32669652e-01,  1.84408709e-01,\n",
       "          1.00282454e+00,  6.01106524e-01,  6.15544856e-01,\n",
       "          8.79846513e-01,  8.93543899e-01,  2.54436105e-01,\n",
       "          3.53563547e-01,  2.96688616e-01,  8.16413164e-01,\n",
       "          9.69825208e-01,  2.38886178e-01,  5.35632595e-02,\n",
       "          9.63267744e-01,  1.48874149e-01,  2.87738621e-01,\n",
       "          8.75743806e-01,  2.10722193e-01,  1.88598752e-01,\n",
       "          8.06634307e-01,  1.12959094e-01,  6.55166134e-02,\n",
       "          9.01150644e-01,  2.30339706e-01,  1.75674573e-01,\n",
       "          9.57391500e-01,  4.15911466e-01,  2.74137586e-01,\n",
       "          2.73463994e-01,  2.49326885e-01,  7.16819108e-01,\n",
       "          2.06290230e-01,  4.20926243e-01,  3.02406400e-01,\n",
       "          2.99163282e-01,  8.17639768e-01,  4.30528939e-01,\n",
       "          1.16550736e-01,  4.61395122e-02,  9.11712110e-01,\n",
       "          1.35508940e-01,  4.40380424e-01]], dtype=float32),\n",
       " array([[ 0.12928236,  0.00709345,  0.2270143 , ..., -0.11943059,\n",
       "          0.70338863,  0.65438473],\n",
       "        [ 0.5483187 ,  0.02092948,  0.75045013, ...,  0.6519301 ,\n",
       "          0.2481015 , -0.07473479],\n",
       "        [ 0.6927793 ,  0.39143902,  0.849975  , ..., -0.02917881,\n",
       "          0.7804612 ,  0.8315323 ],\n",
       "        ...,\n",
       "        [ 0.5786322 ,  0.14762916, -0.08185872, ...,  0.49579588,\n",
       "         -0.18292516, -0.07976033],\n",
       "        [ 0.40146548,  0.82552207,  0.22120453, ...,  0.37094074,\n",
       "          0.6960912 ,  0.29183385],\n",
       "        [ 0.7315277 ,  0.3760425 ,  0.20362827, ...,  0.39146245,\n",
       "          0.6885634 ,  0.46912655]], dtype=float32),\n",
       " array([[ 0.35522136],\n",
       "        [ 0.69389915],\n",
       "        [ 0.5643286 ],\n",
       "        [ 0.41816524],\n",
       "        [ 0.5685585 ],\n",
       "        [-1.0602589 ],\n",
       "        [-1.0581701 ],\n",
       "        [-1.2828221 ],\n",
       "        [ 0.41325775],\n",
       "        [ 1.1368498 ],\n",
       "        [ 0.75989974],\n",
       "        [ 0.62753683],\n",
       "        [ 0.5802614 ],\n",
       "        [ 0.5320976 ],\n",
       "        [ 0.9609214 ],\n",
       "        [ 0.5695341 ],\n",
       "        [ 1.0445309 ],\n",
       "        [ 0.3090306 ],\n",
       "        [ 0.7405133 ],\n",
       "        [ 1.1603845 ],\n",
       "        [-1.057154  ],\n",
       "        [ 0.9274573 ],\n",
       "        [-0.9901777 ],\n",
       "        [-1.139869  ],\n",
       "        [ 0.34187225],\n",
       "        [ 0.3492821 ],\n",
       "        [ 0.44456044],\n",
       "        [ 0.6157467 ],\n",
       "        [ 1.07403   ],\n",
       "        [ 1.0525222 ],\n",
       "        [ 0.5960316 ]], dtype=float32),\n",
       " array([-0.28383029, -0.31458557, -0.15186486, -0.08568849, -0.26639026,\n",
       "         0.46616086,  0.38171363, -0.03149702, -0.00305842, -0.06689897,\n",
       "         0.11861382, -0.21263544, -0.06160916, -0.31217527, -0.10744675,\n",
       "         0.46866935, -0.12664579, -0.06842119,  0.12218756, -0.08283355,\n",
       "        -0.23805155, -0.1870908 , -0.23751526, -0.3471313 , -0.21489719,\n",
       "        -0.18942702,  0.00103795,  0.20446862,  0.14648442, -0.02596493,\n",
       "         0.3810373 , -0.33435127, -0.15995553, -0.20170794, -0.14258547,\n",
       "        -0.01627403, -0.10622326,  0.03134596, -0.3327444 ,  0.6301357 ,\n",
       "        -0.06249094, -0.20345554, -0.00187809, -0.10168617, -0.10713416,\n",
       "        -0.32413107, -0.04729197, -0.11250894, -0.19976912, -0.28495467,\n",
       "        -0.17469911, -0.30920935,  0.18708168,  0.6715552 , -0.13741975,\n",
       "        -0.07063854, -0.16984136, -0.18727449, -0.30248228,  0.02102096,\n",
       "        -0.23112178, -0.00735454, -0.19898465, -0.23572895, -0.23653843,\n",
       "        -0.27749056, -0.33645573,  0.10967816, -0.31371927, -0.30730048,\n",
       "         0.0405416 , -0.34579587, -0.23848681, -0.1865959 , -0.09067887,\n",
       "        -0.01844228, -0.18869911,  0.40769142,  0.28281525,  0.27972955,\n",
       "        -0.19297187, -0.13239871,  0.2738506 , -0.19007044, -0.25604025,\n",
       "        -0.32444695, -0.2393859 , -0.16607864, -0.18790606, -0.24759218,\n",
       "        -0.01826485, -0.31940347, -0.25278816, -0.10948997,  0.13003682,\n",
       "        -0.17285003, -0.00264572, -0.14541171, -0.31624797,  0.02937284,\n",
       "         0.11000626, -0.11497195,  0.10267633,  0.20169014, -0.17002307,\n",
       "        -0.20420423,  0.12961616, -0.26094735, -0.10315148, -0.06065961,\n",
       "         0.18445215, -0.12804289, -0.17049542, -0.13507186, -0.04971129,\n",
       "         0.2141091 ,  0.25883555,  0.02746032, -0.08917745, -0.18614395,\n",
       "        -0.25848284, -0.21713065,  0.11976226,  0.12408338, -0.17476822,\n",
       "        -0.0395139 ,  0.12471218, -0.1089573 , -0.21143371,  0.13218367,\n",
       "        -0.15427087, -0.13839707,  0.11415293, -0.08271152, -0.04803753,\n",
       "         0.03850853, -0.16844337, -0.12841488,  0.12194377, -0.30410913,\n",
       "        -0.20056294, -0.20006253, -0.18251912,  0.16646135, -0.15121455,\n",
       "        -0.30812535, -0.22134608, -0.21894099,  0.11218538, -0.31525296,\n",
       "        -0.08532681, -0.03395198,  0.06721139, -0.09930573, -0.32260868],\n",
       "       dtype=float32),\n",
       " array([-8.5779559e-03, -4.3256771e-02, -1.5175826e-02,  7.9410721e-04,\n",
       "         9.5527829e-04, -6.5221602e-01,  1.2122130e+00, -9.0513527e-01,\n",
       "        -1.4564237e-02, -1.4557555e-01,  8.2974182e-04,  8.4305281e-04,\n",
       "         8.7601156e-04, -4.8266802e-02,  9.1064977e-04,  8.2593999e-04,\n",
       "         8.5313502e-04,  7.7705708e-04,  8.3741522e-04,  8.6063647e-04,\n",
       "        -8.0232173e-01, -8.8200428e-02, -7.5361711e-01,  1.2203188e+00,\n",
       "        -9.3311787e-02,  7.9648086e-04, -1.7449563e-02,  9.3679735e-04,\n",
       "        -6.8908416e-02, -1.5880530e-01,  8.3580124e-04], dtype=float32),\n",
       " array([-1.0601544], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(params)):\n",
    "    np.save('../save/weights/slearn_parms{}_2-1.npy'.format(i),params[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
