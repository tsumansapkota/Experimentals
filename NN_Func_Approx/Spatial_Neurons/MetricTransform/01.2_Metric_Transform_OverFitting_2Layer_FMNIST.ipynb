{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf8423fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms as T\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm\n",
    "# from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019e798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53af51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b34b043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtnnlib as dtnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1602c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.5,],\n",
    "        std=[0.5,],\n",
    "    ),\n",
    "])\n",
    "\n",
    "# train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/\", train=True, download=True, transform=mnist_transform)\n",
    "# test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/\", train=False, download=True, transform=mnist_transform)\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"../../../../_Datasets/\", train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = datasets.MNIST(root=\"../../../../_Datasets/\", train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a6807321",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "47582925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4d0f1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1000\n",
    "model = nn.Sequential(\n",
    "            dtnn.DistanceTransform_MinExp(784, h),\n",
    "#             dtnn.DistanceTransform_Exp(784, h),\n",
    "#             nn.BatchNorm1d(10),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(h, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c4287b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DistanceTransform_MinExp()\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=1000, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "228a867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model[0].set_centroid_to_data_maxdist(train_loader)\n",
    "# model[0].set_centroid_to_data(train_loader)\n",
    "# model[0].set_centroid_to_data_randomly(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c095570",
   "metadata": {},
   "source": [
    "## Randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4b46ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = model[0].centers.shape[0]\n",
    "new_center = []\n",
    "new_labels = []\n",
    "count = 0\n",
    "for i, (xx, yy) in enumerate(train_loader):\n",
    "    xx = xx.reshape(-1, model[0].input_dim).to(model[0].centers.device)\n",
    "    if count+xx.shape[0] < N:\n",
    "        new_center.append(xx)\n",
    "        new_labels.append(yy)\n",
    "        count += xx.shape[0]\n",
    "    elif count >= N:\n",
    "        break\n",
    "    else:\n",
    "        new_center.append(xx[:N-count])\n",
    "        new_labels.append(yy[:N-count])\n",
    "        count = N\n",
    "        break\n",
    "        \n",
    "new_center = torch.cat(new_center, dim=0)\n",
    "new_labels = torch.cat(new_labels, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b7557",
   "metadata": {},
   "source": [
    "## Maxdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e535a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4fa551d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████                                        | 241/1200 [00:18<01:15, 12.73it/s]\n"
     ]
    }
   ],
   "source": [
    "N = model[0].centers.shape[0]\n",
    "new_center = torch.empty_like(model[0].centers)\n",
    "new_labels = torch.empty(model[0].num_centers, dtype=torch.long)\n",
    "\n",
    "min_dists = torch.empty(N)\n",
    "count = 0\n",
    "steps = int(epoch*len(train_loader))\n",
    "for i, (xx, yy) in enumerate(tqdm(train_loader)):\n",
    "    if i > steps: break\n",
    "\n",
    "    xx = xx.reshape(-1, model[0].input_dim).to(model[0].centers.device)\n",
    "    if count < N:\n",
    "        if N-count < train_loader.batch_size:\n",
    "            #### final fillup\n",
    "            new_center[count:count+N-count] = xx[:N-count]\n",
    "            xx = xx[N-count:]\n",
    "            yy = yy[N-count:]\n",
    "            dists = torch.cdist(new_center, new_center)+torch.eye(N).to(model[0].centers.device)*1e5\n",
    "            min_dists = dists.min(dim=0)[0]\n",
    "            count = N\n",
    "\n",
    "        else:#### fill the center\n",
    "            new_center[count:count+len(xx)] = xx\n",
    "            new_labels[count:count+len(xx)] = yy\n",
    "            count += len(xx)\n",
    "            continue\n",
    "\n",
    "    ammd = min_dists.argmin()\n",
    "    for i, x in enumerate(xx):\n",
    "        dists = torch.norm(new_center-x, dim=1)\n",
    "        md = dists.min()\n",
    "        if md > min_dists[ammd]:\n",
    "            min_dists[ammd] = md\n",
    "            new_center[ammd] = x\n",
    "            new_labels[ammd] = yy[i]\n",
    "            ammd = min_dists.argmin()\n",
    "            \n",
    "# self.centers.data = new_center.to(self.centers.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aaf6a088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 784]), torch.Size([100]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_center.shape, new_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160fc790",
   "metadata": {},
   "source": [
    "## Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "02e46e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.zeros(len(new_labels), 10)\n",
    "for i in range(len(new_labels)):\n",
    "    weights[i, new_labels[i]] = 1.\n",
    "# weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "29e37870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 10])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9f5198aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].centers.data = new_center.to(model[0].centers.device)\n",
    "model[-1].weight.data = weights.t().to(model[-1].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a7bd80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch, model):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    acc = 100.*correct/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5ab89fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DistanceTransform_MinExp()\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=1000, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d7f5800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d0441388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 146.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.090 | Acc: 86.130 8613/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86.13"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = test(0, model)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545b2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "65.09"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
