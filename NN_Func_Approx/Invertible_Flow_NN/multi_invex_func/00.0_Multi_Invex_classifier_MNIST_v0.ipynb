{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nflib\n",
    "from nflib.flows import SequentialFlow, NormalizingFlow, ActNorm, AffineConstantFlow\n",
    "import nflib.coupling_flows as icf\n",
    "import nflib.inn_flow as inn\n",
    "import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import distributions\n",
    "from torch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mylibrary.datasets as datasets\n",
    "# import mylibrary.nnlib as tnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.FashionMNIST()\n",
    "# mnist.download_mnist()\n",
    "# mnist.save_mnist()\n",
    "train_data, train_label_, test_data, test_label_ = mnist.load()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "# train_label = tnn.Logits.index_to_logit(train_label_)\n",
    "train_size = len(train_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting data to pytorch format\n",
    "train_data = torch.Tensor(train_data)\n",
    "test_data = torch.Tensor(test_data)\n",
    "train_label = torch.LongTensor(train_label_)\n",
    "test_label = torch.LongTensor(test_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        \n",
    "#         self.label = mask.type(torch.float32).reshape(-1,1)\n",
    "        self._shuffle_data_()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _shuffle_data_(self):\n",
    "        randidx = random.sample(range(len(self.data)), k=len(self.data))\n",
    "        self.data = self.data[randidx]\n",
    "        self.label = self.label[randidx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, lbl = self.data[idx], self.label[idx]\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST_Dataset(train_data, train_label)\n",
    "test_dataset = MNIST_Dataset(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_Softmax(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.linear = nn.Linear(input_dim, num_sets)\n",
    "        self.linear.bias.data *= 0\n",
    "        self.linear.weight.data *= 0.1\n",
    "        self.cls_weight = nn.Parameter(torch.ones(num_sets, output_dim)/output_dim)\n",
    "        self.cls_confidence = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hard=True):\n",
    "        x = self.linear(x)\n",
    "        if hard:\n",
    "            x = torch.softmax(-x*1e5, dim=1)\n",
    "        else:\n",
    "            x = torch.softmax(-x*self.inv_temp, dim=1)\n",
    "        self.cls_confidence = x\n",
    "        c = torch.softmax(self.cls_weight, dim=1)\n",
    "#         c = self.cls_weight\n",
    "        return x@c ## since both are normalized, it is also normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConnectedClassifier_SoftKMeans(nn.Module):\n",
    "    \n",
    "#     def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "#         super().__init__()\n",
    "#         self.input_dim = input_dim\n",
    "#         self.output_dim = output_dim\n",
    "#         self.num_sets = num_sets\n",
    "#         self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "#         self.centers = nn.Parameter(torch.rand(num_sets, input_dim)*2-1)\n",
    "        \n",
    "# #         self.cls_weight = nn.Parameter(torch.ones(num_sets, output_dim)/output_dim)\n",
    "\n",
    "#         init_val = torch.randn(num_sets, output_dim)*0.01\n",
    "#         for ns in range(num_sets):\n",
    "#             init_val[ns, ns%output_dim] = 10.\n",
    "#         self.cls_weight = nn.Parameter(init_val)\n",
    "\n",
    "#         self.cls_confidence = None\n",
    "        \n",
    "        \n",
    "#     def forward(self, x, hard=False):\n",
    "#         x = x[:, :self.input_dim]\n",
    "#         dists = torch.cdist(x, self.centers)\n",
    "#         dists = dists/np.sqrt(self.input_dim) ### correction to make diagonal of unit square 1 in nD space\n",
    "        \n",
    "#         if hard:\n",
    "#             x = torch.softmax(-dists*1e5, dim=1)\n",
    "#         else:\n",
    "#             x = torch.softmax(-dists*self.inv_temp, dim=1)\n",
    "#         self.cls_confidence = x\n",
    "#         c = torch.softmax(self.cls_weight, dim=1)\n",
    "# #         c = self.cls_weight\n",
    "#         return x@c ## since both are normalized, it is also normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_SoftKMeans(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.centers = nn.Parameter(torch.rand(num_sets, input_dim)*2-1)\n",
    "        \n",
    "#         self.cls_weight = nn.Parameter(torch.ones(num_sets, output_dim)/output_dim)\n",
    "\n",
    "        init_val = torch.randn(num_sets, output_dim)*0.01\n",
    "        for ns in range(num_sets):\n",
    "            init_val[ns, ns%output_dim] = 10.\n",
    "        self.cls_weight = nn.Parameter(init_val)\n",
    "\n",
    "        self.cls_confidence = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "        self.cls_weight.data = torch.abs(self.cls_weight.data/self.cls_weight.data.sum(dim=1, keepdim=True))\n",
    "        \n",
    "        x = x[:, :self.input_dim]\n",
    "        dists = torch.cdist(x, self.centers)\n",
    "        dists = dists/np.sqrt(self.input_dim) ### correction to make diagonal of unit square 1 in nD space\n",
    "        \n",
    "        if hard:\n",
    "            x = torch.softmax(-dists*1e5, dim=1)\n",
    "        else:\n",
    "            x = torch.softmax(-dists*self.inv_temp, dim=1)\n",
    "        self.cls_confidence = x\n",
    "#         c = torch.softmax(self.cls_weight, dim=1)\n",
    "        c = self.cls_weight\n",
    "        return x@c ## since both are normalized, it is also normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "actf = irf.Swish\n",
    "flows = [\n",
    "    ActNorm(784),\n",
    "    irf.ResidualFlow(784, [784], activation=actf),\n",
    "    ActNorm(784),\n",
    "    irf.ResidualFlow(784, [784], activation=actf),\n",
    "    ActNorm(784),\n",
    "        ]\n",
    "\n",
    "model = SequentialFlow(flows)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Sequential(nn.Linear(784, 784, bias=False),\n",
    "#                       nn.BatchNorm1d(784),\n",
    "#                       nn.SELU(),\n",
    "#                       nn.Linear(784, 784, bias=False),\n",
    "#                       nn.BatchNorm1d(784),\n",
    "#                       nn.SELU(),\n",
    "#                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialFlow(\n",
       "  (flows): ModuleList(\n",
       "    (0): ActNorm()\n",
       "    (1): ResidualFlow(\n",
       "      (resblock): ModuleList(\n",
       "        (0): Linear(in_features=784, out_features=784, bias=True)\n",
       "        (1): Swish()\n",
       "        (2): Linear(in_features=784, out_features=784, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ActNorm()\n",
       "    (3): ResidualFlow(\n",
       "      (resblock): ModuleList(\n",
       "        (0): Linear(in_features=784, out_features=784, bias=True)\n",
       "        (1): Swish()\n",
       "        (2): Linear(in_features=784, out_features=784, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ActNorm()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-5.2329e-01, -9.5173e-01, -1.3168e+00,  7.7942e-01, -3.3448e-01,\n",
       "          -4.0439e-01, -6.2763e-01,  4.5768e-01, -3.0654e-01,  9.8062e-01,\n",
       "          -1.9224e-01,  3.6289e-01,  7.4330e-01,  1.4523e-01, -4.1951e-01,\n",
       "          -3.4426e-01, -4.4905e-02, -1.7280e+00, -6.9065e-01,  1.3470e+00,\n",
       "           1.7937e+00,  2.1665e-01, -3.2041e-02,  5.4881e-01,  1.3522e+00,\n",
       "          -2.1197e+00, -1.6294e+00,  1.9281e-02, -9.1860e-01, -1.0233e+00,\n",
       "           2.0823e+00,  7.1021e-01, -1.1690e+00,  1.5567e+00,  5.1556e-01,\n",
       "           2.7652e-01,  4.5479e-01, -2.8915e-01,  1.0738e+00,  2.4312e+00,\n",
       "           2.7813e+00,  3.4386e-02, -3.5578e-01, -1.4994e+00,  4.6217e-01,\n",
       "           1.2910e+00, -5.1789e-01,  6.8852e-01,  1.9942e+00,  2.9899e-02,\n",
       "           1.0201e+00, -4.8417e-01,  1.1400e+00,  1.5406e+00,  2.8544e-01,\n",
       "          -2.3441e-01, -6.9238e-01,  1.2394e+00,  7.7584e-01, -7.7021e-01,\n",
       "          -1.0340e+00,  4.4855e-01,  1.0274e+00, -5.4802e-01,  1.2045e+00,\n",
       "           8.8437e-01, -3.8892e-01,  1.1630e+00,  1.1074e+00, -6.4393e-01,\n",
       "          -7.6198e-01,  1.6798e+00,  1.4315e+00, -2.0697e+00, -8.8594e-01,\n",
       "          -1.3520e+00,  8.9486e-01,  3.4554e-01,  9.0976e-02,  1.6393e+00,\n",
       "          -1.2380e+00, -6.3068e-01, -1.0512e+00, -3.8028e-01,  9.7909e-02,\n",
       "           9.0741e-01,  2.3164e+00, -1.0471e+00,  5.5290e-01, -9.7018e-01,\n",
       "           4.7337e-01,  6.1880e-01,  1.4245e+00, -4.5350e-01,  1.7591e+00,\n",
       "           1.1203e+00, -6.7907e-01, -3.3887e-01,  9.1100e-01, -6.5092e-01,\n",
       "          -2.1152e+00, -1.3136e+00,  6.4219e-01,  1.3911e+00, -1.3340e+00,\n",
       "          -6.8049e-01,  8.5130e-01,  1.4844e+00, -1.1206e+00, -1.2413e+00,\n",
       "          -4.8028e-01,  3.2460e-02, -4.9412e-01, -9.3475e-01, -6.1528e-01,\n",
       "          -4.3192e-01, -1.4888e-01, -2.5763e-01, -7.7718e-01, -1.6043e+00,\n",
       "           1.4389e+00,  5.2323e-01,  1.3849e-01,  1.6180e+00,  4.5122e-01,\n",
       "           6.5017e-01,  2.8913e-01, -4.1872e-03,  7.0055e-01, -2.9521e-01,\n",
       "           7.7163e-01,  5.9555e-02,  5.5550e-01, -4.9665e-01, -1.4904e+00,\n",
       "           6.1574e-01,  6.8667e-01,  1.0225e+00,  2.3972e+00, -6.1881e-03,\n",
       "          -5.9627e-01, -4.8539e-01,  5.0044e-01, -4.1325e-01,  1.7221e+00,\n",
       "          -1.1491e+00,  8.0493e-01,  5.4938e-01, -1.2050e+00, -1.1563e+00,\n",
       "          -1.5375e-01,  1.5068e-01,  4.0685e-01,  4.3791e-01,  2.1698e-01,\n",
       "           7.0529e-01,  6.1845e-01,  2.3814e+00,  2.6364e+00, -5.1159e-01,\n",
       "           2.0440e+00,  8.6777e-01,  1.1005e+00, -7.4115e-01,  1.2226e-01,\n",
       "           5.7052e-01,  6.8527e-01, -1.9258e+00, -1.1331e-01, -9.4121e-04,\n",
       "          -1.5512e-02,  1.0461e+00, -1.3362e+00,  3.5857e-01, -4.6028e-01,\n",
       "          -2.4617e-02,  5.6216e-01, -3.3387e-01, -2.1795e-02, -9.1642e-01,\n",
       "           3.6880e-01, -1.6647e+00, -8.7207e-01,  1.8648e-01,  7.5880e-01,\n",
       "           2.5608e+00,  6.6778e-01,  1.4823e+00, -4.2950e-01, -7.9875e-01,\n",
       "          -3.7613e-01,  1.8262e+00, -1.9260e+00,  1.0874e+00,  8.8050e-01,\n",
       "           6.9098e-01, -6.0873e-01, -3.7611e-02, -6.9932e-01,  4.2082e-01,\n",
       "           6.3983e-01,  4.9621e-01,  1.2499e+00,  9.8721e-01,  2.1993e+00,\n",
       "          -9.8594e-01,  5.6277e-01, -3.8032e-01,  1.2981e+00, -5.7932e-02,\n",
       "          -3.7812e-01,  6.8824e-02,  3.2146e-01,  9.8567e-01, -1.6610e+00,\n",
       "           2.7047e+00, -8.7589e-01, -1.1266e+00,  9.6536e-01, -5.6722e-01,\n",
       "          -2.8935e-01,  1.5536e+00, -2.2464e-01, -2.0018e+00, -1.2570e+00,\n",
       "          -4.0641e-01, -1.4666e-01, -1.7020e-01,  2.7576e+00,  9.6463e-01,\n",
       "          -8.4866e-02, -1.9519e-01, -1.2982e+00,  9.7118e-01,  9.6910e-01,\n",
       "          -1.9317e-01,  8.6956e-01,  1.8540e-01, -1.1924e+00,  7.8213e-01,\n",
       "           5.7488e-01,  9.6477e-01,  1.9432e+00, -5.7391e-01, -1.9386e+00,\n",
       "          -1.2129e+00, -1.9464e-01, -3.3775e-01,  7.9846e-01,  1.6491e+00,\n",
       "          -9.8734e-02,  8.1046e-01, -8.5131e-02,  6.0516e-02, -7.7650e-01,\n",
       "           1.3219e+00,  1.3935e-01, -3.6486e-01, -1.1044e+00,  8.1525e-01,\n",
       "           1.1966e+00, -3.3830e-01,  1.5556e+00,  1.3438e+00,  2.2412e+00,\n",
       "           1.5388e+00, -1.8004e+00,  4.9650e-01, -1.0725e+00, -2.6026e-01,\n",
       "          -3.5623e-01, -7.0050e-01, -2.4155e-01,  1.0573e+00, -1.2639e-01,\n",
       "          -1.5991e-02, -3.4094e-01, -6.0873e-02,  7.8395e-02, -1.1494e+00,\n",
       "          -7.1036e-01,  1.6175e-01,  2.8441e-01,  6.9295e-01,  8.3294e-01,\n",
       "           2.0198e-01,  6.9443e-01, -1.9926e-01,  9.8969e-01,  9.9841e-01,\n",
       "          -3.9067e-01, -1.1116e+00,  2.1135e-01,  1.6774e-01, -7.5454e-01,\n",
       "           3.7679e-01, -2.1818e-01, -8.0953e-01, -1.0314e+00,  1.6503e+00,\n",
       "           2.9642e-01, -9.4567e-01,  7.4462e-02, -1.1779e+00, -2.6600e-01,\n",
       "          -9.6369e-01, -5.8723e-01, -2.3276e+00, -2.0550e-01,  2.4506e+00,\n",
       "           1.2809e+00,  8.6211e-01, -1.2086e+00,  1.2105e+00, -1.3791e+00,\n",
       "           5.4706e-01,  6.5821e-01,  1.9749e-01, -2.5883e+00,  2.5054e-02,\n",
       "          -3.1085e-01, -3.3661e-01, -7.4192e-01, -1.3537e+00,  1.9192e-02,\n",
       "           1.7119e-02, -8.3472e-01,  2.0466e+00, -1.7420e+00, -1.4222e+00,\n",
       "           1.1184e-01, -2.3751e+00,  8.5994e-01,  4.5555e-01,  1.3471e+00,\n",
       "          -1.0088e+00,  6.3834e-01, -3.3148e-01,  2.0652e-01,  8.0393e-01,\n",
       "           1.9048e+00,  1.1598e+00, -2.9871e-01,  5.9102e-01,  1.6418e+00,\n",
       "           2.4381e-01,  2.9455e-01, -1.7788e-01,  7.2015e-01,  1.6132e-01,\n",
       "           1.2915e+00, -7.7978e-01,  3.6463e-01, -6.3135e-01, -1.0570e+00,\n",
       "          -2.1996e-01, -3.0562e-01, -2.9568e+00, -7.3277e-01, -8.1781e-01,\n",
       "           6.7599e-01,  1.4247e+00,  6.4607e-01, -1.2847e+00,  5.7633e-01,\n",
       "           1.8922e+00, -1.5800e-01,  1.8800e+00, -4.5278e-01, -4.1824e-01,\n",
       "           6.8307e-01, -1.5501e+00, -1.4590e-01,  1.1633e+00, -1.2790e+00,\n",
       "          -6.0454e-01,  1.1293e+00, -9.7264e-01,  6.0217e-02, -9.0560e-01,\n",
       "           6.9074e-01,  4.8874e-01, -1.1842e+00, -1.1716e+00,  1.7193e+00,\n",
       "          -8.4994e-01,  8.3462e-01, -7.6105e-02, -1.7842e-01, -4.9099e-02,\n",
       "          -1.9471e-01, -5.6640e-01,  9.3733e-02, -1.3333e+00,  1.4574e-01,\n",
       "           5.7644e-01,  1.1940e+00, -7.9783e-01, -5.9168e-01,  1.3243e-01,\n",
       "          -2.3831e-01,  6.5148e-01, -4.8210e-01,  1.7670e-01,  1.4029e+00,\n",
       "          -1.4432e+00,  1.5029e+00, -7.8805e-01, -8.6172e-02,  6.6275e-02,\n",
       "           9.5993e-01,  5.5574e-01,  1.0454e+00,  1.7239e+00,  1.5483e-01,\n",
       "          -4.2345e-02, -9.9791e-01,  1.0118e+00,  1.3958e+00,  1.9746e+00,\n",
       "          -1.6848e-01, -5.0124e-01,  7.4549e-01,  2.4991e-01,  8.9332e-01,\n",
       "          -1.0110e+00,  1.8612e-01,  2.9384e+00, -1.0142e+00, -8.1930e-02,\n",
       "          -5.0371e-01,  2.6895e+00,  2.1334e-02, -1.6166e-01, -9.2909e-01,\n",
       "          -3.7540e-01, -3.8448e-02,  8.4182e-01, -4.9428e-02, -2.8673e-01,\n",
       "           3.7081e-01, -1.1536e+00, -1.1340e+00, -2.8723e-02, -3.6564e-01,\n",
       "          -7.2017e-01,  1.3051e+00,  5.6903e-01,  6.0736e-01, -2.7019e-01,\n",
       "          -2.6994e-01,  7.5705e-01,  1.6813e-01, -1.8746e+00,  1.0040e-01,\n",
       "           6.6754e-01,  7.4717e-01,  1.0542e-02, -2.5063e-01,  1.4928e+00,\n",
       "           6.6299e-01,  5.4599e-04,  8.6052e-01,  1.6384e+00,  2.3145e+00,\n",
       "           3.0017e-01, -1.0674e-01,  4.2985e-01, -2.2040e-01,  6.9462e-01,\n",
       "          -8.7766e-01,  8.0750e-01,  6.6189e-03,  1.7898e+00,  5.5200e-01,\n",
       "           1.8878e+00,  1.5454e-01, -3.1977e-02,  1.4921e+00, -3.5249e-02,\n",
       "          -1.5662e+00,  1.3653e+00, -4.1823e-01,  2.2213e-01, -2.0524e-01,\n",
       "          -8.0681e-01, -2.5725e-01,  4.2142e-01, -3.8271e-01,  1.6935e+00,\n",
       "          -4.9726e-01,  3.3266e-01, -1.2536e-01,  2.4638e+00, -2.3293e-01,\n",
       "           5.6545e-01, -2.5116e-01,  7.3104e-01, -9.4436e-01,  5.3724e-01,\n",
       "           1.8067e+00,  9.9486e-02,  1.5806e+00,  1.5180e-01, -1.6358e+00,\n",
       "          -7.6986e-01,  4.2780e-01,  4.0812e-01,  8.7083e-02, -6.0144e-01,\n",
       "          -3.6009e-01,  1.6883e+00, -4.7966e-01,  6.6979e-01,  1.1570e-01,\n",
       "           6.5955e-01, -1.6916e+00, -1.7275e+00,  1.5487e-01, -4.1262e-01,\n",
       "           1.1349e+00, -2.1315e-01, -6.7495e-01,  7.0775e-01, -1.4391e+00,\n",
       "           5.8165e-01, -5.9426e-01,  4.0567e-01, -1.4322e-01,  1.6187e+00,\n",
       "           8.8620e-01,  6.5750e-02,  2.8855e-01, -5.4450e-01, -1.0622e+00,\n",
       "           3.6350e-02,  3.8823e-01,  1.4005e+00, -1.3871e+00, -2.5528e-01,\n",
       "          -6.3355e-01,  8.4362e-01,  1.0883e+00, -1.1207e-01, -4.1610e-02,\n",
       "           2.4438e-01,  3.3335e-01, -8.5183e-01, -1.6028e+00,  1.4049e-01,\n",
       "           1.1951e-01, -7.1621e-01, -5.8147e-01, -1.2987e+00, -8.2618e-01,\n",
       "           1.9645e+00, -1.6507e-01, -7.3389e-01,  5.2630e-01,  1.2181e-01,\n",
       "          -4.4997e-01,  3.4802e-02, -8.6605e-01,  1.9009e+00, -1.7859e+00,\n",
       "          -9.8802e-01,  1.9027e-02,  1.7523e+00,  3.5549e-01, -5.1398e-01,\n",
       "          -1.5548e-01, -3.1153e-01,  6.4913e-01,  6.1649e-01, -2.0311e+00,\n",
       "           1.0882e+00,  8.6336e-02,  4.8911e-01,  1.6058e+00, -1.6319e+00,\n",
       "           1.7607e+00, -2.3179e-01,  1.2469e+00, -2.3236e+00,  2.3152e+00,\n",
       "          -6.4039e-01, -7.4734e-01,  1.2947e-01, -3.1442e-01,  1.1805e+00,\n",
       "           1.1763e+00,  2.8334e-01, -6.8131e-02,  2.7786e-01, -6.3562e-02,\n",
       "           7.0256e-01, -6.7320e-01,  1.2495e+00,  5.8892e-01,  1.1553e+00,\n",
       "          -1.1856e+00,  7.6908e-01, -8.6967e-01,  6.2033e-01, -7.7773e-01,\n",
       "          -8.1152e-02, -1.3439e+00,  9.9802e-01, -4.6176e-01,  3.0692e-01,\n",
       "          -1.6639e-01,  1.6277e+00, -7.9533e-03,  9.0437e-01,  9.7419e-01,\n",
       "          -5.7207e-01, -1.8982e-01,  1.5663e+00,  1.7968e+00, -8.0276e-01,\n",
       "          -5.2760e-01,  6.0108e-01, -3.6782e-01,  1.5451e+00, -1.3025e+00,\n",
       "           1.7802e-01, -1.4109e+00,  1.4542e+00,  3.5907e-01,  1.0264e+00,\n",
       "           8.0137e-01,  2.1274e+00,  1.3460e+00,  1.5633e+00,  4.7480e-02,\n",
       "          -2.9496e-01, -1.9196e+00, -9.1304e-01, -6.7605e-02,  1.4426e-01,\n",
       "           1.6221e-01,  4.5583e-01,  1.5226e+00,  1.2133e+00, -9.5455e-02,\n",
       "           9.6139e-01, -1.0860e+00, -4.0406e-01,  1.5187e+00,  1.2034e-01,\n",
       "           1.1919e-01,  4.9369e-01, -1.3845e+00, -4.1492e-01,  1.8761e+00,\n",
       "          -8.2139e-01, -5.0268e-01,  3.0152e-01, -7.4986e-01,  1.2029e+00,\n",
       "           2.2790e-01, -7.6022e-01, -1.5743e+00,  1.4586e+00,  2.5889e+00,\n",
       "           8.1881e-01,  1.1983e+00, -6.9450e-01,  1.0512e+00, -4.2974e-01,\n",
       "          -2.2022e+00, -4.2897e-01,  6.2157e-01, -1.1884e-01, -1.1812e-01,\n",
       "          -1.8770e-01, -1.0462e-01,  7.1719e-01,  2.3742e+00,  2.2650e+00,\n",
       "           7.4163e-01, -8.0652e-01,  5.1361e-02,  1.4317e+00, -5.5377e-01,\n",
       "          -7.2266e-01, -5.2573e-01, -3.6501e-02,  7.3115e-03, -4.7497e-01,\n",
       "           1.0471e+00,  7.8826e-02, -1.1219e-01,  5.1239e-01, -3.9232e-01,\n",
       "          -1.1439e+00,  1.5179e-02,  1.2215e+00,  1.3079e+00,  3.8241e-01,\n",
       "           7.4081e-01, -4.9287e-02,  3.9820e-01, -5.0242e-02,  2.4676e-01,\n",
       "           2.8253e-02, -4.0100e-01,  1.1160e+00,  5.9644e-01,  1.0548e-01,\n",
       "           6.5064e-01,  1.2392e-01,  3.8958e-01,  3.7750e-01,  1.7839e-01,\n",
       "          -1.0608e+00,  2.5809e-01,  1.4034e-01,  3.0992e-01, -2.0225e-01,\n",
       "           6.2918e-01,  9.0721e-01, -1.0817e+00, -7.7028e-01,  7.0602e-01,\n",
       "          -9.0884e-01,  1.1502e+00, -1.0410e+00, -4.8320e-01, -1.8063e-01,\n",
       "           1.3090e+00, -5.3347e-01,  8.1972e-01, -7.3445e-02,  6.3055e-01,\n",
       "           2.4760e-01, -9.3122e-01, -2.6919e-01,  8.8803e-01,  1.4153e+00,\n",
       "          -2.3885e-01,  1.6557e+00,  1.9791e-01, -3.7389e-01, -8.2826e-01,\n",
       "           1.6649e-01, -9.1525e-01, -6.9442e-01,  1.0270e+00, -5.3831e-01,\n",
       "          -5.9111e-01,  3.0599e-01,  2.6522e+00, -8.2412e-01,  9.8196e-01,\n",
       "          -3.0605e-01,  3.5859e-02, -2.1827e-01, -1.3928e+00, -5.8891e-01,\n",
       "           3.2352e-01, -2.1027e+00, -1.2838e+00,  7.9257e-01, -8.5599e-01,\n",
       "          -2.5491e-01, -1.4208e+00, -5.3503e-01,  1.6530e+00,  5.1472e-03,\n",
       "           5.7995e-01,  1.5801e+00, -6.7118e-01,  9.0555e-01,  1.2477e+00,\n",
       "           4.7040e-01,  6.5015e-01,  6.5767e-02, -1.4986e+00,  4.8672e-01,\n",
       "          -1.7138e+00, -8.9492e-01, -1.3633e+00,  1.9472e+00]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-3.9166e-01, -1.0040e-01,  6.4997e-01, -1.0073e+00,  9.2143e-02,\n",
       "           1.1199e+00,  3.8172e-01, -1.0237e+00, -2.6737e-01, -1.3778e+00,\n",
       "          -4.9928e-01,  3.7584e-01, -9.7402e-01,  4.8350e-01, -1.6871e-01,\n",
       "           2.1823e-01,  9.1816e-01, -3.8233e-01,  9.8729e-01,  1.2271e+00,\n",
       "           1.5876e-01, -1.5457e+00,  7.0066e-01,  3.5159e-01,  1.3556e+00,\n",
       "           4.9354e-01, -1.2951e+00,  8.1485e-01, -3.2356e-01,  1.1413e+00,\n",
       "          -1.2980e+00, -9.9896e-02,  3.4001e-01, -1.4145e-01,  5.5593e-01,\n",
       "           8.2940e-01,  1.3156e+00, -7.3465e-01, -9.2699e-01,  1.7474e+00,\n",
       "          -6.4112e-01,  1.0909e+00,  6.3567e-01, -8.6810e-01,  4.2010e-01,\n",
       "           6.8743e-02,  4.7291e-01,  1.1037e+00, -1.9275e+00, -8.7623e-01,\n",
       "          -1.6107e+00, -1.3892e-01, -1.6825e+00,  8.5232e-01, -8.2278e-01,\n",
       "           3.0173e-01,  8.0578e-01, -1.1083e-01,  2.3746e+00, -3.2908e-01,\n",
       "          -3.4681e+00,  3.5796e-01, -5.4465e-01, -4.6608e-01,  7.7955e-01,\n",
       "           5.7798e-01,  1.2589e+00, -6.1293e-01,  3.0854e-01, -8.4904e-02,\n",
       "           6.0052e-01, -1.5601e+00, -5.9321e-01, -6.5087e-01,  1.1624e+00,\n",
       "           1.4015e+00,  2.9106e-02, -1.6976e+00,  7.2780e-01, -1.7744e+00,\n",
       "           1.3193e+00, -3.8544e-01,  1.1738e+00,  7.5441e-01,  3.3252e-01,\n",
       "          -7.7099e-01,  9.7397e-01, -1.0833e-01,  9.1445e-01,  3.2593e-01,\n",
       "          -3.2084e-01,  6.3431e-01,  1.9712e+00, -1.1906e+00, -6.2572e-01,\n",
       "           9.1675e-01,  7.8679e-01,  3.4453e-01,  2.9295e-01, -4.9626e-01,\n",
       "          -1.5778e+00, -3.6593e-01,  1.0586e+00,  4.4379e-01,  1.8303e-01,\n",
       "          -4.7965e-01, -1.2962e-01,  1.4005e-01,  4.1415e-01,  8.7222e-01,\n",
       "           7.4489e-01, -3.3275e-01,  6.6817e-01, -9.1482e-01,  1.9240e+00,\n",
       "           3.4058e-01,  1.4798e+00, -2.3341e+00,  6.0604e-01,  1.0069e-01,\n",
       "          -1.6537e-02,  4.6495e-01, -8.1628e-01, -1.1314e+00,  9.3107e-01,\n",
       "          -9.5852e-01,  8.4942e-01, -5.6512e-01, -8.7576e-02, -3.5112e-01,\n",
       "          -6.4686e-01,  2.4180e+00,  1.6729e+00,  3.3045e-01, -8.3202e-01,\n",
       "           1.9209e+00, -1.4625e+00,  6.9688e-01, -6.7180e-01,  4.5055e-01,\n",
       "          -1.5827e+00,  2.7980e+00, -3.5260e-01,  1.4205e+00, -6.7489e-01,\n",
       "          -6.8469e-01, -1.4338e+00, -4.1173e-01, -9.5088e-01,  1.3596e+00,\n",
       "           4.0235e-02,  8.7296e-03, -1.7737e+00, -2.1066e-01,  9.6223e-01,\n",
       "           1.3239e+00, -3.8368e+00, -4.1392e-01, -8.7211e-01, -2.0923e-01,\n",
       "          -6.0716e-01,  4.1353e-01,  9.0184e-01, -1.3169e+00,  3.5424e-01,\n",
       "           9.1335e-01,  8.6755e-01, -2.9606e-01,  1.0806e+00, -7.1321e-01,\n",
       "          -2.5529e-01, -6.8674e-01,  1.0009e+00,  1.5180e+00, -3.7670e-01,\n",
       "           8.4149e-01,  8.0295e-01,  4.4929e-01,  1.5551e+00,  7.3543e-01,\n",
       "           9.7833e-02,  6.7022e-01,  3.1128e-02,  1.3288e+00, -7.6649e-02,\n",
       "          -1.7863e+00, -5.3348e-01, -6.7678e-01, -1.6573e-01,  3.8414e-01,\n",
       "          -4.8904e-02, -9.3170e-01,  4.8978e-02, -1.2544e+00,  4.9409e-01,\n",
       "          -3.9039e-01,  5.9320e-01,  2.9739e-01,  2.4891e-01, -1.4159e-01,\n",
       "          -6.8774e-02,  2.5019e-01,  9.3193e-02,  1.2673e-01, -6.0185e-01,\n",
       "          -1.8994e+00, -9.0039e-01,  7.4255e-01, -2.3059e+00,  7.0292e-01,\n",
       "           3.6839e-01, -1.3405e+00,  3.8045e-01, -1.3960e-01,  1.1111e+00,\n",
       "           1.8722e-01, -8.3459e-01,  3.9885e-01,  1.7404e-01, -5.9655e-01,\n",
       "          -5.2542e-01,  5.6913e-01, -2.4202e-01,  1.6280e+00,  1.6214e+00,\n",
       "          -1.2569e+00, -3.6959e-01, -7.1283e-01, -5.2347e-01, -1.3344e-01,\n",
       "           3.9892e-01,  1.7092e-01,  1.2418e+00, -1.9949e-01,  2.0942e-01,\n",
       "          -7.4077e-01,  2.4119e+00, -7.4405e-01, -3.0836e-01,  6.0006e-01,\n",
       "          -4.1558e-01,  1.4225e+00, -5.4313e-01,  6.9685e-01,  4.5155e-01,\n",
       "          -2.9167e-01,  1.1827e+00, -8.7503e-01, -7.6031e-01,  3.1726e-01,\n",
       "          -2.2985e+00, -8.1577e-01,  6.6260e-01, -8.9844e-01, -2.3890e-01,\n",
       "          -1.5407e-01, -5.1168e-01, -1.5695e+00,  5.1720e-01, -8.6186e-01,\n",
       "          -7.1312e-01, -1.6207e+00,  2.3295e-01,  1.5130e+00, -1.0952e-02,\n",
       "          -4.2838e-01, -2.5042e-01,  1.4095e+00, -1.7493e+00, -1.0849e+00,\n",
       "           1.2942e+00, -6.2262e-02,  2.3674e+00, -1.5270e+00, -2.3220e-01,\n",
       "           4.4587e-01, -8.4108e-01,  5.9316e-02, -6.3567e-01,  1.2094e+00,\n",
       "           1.3542e-01,  8.3891e-01, -2.8275e-01, -1.3260e+00,  7.2291e-01,\n",
       "           9.2997e-01,  3.1989e-01,  2.4611e+00, -1.8551e+00,  1.7218e-01,\n",
       "          -1.4356e+00,  6.2708e-01, -1.3836e+00,  4.9545e-01, -1.2335e+00,\n",
       "          -1.0466e+00, -4.2350e-01,  1.0694e+00, -4.8243e-01,  1.9370e+00,\n",
       "           1.0312e+00, -1.3554e+00, -1.7008e+00, -4.5163e-01, -1.4122e+00,\n",
       "          -4.1555e-01, -1.4996e-01,  1.4806e-01,  3.9323e-01, -1.6042e+00,\n",
       "          -2.8585e-01,  1.0981e+00,  8.5029e-01, -1.5536e+00,  1.3265e+00,\n",
       "           1.8798e+00, -3.8580e-01,  1.2902e+00,  5.9825e-01,  4.2072e-01,\n",
       "           9.7083e-01,  6.6814e-01, -3.8496e-02,  1.0551e+00,  5.4074e-01,\n",
       "           1.4985e+00,  3.2346e-01,  1.2893e+00,  1.4811e+00, -2.4114e+00,\n",
       "          -9.5403e-01, -1.5300e-01, -3.6410e-01,  1.9633e-01, -1.1135e+00,\n",
       "          -1.3146e-01, -2.3160e-01, -2.1011e+00, -1.2826e+00, -1.4067e+00,\n",
       "          -7.0754e-01,  1.9166e+00,  1.5742e+00, -1.1926e-01,  2.1501e+00,\n",
       "          -2.2637e-01, -3.2970e-01,  1.9956e+00,  3.9310e-01, -1.3825e+00,\n",
       "          -1.0137e+00,  2.8917e+00,  8.5085e-01,  3.8749e-01, -1.0283e+00,\n",
       "           2.5719e-01, -9.2470e-01,  4.7259e-01,  2.0090e-01, -7.9449e-01,\n",
       "           1.6762e-01,  9.5952e-02, -2.3304e-01,  4.6631e-01,  7.8124e-01,\n",
       "           2.7403e-01,  5.3041e-01,  2.1350e+00,  3.0882e-01, -2.6675e-01,\n",
       "           1.9822e+00, -7.6940e-01,  1.9425e-01, -3.1228e-01,  6.4881e-01,\n",
       "           2.2835e-01,  1.6933e+00,  1.3424e+00, -9.5907e-01,  1.2651e+00,\n",
       "          -2.1338e-01,  4.3523e-01,  5.0301e-01,  1.4945e-01,  5.2774e-01,\n",
       "           2.0505e+00, -4.9094e-01,  6.8687e-02, -1.5902e+00,  9.4765e-01,\n",
       "           3.1811e+00,  5.3111e-01, -2.1122e-01,  9.6695e-01,  6.5906e-01,\n",
       "          -5.6576e-01,  2.3442e-01, -2.0708e+00, -6.7880e-02,  6.7233e-01,\n",
       "           3.9810e-01, -2.0190e+00, -8.7662e-01, -2.6196e-01,  1.1307e+00,\n",
       "           6.9470e-01, -2.0583e+00, -4.7471e-01, -3.8604e-01,  1.3190e+00,\n",
       "          -2.3997e-01, -5.5003e-01, -1.0919e-02,  3.6256e-01,  1.4537e+00,\n",
       "           8.7111e-01,  1.0716e+00,  2.4901e-01, -2.8050e-01,  3.6791e-01,\n",
       "          -4.3981e-01, -1.1657e+00, -1.0225e+00, -4.6830e-01, -4.9009e-01,\n",
       "          -1.7914e+00, -1.6296e-01,  1.5005e+00, -1.0248e+00, -5.0120e-01,\n",
       "           1.6988e-01,  3.3342e-01,  1.9299e+00,  6.2621e-01, -1.1877e+00,\n",
       "          -1.2347e+00, -7.9723e-01,  8.5919e-01,  8.4023e-01,  6.6831e-01,\n",
       "           1.0286e+00,  2.2682e+00, -6.5724e-01,  1.8369e+00,  1.9669e+00,\n",
       "           6.2219e-01, -2.4064e+00,  2.9816e-01,  9.4933e-01,  2.6018e+00,\n",
       "           3.1062e-01,  4.0157e-01, -9.6759e-01, -5.1663e-01,  8.4549e-01,\n",
       "          -2.3131e-01,  1.3966e+00, -3.6770e-01, -1.2187e+00, -5.3568e-02,\n",
       "           7.8284e-01, -4.7971e-01,  5.4226e-01,  1.5551e+00, -2.1273e+00,\n",
       "          -1.1219e+00,  2.5653e-01, -7.7669e-01,  5.7389e-01, -1.6179e+00,\n",
       "          -1.6788e-01,  5.2916e-01,  3.5835e-02,  9.6166e-01, -1.0723e+00,\n",
       "           8.2207e-01,  4.1871e-01, -9.5259e-01, -9.1266e-02, -4.3261e-01,\n",
       "           2.0892e+00, -5.9151e-02, -6.3939e-01, -1.7201e+00,  4.4587e-01,\n",
       "          -4.6853e-01, -1.0915e+00, -1.0543e+00, -4.4968e-01,  4.5774e-01,\n",
       "          -1.7509e+00,  1.1688e+00,  1.2783e-01,  1.6653e+00, -8.0374e-01,\n",
       "          -1.2460e+00,  5.9548e-01,  2.0684e-01,  1.1393e+00, -1.3405e+00,\n",
       "           7.7752e-01, -2.0868e+00, -1.0349e+00, -4.8024e-01, -6.9904e-01,\n",
       "           6.2854e-01, -3.6098e-01,  9.4259e-02, -4.2434e-01, -2.0210e-01,\n",
       "           8.0627e-01,  5.2204e-01,  6.9820e-01,  2.6692e-01, -1.9412e+00,\n",
       "           1.2697e+00, -8.3404e-01,  9.9807e-01,  1.0995e-01,  1.5780e-01,\n",
       "          -7.6513e-01, -1.5666e-01, -1.5179e+00,  4.3167e-01,  4.6620e-01,\n",
       "           1.1864e+00, -1.9027e-01, -1.3404e+00, -1.4752e+00, -3.3297e-01,\n",
       "           1.1325e-01, -1.8173e+00, -1.6824e-01, -8.4884e-01,  2.7121e-01,\n",
       "           7.7193e-01,  6.7628e-01, -1.0290e+00, -3.7061e-01,  1.0975e+00,\n",
       "          -2.9578e-01, -1.5710e+00, -4.8722e-01,  1.7108e+00,  1.8432e+00,\n",
       "           1.4861e+00, -8.6111e-02,  6.9665e-01, -5.1060e-01, -5.7827e-02,\n",
       "          -1.1498e+00, -7.5899e-01, -1.0728e+00,  1.4583e+00, -5.4801e-01,\n",
       "          -6.9004e-01, -2.5937e-01,  8.4155e-01, -6.6971e-01,  9.7790e-02,\n",
       "          -1.4312e+00,  5.5640e-01,  2.8628e+00, -4.4635e-01,  6.2199e-01,\n",
       "           8.9189e-01, -4.7640e-01,  6.6897e-01,  2.1416e-02,  9.2648e-01,\n",
       "           9.8533e-01,  2.1949e+00, -3.4125e-01,  4.4458e-01,  8.8472e-01,\n",
       "           7.8761e-01, -1.8359e+00, -1.1911e+00, -4.7333e-01, -1.5157e+00,\n",
       "          -5.1257e-01,  5.3893e-01, -1.0814e+00, -2.3484e-01,  3.7465e-01,\n",
       "           1.5648e+00,  5.2983e-01, -1.2153e+00, -3.3020e-03,  1.7115e+00,\n",
       "           1.0593e+00,  3.6183e-02,  8.0238e-01,  6.0799e-01,  2.3677e-01,\n",
       "          -1.6562e+00,  4.8283e-01,  7.2929e-02, -1.0063e+00,  4.5542e-01,\n",
       "          -5.1987e-01,  8.4624e-02, -1.4942e+00, -9.8850e-01,  1.0837e+00,\n",
       "           1.2018e-01, -3.5376e-01, -1.1082e+00,  1.1770e+00, -5.4691e-01,\n",
       "          -9.8440e-01,  2.9360e+00, -9.7970e-01,  1.1054e+00,  1.6824e-01,\n",
       "          -1.2811e-01,  6.8886e-01, -1.3509e+00,  1.3691e+00, -5.4837e-01,\n",
       "          -9.0520e-01, -6.8263e-01,  1.1249e+00,  1.0921e+00,  5.5728e-01,\n",
       "           1.2066e+00, -9.7678e-01, -2.3685e+00,  8.6352e-01,  2.3778e+00,\n",
       "           2.0914e-02,  2.0687e-01,  3.9814e-01,  3.2291e-01, -1.5093e+00,\n",
       "           9.4309e-01, -5.0163e-02,  7.4901e-01,  1.1674e+00, -2.9894e-01,\n",
       "          -7.6864e-01,  1.5843e-01,  8.1760e-01, -1.0753e-02, -3.4794e-01,\n",
       "           1.1967e+00, -1.9065e+00,  1.2978e+00, -1.4040e-01, -8.1725e-01,\n",
       "          -1.2242e+00, -1.5780e+00, -6.0595e-01,  1.8661e-01,  1.1530e+00,\n",
       "          -1.0831e-01, -7.9398e-02, -1.8944e+00,  1.7565e-01,  1.8911e+00,\n",
       "          -1.5134e+00, -4.6354e-02, -5.4455e-01,  9.3783e-01, -8.0294e-01,\n",
       "          -1.3399e+00, -1.0150e+00,  2.4734e+00,  1.0834e+00,  6.5103e-01,\n",
       "           1.4926e+00,  2.3875e-01, -6.9021e-01, -7.4043e-01,  7.4873e-01,\n",
       "           4.1456e-01,  6.1206e-01,  1.0848e+00, -9.3252e-01,  1.5660e+00,\n",
       "           2.1057e-01, -4.1869e-01,  1.2453e+00, -8.4142e-01, -1.4632e-01,\n",
       "           2.0424e-01,  3.1543e-01,  9.8619e-01, -1.3150e+00,  7.9748e-01,\n",
       "          -9.9778e-01, -1.9133e-01,  1.8956e+00, -7.5641e-01,  3.8160e-01,\n",
       "           2.2035e+00, -1.4045e+00, -1.0400e+00,  1.1906e+00, -3.1382e-02,\n",
       "          -3.1040e-01,  1.0239e+00,  7.1299e-01,  1.4950e+00,  1.0275e+00,\n",
       "           7.1391e-01,  5.9590e-01,  4.0324e-01,  2.3451e-02,  2.1017e+00,\n",
       "           8.8503e-01, -6.3484e-01, -9.7268e-01, -1.8741e+00,  3.1209e-02,\n",
       "           1.9589e-01,  3.9510e-02, -2.5562e-01, -5.6427e-01, -8.7461e-02,\n",
       "          -1.5931e+00, -8.0337e-01, -4.3687e-01, -1.1189e+00, -2.0674e+00,\n",
       "           8.4660e-01, -2.4669e+00, -1.8438e-01,  5.3370e-01,  2.5058e-01,\n",
       "           5.9928e-01, -2.5220e-01, -1.5451e-01,  1.7947e+00,  1.3230e+00,\n",
       "          -1.3350e-01, -1.1151e-01,  4.1037e-01,  7.5608e-02, -5.3738e-01,\n",
       "           2.1731e-01,  8.9964e-01,  1.0421e+00, -1.1836e+00, -7.6237e-01,\n",
       "          -6.6553e-01,  1.2980e+00, -4.0412e-01, -1.0393e+00,  1.5343e+00,\n",
       "           3.3696e-01, -3.0643e-01, -1.4293e+00, -1.3095e-01, -2.7092e-01,\n",
       "          -1.3853e-01, -1.5205e-01, -1.9451e+00, -1.0695e-01, -7.5116e-01,\n",
       "           1.5457e+00, -1.4192e+00,  5.1339e-01, -4.2139e-01,  1.4865e+00,\n",
       "          -2.8066e-01,  2.6147e+00,  6.3871e-01,  1.8432e+00,  1.0448e+00,\n",
       "          -7.4887e-01,  4.6763e-01,  1.1530e-01, -5.9727e-01, -3.7423e-01,\n",
       "           7.4995e-01, -1.7149e+00, -2.8057e-01,  3.9186e-01,  4.9155e-01,\n",
       "           1.8642e+00, -3.2209e-02,  2.8405e-02, -7.2797e-01]], device='cuda:0',\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.flows[0].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ConnectedClassifier_SoftKMeans(784, 100, 10)\n",
    "# classifier = ConnectedClassifier_Softmax(784, 10, 10)\n",
    "classifier = classifier.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0003\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  2466466\n"
     ]
    }
   ],
   "source": [
    "# criterion = nn.NLLLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(list(model.parameters())+list(classifier.parameters()),\n",
    "                       lr=learning_rate, weight_decay=1e-15) # todo tune WD\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(torch.isnan(p).type(torch.float32).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5607,  0.6105,  1.1704,  ..., -0.5931, -1.0189, -1.0891],\n",
       "        [ 1.3151, -2.1658, -1.2809,  ..., -1.5512,  0.4107, -0.0355],\n",
       "        [-0.3232,  0.2452,  1.1155,  ...,  0.0886,  0.7967, -0.5107],\n",
       "        ...,\n",
       "        [ 0.5892, -0.5161,  0.4618,  ...,  0.5948,  1.3824,  1.2422],\n",
       "        [-1.6883, -0.1353, -1.9031,  ..., -0.7540,  0.3301, -1.4200],\n",
       "        [ 0.0261,  0.1167,  0.7527,  ...,  1.6670, -1.4482,  0.7953]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(10, 784).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 784])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = iter(test_loader).next()[0]\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.19it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0:0,  Loss:1.5872070789337158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 231.65it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:88.99%, Test Acc:87.39%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.54it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1:0,  Loss:1.6091848611831665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 239.62it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:89.61%, Test Acc:87.27%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.26it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2:0,  Loss:1.617140769958496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 223.47it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:89.89%, Test Acc:87.63%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.08it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3:0,  Loss:1.575707197189331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 234.16it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:90.24%, Test Acc:87.70%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.65it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4:0,  Loss:1.5634993314743042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 244.43it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:90.48%, Test Acc:87.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.11it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5:0,  Loss:1.5652235746383667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 254.21it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:90.65%, Test Acc:88.03%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.32it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6:0,  Loss:1.4846620559692383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 234.28it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:90.92%, Test Acc:88.39%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.90it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7:0,  Loss:1.5491163730621338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 252.35it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:90.97%, Test Acc:88.44%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 112.83it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8:0,  Loss:1.5592498779296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 236.85it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:91.33%, Test Acc:88.31%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.49it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9:0,  Loss:1.4895471334457397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 243.68it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:91.42%, Test Acc:88.60%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.68it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10:0,  Loss:1.544619083404541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 252.61it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:91.66%, Test Acc:88.49%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.06it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11:0,  Loss:1.5180134773254395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 238.11it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:91.73%, Test Acc:89.04%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 112.83it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12:0,  Loss:1.5188182592391968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 231.23it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:91.94%, Test Acc:88.52%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.40it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13:0,  Loss:1.6488500833511353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 244.69it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.10%, Test Acc:88.53%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.49it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14:0,  Loss:1.5558513402938843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 233.67it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.20%, Test Acc:88.98%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.23it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15:0,  Loss:1.5284711122512817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 248.26it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.48%, Test Acc:88.38%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.75it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16:0,  Loss:1.5698734521865845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 224.44it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.57%, Test Acc:88.27%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.76it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17:0,  Loss:1.6316076517105103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 236.24it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.63%, Test Acc:88.76%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.30it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18:0,  Loss:1.4893118143081665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 232.25it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.81%, Test Acc:88.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.48it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19:0,  Loss:1.5801801681518555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 238.74it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.89%, Test Acc:88.58%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.30it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20:0,  Loss:1.5155861377716064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 227.27it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.08%, Test Acc:88.88%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.30it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21:0,  Loss:1.5979125499725342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 238.53it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.14%, Test Acc:88.28%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.73it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22:0,  Loss:1.5524548292160034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 243.28it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.22%, Test Acc:88.63%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.54it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23:0,  Loss:1.4927555322647095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 245.30it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.44%, Test Acc:88.50%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 112.27it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24:0,  Loss:1.5481436252593994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 230.24it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.36%, Test Acc:89.42%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 239.63it/s]]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.30%, Test Acc:89.26%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 112.96it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34:0,  Loss:1.460972547531128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 234.89it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.39%, Test Acc:88.87%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 112.53it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35:0,  Loss:1.551367163658142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 244.10it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.40%, Test Acc:89.22%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.90it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36:0,  Loss:1.4859247207641602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 247.59it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.57%, Test Acc:88.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.10it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37:0,  Loss:1.5142561197280884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 244.24it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.68%, Test Acc:88.95%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.14it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38:0,  Loss:1.4878987073898315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 243.87it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.77%, Test Acc:89.16%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 112.95it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39:0,  Loss:1.502936601638794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 229.54it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.73%, Test Acc:89.21%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.57it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40:0,  Loss:1.500788688659668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 242.98it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.83%, Test Acc:89.11%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.76it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41:0,  Loss:1.4805999994277954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 242.36it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.98%, Test Acc:89.52%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 112.86it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42:0,  Loss:1.4990063905715942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 234.57it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.10%, Test Acc:89.65%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.04it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43:0,  Loss:1.5205912590026855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 245.66it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.13%, Test Acc:89.46%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.04it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44:0,  Loss:1.4804770946502686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 235.74it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.36%, Test Acc:89.29%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.09it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45:0,  Loss:1.460913896560669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 227.44it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.27%, Test Acc:89.51%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 114.39it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46:0,  Loss:1.5688625574111938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 235.75it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.40%, Test Acc:89.05%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.08it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47:0,  Loss:1.491915225982666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 234.27it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.34%, Test Acc:89.50%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 113.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48:0,  Loss:1.5005404949188232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 239.39it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.47%, Test Acc:89.51%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:10<00:00, 112.42it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49:0,  Loss:1.5203367471694946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 201.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.49%, Test Acc:88.74%\n",
      "\n",
      "\t-> Train Acc 95.48833333333333 ; Test Acc 89.64999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "EPOCHS = 50\n",
    "\n",
    "index = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "    for xx, yy in tqdm(train_loader):\n",
    "        xx, yy = xx.to(device), yy.to(device)\n",
    "#     for xx, yy in tqdm(test_loader):\n",
    "\n",
    "        yout = model(xx)\n",
    "#         print(yout)\n",
    "        yout = classifier(yout)    \n",
    "#         print(yout)\n",
    "        loss = criterion(yout, yy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(float(loss))\n",
    "\n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        train_acc += correct\n",
    "        train_count += len(outputs)\n",
    "#         break\n",
    "\n",
    "    train_accs.append(float(train_acc)/train_count*100)\n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "\n",
    "    print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "    test_count = 0\n",
    "    test_acc = 0\n",
    "    for xx, yy in tqdm(test_loader):\n",
    "        xx, yy = xx.to(device), yy.to(device)\n",
    "        with torch.no_grad():\n",
    "            yout = classifier(model(xx))    \n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        test_acc += correct\n",
    "        test_count += len(xx)\n",
    "    test_accs.append(float(test_acc)/test_count*100)\n",
    "    print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "    print()\n",
    "\n",
    "### after each class index is finished training\n",
    "print(f'\\t-> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.cls_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard test accuracy with count per classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 211.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Test Acc:88.76%\n",
      "[0, 0, 1040, 15, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 138, 0, 0, 92, 7, 0, 2, 0, 149, 949, 0, 0, 0, 626, 15, 0, 1, 0, 134, 0, 1, 0, 955, 71, 422, 0, 0, 0, 0, 0, 850, 0, 0, 3, 0, 0, 0, 0, 101, 0, 0, 0, 0, 69, 0, 0, 0, 0, 1, 0, 0, 0, 0, 51, 0, 910, 0, 0, 0, 0, 0, 0, 0, 10, 0, 1195, 968, 0, 2, 0, 0, 0, 0, 5, 618, 0, 6, 0, 539, 0, 0, 0, 0, 35, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "test_acc = 0\n",
    "set_count = torch.zeros(classifier.num_sets).to(device)\n",
    "for xx, yy in tqdm(test_loader):\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    with torch.no_grad():\n",
    "        yout = classifier(model(xx), hard=True)\n",
    "        set_indx, count = torch.unique(torch.argmax(classifier.cls_confidence, dim=1), return_counts=True) \n",
    "        set_count[set_indx] += count\n",
    "    outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "    test_acc += correct\n",
    "    test_count += len(xx)\n",
    "\n",
    "print(f'Hard Test Acc:{float(test_acc)/test_count*100:.2f}%')\n",
    "print(set_count.type(torch.long).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard train accuracy with count per classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:04<00:00, 254.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Train Acc:94.73%\n",
      "[0, 0, 6122, 87, 0, 0, 0, 0, 161, 0, 0, 0, 0, 0, 0, 782, 0, 0, 460, 50, 0, 4, 0, 820, 5862, 0, 0, 0, 3782, 46, 0, 4, 0, 875, 0, 1, 0, 5767, 433, 2409, 0, 2, 0, 0, 0, 5186, 0, 0, 15, 0, 0, 0, 0, 600, 0, 0, 0, 0, 500, 0, 0, 1, 0, 23, 0, 0, 0, 0, 331, 0, 5684, 1, 0, 14, 0, 0, 0, 0, 67, 0, 6490, 5909, 0, 27, 0, 0, 0, 0, 42, 3759, 0, 17, 0, 3480, 0, 0, 0, 0, 187, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "test_acc = 0\n",
    "set_count = torch.zeros(classifier.num_sets).to(device)\n",
    "for xx, yy in tqdm(train_loader):\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    with torch.no_grad():\n",
    "        yout = classifier(model(xx), hard=True)\n",
    "        set_indx, count = torch.unique(torch.argmax(classifier.cls_confidence, dim=1), return_counts=True) \n",
    "        set_count[set_indx] += count\n",
    "    outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "    test_acc += correct\n",
    "    test_count += len(xx)\n",
    "\n",
    "print(f'Hard Train Acc:{float(test_acc)/test_count*100:.2f}%')\n",
    "print(set_count.type(torch.long).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(37, device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Classifiers that enclose any data\n",
    "torch.count_nonzero(set_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 2, 3, 4, 5, 6, 7, 8, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 1, 2, 3,\n",
       "        4, 5, 6, 7, 8, 9, 6, 1, 6, 3, 4, 5, 6, 7, 8, 9, 6, 1, 2, 3, 4, 5, 6, 7,\n",
       "        8, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 1, 6, 3, 4, 5, 6, 7, 8, 9, 0, 1,\n",
       "        2, 3, 4, 5, 6, 7, 8, 9, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 1, 2, 3, 4, 5,\n",
       "        6, 7, 8, 9], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### classifier with class representation\n",
    "torch.argmax(classifier.cls_weight, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class labels are same as that of initialized\n",
    "# tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
    "#         4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
    "#         8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1,\n",
    "#         2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,\n",
    "#         6, 7, 8, 9], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[14.5033, -2.3390, -2.3409, -2.2740, -2.3565, -2.3720, -2.1097, -2.3840,\n",
       "         -2.3706, -2.3809],\n",
       "        [-2.3772, 14.4716, -2.3956, -2.3275, -2.3879, -2.3858, -2.3834, -2.3961,\n",
       "         -2.4096, -2.4031],\n",
       "        [-2.3144, -2.3321, 14.5638, -2.3289, -2.1009, -2.3546, -2.1033, -2.3621,\n",
       "         -2.3181, -2.3527],\n",
       "        [-2.2622, -2.2628, -2.3509, 14.4797, -2.3197, -2.3655, -2.3083, -2.3762,\n",
       "         -2.3589, -2.3743],\n",
       "        [-2.4062, -2.4268, -2.1114, -2.3799, 14.5947, -2.4376, -2.1948, -2.4477,\n",
       "         -2.3933, -2.4408],\n",
       "        [-2.3914, -2.3885, -2.3987, -2.3950, -2.4002, 14.5619, -2.3902, -2.2499,\n",
       "         -2.3637, -2.3111],\n",
       "        [-2.0379, -2.2405, -1.9522, -2.1715, -1.9584, -2.2554, 14.4938, -2.2768,\n",
       "         -2.2024, -2.2734],\n",
       "        [-2.4377, -2.4237, -2.4369, -2.4340, -2.4470, -2.2871, -2.4310, 14.6102,\n",
       "         -2.4123, -2.3418],\n",
       "        [-2.4166, -2.4554, -2.4106, -2.4334, -2.4156, -2.4106, -2.3998, -2.4082,\n",
       "         14.5393, -2.4187],\n",
       "        [-2.4469, -2.4581, -2.4528, -2.4438, -2.4467, -2.3900, -2.4535, -2.3702,\n",
       "         -2.4254, 14.5676],\n",
       "        [14.5766, -2.4126, -2.4018, -2.3672, -2.4212, -2.4484, -2.1930, -2.4511,\n",
       "         -2.4380, -2.4530],\n",
       "        [-2.4461, 14.5942, -2.4693, -2.4125, -2.4606, -2.4656, -2.4632, -2.4777,\n",
       "         -2.4743, -2.4752],\n",
       "        [-2.3210, -2.3574, 14.5542, -2.3470, -2.1084, -2.3586, -2.1174, -2.3685,\n",
       "         -2.3288, -2.3571],\n",
       "        [-2.3095, -2.3021, -2.3972, 14.5566, -2.3533, -2.4150, -2.3574, -2.4180,\n",
       "         -2.4066, -2.4194],\n",
       "        [-2.3510, -2.3707, -2.0640, -2.3366, 14.5434, -2.3865, -2.1573, -2.3875,\n",
       "         -2.3472, -2.3690],\n",
       "        [-2.4329, -2.4485, -2.4334, -2.4391, -2.4435, 14.6500, -2.4411, -2.2928,\n",
       "         -2.4005, -2.3545],\n",
       "        [-2.0620, -2.2636, -1.9974, -2.2088, -2.0036, -2.2835, 14.5137, -2.3031,\n",
       "         -2.2350, -2.2977],\n",
       "        [-2.3989, -2.3888, -2.3922, -2.3984, -2.4051, -2.2437, -2.3967, 14.5476,\n",
       "         -2.3704, -2.2914],\n",
       "        [-2.4025, -2.4227, -2.3964, -2.4122, -2.3904, -2.3960, -2.3845, -2.3923,\n",
       "         14.5339, -2.3923],\n",
       "        [-2.3507, -2.3534, -2.3456, -2.3543, -2.3471, -2.2604, -2.3510, -2.2537,\n",
       "         -2.3339, 14.4762],\n",
       "        [14.5296, -2.3719, -2.3739, -2.3159, -2.3877, -2.4054, -2.1550, -2.4165,\n",
       "         -2.4044, -2.4104],\n",
       "        [-2.3796, 14.4992, -2.4026, -2.3413, -2.4004, -2.3983, -2.3927, -2.4012,\n",
       "         -2.4206, -2.4071],\n",
       "        [-2.3303, -2.3664, 14.5460, -2.3577, -2.1263, -2.3669, -2.1403, -2.3756,\n",
       "         -2.3354, -2.3696],\n",
       "        [-2.3322, -2.3261, -2.4181, 14.5667, -2.3797, -2.4528, -2.3768, -2.4533,\n",
       "         -2.4447, -2.4437],\n",
       "        [-2.3149, -2.3296, -2.0452, -2.2880, 14.4786, -2.3682, -2.1279, -2.3611,\n",
       "         -2.3176, -2.3621],\n",
       "        [-2.4764, -2.4816, -2.4740, -2.4775, -2.4810, 14.6950, -2.4702, -2.3083,\n",
       "         -2.4508, -2.4014],\n",
       "        [-1.8848, -2.0978, -1.8106, -2.0391, -1.8179, -2.1058, 14.2939, -2.1305,\n",
       "         -2.0354, -2.1155],\n",
       "        [-2.4528, -2.4466, -2.4418, -2.4593, -2.4550, -2.2974, -2.4436, 14.6194,\n",
       "         -2.4207, -2.3720],\n",
       "        [-2.4854, -2.5100, -2.4772, -2.5042, -2.4786, -2.4842, -2.4717, -2.4782,\n",
       "         14.6181, -2.4817],\n",
       "        [-2.4965, -2.4924, -2.4904, -2.4920, -2.4852, -2.4192, -2.4910, -2.4068,\n",
       "         -2.4716, 14.6400],\n",
       "        [14.5415, -2.3508, -2.3549, -2.3035, -2.3709, -2.3928, -2.1489, -2.4027,\n",
       "         -2.3956, -2.4025],\n",
       "        [-2.3886, 14.4800, -2.4023, -2.3400, -2.3989, -2.4032, -2.4068, -2.4188,\n",
       "         -2.4354, -2.4183],\n",
       "        [-2.3374, -2.3723, 14.5774, -2.3641, -2.1106, -2.3839, -2.1344, -2.3914,\n",
       "         -2.3493, -2.3799],\n",
       "        [-2.2975, -2.2962, -2.3862, 14.5273, -2.3536, -2.4035, -2.3393, -2.4033,\n",
       "         -2.3935, -2.3990],\n",
       "        [-2.3454, -2.3612, -2.0455, -2.3185, 14.5273, -2.3622, -2.1348, -2.3799,\n",
       "         -2.3374, -2.3665],\n",
       "        [-2.4339, -2.4274, -2.4286, -2.4330, -2.4461, 14.6178, -2.4375, -2.2734,\n",
       "         -2.4041, -2.3502],\n",
       "        [-2.0059, -2.1919, -1.8962, -2.1311, -1.9004, -2.1859, 14.4045, -2.2104,\n",
       "         -2.1367, -2.1974],\n",
       "        [-2.4376, -2.4244, -2.4336, -2.4428, -2.4389, -2.2802, -2.4268, 14.5759,\n",
       "         -2.4053, -2.3391],\n",
       "        [-2.3751, -2.3982, -2.3506, -2.3817, -2.3608, -2.3509, -2.3434, -2.3606,\n",
       "         14.4962, -2.3504],\n",
       "        [-2.4516, -2.4512, -2.4523, -2.4476, -2.4517, -2.3801, -2.4471, -2.3584,\n",
       "         -2.4193, 14.5929],\n",
       "        [14.5519, -2.3955, -2.3991, -2.3358, -2.4108, -2.4406, -2.1777, -2.4469,\n",
       "         -2.4267, -2.4440],\n",
       "        [-2.4937, 14.6647, -2.5227, -2.4590, -2.5125, -2.5149, -2.5085, -2.5233,\n",
       "         -2.5245, -2.5288],\n",
       "        [-2.3553, -2.3982, 14.6072, -2.3871, -2.1606, -2.4076, -2.1619, -2.4155,\n",
       "         -2.3892, -2.4179],\n",
       "        [-2.3319, -2.3166, -2.4188, 14.5670, -2.3798, -2.4184, -2.3777, -2.4315,\n",
       "         -2.4223, -2.4239],\n",
       "        [-2.3413, -2.3543, -2.0604, -2.3177, 14.5209, -2.3753, -2.1303, -2.3759,\n",
       "         -2.3352, -2.3755],\n",
       "        [-2.3952, -2.3907, -2.3907, -2.3917, -2.3973, 14.5710, -2.3924, -2.2285,\n",
       "         -2.3587, -2.3165],\n",
       "        [-2.1170, -2.2771, -2.0100, -2.2367, -1.9951, -2.3033, 14.5616, -2.3181,\n",
       "         -2.2466, -2.3134],\n",
       "        [-2.4266, -2.4031, -2.4250, -2.4234, -2.4361, -2.2753, -2.4186, 14.5742,\n",
       "         -2.3922, -2.3399],\n",
       "        [-2.4717, -2.4837, -2.4454, -2.4709, -2.4568, -2.4450, -2.4504, -2.4444,\n",
       "         14.6156, -2.4503],\n",
       "        [-2.4217, -2.4254, -2.4107, -2.4165, -2.4139, -2.3409, -2.4117, -2.3250,\n",
       "         -2.3919, 14.5440],\n",
       "        [14.4715, -2.3349, -2.3315, -2.2712, -2.3406, -2.3784, -2.1026, -2.3803,\n",
       "         -2.3692, -2.3838],\n",
       "        [-2.4630, 14.6433, -2.4787, -2.4246, -2.4741, -2.4875, -2.4734, -2.4897,\n",
       "         -2.4876, -2.4806],\n",
       "        [-2.3167, -2.3573, 14.5493, -2.3474, -2.1006, -2.3597, -2.1230, -2.3730,\n",
       "         -2.3196, -2.3622],\n",
       "        [-2.3485, -2.3291, -2.4384, 14.5785, -2.4065, -2.4526, -2.3927, -2.4577,\n",
       "         -2.4409, -2.4591],\n",
       "        [-2.3057, -2.3212, -2.0268, -2.2787, 14.4821, -2.3356, -2.1083, -2.3506,\n",
       "         -2.2928, -2.3359],\n",
       "        [-2.4330, -2.4243, -2.4178, -2.4281, -2.4352, 14.6672, -2.4395, -2.2850,\n",
       "         -2.3981, -2.3551],\n",
       "        [-2.0846, -2.2473, -1.9914, -2.2005, -1.9815, -2.2787, 14.5436, -2.2919,\n",
       "         -2.2337, -2.2884],\n",
       "        [-2.4549, -2.4565, -2.4550, -2.4553, -2.4591, -2.3082, -2.4587, 14.6221,\n",
       "         -2.4313, -2.3745],\n",
       "        [-2.4281, -2.4526, -2.4163, -2.4448, -2.4245, -2.4047, -2.4084, -2.3920,\n",
       "         14.5474, -2.3988],\n",
       "        [-2.4941, -2.5055, -2.4882, -2.5039, -2.4971, -2.4335, -2.5025, -2.4171,\n",
       "         -2.4803, 14.6240],\n",
       "        [14.5001, -2.3353, -2.3315, -2.2812, -2.3408, -2.3660, -2.0976, -2.3767,\n",
       "         -2.3565, -2.3697],\n",
       "        [-2.4550, 14.5984, -2.4581, -2.3980, -2.4573, -2.4574, -2.4557, -2.4751,\n",
       "         -2.4748, -2.4644],\n",
       "        [-2.3042, -2.3389, 14.5511, -2.3364, -2.0957, -2.3528, -2.0988, -2.3652,\n",
       "         -2.3218, -2.3589],\n",
       "        [-2.3292, -2.3062, -2.4120, 14.5757, -2.3812, -2.4323, -2.3684, -2.4344,\n",
       "         -2.4263, -2.4350],\n",
       "        [-2.3127, -2.3257, -2.0327, -2.2728, 14.5020, -2.3502, -2.1100, -2.3521,\n",
       "         -2.3157, -2.3418],\n",
       "        [-2.4532, -2.4487, -2.4563, -2.4530, -2.4577, 14.6664, -2.4511, -2.3096,\n",
       "         -2.4231, -2.3850],\n",
       "        [-1.9991, -2.1968, -1.9266, -2.1418, -1.9624, -2.2042, 14.4408, -2.2322,\n",
       "         -2.1712, -2.2150],\n",
       "        [-2.4896, -2.4842, -2.4922, -2.4936, -2.4931, -2.3469, -2.4831, 14.6560,\n",
       "         -2.4672, -2.4021],\n",
       "        [-2.4698, -2.4895, -2.4536, -2.4841, -2.4566, -2.4622, -2.4432, -2.4569,\n",
       "         14.6035, -2.4495],\n",
       "        [-2.4485, -2.4373, -2.4347, -2.4545, -2.4426, -2.3696, -2.4315, -2.3569,\n",
       "         -2.4186, 14.5698],\n",
       "        [14.4746, -2.3198, -2.3295, -2.2560, -2.3422, -2.3667, -2.1087, -2.3813,\n",
       "         -2.3553, -2.3685],\n",
       "        [-2.4757, 14.6365, -2.5036, -2.4422, -2.4936, -2.5058, -2.4911, -2.5101,\n",
       "         -2.5143, -2.5100],\n",
       "        [-2.3072, -2.3396, 14.5470, -2.3316, -2.0918, -2.3423, -2.1036, -2.3584,\n",
       "         -2.3195, -2.3461],\n",
       "        [-2.2840, -2.2525, -2.3592, 14.5209, -2.3175, -2.3788, -2.3170, -2.3861,\n",
       "         -2.3692, -2.3857],\n",
       "        [-2.3486, -2.3576, -2.0699, -2.3180, 14.5256, -2.3889, -2.1377, -2.3856,\n",
       "         -2.3335, -2.3774],\n",
       "        [-2.4465, -2.4494, -2.4474, -2.4486, -2.4591, 14.6589, -2.4454, -2.2923,\n",
       "         -2.4156, -2.3664],\n",
       "        [-1.9892, -2.1670, -1.8658, -2.1116, -1.8750, -2.1887, 14.3938, -2.2008,\n",
       "         -2.1338, -2.1907],\n",
       "        [-2.4344, -2.4343, -2.4389, -2.4376, -2.4409, -2.2955, -2.4281, 14.5613,\n",
       "         -2.4018, -2.3460],\n",
       "        [-2.4459, -2.4827, -2.4483, -2.4569, -2.4419, -2.4349, -2.4307, -2.4260,\n",
       "         14.5314, -2.4283],\n",
       "        [-2.4783, -2.4831, -2.4773, -2.4706, -2.4653, -2.4156, -2.4774, -2.4006,\n",
       "         -2.4510, 14.6073],\n",
       "        [14.5565, -2.3996, -2.3966, -2.3432, -2.4078, -2.4334, -2.1807, -2.4346,\n",
       "         -2.4193, -2.4353],\n",
       "        [-2.3963, 14.5455, -2.4224, -2.3481, -2.4138, -2.4183, -2.4088, -2.4232,\n",
       "         -2.4364, -2.4360],\n",
       "        [-2.2266, -2.2783, 14.4820, -2.2485, -2.0074, -2.2885, -2.0126, -2.2955,\n",
       "         -2.2511, -2.2870],\n",
       "        [-2.3198, -2.3155, -2.4124, 14.5810, -2.3715, -2.4264, -2.3673, -2.4300,\n",
       "         -2.4129, -2.4268],\n",
       "        [-2.3411, -2.3638, -2.0570, -2.3106, 14.5319, -2.3835, -2.1356, -2.3823,\n",
       "         -2.3357, -2.3726],\n",
       "        [-2.4161, -2.4082, -2.4119, -2.4156, -2.4206, 14.5984, -2.4173, -2.2752,\n",
       "         -2.3863, -2.3338],\n",
       "        [-2.0933, -2.2739, -2.0152, -2.2259, -2.0239, -2.2802, 14.5167, -2.2945,\n",
       "         -2.2300, -2.2896],\n",
       "        [-2.4395, -2.4366, -2.4317, -2.4294, -2.4384, -2.3006, -2.4422, 14.5824,\n",
       "         -2.3993, -2.3388],\n",
       "        [-2.4946, -2.5203, -2.4675, -2.5071, -2.4760, -2.4765, -2.4679, -2.4736,\n",
       "         14.6393, -2.4656],\n",
       "        [-2.4549, -2.4499, -2.4404, -2.4496, -2.4465, -2.3789, -2.4362, -2.3592,\n",
       "         -2.4104, 14.5717],\n",
       "        [14.5037, -2.3617, -2.3541, -2.2925, -2.3603, -2.3849, -2.1256, -2.4033,\n",
       "         -2.3764, -2.3942],\n",
       "        [-2.4786, 14.6242, -2.4967, -2.4416, -2.4846, -2.4951, -2.4947, -2.5042,\n",
       "         -2.5029, -2.5058],\n",
       "        [-2.3098, -2.3394, 14.5434, -2.3329, -2.0861, -2.3534, -2.1093, -2.3666,\n",
       "         -2.3229, -2.3485],\n",
       "        [-2.3261, -2.3115, -2.4256, 14.5816, -2.3874, -2.4354, -2.3763, -2.4406,\n",
       "         -2.4389, -2.4394],\n",
       "        [-2.3585, -2.3761, -2.0964, -2.3300, 14.5634, -2.3946, -2.1725, -2.3972,\n",
       "         -2.3686, -2.3970],\n",
       "        [-2.4742, -2.4709, -2.4810, -2.4761, -2.4773, 14.6967, -2.4780, -2.3347,\n",
       "         -2.4526, -2.3952],\n",
       "        [-2.0710, -2.2568, -1.9742, -2.2007, -1.9760, -2.2670, 14.5117, -2.2925,\n",
       "         -2.2258, -2.2925],\n",
       "        [-2.4088, -2.4150, -2.4205, -2.4154, -2.4169, -2.2604, -2.4153, 14.5622,\n",
       "         -2.3793, -2.3144],\n",
       "        [-2.4502, -2.4829, -2.4334, -2.4692, -2.4474, -2.4313, -2.4347, -2.4369,\n",
       "         14.5791, -2.4386],\n",
       "        [-2.4916, -2.4937, -2.4834, -2.4945, -2.4893, -2.4206, -2.4936, -2.4037,\n",
       "         -2.4708, 14.5785]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.cls_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.unique(torch.argmax(classifier.cls_confidence, dim=1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([7.8020], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.inv_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.8328e-08, 3.8267e-08, 3.8325e-08, 3.8312e-08, 3.8171e-08, 4.4385e-08,\n",
       "        3.8185e-08, 1.0000e+00, 3.9245e-08, 4.1537e-08], device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### example output per classifier\n",
    "yout[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdfsdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-80a679df1217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masdfsdf\u001b[0m \u001b[0;31m## to break the code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'asdfsdf' is not defined"
     ]
    }
   ],
   "source": [
    "asdfsdf ## to break the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyze per classifier accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:05<00:00, 233.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Train Acc:91.65%\n",
      "[409, 0, 318, 18, 3561, 2, 368, 86, 44, 60, 2173, 17, 588, 65, 242, 238, 788, 66, 19, 0, 59, 0, 213, 250, 27, 1823, 11, 595, 1173, 3158, 265, 0, 1260, 125, 72, 23, 7, 49, 11, 397, 457, 2083, 2972, 701, 157, 31, 2750, 5, 1994, 5, 116, 1421, 196, 891, 3, 507, 1342, 707, 47, 1212, 130, 76, 88, 338, 91, 222, 68, 4301, 373, 39, 0, 1870, 117, 79, 292, 126, 3, 108, 18, 997, 1614, 0, 8, 1717, 243, 20, 389, 59, 2211, 96, 14, 452, 84, 2009, 2009, 2892, 381, 47, 109, 133]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "test_acc = 0\n",
    "set_count = torch.zeros(classifier.num_sets).to(device)\n",
    "set_acc = torch.zeros(classifier.num_sets).to(device)\n",
    "for xx, yy in tqdm(train_loader):\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    with torch.no_grad():\n",
    "        yout = classifier(model(xx), hard=True)\n",
    "        \n",
    "    cls_indx = torch.argmax(classifier.cls_confidence, dim=1)\n",
    "    set_indx, count = torch.unique(cls_indx, return_counts=True) \n",
    "    set_count[set_indx] += count\n",
    "    \n",
    "    outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "    correct = (outputs == yy.data.cpu().numpy()).astype(float)\n",
    "    \n",
    "    ### class_index has 100 possible values\n",
    "    for i, c in enumerate(correct):\n",
    "        set_acc[cls_indx[i]] += c\n",
    "    \n",
    "#     print(set_acc.sum(), set_count.sum())\n",
    "#     break\n",
    "    test_acc += correct.sum()\n",
    "    test_count += len(xx)\n",
    "\n",
    "print(f'Hard Train Acc:{float(test_acc)/test_count*100:.2f}%')\n",
    "print(set_count.type(torch.long).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8973,    nan, 0.8711, 0.5000, 0.8110, 1.0000, 0.6168, 0.8953, 0.8864,\n",
       "        0.9000, 0.9609, 0.9412, 0.8197, 0.6769, 0.8430, 0.9874, 0.5723, 0.8333,\n",
       "        0.8421,    nan, 0.8644,    nan, 0.9624, 0.7560, 0.6667, 0.9863, 0.3636,\n",
       "        0.9580, 0.9838, 0.9725, 0.9472,    nan, 0.8754, 0.7040, 0.5000, 1.0000,\n",
       "        0.7143, 0.8980, 1.0000, 0.9673, 0.8709, 0.9981, 0.8782, 0.8488, 0.6624,\n",
       "        0.9355, 0.7967, 1.0000, 0.9940, 0.4000, 0.8707, 0.9887, 0.8418, 0.9484,\n",
       "        0.0000, 0.9961, 0.8860, 0.9760, 0.8298, 0.9645, 0.7769, 0.9737, 0.8068,\n",
       "        0.9379, 0.6264, 0.9820, 0.5882, 0.9772, 0.9786, 0.9231,    nan, 0.9968,\n",
       "        0.7350, 0.6709, 0.7774, 0.9365, 0.6667, 0.8241, 0.8889, 0.9609, 0.8990,\n",
       "           nan, 0.1250, 0.9278, 0.6132, 1.0000, 0.8869, 0.8136, 0.9851, 0.9062,\n",
       "        0.9286, 0.9978, 0.8095, 0.9512, 0.8706, 0.9969, 0.7087, 0.7447, 0.9083,\n",
       "        0.7820], device='cuda:0')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_acc/set_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,\t 409,\t 0\t 89.73%\n",
      "2,\t 318,\t 2\t 87.11%\n",
      "3,\t 18,\t 3\t 50.00%\n",
      "4,\t 3561,\t 4\t 81.10%\n",
      "5,\t 2,\t 5\t 100.00%\n",
      "6,\t 368,\t 6\t 61.68%\n",
      "7,\t 86,\t 7\t 89.53%\n",
      "8,\t 44,\t 8\t 88.64%\n",
      "9,\t 60,\t 9\t 90.00%\n",
      "10,\t 2173,\t 0\t 96.09%\n",
      "11,\t 17,\t 1\t 94.12%\n",
      "12,\t 588,\t 2\t 81.97%\n",
      "13,\t 65,\t 3\t 67.69%\n",
      "14,\t 242,\t 4\t 84.30%\n",
      "15,\t 238,\t 5\t 98.74%\n",
      "16,\t 788,\t 6\t 57.23%\n",
      "17,\t 66,\t 7\t 83.33%\n",
      "18,\t 19,\t 8\t 84.21%\n",
      "20,\t 59,\t 0\t 86.44%\n",
      "22,\t 213,\t 2\t 96.24%\n",
      "23,\t 250,\t 3\t 75.60%\n",
      "24,\t 27,\t 4\t 66.67%\n",
      "25,\t 1823,\t 5\t 98.63%\n",
      "26,\t 11,\t 6\t 36.36%\n",
      "27,\t 595,\t 7\t 95.80%\n",
      "28,\t 1173,\t 8\t 98.38%\n",
      "29,\t 3158,\t 9\t 97.25%\n",
      "30,\t 265,\t 0\t 94.72%\n",
      "32,\t 1260,\t 2\t 87.54%\n",
      "33,\t 125,\t 3\t 70.40%\n",
      "34,\t 72,\t 4\t 50.00%\n",
      "35,\t 23,\t 5\t 100.00%\n",
      "36,\t 7,\t 6\t 71.43%\n",
      "37,\t 49,\t 7\t 89.80%\n",
      "38,\t 11,\t 8\t 100.00%\n",
      "39,\t 397,\t 9\t 96.73%\n",
      "40,\t 457,\t 0\t 87.09%\n",
      "41,\t 2083,\t 1\t 99.81%\n",
      "42,\t 2972,\t 2\t 87.82%\n",
      "43,\t 701,\t 3\t 84.88%\n",
      "44,\t 157,\t 4\t 66.24%\n",
      "45,\t 31,\t 5\t 93.55%\n",
      "46,\t 2750,\t 6\t 79.67%\n",
      "47,\t 5,\t 7\t 100.00%\n",
      "48,\t 1994,\t 8\t 99.40%\n",
      "49,\t 5,\t 9\t 40.00%\n",
      "50,\t 116,\t 0\t 87.07%\n",
      "51,\t 1421,\t 1\t 98.87%\n",
      "52,\t 196,\t 2\t 84.18%\n",
      "53,\t 891,\t 3\t 94.84%\n",
      "54,\t 3,\t 4\t 0.00%\n",
      "55,\t 507,\t 5\t 99.61%\n",
      "56,\t 1342,\t 6\t 88.60%\n",
      "57,\t 707,\t 7\t 97.60%\n",
      "58,\t 47,\t 8\t 82.98%\n",
      "59,\t 1212,\t 9\t 96.45%\n",
      "60,\t 130,\t 0\t 77.69%\n",
      "61,\t 76,\t 1\t 97.37%\n",
      "62,\t 88,\t 2\t 80.68%\n",
      "63,\t 338,\t 3\t 93.79%\n",
      "64,\t 91,\t 4\t 62.64%\n",
      "65,\t 222,\t 5\t 98.20%\n",
      "66,\t 68,\t 6\t 58.82%\n",
      "67,\t 4301,\t 7\t 97.72%\n",
      "68,\t 373,\t 8\t 97.86%\n",
      "69,\t 39,\t 9\t 92.31%\n",
      "71,\t 1870,\t 1\t 99.68%\n",
      "72,\t 117,\t 2\t 73.50%\n",
      "73,\t 79,\t 3\t 67.09%\n",
      "74,\t 292,\t 4\t 77.74%\n",
      "75,\t 126,\t 5\t 93.65%\n",
      "76,\t 3,\t 6\t 66.67%\n",
      "77,\t 108,\t 7\t 82.41%\n",
      "78,\t 18,\t 8\t 88.89%\n",
      "79,\t 997,\t 9\t 96.09%\n",
      "80,\t 1614,\t 0\t 89.90%\n",
      "82,\t 8,\t 2\t 12.50%\n",
      "83,\t 1717,\t 3\t 92.78%\n",
      "84,\t 243,\t 4\t 61.32%\n",
      "85,\t 20,\t 5\t 100.00%\n",
      "86,\t 389,\t 6\t 88.69%\n",
      "87,\t 59,\t 7\t 81.36%\n",
      "88,\t 2211,\t 8\t 98.51%\n",
      "89,\t 96,\t 9\t 90.62%\n",
      "90,\t 14,\t 0\t 92.86%\n",
      "91,\t 452,\t 1\t 99.78%\n",
      "92,\t 84,\t 2\t 80.95%\n",
      "93,\t 2009,\t 3\t 95.12%\n",
      "94,\t 2009,\t 4\t 87.06%\n",
      "95,\t 2892,\t 5\t 99.69%\n",
      "96,\t 381,\t 6\t 70.87%\n",
      "97,\t 47,\t 7\t 74.47%\n",
      "98,\t 109,\t 8\t 90.83%\n",
      "99,\t 133,\t 9\t 78.20%\n"
     ]
    }
   ],
   "source": [
    "for i, (cnt, acc, cls) in enumerate(zip(set_count.type(torch.long).tolist(),\n",
    "                                   (set_acc/set_count).tolist(),\n",
    "                                   torch.argmax(classifier.cls_weight, dim=1).tolist())):\n",
    "    if cnt == 0: continue\n",
    "    print(f\"{i},\\t {cnt},\\t {cls}\\t {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
