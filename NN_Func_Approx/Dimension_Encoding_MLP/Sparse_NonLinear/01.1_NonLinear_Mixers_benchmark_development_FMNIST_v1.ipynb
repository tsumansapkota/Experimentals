{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9adde6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16e6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random, time, os, sys, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc9826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparse_nonlinear_lib as snl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9116e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43422589",
   "metadata": {},
   "source": [
    "## For FMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb3149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6203202",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=50, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=50, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3161b7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## demo of train loader\n",
    "xx, yy = iter(train_loader).next()\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1cb444",
   "metadata": {},
   "source": [
    "# Model Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad34b9b1",
   "metadata": {},
   "source": [
    "## Pair Linear Mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d17e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2patch(x, input_dim=(1, 28, 28), patch_size=(7, 4)):\n",
    "    y = nn.functional.unfold(x, \n",
    "                             kernel_size=patch_size, \n",
    "                             stride=patch_size\n",
    "                            )\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0293c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch2img(x, patch_size=(7, 4), input_dim=(1, 28, 28)):\n",
    "    y = nn.functional.fold(x, (input_dim[-2], input_dim[-1]), \n",
    "                               kernel_size=patch_size, \n",
    "                               stride=patch_size\n",
    "                              )\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b706042c",
   "metadata": {},
   "source": [
    "1. Linearize by expanding the dimension of folded image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b94d83",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25412a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMNIST_BlockMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_size=(1, 28, 28), select=1024, block_size=2, hidden_layers_ratio=[4], actf=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.dim_sel = snl.DimensionSelector(np.prod(img_size), select)\n",
    "\n",
    "        self.block_mlp = snl.BlockMLP_MixerBlock(select, block_size, \n",
    "                                                 hidden_layers_ratio=hidden_layers_ratio, actf=actf)\n",
    "#         self.norm = nn.BatchNorm1d(select)\n",
    "        self.norm = nn.LayerNorm(select)\n",
    "\n",
    "        self.actf = actf()\n",
    "        self.fc = nn.Linear(select, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = x.reshape(bs, -1)\n",
    "        x = self.dim_sel(x)\n",
    "        x = self.block_mlp(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.actf(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a3bc0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  201738\n"
     ]
    }
   ],
   "source": [
    "model = FMNIST_BlockMLP(block_size=4)\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d857d07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FMNIST_BlockMLP(\n",
       "  (dim_sel): DimensionSelector: [+=240]\n",
       "  (block_mlp): BlockMLP_MixerBlock(\n",
       "    (facto_nets): ModuleList(\n",
       "      (0): BlockMLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): BlockLinear: [256, 4, 16]\n",
       "          (1): GELU()\n",
       "          (2): BlockLinear: [256, 16, 4]\n",
       "        )\n",
       "      )\n",
       "      (1): BlockMLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): BlockLinear: [256, 4, 16]\n",
       "          (1): GELU()\n",
       "          (2): BlockLinear: [256, 16, 4]\n",
       "        )\n",
       "      )\n",
       "      (2): BlockMLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): BlockLinear: [256, 4, 16]\n",
       "          (1): GELU()\n",
       "          (2): BlockLinear: [256, 16, 4]\n",
       "        )\n",
       "      )\n",
       "      (3): BlockMLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): BlockLinear: [256, 4, 16]\n",
       "          (1): GELU()\n",
       "          (2): BlockLinear: [256, 16, 4]\n",
       "        )\n",
       "      )\n",
       "      (4): BlockMLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): BlockLinear: [256, 4, 16]\n",
       "          (1): GELU()\n",
       "          (2): BlockLinear: [256, 16, 4]\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (actf): GELU()\n",
       "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c74d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdfasdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5d9e1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USING DimensionSelector to make comparative\n",
    "\n",
    "class FMNIST_OrdMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_size=(1, 28, 28), select=1024):\n",
    "        super().__init__()\n",
    "        self.input_dim = np.prod(img_size)\n",
    "        self.dim_sel = snl.DimensionSelector(np.prod(img_size), select)\n",
    "        \n",
    "        self.l0 = nn.Linear(select, select)\n",
    "        self.norm = nn.LayerNorm(select)\n",
    "        self.actf = nn.GELU()\n",
    "        self.l1 = nn.Linear(select, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = x.reshape(bs, -1)\n",
    "        x = self.dim_sel(x)\n",
    "        x = self.l0(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.actf(x)\n",
    "        x = self.l1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ed7d64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  1061898\n"
     ]
    }
   ],
   "source": [
    "model = FMNIST_OrdMLP(select=1024)\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "386c8d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FMNIST_OrdMLP(\n",
       "  (dim_sel): DimensionSelector: [+=240]\n",
       "  (l0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (actf): GELU()\n",
       "  (l1): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d62bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMNIST_SparseMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_size=(1, 28, 28), select=1024, block_size=2):\n",
    "        super().__init__()\n",
    "        self.dim_sel = snl.DimensionSelector(np.prod(img_size), select)\n",
    "        \n",
    "        self.l0 = snl.BlockLinear_MixerBlock(select, block_size)\n",
    "        self.norm = nn.LayerNorm(select)\n",
    "        self.actf = nn.GELU()\n",
    "        self.l1 = nn.Linear(select, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = x.reshape(bs, -1)\n",
    "        x = self.dim_sel(x)\n",
    "        x = self.l0(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.actf(x)\n",
    "        x = self.l1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f5ca5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMNIST_SparseMLP_PWLF(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_size=(1, 28, 28), select=1024, block_size=2):\n",
    "        super().__init__()\n",
    "        self.dim_sel = snl.DimensionSelector(np.prod(img_size), select)\n",
    "        \n",
    "        self.l0 = snl.BlockLinear_MixerBlock(select, block_size)\n",
    "        self.norm = nn.LayerNorm(select)\n",
    "        self.pwlf = snl.PairBilinear(select, 5)\n",
    "#         self.actf = nn.GELU()\n",
    "        self.l1 = nn.Linear(select, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = x.reshape(bs, -1)\n",
    "        x = self.dim_sel(x)\n",
    "        x = self.l0(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwlf(x)\n",
    "#         x = self.actf(x)\n",
    "        x = self.l1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40211288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  105482\n"
     ]
    }
   ],
   "source": [
    "# model = FMNIST_SparseMLP(block_size=32).to(device)\n",
    "model = FMNIST_SparseMLP_PWLF(block_size=32).to(device)\n",
    "\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ee5d576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(2, 1, 28, 28).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85b6f617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FMNIST_SparseMLP_PWLF(\n",
       "  (dim_sel): DimensionSelector: [+=240]\n",
       "  (l0): BlockLinear_MixerBlock(\n",
       "    (facto_nets): ModuleList(\n",
       "      (0): BlockWeight: [32, 32, 32]\n",
       "      (1): BlockWeight: [32, 32, 32]\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (pwlf): PairBilinear: [1024 -> 1024] (grid: 5)\n",
       "  (l1): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dc5d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMNIST_PairBilinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_size=(1, 28, 28), select=1024, grid_width=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim_sel = snl.DimensionSelector(np.prod(img_size), select)\n",
    "        self.block_func = snl.PairBilinear_MixerBlock(select, select, grid_width=grid_width)\n",
    "        self.norm = nn.LayerNorm(select)\n",
    "        self.actf = nn.GELU()\n",
    "#         self.actf = nn.ELU()\n",
    "        self.fc = nn.Linear(select, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = x.reshape(bs,-1)\n",
    "        x = self.dim_sel(x)\n",
    "        x = self.block_func(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.actf(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fde08633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  125962\n"
     ]
    }
   ],
   "source": [
    "model = FMNIST_PairBilinear(grid_width=3)\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bd9df4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FMNIST_PairBilinear(\n",
       "  (dim_sel): DimensionSelector: [+=240]\n",
       "  (block_func): PairBilinear_MixerBlock(\n",
       "    (selector): BiasLayer: [1024]\n",
       "    (pairwise_mixing): ModuleList(\n",
       "      (0): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (1): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (2): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (3): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (4): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (5): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (6): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (7): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (8): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (9): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "    )\n",
       "    (reducer): Identity()\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (actf): GELU()\n",
       "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6258a55b",
   "metadata": {},
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e0ea73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = FMNIST_BlockMLP(img_size=(1, 28, 28), patch_size=(7, 7))\n",
    "# model = FMNIST_OrdMLP(img_size=(1, 28, 28))\n",
    "# model = FMNIST_PairBilinear(img_size=(1, 28, 28), grid_width=7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcd8010f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FMNIST_PairBilinear(\n",
       "  (dim_sel): DimensionSelector: [+=240]\n",
       "  (block_func): PairBilinear_MixerBlock(\n",
       "    (selector): BiasLayer: [1024]\n",
       "    (pairwise_mixing): ModuleList(\n",
       "      (0): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (1): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (2): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (3): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (4): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (5): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (6): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (7): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (8): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "      (9): PairBilinear: [1024 -> 1024] (grid: 3)\n",
       "    )\n",
       "    (reducer): Identity()\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (actf): GELU()\n",
       "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fc18f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(2, 1, 28, 28).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "145a10f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  125962\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d531c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b373358a",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## debugging to find the good classifier/output distribution.\n",
    "# model_name = 'block_mlp_mixer_fmnist_v0'\n",
    "# model_name = 'ord_mlp_mixer_fmnist_v0'\n",
    "model_name = 'pair_bilinear_mixer_fmnist_v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b9e292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.00003)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4e8858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    loss = train_loss/(batch_idx+1)\n",
    "    acc = 100.*correct/total\n",
    "    print(f\"[Train] {epoch} Loss: {loss:.3f} | Acc: {acc:.3f} {correct}/{total}\")\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2867980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_acc = -1\n",
    "def test(epoch, model, optimizer, best_acc, model_name):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    latency = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            start = time.time()\n",
    "            outputs = model(inputs)\n",
    "            ttaken = time.time()-start\n",
    "                \n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            latency.append(ttaken)\n",
    "    \n",
    "    loss = test_loss/(batch_idx+1)\n",
    "    acc = 100.*correct/total\n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc\n",
    "        \n",
    "    return loss, acc, best_acc, latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0b5e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('./models'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf30ff1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # ### Train the whole damn thing\n",
    "\n",
    "# best_acc = -1\n",
    "# for epoch in range(start_epoch, start_epoch+EPOCHS): ## for 200 epochs\n",
    "#     trloss, tracc = train(epoch, model, optimizer)\n",
    "#     teloss, teacc, best_acc, latency = test(epoch, model, optimizer, best_acc, model_name)\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "946f904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_acc ## 90.42 for ordinary, 89.59 for sparse, 89.82 fro 32bMLP, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae1ce1e",
   "metadata": {},
   "source": [
    "### Do all experiments in repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "265fd1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, lr, model_name, epochs=50, seed=0):\n",
    "    global criterion, train_loader, test_loader\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=50, shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=50, shuffle=False, num_workers=2)\n",
    "    \n",
    "    best_acc = -1\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    stats = {'num_param':n_params, 'latency': [], \n",
    "             'train_acc':[], 'train_loss':[], \n",
    "             'test_acc':[], 'test_loss':[] \n",
    "            }\n",
    "    \n",
    "    print(f\"Begin Training for {model_name}\")\n",
    "    print(f\"Num Parameters: {n_params}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        trloss, tracc = train(epoch, model, optimizer)\n",
    "        teloss, teacc, best_acc, laten = test(epoch, model, optimizer, best_acc, model_name)\n",
    "        scheduler.step()\n",
    "        \n",
    "        stats['latency'] += laten\n",
    "        stats['train_acc'].append(tracc)\n",
    "        stats['test_acc'].append(teacc)\n",
    "        stats['train_loss'].append(trloss)\n",
    "        stats['test_loss'].append(teloss)\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    latency = np.array(stats['latency'])\n",
    "    mu, std = np.mean(latency), np.std(latency)\n",
    "    stats['latency'] = {'mean':mu, 'std':std}\n",
    "    ### Save stats of the model\n",
    "    with open(f'./models/stats/{model_name}_stats.json', 'w') as f:\n",
    "        json.dump(stats, f)\n",
    "    \n",
    "    return stats, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4938e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\t2\t280586\tBlockMLP\n",
      "32\t4\t546826\tBlockMLP\n",
      "32\t8\t1079306\tBlockMLP\n",
      "32\t\t77834\tSparseMLP\n",
      "32\t\t105482\tSparseMLP_PWLF\n",
      "\n",
      "4\t4\t201738\tBlockMLP\n",
      "4\t8\t386058\tBlockMLP\n",
      "4\t16\t754698\tBlockMLP\n",
      "4\t\t32778\tSparseMLP\n",
      "4\t\t60426\tSparseMLP_PWLF\n",
      "\n",
      "2\t4\t227338\tBlockMLP\n",
      "2\t8\t432138\tBlockMLP\n",
      "2\t16\t841738\tBlockMLP\n",
      "2\t\t32778\tSparseMLP\n",
      "2\t\t60426\tSparseMLP_PWLF\n",
      "\n",
      "2\t3\t125962\tPairPWLF\n",
      "2\t5\t289802\tPairPWLF\n",
      "2\t9\t863242\tPairPWLF\n",
      "\n",
      "\t\t1061898\tOrdMLP\n"
     ]
    }
   ],
   "source": [
    "mlp_dims_scale = {\n",
    "    32: [2, 4, 8],\n",
    "    4: [4, 8, 16],\n",
    "    2: [4, 8, 16],\n",
    "}\n",
    "pwlf_grid_size = [3, 5, 9]\n",
    "\n",
    "SEEDS = [147, 258, 369]\n",
    "\n",
    "def benchmark_fmnist():\n",
    "    for seed in [147]:\n",
    "        ### First test MLP with allowed dimension mixing\n",
    "        for dim, hid_dim in mlp_dims_scale.items(): ## For 1024 these are the factors\n",
    "            for hr in hid_dim:\n",
    "                model = FMNIST_BlockMLP(block_size=dim, hidden_layers_ratio=[hr])\n",
    "                n_params = sum(p.numel() for p in model.parameters())\n",
    "                print(f\"{dim}\\t{hr}\\t{n_params}\\tBlockMLP\")\n",
    "            \n",
    "            model = FMNIST_SparseMLP(block_size=dim)\n",
    "            n_params = sum(p.numel() for p in model.parameters())\n",
    "            print(f\"{dim}\\t\\t{n_params}\\tSparseMLP\")\n",
    "            \n",
    "            model = FMNIST_SparseMLP_PWLF(block_size=dim)\n",
    "            n_params = sum(p.numel() for p in model.parameters())\n",
    "            print(f\"{dim}\\t\\t{n_params}\\tSparseMLP_PWLF\")\n",
    "            print()\n",
    "        \n",
    "        for gsz in pwlf_grid_size:\n",
    "            model = FMNIST_PairBilinear(grid_width=gsz)\n",
    "            n_params = sum(p.numel() for p in model.parameters())\n",
    "            print(f\"{2}\\t{gsz}\\t{n_params}\\tPairPWLF\")\n",
    "        \n",
    "        print()\n",
    "        model = FMNIST_OrdMLP()\n",
    "        n_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"\\t\\t{n_params}\\tOrdMLP\")\n",
    "\n",
    "\n",
    "benchmark_fmnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d245730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = FMNIST_OrdMLP()\n",
    "# sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba217d",
   "metadata": {},
   "source": [
    "## Configuring training and saving functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83475e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_dims_scale = {\n",
    "    32: [2, 4, 8],\n",
    "    4: [4, 8, 16],\n",
    "    2: [4, 8, 16],\n",
    "}\n",
    "pwlf_grid_size = [3, 5, 9]\n",
    "\n",
    "SEEDS = [147, 258, 369]\n",
    "EPOCHS = 50\n",
    "LR = 0.001\n",
    "\n",
    "def benchmark_fmnist():\n",
    "#     for seed in [147]:\n",
    "    for seed in SEEDS:\n",
    "        ## First test MLP with allowed dimension mixing\n",
    "        for dim, hid_dim in mlp_dims_scale.items(): ## For 1024 these are the factors\n",
    "            for hr in hid_dim:\n",
    "                torch.manual_seed(seed)\n",
    "                model = FMNIST_BlockMLP(block_size=dim, hidden_layers_ratio=[hr])\n",
    "                model_name = f\"fmnist_BlockMLP_b{dim}_h{hr}_s{seed}\"\n",
    "                train_model(model, LR, model_name, EPOCHS, seed)\n",
    "\n",
    "            torch.manual_seed(seed)\n",
    "            model = FMNIST_SparseMLP(block_size=dim)\n",
    "            model_name = f\"fmnist_SparseMLP_b{dim}_s{seed}\"\n",
    "            train_model(model, LR, model_name, EPOCHS, seed)\n",
    "            \n",
    "            torch.manual_seed(seed)\n",
    "            model = FMNIST_SparseMLP_PWLF(block_size=dim)\n",
    "            model_name = f\"fmnist_SparseMLP_PWLF_b{dim}_s{seed}\"\n",
    "            train_model(model, LR, model_name, EPOCHS, seed)\n",
    "            \n",
    "        for gsz in pwlf_grid_size:\n",
    "            torch.manual_seed(seed)\n",
    "            model = FMNIST_PairBilinear(grid_width=gsz)\n",
    "            model_name = f\"fmnist_PairPWLF_g{gsz}_s{seed}\"\n",
    "            train_model(model, 0.00003, model_name, EPOCHS, seed)\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "        model = FMNIST_OrdMLP()\n",
    "        model_name = f\"fmnist_OrdinaryMLP_s{seed}\"\n",
    "        train_model(model, LR, model_name, EPOCHS, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32f68373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:15<00:00, 79.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 28 Loss: 0.070 | Acc: 97.507 58504/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 118.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 28 Loss: 0.446 | Acc: 88.840 8884/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:18<00:00, 65.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 29 Loss: 0.064 | Acc: 97.822 58693/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 144.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 29 Loss: 0.439 | Acc: 89.140 8914/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:18<00:00, 64.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 30 Loss: 0.057 | Acc: 98.070 58842/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 131.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 30 Loss: 0.460 | Acc: 89.010 8901/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:18<00:00, 65.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 31 Loss: 0.051 | Acc: 98.348 59009/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 138.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 31 Loss: 0.468 | Acc: 88.920 8892/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:17<00:00, 69.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 32 Loss: 0.045 | Acc: 98.592 59155/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 145.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 32 Loss: 0.474 | Acc: 89.060 8906/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:15<00:00, 78.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 33 Loss: 0.039 | Acc: 98.828 59297/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 147.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 33 Loss: 0.486 | Acc: 89.140 8914/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:17<00:00, 68.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 34 Loss: 0.034 | Acc: 98.997 59398/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 162.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 34 Loss: 0.503 | Acc: 88.940 8894/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:16<00:00, 70.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 35 Loss: 0.029 | Acc: 99.197 59518/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 185.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 35 Loss: 0.522 | Acc: 88.760 8876/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:16<00:00, 74.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 36 Loss: 0.025 | Acc: 99.367 59620/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 145.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 36 Loss: 0.531 | Acc: 88.820 8882/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████▏                      | 653/1200 [00:09<00:07, 71.28it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark_fmnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac283f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
