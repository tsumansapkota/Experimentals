{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-b22782e32495>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image = mnist.train.images[1].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2273dc24a20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2273dbb12e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(single_image, cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_image.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLACEHOLDERS\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VARIABLES\n",
    "# initializer = tf.variance_scaling_initializer()\n",
    "initializer = tf.random_uniform_initializer()\n",
    "\n",
    "W1 = tf.Variable(initializer([784,155]), dtype=tf.float32)\n",
    "b1 = tf.Variable(tf.zeros([155]), dtype=tf.float32)\n",
    "a1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(initializer([155, 31]), dtype=tf.float32)\n",
    "b2 = tf.Variable(tf.zeros([31]), dtype=tf.float32)\n",
    "a2 = tf.nn.relu(tf.matmul(a1, W2) + b2)\n",
    "\n",
    "\n",
    "W3 = tf.Variable(initializer([31,10]), dtype=tf.float32)\n",
    "b3 = tf.Variable(tf.zeros([10]), dtype=tf.float32)\n",
    "# a13 = tf.nn.relu(tf.matmul(a2, W3) + b3)\n",
    "a13 = tf.matmul(a2, W3) + b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE GRAPH OPERATION\n",
    "y = a13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOSS FUNCTION\n",
    "y_true = tf.placeholder(tf.float32, [None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIMIZER\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATION\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Complete. Training Cost: 4.1348114013671875\n",
      "0.549\n",
      "Epoch 1 Complete. Training Cost: 2.660403251647949\n",
      "0.6904\n",
      "Epoch 2 Complete. Training Cost: 2.4192006587982178\n",
      "0.7839\n",
      "Epoch 3 Complete. Training Cost: 1.2401957511901855\n",
      "0.7883\n",
      "Epoch 4 Complete. Training Cost: 1.0033690929412842\n",
      "0.8315\n",
      "Epoch 5 Complete. Training Cost: 3.4402143955230713\n",
      "0.7434\n",
      "Epoch 6 Complete. Training Cost: 1.0141814947128296\n",
      "0.8603\n",
      "Epoch 7 Complete. Training Cost: 1.3287031650543213\n",
      "0.8621\n",
      "Epoch 8 Complete. Training Cost: 1.201291799545288\n",
      "0.8535\n",
      "Epoch 9 Complete. Training Cost: 1.1581193208694458\n",
      "0.8694\n",
      "Epoch 10 Complete. Training Cost: 0.7608135342597961\n",
      "0.8943\n",
      "Epoch 11 Complete. Training Cost: 1.1632561683654785\n",
      "0.8772\n",
      "Epoch 12 Complete. Training Cost: 1.0109062194824219\n",
      "0.8818\n",
      "Epoch 13 Complete. Training Cost: 0.8511311411857605\n",
      "0.8465\n",
      "Epoch 14 Complete. Training Cost: 0.9102868437767029\n",
      "0.8746\n",
      "Epoch 15 Complete. Training Cost: 0.9826450347900391\n",
      "0.8636\n",
      "Epoch 16 Complete. Training Cost: 2.007093906402588\n",
      "0.8767\n",
      "Epoch 17 Complete. Training Cost: 1.4679003953933716\n",
      "0.8894\n",
      "Epoch 18 Complete. Training Cost: 0.623998761177063\n",
      "0.8414\n",
      "Epoch 19 Complete. Training Cost: 0.5566084980964661\n",
      "0.8945\n",
      "Epoch 20 Complete. Training Cost: 1.3567744493484497\n",
      "0.8783\n",
      "Epoch 21 Complete. Training Cost: 0.8427836894989014\n",
      "0.8864\n",
      "Epoch 22 Complete. Training Cost: 1.0410701036453247\n",
      "0.8961\n",
      "Epoch 23 Complete. Training Cost: 1.65011465549469\n",
      "0.8403\n",
      "Epoch 24 Complete. Training Cost: 2.264904737472534\n",
      "0.8439\n",
      "Epoch 25 Complete. Training Cost: 1.4844542741775513\n",
      "0.8515\n",
      "Epoch 26 Complete. Training Cost: 1.7200772762298584\n",
      "0.7929\n",
      "Epoch 27 Complete. Training Cost: 0.42190802097320557\n",
      "0.9074\n",
      "Epoch 28 Complete. Training Cost: 1.5041769742965698\n",
      "0.8935\n",
      "Epoch 29 Complete. Training Cost: 1.0757668018341064\n",
      "0.8741\n",
      "Epoch 30 Complete. Training Cost: 0.974928617477417\n",
      "0.8699\n",
      "Epoch 31 Complete. Training Cost: 2.746544599533081\n",
      "0.8251\n",
      "Epoch 32 Complete. Training Cost: 1.1331194639205933\n",
      "0.8709\n",
      "Epoch 33 Complete. Training Cost: 1.6354503631591797\n",
      "0.8991\n",
      "Epoch 34 Complete. Training Cost: 1.7817184925079346\n",
      "0.8075\n",
      "Epoch 35 Complete. Training Cost: 0.7782256603240967\n",
      "0.8999\n",
      "Epoch 36 Complete. Training Cost: 1.4527437686920166\n",
      "0.8664\n",
      "Epoch 37 Complete. Training Cost: 0.5218355059623718\n",
      "0.9011\n",
      "Epoch 38 Complete. Training Cost: 2.08134126663208\n",
      "0.8912\n",
      "Epoch 39 Complete. Training Cost: 0.7480843663215637\n",
      "0.9155\n",
      "Epoch 40 Complete. Training Cost: 0.8142501711845398\n",
      "0.9055\n",
      "Epoch 41 Complete. Training Cost: 0.7515552043914795\n",
      "0.8889\n",
      "Epoch 42 Complete. Training Cost: 1.2265597581863403\n",
      "0.9008\n",
      "Epoch 43 Complete. Training Cost: 2.9744269847869873\n",
      "0.7714\n",
      "Epoch 44 Complete. Training Cost: 0.6698121428489685\n",
      "0.8925\n",
      "Epoch 45 Complete. Training Cost: 1.1839637756347656\n",
      "0.8917\n",
      "Epoch 46 Complete. Training Cost: 2.7986512184143066\n",
      "0.7894\n",
      "Epoch 47 Complete. Training Cost: 1.3325552940368652\n",
      "0.7971\n",
      "Epoch 48 Complete. Training Cost: 0.7881054878234863\n",
      "0.9043\n",
      "Epoch 49 Complete. Training Cost: 0.9635797142982483\n",
      "0.8968\n",
      "Epoch 50 Complete. Training Cost: 1.2815382480621338\n",
      "0.8956\n",
      "Epoch 51 Complete. Training Cost: 1.3726831674575806\n",
      "0.8759\n",
      "Epoch 52 Complete. Training Cost: 1.1425429582595825\n",
      "0.8535\n",
      "Epoch 53 Complete. Training Cost: 1.2904841899871826\n",
      "0.8888\n",
      "Epoch 54 Complete. Training Cost: 0.8143141269683838\n",
      "0.9076\n",
      "Epoch 55 Complete. Training Cost: 1.1617779731750488\n",
      "0.8771\n",
      "Epoch 56 Complete. Training Cost: 2.9173314571380615\n",
      "0.7798\n",
      "Epoch 57 Complete. Training Cost: 1.7486515045166016\n",
      "0.8721\n",
      "Epoch 58 Complete. Training Cost: 0.41744622588157654\n",
      "0.8982\n",
      "Epoch 59 Complete. Training Cost: 0.5991494655609131\n",
      "0.8862\n",
      "Epoch 60 Complete. Training Cost: 0.5602014660835266\n",
      "0.8966\n",
      "Epoch 61 Complete. Training Cost: 0.8471785187721252\n",
      "0.8364\n",
      "Epoch 62 Complete. Training Cost: 1.0100957155227661\n",
      "0.9083\n",
      "Epoch 63 Complete. Training Cost: 1.7421181201934814\n",
      "0.872\n",
      "Epoch 64 Complete. Training Cost: 1.9973372220993042\n",
      "0.8881\n",
      "Epoch 65 Complete. Training Cost: 0.8142916560173035\n",
      "0.8958\n",
      "Epoch 66 Complete. Training Cost: 1.180729627609253\n",
      "0.8483\n",
      "Epoch 67 Complete. Training Cost: 1.5263824462890625\n",
      "0.8692\n",
      "Epoch 68 Complete. Training Cost: 0.9601855278015137\n",
      "0.875\n",
      "Epoch 69 Complete. Training Cost: 0.8975202441215515\n",
      "0.8778\n",
      "Epoch 70 Complete. Training Cost: 1.0113599300384521\n",
      "0.8948\n",
      "Epoch 71 Complete. Training Cost: 1.0205435752868652\n",
      "0.8688\n",
      "Epoch 72 Complete. Training Cost: 0.9707074761390686\n",
      "0.8644\n",
      "Epoch 73 Complete. Training Cost: 0.8846901655197144\n",
      "0.9244\n",
      "Epoch 74 Complete. Training Cost: 1.3257887363433838\n",
      "0.9087\n",
      "Epoch 75 Complete. Training Cost: 0.6062103509902954\n",
      "0.9013\n",
      "Epoch 76 Complete. Training Cost: 3.0296950340270996\n",
      "0.7443\n",
      "Epoch 77 Complete. Training Cost: 0.35819458961486816\n",
      "0.8899\n",
      "Epoch 78 Complete. Training Cost: 0.9423691630363464\n",
      "0.8857\n",
      "Epoch 79 Complete. Training Cost: 0.9965513348579407\n",
      "0.9159\n",
      "Epoch 80 Complete. Training Cost: 0.8729885816574097\n",
      "0.866\n",
      "Epoch 81 Complete. Training Cost: 1.5238945484161377\n",
      "0.8994\n",
      "Epoch 82 Complete. Training Cost: 0.7342939376831055\n",
      "0.8954\n",
      "Epoch 83 Complete. Training Cost: 1.1976052522659302\n",
      "0.8949\n",
      "Epoch 84 Complete. Training Cost: 0.8557527661323547\n",
      "0.9035\n",
      "Epoch 85 Complete. Training Cost: 0.6160268187522888\n",
      "0.9148\n",
      "Epoch 86 Complete. Training Cost: 0.8362516760826111\n",
      "0.8538\n",
      "Epoch 87 Complete. Training Cost: 0.9454138278961182\n",
      "0.9004\n",
      "Epoch 88 Complete. Training Cost: 0.8930519819259644\n",
      "0.891\n",
      "Epoch 89 Complete. Training Cost: 1.3582266569137573\n",
      "0.8979\n",
      "Epoch 90 Complete. Training Cost: 1.552480936050415\n",
      "0.8963\n",
      "Epoch 91 Complete. Training Cost: 1.0842174291610718\n",
      "0.8508\n",
      "Epoch 92 Complete. Training Cost: 1.6152275800704956\n",
      "0.9028\n",
      "Epoch 93 Complete. Training Cost: 1.0546238422393799\n",
      "0.8922\n",
      "Epoch 94 Complete. Training Cost: 1.1610352993011475\n",
      "0.8925\n",
      "Epoch 95 Complete. Training Cost: 1.2456294298171997\n",
      "0.9115\n",
      "Epoch 96 Complete. Training Cost: 0.842034637928009\n",
      "0.9089\n",
      "Epoch 97 Complete. Training Cost: 0.5257832407951355\n",
      "0.9141\n",
      "Epoch 98 Complete. Training Cost: 0.2046426236629486\n",
      "0.8865\n",
      "Epoch 99 Complete. Training Cost: 1.1776050329208374\n",
      "0.8468\n",
      "Finished Training the Model\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "try:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # Epoch == Entire Training Set\n",
    "        for epoch in range(num_epochs):\n",
    "            num_batches = mnist.train.num_examples // batch_size\n",
    "\n",
    "            # 150 batch size\n",
    "            for iteration in range(num_batches):\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "                sess.run(train, feed_dict={X: X_batch, y_true:y_batch})\n",
    "\n",
    "            training_loss = cross_entropy.eval(feed_dict={X: X_batch, y_true:y_batch})   \n",
    "            print(\"Epoch {} Complete. Training Cost: {}\".format(epoch,training_loss))\n",
    "            saver.save(sess, \"../save/mnist_wo_ae.ckpt\")\n",
    "            \n",
    "            correct_prediction = tf.equal(tf.argmax(y,axis=1), tf.argmax(y_true,1))\n",
    "            acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            print(sess.run(acc, feed_dict={X:mnist.test.images, y_true:mnist.test.labels}))\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print('Keyboard Interrupted')\n",
    "finally:\n",
    "    print('Finished Training the Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9811 accuracy .. 784, 155, 31, 10 reluss, softmax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
