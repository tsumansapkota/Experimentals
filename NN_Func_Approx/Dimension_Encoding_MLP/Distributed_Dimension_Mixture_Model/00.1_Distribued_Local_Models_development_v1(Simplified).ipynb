{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os, sys, pathlib, random, time, pickle, copy, json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 147\n",
    "# SEED = 258\n",
    "# SEED = 369\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## demo of train loader\n",
    "xx, yy = iter(train_loader).next()\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpBLock(nn.Module):\n",
    "    \n",
    "    def __init__(self, dims, actf=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.dims = dims\n",
    "        #### convert hidden layers ratio to list if integer is inputted\n",
    "            \n",
    "        self.mlp = []\n",
    "        ### for 1 hidden layer, we iterate 2 times\n",
    "        for h in range(len(self.dims)-1):\n",
    "            i, o = int(self.dims[h]),\\\n",
    "                    int(self.dims[h+1])\n",
    "            self.mlp.append(nn.Linear(i, o))\n",
    "            self.mlp.append(actf())\n",
    "        self.mlp = self.mlp[:-1]\n",
    "        \n",
    "        self.mlp = nn.Sequential(*self.mlp)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpBLock(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=3, bias=True)\n",
       "    (1): GELU()\n",
       "    (2): Linear(in_features=3, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MlpBLock([2, 3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_edge(0, 1)\n",
    "G.add_edge(0, 2)\n",
    "G.add_edge(0, 3)\n",
    "G.add_edge(1, 4)\n",
    "G.add_edge(1, 5)\n",
    "G.add_edge(2, 5)\n",
    "G.add_edge(2, 6)\n",
    "G.add_edge(3, 6)\n",
    "G.add_edge(4, 7)\n",
    "G.add_edge(5, 7)\n",
    "G.add_edge(6, 7)\n",
    "G.add_edge(7, 8)\n",
    "G.add_edge(7, 9)\n",
    "G.add_edge(6, 9)\n",
    "G.add_edge(8, 10)\n",
    "G.add_edge(9, 10)\n",
    "G.add_edge(10, 11)\n",
    "\n",
    "\n",
    "# explicitly set positions\n",
    "pos = {0: (0, 1), \n",
    "       1: (1, 0), \n",
    "       2: (1, 1), \n",
    "       3: (1, 2), \n",
    "       4: (2, 0),\n",
    "       5: (2, 1),\n",
    "       6: (2.25, 2),\n",
    "       7: (3, 0.5),\n",
    "       8: (4, 0.5),\n",
    "       9: (4, 1.5),\n",
    "       10: (5, 1),\n",
    "       11: (6, 1),\n",
    "      }\n",
    "\n",
    "options = {\n",
    "    \"font_size\": 10,\n",
    "    \"node_size\": 300,\n",
    "    \"node_color\": \"white\",\n",
    "    \"edgecolors\": \"black\",\n",
    "    \"linewidths\": 2,\n",
    "    \"width\": 2,\n",
    "}\n",
    "nx.draw_networkx(G, pos, **options)\n",
    "\n",
    "# Set margins for the axes so that nodes aren't clipped\n",
    "ax = plt.gca()\n",
    "ax.margins(0.20)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeView([(0, 1), (0, 2), (0, 3), (1, 4), (1, 5), (2, 5), (2, 6), (3, 6), (4, 7), (5, 7), (6, 7), (6, 9), (7, 8), (7, 9), (8, 10), (9, 10), (10, 11)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(InDegreeView({0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 2, 6: 2, 7: 3, 8: 1, 9: 2, 10: 2, 11: 1}),\n",
       " OutDegreeView({0: 3, 1: 2, 2: 2, 3: 1, 4: 1, 5: 1, 6: 2, 7: 2, 8: 1, 9: 1, 10: 1, 11: 0}))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.in_degree(), G.out_degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeView([(0, 1), (0, 2), (0, 3), (1, 4), (1, 5), (2, 5), (2, 6), (3, 6), (4, 7), (5, 7), (6, 7), (6, 9), (7, 8), (7, 9), (8, 10), (9, 10), (10, 11)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.out_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InEdgeView([(0, 1), (0, 2), (0, 3), (1, 4), (1, 5), (2, 5), (2, 6), (3, 6), (4, 7), (5, 7), (6, 7), (7, 8), (7, 9), (6, 9), (8, 10), (9, 10), (10, 11)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.in_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Dimension-Mixer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `Local Models` are the basis for local training of models.\n",
    "2. `Local Models` have their own optimizer and communicate via low bandwidth connection.\n",
    "3. This experiment verifies if training local models reduces the number of forward and backward pass for reaching the solution.\n",
    "4. The main idea is to update local model multiple times and backproping the final gradient, rather than doing it one iteration (similar to higher order optimization ?? like 1.5-nd optimization)\n",
    "5. The optimal spectrum lies in between (Its like dynamic optimization, while doing inference with more communication between local models, far away models communicate less). There has been similar ideas otherwhere as well but not exactly. Its based on my own experiment using optimizer for find better gradient for global optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedNode(abc.ABC):\n",
    "#     @abc.abstractmethod\n",
    "    def set_input_nodes(self, nodes):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "    def set_output_nodes(self, nodes):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "    def forward_local(self):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "    def backward_local(self):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "    def update_local(self):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "#     def train_loop(self, ):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalModel(DistributedNode):\n",
    "    \n",
    "    def __init__(self, model, lr=0.1, local_lr=0.01, local_updates=100):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.optimizer = None\n",
    "#         self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.local_lr = local_lr\n",
    "        self.local_updates = local_updates\n",
    "        \n",
    "        self.output_dim = model.dims[-1]\n",
    "        self.split_indices = None\n",
    "        \n",
    "        ### temporary state variables\n",
    "        self.input_received = []\n",
    "        self.input_shapes = []\n",
    "        self.output_shape = None\n",
    "        self.grad_received = None\n",
    "        \n",
    "    def set_split_mixing_indices(self, split_sizes=None):\n",
    "        if split_sizes is None:\n",
    "            split_sizes = [self.output_dim, ]\n",
    "        ## split sizes added must be >= to input size\n",
    "        assert self.output_dim <= np.sum(split_sizes), \"split sizes are less than input dimension\"\n",
    "        for ss in split_sizes:\n",
    "            assert self.output_dim >= ss, \"split sizes are greater than input dimension\"\n",
    "            \n",
    "        \n",
    "        ## also do not use split sizes greater than input dimension\n",
    "        \n",
    "        indices = np.arange(0, self.output_dim, 1, dtype=int)\n",
    "        indices = np.random.permutation(indices)\n",
    "        \n",
    "        ## first divide input dimension into all splits\n",
    "        split_loc = split_sizes/np.sum(split_sizes)*self.output_dim\n",
    "        split_loc = split_loc.astype(int)\n",
    "        split_loc[0] += self.output_dim-split_loc.sum()\n",
    "        \n",
    "        index = np.split(indices, np.cumsum(split_loc[:-1]))\n",
    "        ## for extra input dimensions, sample randomly from remaining node indices.\n",
    "        for i in range(len(index)):\n",
    "            idx = index[i]\n",
    "            mask = np.ones(self.output_dim, dtype=bool)\n",
    "            mask[idx] = False\n",
    "            remaining = np.arange(0, self.output_dim, 1, dtype=int)[mask]\n",
    "            num_remain = split_sizes[i] - len(idx)\n",
    "            new_idx = remaining[np.random.permutation(len(remaining))[:num_remain]]\n",
    "            new_idx = np.array(new_idx)\n",
    "            \n",
    "            all_inx = np.concatenate((idx, new_idx))\n",
    "            index[i] = torch.LongTensor(all_inx)\n",
    "            pass\n",
    "        \n",
    "        self.split_indices = index\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def forward_local(self, xs):\n",
    "        ### concat received inputs\n",
    "        self.input_shapes = [xi.shape for xi in xs]\n",
    "        xs = torch.cat(xs, dim=1)\n",
    "        self.input_received = xs.data\n",
    "\n",
    "        xs = self.model(xs)\n",
    "        self.output_shape = xs.shape\n",
    "        \n",
    "        ys = []\n",
    "        for si in self.split_indices:\n",
    "            ys.append(xs[:, si])\n",
    "\n",
    "#         .split([100, 100], dim=1)\n",
    "        return ys\n",
    "    \n",
    "    def backward_local(self, dys):\n",
    "        ### concat received gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            grads = torch.zeros(self.output_shape).to(dys[0].device)\n",
    "            for i, si in enumerate(self.split_indices):\n",
    "                grads[:,si] += dys[i]\n",
    "\n",
    "            self.grad_received = grads\n",
    "\n",
    "            ys = self.model(self.input_received)\n",
    "            ts = ys - grads\n",
    "            ###### with the information of inputs and grads, we can compute target\n",
    "            #### the model can be optimized for that target.\n",
    "\n",
    "            model_clone = copy.deepcopy(self.model)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model_clone.parameters(), lr=self.local_lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        for epoch in range(self.local_updates):\n",
    "            ys = model_clone(self.input_received)\n",
    "            loss = criterion(ys, ts)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            #### gather the overall gradient\n",
    "            self.model.zero_grad()\n",
    "            for model_parm, modelt_parm in zip(self.model.parameters(), model_clone.parameters()):\n",
    "                model_parm.grad = (model_parm - modelt_parm)\n",
    "        \n",
    "            self.optimizer.step()\n",
    "\n",
    "        ## get input gradients\n",
    "        Xs = torch.autograd.Variable(self.input_received, requires_grad=True)\n",
    "        ys = self.model(Xs)\n",
    "        loss = criterion(ys, ts)\n",
    "        loss.backward()\n",
    "        self.model.zero_grad()\n",
    "        split_sz = [t[-1] for t in self.input_shapes]\n",
    "        input_grads = Xs.grad.split(split_sz, dim=1)\n",
    "        return input_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LocalModel(MlpBLock([3, 5, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpBLock(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=5, bias=True)\n",
       "    (1): GELU()\n",
       "    (2): Linear(in_features=5, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.optimizer = torch.optim.Adam(lm.model.parameters(), lr=lm.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2175,  0.2332, -0.2312]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = torch.randn(1, 3)\n",
    "lm.forward(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm.set_split_mixing_indices([2, 2])\n",
    "lm.set_split_mixing_indices(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 0])]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.split_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.1\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.2332, -0.2312, -0.2175]])]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.forward_local([xx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0384,  0.0721, -0.0031]]),)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dys = [torch.randn(1, 2), torch.randn(1,2)]\n",
    "dys = [torch.randn(1, 3),]\n",
    "\n",
    "lm.backward_local(dys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFeeder(DistributedNode):\n",
    "    \n",
    "    def __init__(self, input_dim, split_sizes = []):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.split_sizes = np.array(split_sizes, dtype=int)\n",
    "        self.split_indices = None\n",
    "\n",
    "        self.inputs = None\n",
    "        self.output_nodes = None\n",
    "        \n",
    "        ## preprocessing steps\n",
    "        self._set_split_mixing_indices_()\n",
    "        \n",
    "    def _set_split_mixing_indices_(self):\n",
    "        ## split sizes added must be >= to input size\n",
    "        assert self.input_dim <= np.sum(self.split_sizes), \"split sizes are less than input dimension\"\n",
    "        for ss in self.split_sizes:\n",
    "            assert self.input_dim >= ss, \"split sizes are greater than input dimension\"\n",
    "            \n",
    "        \n",
    "        ## also do not use split sizes greater than input dimension\n",
    "        \n",
    "        indices = np.arange(0, self.input_dim, 1, dtype=int)\n",
    "        indices = np.random.permutation(indices)\n",
    "        \n",
    "#         print(indices)\n",
    "        ## first divide input dimension into all splits\n",
    "        split_indices = self.split_sizes/np.sum(self.split_sizes)*self.input_dim\n",
    "        split_indices = split_indices.astype(int)\n",
    "        split_indices[0] += self.input_dim-split_indices.sum()\n",
    "        print(split_indices, split_indices.sum())\n",
    "        \n",
    "        index = np.split(indices, np.cumsum(split_indices[:-1]))\n",
    "#         for idx in index:\n",
    "#             print(len(idx))\n",
    "            \n",
    "        ## for extra input dimensions, sample randomly from remaining node indices.\n",
    "        for i in range(len(index)):\n",
    "            idx = index[i]\n",
    "            mask = np.ones(self.input_dim, dtype=bool)\n",
    "            mask[idx] = False\n",
    "            remaining = np.arange(0, self.input_dim, 1, dtype=int)[mask]\n",
    "            num_remain = self.split_sizes[i] - len(idx)\n",
    "            new_idx = remaining[np.random.permutation(len(remaining))[:num_remain]]\n",
    "            new_idx = np.array(new_idx)\n",
    "            \n",
    "            all_inx = np.concatenate((idx, new_idx))\n",
    "            index[i] = torch.LongTensor(all_inx)\n",
    "            \n",
    "        for idx in index:\n",
    "            print(len(idx))\n",
    "            \n",
    "        self.split_indices = index\n",
    "        pass\n",
    "\n",
    "    def set_input(self, x):\n",
    "        '''\n",
    "        x is assumed to be 2D; --> BatchSize, Dimension\n",
    "        '''\n",
    "        sz = x.shape\n",
    "        x = x.reshape(sz[0], -1)\n",
    "        self.inputs = [None for _ in range(len(self.split_indices))]\n",
    "        for i, si in enumerate(self.split_indices):\n",
    "            self.inputs[i] = x[:, si.to(x.device)]\n",
    "        return self.inputs\n",
    "    \n",
    "    def forward_local(self, x):\n",
    "        return self.set_input(x)\n",
    "    \n",
    "    def backward_local(self, ):\n",
    "        pass\n",
    "    \n",
    "    def update_local(self, ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262 261 261] 784\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "df = DataFeeder(784, [300, 300, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDimMixerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ## defining model hardcoded\n",
    "        self.m0 = DataFeeder(784, split_sizes=[300, 300, 300])\n",
    "        \n",
    "        self.m1 = MlpBLock([300, 600, 300])\n",
    "        self.m2 = MlpBLock([300, 500, 250])\n",
    "        self.m3 = MlpBLock([300, 500, 200])\n",
    "        \n",
    "        self.m4 = MlpBLock([150, 300, 100])\n",
    "        self.m5 = MlpBLock([250, 400, 100])\n",
    "        self.m6 = MlpBLock([350, 500, 200])\n",
    "        self.m7 = MlpBLock([300, 500, 200])\n",
    "        self.m8 = MlpBLock([100, 150, 50])\n",
    "        self.m9 = MlpBLock([200, 300, 100])\n",
    "        self.m10 = MlpBLock([150, 200, 10])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1, x2, x3 = self.m0.forward_local(x)\n",
    "        x1 = self.m1(x1).split([150, 150], dim=1)\n",
    "        x2 = self.m2(x2).split([100, 150], dim=1)\n",
    "        x3 = self.m3(x3)\n",
    "        \n",
    "        x4 = x1[0]\n",
    "        x5 = torch.cat([x1[1], x2[0]], dim=1)\n",
    "        x6 = torch.cat([x2[1], x3], dim=1)\n",
    "        x4 = self.m4(x4)\n",
    "        x5 = self.m5(x5)\n",
    "        x6 = self.m6(x6).split([100, 100], dim=1)\n",
    "        \n",
    "        x7 = torch.cat([x4, x5, x6[0]], dim=1)\n",
    "        x7 = self.m7(x7).split([100, 100], dim=1)\n",
    "#         print(x7[0].shape, x7[1].shape)\n",
    "        x8 = x7[0]\n",
    "        x8 = self.m8(x8)\n",
    "        x9 = torch.cat([x6[1], x7[1]], dim=1)\n",
    "        x9 = self.m9(x9)\n",
    "        \n",
    "        x10 = torch.cat([x9, x8], dim=1)\n",
    "        x10 = self.m10(x10)\n",
    "        return x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GraphDimMixerModel().to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dist_GraphDimMixerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ## defining model hardcoded\n",
    "        self.m0 = DataFeeder(784, split_sizes=[300, 300, 300])\n",
    "        \n",
    "        self.m1 = LocalModel(MlpBLock([300, 600, 300]))\n",
    "        self.m1.set_split_mixing_indices([150, 150])\n",
    "        self.m2 = LocalModel(MlpBLock([300, 500, 250]))\n",
    "        self.m2.set_split_mixing_indices([100, 150])\n",
    "        self.m3 = LocalModel(MlpBLock([300, 500, 200]))\n",
    "        self.m3.set_split_mixing_indices(None)\n",
    "        \n",
    "        self.m4 = LocalModel(MlpBLock([150, 300, 100]))\n",
    "        self.m4.set_split_mixing_indices(None)\n",
    "        self.m5 = LocalModel(MlpBLock([250, 400, 100]))\n",
    "        self.m5.set_split_mixing_indices(None)\n",
    "        self.m6 = LocalModel(MlpBLock([350, 500, 200]))\n",
    "        self.m6.set_split_mixing_indices([100, 100])\n",
    "        self.m7 = LocalModel(MlpBLock([300, 500, 200]))\n",
    "        self.m7.set_split_mixing_indices([100, 100])\n",
    "        self.m8 = LocalModel(MlpBLock([100, 150, 50]))\n",
    "        self.m8.set_split_mixing_indices(None)\n",
    "        self.m9 = LocalModel(MlpBLock([200, 300, 100]))\n",
    "        self.m9.set_split_mixing_indices(None)\n",
    "        self.m10 = LocalModel(MlpBLock([150, 200, 10]))\n",
    "        self.m10.set_split_mixing_indices(None)\n",
    "        \n",
    "        self.model_list = [self.m1, self.m2, self.m3, self.m4, self.m5, \n",
    "                           self.m6, self.m7, self.m8, self.m9, self.m10]\n",
    "        \n",
    "    def set_optimizer_with_device(self, device):\n",
    "        for m in self.model_list:\n",
    "            m.model.to(device)\n",
    "            m.optimizer = torch.optim.Adam(m.model.parameters(), lr=m.lr)\n",
    "        pass\n",
    "        \n",
    "    def forward_local(self, x):\n",
    "        x1, x2, x3 = self.m0.forward_local(x)\n",
    "        x1 = self.m1.forward_local([x1])\n",
    "        x2 = self.m2.forward_local([x2])\n",
    "        x3 = self.m3.forward_local([x3])\n",
    "        \n",
    "        x4 = self.m4.forward_local([x1[0]])\n",
    "        x5 = self.m5.forward_local([x1[1], x2[0]])\n",
    "        \n",
    "        x6 = self.m6.forward_local([x2[1], x3[0]])\n",
    "        \n",
    "        x7 = self.m7.forward_local([x4[0], x5[0], x6[0]])\n",
    "        x8 = self.m8.forward_local([x7[0]])\n",
    "        x9 = self.m9.forward_local([x6[1], x7[1]])\n",
    "        \n",
    "        x10 = self.m10.forward_local([x8[0], x9[0]])\n",
    "        return x10[0]\n",
    "    \n",
    "    def backward_local(self, dy):\n",
    "        d10 = self.m10.backward_local([dy])\n",
    "        d9 = self.m9.backward_local([d10[1]])\n",
    "        d8 = self.m8.backward_local([d10[0]])\n",
    "        d7 = self.m7.backward_local([d8[0], d9[1]])\n",
    "        d6 = self.m6.backward_local([d7[2], d9[0]])\n",
    "        d5 = self.m5.backward_local([d7[1]])\n",
    "        d4 = self.m4.backward_local([d7[0]])\n",
    "        d3 = self.m3.backward_local([d6[1]])\n",
    "        d2 = self.m2.backward_local([d5[1], d6[0]])\n",
    "        d1 = self.m1.backward_local([d4[0], d5[0]])\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262 261 261] 784\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "d_dimixer = Dist_GraphDimMixerModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dist_GraphDimMixerModel()"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dimixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dimixer.set_optimizer_with_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0391,  0.0171,  0.0232,  0.0225, -0.0222, -0.0610,  0.0358, -0.0476,\n",
       "          0.0554,  0.0098],\n",
       "        [-0.0387,  0.0168,  0.0243,  0.0222, -0.0224, -0.0612,  0.0364, -0.0478,\n",
       "          0.0558,  0.0103],\n",
       "        [-0.0396,  0.0172,  0.0234,  0.0218, -0.0220, -0.0629,  0.0354, -0.0478,\n",
       "          0.0561,  0.0103]], device='cuda:0')"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dimixer.forward_local(torch.randn(3, 784).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dimixer.backward_local(torch.randn(3, 10).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdfsdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262 261 261] 784\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphDimMixerModel(\n",
       "  (m1): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=300, out_features=600, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Linear(in_features=600, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (m2): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=300, out_features=500, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Linear(in_features=500, out_features=250, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (m3): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=300, out_features=500, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Linear(in_features=500, out_features=200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (m4): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=150, out_features=300, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Linear(in_features=300, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (m5): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=250, out_features=400, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Linear(in_features=400, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (m6): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=350, out_features=500, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Linear(in_features=500, out_features=200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (m7): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=300, out_features=500, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Linear(in_features=500, out_features=200, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (m8): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=150, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Linear(in_features=150, out_features=50, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (m9): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=200, out_features=300, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Linear(in_features=300, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (m10): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=150, out_features=200, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Linear(in_features=200, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GraphDimMixerModel().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  1774960\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'dim_mixer_fmist_s{SEED}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT ={'train_stat':[], 'test_stat':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    STAT['train_stat'].append((epoch, train_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    STAT['test_stat'].append((epoch, test_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc\n",
    "        \n",
    "    with open(f\"./output/{model_name}_data.json\", 'w') as f:\n",
    "        json.dump(STAT, f, indent=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('./models'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    \n",
    "    STAT = checkpoint['stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:41<00:00, 44.76it/s]\n",
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 0 Loss: 0.592 | Acc: 78.463 47078/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 190.72it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 0.535 | Acc: 81.490 8149/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 405/1875 [00:09<00:34, 42.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-252-43766c9b5561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m## for 200 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-249-1e1ded5d1774>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Train the whole damn thing\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+EPOCHS): ## for 200 epochs\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/dim_mixer_fmist_s147.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-260-d596f0199684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./models/{model_name}.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/dim_mixer_fmist_s147.pth'"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "best_acc = checkpoint['acc']\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "best_acc, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stat = np.array(STAT['train_stat'])\n",
    "test_stat = np.array(STAT['test_stat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_stat[:,1], label='train')\n",
    "plt.plot(test_stat[:,1], label='test')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"./output/plots/{model_name}_loss.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_stat[:,2], label='train')\n",
    "plt.plot(test_stat[:,2], label='test')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"./output/plots/{model_name}_accs.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed local model training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262 261 261] 784\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "model = Dist_GraphDimMixerModel()\n",
    "model.set_optimizer_with_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'distrib_dim_mixer_fmist_s{SEED}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT ={'train_stat':[], 'test_stat':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward_local(inputs)\n",
    "        out = torch.autograd.Variable(outputs, requires_grad=True)\n",
    "        loss = criterion(out, targets)\n",
    "        loss.backward()\n",
    "            \n",
    "        model.backward_local(out.grad)\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    STAT['train_stat'].append((epoch, train_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model.forward_local(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    STAT['test_stat'].append((epoch, test_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "#         state = {\n",
    "#             'model': model.state_dict(),\n",
    "#             'acc': acc,\n",
    "#             'epoch': epoch\n",
    "#         }\n",
    "#         if not os.path.isdir('models'):\n",
    "#             os.mkdir('models')\n",
    "#         torch.save(state, f'./models/{model_name}.pth')\n",
    "#         best_acc = acc\n",
    "        \n",
    "    with open(f\"./output/{model_name}_data.json\", 'w') as f:\n",
    "        json.dump(STAT, f, indent=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('./models'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    \n",
    "    STAT = checkpoint['stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 32/1875 [01:09<1:06:16,  2.16s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-303-43766c9b5561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m## for 200 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-300-c2fb90f463f2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-288-5e417b3e3901>\u001b[0m in \u001b[0;36mbackward_local\u001b[0;34m(self, dy)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0md9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md10\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0md8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md10\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0md7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md8\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md9\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0md6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md9\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0md5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-274-573ba45d7db3>\u001b[0m in \u001b[0;36mbackward_local\u001b[0;34m(self, dys)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Train the whole damn thing\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+EPOCHS): ## for 200 epochs\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
