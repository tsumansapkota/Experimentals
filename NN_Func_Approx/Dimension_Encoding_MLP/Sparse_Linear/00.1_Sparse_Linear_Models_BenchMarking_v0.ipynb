{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4619b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708c3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random, sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de471a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparse_linear_lib as sll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3db567",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26f0e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db9beaf",
   "metadata": {},
   "source": [
    "## Pair Linear approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8370636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ns = [16, 64, 256, 1024, 4096] #, 16384]\n",
    "Ns = [256, 1024, 4096] #, 16384]\n",
    "seeds = [147, 258, 369, 321, 654, 987, 741, 852, 963, 159, 357, 951, 753]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce0f0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ns = [16384]\n",
    "# seeds = [147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39d77bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5ec7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_STEPS = 20000 #2000\n",
    "def train_model(model, optimizer, X, A):\n",
    "    for i in range(TRAIN_STEPS):\n",
    "        out = model(X)\n",
    "        loss = mse(out, A)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%1000 == 0:\n",
    "            print(f\"The MSE loss is : {float(mse(out,A))}\")\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        out = model(X)\n",
    "        tt = time.time()-start\n",
    "    return out, tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b51228a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svd_output(A, n_comp):\n",
    "    U, S, V = torch.svd(A)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _U = U[:, :n_comp]\n",
    "        _S = S[:n_comp]\n",
    "        _V = V[:, :n_comp]\n",
    "        \n",
    "        start = time.time()\n",
    "        out = torch.mm(torch.mm(_U, torch.diag(_S)), _V.t())\n",
    "        tt = time.time()-start\n",
    "    \n",
    "#     S[n_comp:] *= 0\n",
    "#     out = torch.mm(torch.mm(U, torch.diag(S)), V.t())\n",
    "    return out, tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "974d7b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_stats(df, out, A, method, seed, nparam, tim, filename):\n",
    "    diff = (out.data-A).abs()\n",
    "    \n",
    "    mean, std = float(diff.mean()), float(diff.std())\n",
    "    err = float(mse(out, A))\n",
    "\n",
    "    df = df.append({\"method\":method, \"seed\":seed, \"mse\":err,\n",
    "                    \"mean\":mean, \"std\":std, \"params\":nparam, \"time\":tim}, \n",
    "                   ignore_index=True)\n",
    "    df_ = df.copy()\n",
    "    df.to_csv(f\"./outputs/{file_name}.csv\")\n",
    "    \n",
    "    print(f\"Saving... file:{file_name} method:{method}\")\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf345bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir outputs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ca4ce3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [mse, mean, std]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['mse', 'mean', 'std'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "816844b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add_PairLinears(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_adds):\n",
    "        super().__init__()\n",
    "        self.pair_mixers = []\n",
    "        self.perm_indices = []\n",
    "        for i in range(num_adds):\n",
    "            m = sll.PairLinear_MixerBlock(input_dim, input_dim)\n",
    "            self.pair_mixers.append(m)\n",
    "            if i > 0:\n",
    "                rm = torch.randperm(input_dim)\n",
    "                self.perm_indices.append(rm)\n",
    "                \n",
    "        self.pair_mixers = nn.ModuleList(self.pair_mixers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = torch.zeros_like(x)\n",
    "        for i, m in enumerate(self.pair_mixers):\n",
    "            if i > 0:\n",
    "                _x = x[:, self.perm_indices[i-1]]\n",
    "            else:\n",
    "                _x = x\n",
    "                \n",
    "            y += m(_x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dc620d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Add_PairLinears(N, 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3454c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stack_PairLinears(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_adds):\n",
    "        super().__init__()\n",
    "        self.pair_mixers = []\n",
    "        self.perm_indices = []\n",
    "        for i in range(num_adds):\n",
    "            m = sll.PairLinear_MixerBlock(input_dim, input_dim)\n",
    "            self.pair_mixers.append(m)\n",
    "            if i > 0:\n",
    "                rm = torch.randperm(input_dim)\n",
    "                self.perm_indices.append(rm)\n",
    "                \n",
    "        self.pair_mixers = nn.ModuleList(self.pair_mixers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, m in enumerate(self.pair_mixers):\n",
    "            if i == 0:\n",
    "                x = m(x)\n",
    "            else:\n",
    "                x = m(x[:, self.perm_indices[i-1]])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da14d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_base(a, base):\n",
    "    return np.log(a) / np.log(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "499149b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.append({\"mse\":1.0, \"mean\":2.0, \"std\":4.0}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2d53de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\\n  df = df.append({\"method\":method, \"seed\":seed, \"mse\":err,\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(action='once') \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "'''\n",
    "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
    "  df = df.append({\"method\":method, \"seed\":seed, \"mse\":err,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36e9df26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment N=256 SEED=147\n",
      "The MSE loss is : 0.33718395233154297\n",
      "The MSE loss is : 0.30751633644104004\n",
      "The MSE loss is : 0.3056437373161316\n",
      "The MSE loss is : 0.30491209030151367\n",
      "The MSE loss is : 0.3048853278160095\n",
      "The MSE loss is : 0.30488526821136475\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.30487051606178284\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.30487051606178284\n",
      "The MSE loss is : 0.30487051606178284\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.30487051606178284\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.3048705458641052\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33718395233154297\n",
      "The MSE loss is : 0.2798923850059509\n",
      "The MSE loss is : 0.2789155840873718\n",
      "The MSE loss is : 0.2787536680698395\n",
      "The MSE loss is : 0.278751015663147\n",
      "The MSE loss is : 0.2787509858608246\n",
      "The MSE loss is : 0.278751015663147\n",
      "The MSE loss is : 0.2787509858608246\n",
      "The MSE loss is : 0.278751015663147\n",
      "The MSE loss is : 0.27874624729156494\n",
      "The MSE loss is : 0.27874624729156494\n",
      "The MSE loss is : 0.27874624729156494\n",
      "The MSE loss is : 0.27874627709388733\n",
      "The MSE loss is : 0.27874624729156494\n",
      "The MSE loss is : 0.27874624729156494\n",
      "The MSE loss is : 0.27874624729156494\n",
      "The MSE loss is : 0.27874624729156494\n",
      "The MSE loss is : 0.27874624729156494\n",
      "The MSE loss is : 0.27874624729156494\n",
      "The MSE loss is : 0.27874624729156494\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33718395233154297\n",
      "The MSE loss is : 0.2658323645591736\n",
      "The MSE loss is : 0.2656536400318146\n",
      "The MSE loss is : 0.2656514644622803\n",
      "The MSE loss is : 0.2656514048576355\n",
      "The MSE loss is : 0.26565128564834595\n",
      "The MSE loss is : 0.2656509280204773\n",
      "The MSE loss is : 0.26565074920654297\n",
      "The MSE loss is : 0.26565074920654297\n",
      "The MSE loss is : 0.2656507194042206\n",
      "The MSE loss is : 0.2656507194042206\n",
      "The MSE loss is : 0.2656507194042206\n",
      "The MSE loss is : 0.26565074920654297\n",
      "The MSE loss is : 0.2656507194042206\n",
      "The MSE loss is : 0.2656507194042206\n",
      "The MSE loss is : 0.26565074920654297\n",
      "The MSE loss is : 0.2656507194042206\n",
      "The MSE loss is : 0.2656507194042206\n",
      "The MSE loss is : 0.2656507194042206\n",
      "The MSE loss is : 0.26565074920654297\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3663501739501953\n",
      "The MSE loss is : 0.15365439653396606\n",
      "The MSE loss is : 0.14430047571659088\n",
      "The MSE loss is : 0.14156019687652588\n",
      "The MSE loss is : 0.1403941512107849\n",
      "The MSE loss is : 0.139498770236969\n",
      "The MSE loss is : 0.13871029019355774\n",
      "The MSE loss is : 0.13802112638950348\n",
      "The MSE loss is : 0.13744062185287476\n",
      "The MSE loss is : 0.13735520839691162\n",
      "The MSE loss is : 0.13734877109527588\n",
      "The MSE loss is : 0.13734368979930878\n",
      "The MSE loss is : 0.1373402178287506\n",
      "The MSE loss is : 0.13732343912124634\n",
      "The MSE loss is : 0.13725319504737854\n",
      "The MSE loss is : 0.13724908232688904\n",
      "The MSE loss is : 0.1372503936290741\n",
      "The MSE loss is : 0.13724930584430695\n",
      "The MSE loss is : 0.13724812865257263\n",
      "The MSE loss is : 0.137248694896698\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3376785218715668\n",
      "The MSE loss is : 0.1497061401605606\n",
      "The MSE loss is : 0.14562933146953583\n",
      "The MSE loss is : 0.14402420818805695\n",
      "The MSE loss is : 0.14344534277915955\n",
      "The MSE loss is : 0.1426708996295929\n",
      "The MSE loss is : 0.1421707570552826\n",
      "The MSE loss is : 0.1417711079120636\n",
      "The MSE loss is : 0.14146360754966736\n",
      "The MSE loss is : 0.14120428264141083\n",
      "The MSE loss is : 0.14099276065826416\n",
      "The MSE loss is : 0.14085698127746582\n",
      "The MSE loss is : 0.14063599705696106\n",
      "The MSE loss is : 0.14050546288490295\n",
      "The MSE loss is : 0.14045356214046478\n",
      "The MSE loss is : 0.1405227780342102\n",
      "The MSE loss is : 0.14029887318611145\n",
      "The MSE loss is : 0.1401970088481903\n",
      "The MSE loss is : 0.14017286896705627\n",
      "The MSE loss is : 0.14008744060993195\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=258\n",
      "The MSE loss is : 0.3378857970237732\n",
      "The MSE loss is : 0.30672529339790344\n",
      "The MSE loss is : 0.3056827783584595\n",
      "The MSE loss is : 0.3052784204483032\n",
      "The MSE loss is : 0.30512136220932007\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459325313568\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459623336792\n",
      "The MSE loss is : 0.3050459027290344\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.3378857970237732\n",
      "The MSE loss is : 0.27995729446411133\n",
      "The MSE loss is : 0.2791920304298401\n",
      "The MSE loss is : 0.2791760563850403\n",
      "The MSE loss is : 0.27905505895614624\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "The MSE loss is : 0.27904099225997925\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.3378857970237732\n",
      "The MSE loss is : 0.26581329107284546\n",
      "The MSE loss is : 0.26555442810058594\n",
      "The MSE loss is : 0.26554274559020996\n",
      "The MSE loss is : 0.2655427157878876\n",
      "The MSE loss is : 0.2655427157878876\n",
      "The MSE loss is : 0.2655427157878876\n",
      "The MSE loss is : 0.2655427157878876\n",
      "The MSE loss is : 0.2655427157878876\n",
      "The MSE loss is : 0.2655427157878876\n",
      "The MSE loss is : 0.2655427157878876\n",
      "The MSE loss is : 0.26554274559020996\n",
      "The MSE loss is : 0.2655427157878876\n",
      "The MSE loss is : 0.2655427157878876\n",
      "The MSE loss is : 0.2655427157878876\n",
      "The MSE loss is : 0.2655427157878876\n",
      "The MSE loss is : 0.2655427157878876\n",
      "The MSE loss is : 0.26554274559020996\n",
      "The MSE loss is : 0.26554274559020996\n",
      "The MSE loss is : 0.26554274559020996\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.36560893058776855\n",
      "The MSE loss is : 0.15356548130512238\n",
      "The MSE loss is : 0.1440727263689041\n",
      "The MSE loss is : 0.14024361968040466\n",
      "The MSE loss is : 0.1387849897146225\n",
      "The MSE loss is : 0.13810569047927856\n",
      "The MSE loss is : 0.13773900270462036\n",
      "The MSE loss is : 0.13757175207138062\n",
      "The MSE loss is : 0.13713978230953217\n",
      "The MSE loss is : 0.13653530180454254\n",
      "The MSE loss is : 0.1361689567565918\n",
      "The MSE loss is : 0.13609252870082855\n",
      "The MSE loss is : 0.1360921859741211\n",
      "The MSE loss is : 0.136092871427536\n",
      "The MSE loss is : 0.13609173893928528\n",
      "The MSE loss is : 0.1360917091369629\n",
      "The MSE loss is : 0.13609279692173004\n",
      "The MSE loss is : 0.1360917091369629\n",
      "The MSE loss is : 0.1360917091369629\n",
      "The MSE loss is : 0.13609160482883453\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.33819329738616943\n",
      "The MSE loss is : 0.15026794373989105\n",
      "The MSE loss is : 0.1466960906982422\n",
      "The MSE loss is : 0.14518249034881592\n",
      "The MSE loss is : 0.1441882848739624\n",
      "The MSE loss is : 0.1435961127281189\n",
      "The MSE loss is : 0.14328433573246002\n",
      "The MSE loss is : 0.14298737049102783\n",
      "The MSE loss is : 0.1427949070930481\n",
      "The MSE loss is : 0.14250674843788147\n",
      "The MSE loss is : 0.14251860976219177\n",
      "The MSE loss is : 0.14233535528182983\n",
      "The MSE loss is : 0.1421118974685669\n",
      "The MSE loss is : 0.1418328732252121\n",
      "The MSE loss is : 0.14164456725120544\n",
      "The MSE loss is : 0.14167127013206482\n",
      "The MSE loss is : 0.1415042281150818\n",
      "The MSE loss is : 0.14130881428718567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.14135268330574036\n",
      "The MSE loss is : 0.14112523198127747\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=369\n",
      "The MSE loss is : 0.33567240834236145\n",
      "The MSE loss is : 0.30574673414230347\n",
      "The MSE loss is : 0.30459409952163696\n",
      "The MSE loss is : 0.30430498719215393\n",
      "The MSE loss is : 0.30381685495376587\n",
      "The MSE loss is : 0.30363529920578003\n",
      "The MSE loss is : 0.30363520979881287\n",
      "The MSE loss is : 0.30363520979881287\n",
      "The MSE loss is : 0.3036351799964905\n",
      "The MSE loss is : 0.30363523960113525\n",
      "The MSE loss is : 0.30363520979881287\n",
      "The MSE loss is : 0.30363523960113525\n",
      "The MSE loss is : 0.30363520979881287\n",
      "The MSE loss is : 0.30363523960113525\n",
      "The MSE loss is : 0.30363523960113525\n",
      "The MSE loss is : 0.30363523960113525\n",
      "The MSE loss is : 0.30363523960113525\n",
      "The MSE loss is : 0.3036351799964905\n",
      "The MSE loss is : 0.3036351799964905\n",
      "The MSE loss is : 0.30363523960113525\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33567240834236145\n",
      "The MSE loss is : 0.27872955799102783\n",
      "The MSE loss is : 0.27776211500167847\n",
      "The MSE loss is : 0.2776011824607849\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.2776009142398834\n",
      "The MSE loss is : 0.27760088443756104\n",
      "The MSE loss is : 0.27760088443756104\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33567240834236145\n",
      "The MSE loss is : 0.2645110785961151\n",
      "The MSE loss is : 0.2642451524734497\n",
      "The MSE loss is : 0.2642410397529602\n",
      "The MSE loss is : 0.2642406225204468\n",
      "The MSE loss is : 0.2642406225204468\n",
      "The MSE loss is : 0.2642405927181244\n",
      "The MSE loss is : 0.2642405927181244\n",
      "The MSE loss is : 0.2642405927181244\n",
      "The MSE loss is : 0.2642405927181244\n",
      "The MSE loss is : 0.2642406225204468\n",
      "The MSE loss is : 0.2642406225204468\n",
      "The MSE loss is : 0.2642406225204468\n",
      "The MSE loss is : 0.2642405927181244\n",
      "The MSE loss is : 0.2642406225204468\n",
      "The MSE loss is : 0.2642406225204468\n",
      "The MSE loss is : 0.2642406225204468\n",
      "The MSE loss is : 0.2642406225204468\n",
      "The MSE loss is : 0.2642405927181244\n",
      "The MSE loss is : 0.2642406225204468\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.36423587799072266\n",
      "The MSE loss is : 0.15325616300106049\n",
      "The MSE loss is : 0.1429721713066101\n",
      "The MSE loss is : 0.14066776633262634\n",
      "The MSE loss is : 0.13929486274719238\n",
      "The MSE loss is : 0.13826021552085876\n",
      "The MSE loss is : 0.13740287721157074\n",
      "The MSE loss is : 0.1368948221206665\n",
      "The MSE loss is : 0.13659454882144928\n",
      "The MSE loss is : 0.13658158481121063\n",
      "The MSE loss is : 0.1365075558423996\n",
      "The MSE loss is : 0.13645866513252258\n",
      "The MSE loss is : 0.13645637035369873\n",
      "The MSE loss is : 0.13645735383033752\n",
      "The MSE loss is : 0.136456698179245\n",
      "The MSE loss is : 0.13645505905151367\n",
      "The MSE loss is : 0.13645514845848083\n",
      "The MSE loss is : 0.136454775929451\n",
      "The MSE loss is : 0.13645505905151367\n",
      "The MSE loss is : 0.1364544928073883\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.33589643239974976\n",
      "The MSE loss is : 0.1494888812303543\n",
      "The MSE loss is : 0.14623211324214935\n",
      "The MSE loss is : 0.1446966528892517\n",
      "The MSE loss is : 0.14381307363510132\n",
      "The MSE loss is : 0.1432880163192749\n",
      "The MSE loss is : 0.1428097039461136\n",
      "The MSE loss is : 0.1425093561410904\n",
      "The MSE loss is : 0.14225398004055023\n",
      "The MSE loss is : 0.14198797941207886\n",
      "The MSE loss is : 0.14177227020263672\n",
      "The MSE loss is : 0.14160265028476715\n",
      "The MSE loss is : 0.14146552979946136\n",
      "The MSE loss is : 0.14133581519126892\n",
      "The MSE loss is : 0.14123129844665527\n",
      "The MSE loss is : 0.14111393690109253\n",
      "The MSE loss is : 0.14100904762744904\n",
      "The MSE loss is : 0.1409195065498352\n",
      "The MSE loss is : 0.1409081071615219\n",
      "The MSE loss is : 0.14100494980812073\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=321\n",
      "The MSE loss is : 0.3375713527202606\n",
      "The MSE loss is : 0.3078843355178833\n",
      "The MSE loss is : 0.3065446615219116\n",
      "The MSE loss is : 0.3059421479701996\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574461817741394\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574461817741394\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574461817741394\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574464797973633\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.3375713527202606\n",
      "The MSE loss is : 0.2808173894882202\n",
      "The MSE loss is : 0.2800125479698181\n",
      "The MSE loss is : 0.27970194816589355\n",
      "The MSE loss is : 0.2796558141708374\n",
      "The MSE loss is : 0.27965545654296875\n",
      "The MSE loss is : 0.27963194251060486\n",
      "The MSE loss is : 0.27963194251060486\n",
      "The MSE loss is : 0.27963197231292725\n",
      "The MSE loss is : 0.27963194251060486\n",
      "The MSE loss is : 0.27963194251060486\n",
      "The MSE loss is : 0.27963194251060486\n",
      "The MSE loss is : 0.27963197231292725\n",
      "The MSE loss is : 0.27963191270828247\n",
      "The MSE loss is : 0.27963194251060486\n",
      "The MSE loss is : 0.27963194251060486\n",
      "The MSE loss is : 0.27963194251060486\n",
      "The MSE loss is : 0.27963194251060486\n",
      "The MSE loss is : 0.27963197231292725\n",
      "The MSE loss is : 0.27963191270828247\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.3375713527202606\n",
      "The MSE loss is : 0.2654116749763489\n",
      "The MSE loss is : 0.265239417552948\n",
      "The MSE loss is : 0.265217661857605\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "The MSE loss is : 0.2652174234390259\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3654269576072693\n",
      "The MSE loss is : 0.15317167341709137\n",
      "The MSE loss is : 0.1429278552532196\n",
      "The MSE loss is : 0.13992682099342346\n",
      "The MSE loss is : 0.13850489258766174\n",
      "The MSE loss is : 0.13762840628623962\n",
      "The MSE loss is : 0.13730940222740173\n",
      "The MSE loss is : 0.13689284026622772\n",
      "The MSE loss is : 0.13680419325828552\n",
      "The MSE loss is : 0.13679513335227966\n",
      "The MSE loss is : 0.13679146766662598\n",
      "The MSE loss is : 0.13678482174873352\n",
      "The MSE loss is : 0.13653972744941711\n",
      "The MSE loss is : 0.1363907903432846\n",
      "The MSE loss is : 0.13637816905975342\n",
      "The MSE loss is : 0.13636678457260132\n",
      "The MSE loss is : 0.13634678721427917\n",
      "The MSE loss is : 0.13633938133716583\n",
      "The MSE loss is : 0.13633999228477478\n",
      "The MSE loss is : 0.1363377571105957\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.33846840262413025\n",
      "The MSE loss is : 0.15200820565223694\n",
      "The MSE loss is : 0.14827017486095428\n",
      "The MSE loss is : 0.14666986465454102\n",
      "The MSE loss is : 0.14576295018196106\n",
      "The MSE loss is : 0.1453905999660492\n",
      "The MSE loss is : 0.1445774883031845\n",
      "The MSE loss is : 0.14414355158805847\n",
      "The MSE loss is : 0.14386090636253357\n",
      "The MSE loss is : 0.14377564191818237\n",
      "The MSE loss is : 0.14354676008224487\n",
      "The MSE loss is : 0.14354214072227478\n",
      "The MSE loss is : 0.1435222625732422\n",
      "The MSE loss is : 0.143240824341774\n",
      "The MSE loss is : 0.14325180649757385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.14337050914764404\n",
      "The MSE loss is : 0.1430325210094452\n",
      "The MSE loss is : 0.1429394781589508\n",
      "The MSE loss is : 0.1429389864206314\n",
      "The MSE loss is : 0.14294520020484924\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=654\n",
      "The MSE loss is : 0.3369494080543518\n",
      "The MSE loss is : 0.30652084946632385\n",
      "The MSE loss is : 0.3048412799835205\n",
      "The MSE loss is : 0.3045271933078766\n",
      "The MSE loss is : 0.30430877208709717\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087124824524\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087124824524\n",
      "The MSE loss is : 0.30430880188941956\n",
      "The MSE loss is : 0.30430877208709717\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087124824524\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.30430877208709717\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.3369494080543518\n",
      "The MSE loss is : 0.2788752317428589\n",
      "The MSE loss is : 0.2779507339000702\n",
      "The MSE loss is : 0.27788102626800537\n",
      "The MSE loss is : 0.27787113189697266\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "The MSE loss is : 0.27787089347839355\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.3369494080543518\n",
      "The MSE loss is : 0.2648952603340149\n",
      "The MSE loss is : 0.2646118998527527\n",
      "The MSE loss is : 0.2645838260650635\n",
      "The MSE loss is : 0.2645835876464844\n",
      "The MSE loss is : 0.264583557844162\n",
      "The MSE loss is : 0.2645835876464844\n",
      "The MSE loss is : 0.2645835876464844\n",
      "The MSE loss is : 0.2645835876464844\n",
      "The MSE loss is : 0.2645835876464844\n",
      "The MSE loss is : 0.2645835876464844\n",
      "The MSE loss is : 0.2645835876464844\n",
      "The MSE loss is : 0.2645835876464844\n",
      "The MSE loss is : 0.264583557844162\n",
      "The MSE loss is : 0.2645835876464844\n",
      "The MSE loss is : 0.2645835876464844\n",
      "The MSE loss is : 0.2645835876464844\n",
      "The MSE loss is : 0.264583557844162\n",
      "The MSE loss is : 0.264583557844162\n",
      "The MSE loss is : 0.264583557844162\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3653230667114258\n",
      "The MSE loss is : 0.1527603566646576\n",
      "The MSE loss is : 0.14408165216445923\n",
      "The MSE loss is : 0.14142771065235138\n",
      "The MSE loss is : 0.13965588808059692\n",
      "The MSE loss is : 0.139169380068779\n",
      "The MSE loss is : 0.13845866918563843\n",
      "The MSE loss is : 0.13819459080696106\n",
      "The MSE loss is : 0.13771772384643555\n",
      "The MSE loss is : 0.13754869997501373\n",
      "The MSE loss is : 0.13754355907440186\n",
      "The MSE loss is : 0.13754048943519592\n",
      "The MSE loss is : 0.1375342309474945\n",
      "The MSE loss is : 0.13752515614032745\n",
      "The MSE loss is : 0.13746221363544464\n",
      "The MSE loss is : 0.13741916418075562\n",
      "The MSE loss is : 0.13722389936447144\n",
      "The MSE loss is : 0.13714845478534698\n",
      "The MSE loss is : 0.13709132373332977\n",
      "The MSE loss is : 0.1370777189731598\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3369959592819214\n",
      "The MSE loss is : 0.1514083743095398\n",
      "The MSE loss is : 0.1479378342628479\n",
      "The MSE loss is : 0.14639373123645782\n",
      "The MSE loss is : 0.14550690352916718\n",
      "The MSE loss is : 0.14451180398464203\n",
      "The MSE loss is : 0.1444023996591568\n",
      "The MSE loss is : 0.14381864666938782\n",
      "The MSE loss is : 0.14352962374687195\n",
      "The MSE loss is : 0.1432914435863495\n",
      "The MSE loss is : 0.14327022433280945\n",
      "The MSE loss is : 0.1429046392440796\n",
      "The MSE loss is : 0.14273065328598022\n",
      "The MSE loss is : 0.14255720376968384\n",
      "The MSE loss is : 0.1424776166677475\n",
      "The MSE loss is : 0.1423678696155548\n",
      "The MSE loss is : 0.1422690749168396\n",
      "The MSE loss is : 0.1422182321548462\n",
      "The MSE loss is : 0.14218862354755402\n",
      "The MSE loss is : 0.14189964532852173\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=987\n",
      "The MSE loss is : 0.3369542360305786\n",
      "The MSE loss is : 0.3062925934791565\n",
      "The MSE loss is : 0.3047820031642914\n",
      "The MSE loss is : 0.30450740456581116\n",
      "The MSE loss is : 0.3043172359466553\n",
      "The MSE loss is : 0.30429577827453613\n",
      "The MSE loss is : 0.30429574847221375\n",
      "The MSE loss is : 0.30429577827453613\n",
      "The MSE loss is : 0.30429577827453613\n",
      "The MSE loss is : 0.30429577827453613\n",
      "The MSE loss is : 0.30429577827453613\n",
      "The MSE loss is : 0.30429574847221375\n",
      "The MSE loss is : 0.30429574847221375\n",
      "The MSE loss is : 0.3042958676815033\n",
      "The MSE loss is : 0.3042958378791809\n",
      "The MSE loss is : 0.30429574847221375\n",
      "The MSE loss is : 0.30429577827453613\n",
      "The MSE loss is : 0.30429574847221375\n",
      "The MSE loss is : 0.30429574847221375\n",
      "The MSE loss is : 0.30429577827453613\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.3369542360305786\n",
      "The MSE loss is : 0.2790631055831909\n",
      "The MSE loss is : 0.27824223041534424\n",
      "The MSE loss is : 0.2781705856323242\n",
      "The MSE loss is : 0.27815887331962585\n",
      "The MSE loss is : 0.27815884351730347\n",
      "The MSE loss is : 0.27815884351730347\n",
      "The MSE loss is : 0.27815884351730347\n",
      "The MSE loss is : 0.27815887331962585\n",
      "The MSE loss is : 0.27815884351730347\n",
      "The MSE loss is : 0.27815887331962585\n",
      "The MSE loss is : 0.27815884351730347\n",
      "The MSE loss is : 0.27815887331962585\n",
      "The MSE loss is : 0.27815887331962585\n",
      "The MSE loss is : 0.27815887331962585\n",
      "The MSE loss is : 0.27815887331962585\n",
      "The MSE loss is : 0.27815887331962585\n",
      "The MSE loss is : 0.27815884351730347\n",
      "The MSE loss is : 0.27815887331962585\n",
      "The MSE loss is : 0.27815887331962585\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.3369542360305786\n",
      "The MSE loss is : 0.26518920063972473\n",
      "The MSE loss is : 0.2649664282798767\n",
      "The MSE loss is : 0.2649606168270111\n",
      "The MSE loss is : 0.2649586498737335\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "The MSE loss is : 0.26495862007141113\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3660483658313751\n",
      "The MSE loss is : 0.15283380448818207\n",
      "The MSE loss is : 0.14437726140022278\n",
      "The MSE loss is : 0.14162594079971313\n",
      "The MSE loss is : 0.14032846689224243\n",
      "The MSE loss is : 0.1385892927646637\n",
      "The MSE loss is : 0.13777893781661987\n",
      "The MSE loss is : 0.13732531666755676\n",
      "The MSE loss is : 0.13665035367012024\n",
      "The MSE loss is : 0.13657492399215698\n",
      "The MSE loss is : 0.13655149936676025\n",
      "The MSE loss is : 0.13652899861335754\n",
      "The MSE loss is : 0.13652890920639038\n",
      "The MSE loss is : 0.13652662932872772\n",
      "The MSE loss is : 0.1365261673927307\n",
      "The MSE loss is : 0.13652560114860535\n",
      "The MSE loss is : 0.13652655482292175\n",
      "The MSE loss is : 0.13652560114860535\n",
      "The MSE loss is : 0.13652575016021729\n",
      "The MSE loss is : 0.1365261822938919\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3367016911506653\n",
      "The MSE loss is : 0.14984706044197083\n",
      "The MSE loss is : 0.14588476717472076\n",
      "The MSE loss is : 0.14459902048110962\n",
      "The MSE loss is : 0.1438753604888916\n",
      "The MSE loss is : 0.14328256249427795\n",
      "The MSE loss is : 0.14298661053180695\n",
      "The MSE loss is : 0.14274470508098602\n",
      "The MSE loss is : 0.14239943027496338\n",
      "The MSE loss is : 0.1423318088054657\n",
      "The MSE loss is : 0.14218708872795105\n",
      "The MSE loss is : 0.14196720719337463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.14169561862945557\n",
      "The MSE loss is : 0.14170658588409424\n",
      "The MSE loss is : 0.14143608510494232\n",
      "The MSE loss is : 0.14167745411396027\n",
      "The MSE loss is : 0.14127948880195618\n",
      "The MSE loss is : 0.14162319898605347\n",
      "The MSE loss is : 0.1413271129131317\n",
      "The MSE loss is : 0.14107997715473175\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=741\n",
      "The MSE loss is : 0.33608463406562805\n",
      "The MSE loss is : 0.30543357133865356\n",
      "The MSE loss is : 0.3041008710861206\n",
      "The MSE loss is : 0.3037857413291931\n",
      "The MSE loss is : 0.30368655920028687\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036806285381317\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036806285381317\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036806285381317\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33608463406562805\n",
      "The MSE loss is : 0.27751025557518005\n",
      "The MSE loss is : 0.27680230140686035\n",
      "The MSE loss is : 0.2766698896884918\n",
      "The MSE loss is : 0.27666980028152466\n",
      "The MSE loss is : 0.2766681909561157\n",
      "The MSE loss is : 0.27666786313056946\n",
      "The MSE loss is : 0.27666783332824707\n",
      "The MSE loss is : 0.27666786313056946\n",
      "The MSE loss is : 0.27666786313056946\n",
      "The MSE loss is : 0.27666789293289185\n",
      "The MSE loss is : 0.27666789293289185\n",
      "The MSE loss is : 0.27666786313056946\n",
      "The MSE loss is : 0.27666786313056946\n",
      "The MSE loss is : 0.27666786313056946\n",
      "The MSE loss is : 0.27666786313056946\n",
      "The MSE loss is : 0.27666783332824707\n",
      "The MSE loss is : 0.27666786313056946\n",
      "The MSE loss is : 0.27666786313056946\n",
      "The MSE loss is : 0.27666783332824707\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33608463406562805\n",
      "The MSE loss is : 0.2637634873390198\n",
      "The MSE loss is : 0.2635958194732666\n",
      "The MSE loss is : 0.26357924938201904\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "The MSE loss is : 0.2635769248008728\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.36241453886032104\n",
      "The MSE loss is : 0.1523858606815338\n",
      "The MSE loss is : 0.14423419535160065\n",
      "The MSE loss is : 0.14126557111740112\n",
      "The MSE loss is : 0.13951650261878967\n",
      "The MSE loss is : 0.1385451704263687\n",
      "The MSE loss is : 0.13811565935611725\n",
      "The MSE loss is : 0.13751381635665894\n",
      "The MSE loss is : 0.13711442053318024\n",
      "The MSE loss is : 0.13685506582260132\n",
      "The MSE loss is : 0.13675647974014282\n",
      "The MSE loss is : 0.13673821091651917\n",
      "The MSE loss is : 0.13673268258571625\n",
      "The MSE loss is : 0.1367330253124237\n",
      "The MSE loss is : 0.13673369586467743\n",
      "The MSE loss is : 0.13673126697540283\n",
      "The MSE loss is : 0.1367294043302536\n",
      "The MSE loss is : 0.1367291510105133\n",
      "The MSE loss is : 0.13672983646392822\n",
      "The MSE loss is : 0.1367305964231491\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3357473611831665\n",
      "The MSE loss is : 0.14947998523712158\n",
      "The MSE loss is : 0.14605404436588287\n",
      "The MSE loss is : 0.1446247696876526\n",
      "The MSE loss is : 0.14372605085372925\n",
      "The MSE loss is : 0.14303874969482422\n",
      "The MSE loss is : 0.14257565140724182\n",
      "The MSE loss is : 0.14215686917304993\n",
      "The MSE loss is : 0.14174802601337433\n",
      "The MSE loss is : 0.1415216475725174\n",
      "The MSE loss is : 0.14146773517131805\n",
      "The MSE loss is : 0.14118504524230957\n",
      "The MSE loss is : 0.14107701182365417\n",
      "The MSE loss is : 0.14103075861930847\n",
      "The MSE loss is : 0.14106154441833496\n",
      "The MSE loss is : 0.1407681107521057\n",
      "The MSE loss is : 0.1406470686197281\n",
      "The MSE loss is : 0.1406508982181549\n",
      "The MSE loss is : 0.1403617560863495\n",
      "The MSE loss is : 0.14044560492038727\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=852\n",
      "The MSE loss is : 0.3376447558403015\n",
      "The MSE loss is : 0.3066113591194153\n",
      "The MSE loss is : 0.3049757480621338\n",
      "The MSE loss is : 0.3047933280467987\n",
      "The MSE loss is : 0.3047035336494446\n",
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.3046942353248596\n",
      "The MSE loss is : 0.30469420552253723\n",
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.3046942353248596\n",
      "The MSE loss is : 0.30469420552253723\n",
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.3046942353248596\n",
      "The MSE loss is : 0.30469420552253723\n",
      "The MSE loss is : 0.30469420552253723\n",
      "The MSE loss is : 0.30469417572021484\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.3376447558403015\n",
      "The MSE loss is : 0.2801912724971771\n",
      "The MSE loss is : 0.2794533669948578\n",
      "The MSE loss is : 0.2791789174079895\n",
      "The MSE loss is : 0.27915745973587036\n",
      "The MSE loss is : 0.27913665771484375\n",
      "The MSE loss is : 0.27913618087768555\n",
      "The MSE loss is : 0.27913621068000793\n",
      "The MSE loss is : 0.27913618087768555\n",
      "The MSE loss is : 0.27913618087768555\n",
      "The MSE loss is : 0.27913618087768555\n",
      "The MSE loss is : 0.27913621068000793\n",
      "The MSE loss is : 0.27913621068000793\n",
      "The MSE loss is : 0.27913618087768555\n",
      "The MSE loss is : 0.27913621068000793\n",
      "The MSE loss is : 0.27913618087768555\n",
      "The MSE loss is : 0.27913618087768555\n",
      "The MSE loss is : 0.27913618087768555\n",
      "The MSE loss is : 0.27913618087768555\n",
      "The MSE loss is : 0.27913618087768555\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.3376447558403015\n",
      "The MSE loss is : 0.2656146287918091\n",
      "The MSE loss is : 0.2653723359107971\n",
      "The MSE loss is : 0.26535722613334656\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "The MSE loss is : 0.26535695791244507\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.36543694138526917\n",
      "The MSE loss is : 0.15352016687393188\n",
      "The MSE loss is : 0.14397326111793518\n",
      "The MSE loss is : 0.14050132036209106\n",
      "The MSE loss is : 0.1390429139137268\n",
      "The MSE loss is : 0.13824211061000824\n",
      "The MSE loss is : 0.13773873448371887\n",
      "The MSE loss is : 0.1375032663345337\n",
      "The MSE loss is : 0.1372348815202713\n",
      "The MSE loss is : 0.13700544834136963\n",
      "The MSE loss is : 0.13688869774341583\n",
      "The MSE loss is : 0.13688713312149048\n",
      "The MSE loss is : 0.1368858814239502\n",
      "The MSE loss is : 0.13688558340072632\n",
      "The MSE loss is : 0.136886328458786\n",
      "The MSE loss is : 0.13688689470291138\n",
      "The MSE loss is : 0.1368866264820099\n",
      "The MSE loss is : 0.13688528537750244\n",
      "The MSE loss is : 0.13688567280769348\n",
      "The MSE loss is : 0.13688530027866364\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.33829689025878906\n",
      "The MSE loss is : 0.1505243480205536\n",
      "The MSE loss is : 0.1468338519334793\n",
      "The MSE loss is : 0.14567750692367554\n",
      "The MSE loss is : 0.14483395218849182\n",
      "The MSE loss is : 0.1442808210849762\n",
      "The MSE loss is : 0.143722265958786\n",
      "The MSE loss is : 0.1434665322303772\n",
      "The MSE loss is : 0.14326542615890503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.142990842461586\n",
      "The MSE loss is : 0.14292922616004944\n",
      "The MSE loss is : 0.14271283149719238\n",
      "The MSE loss is : 0.1425926834344864\n",
      "The MSE loss is : 0.14250722527503967\n",
      "The MSE loss is : 0.14250104129314423\n",
      "The MSE loss is : 0.1422724425792694\n",
      "The MSE loss is : 0.142215296626091\n",
      "The MSE loss is : 0.14239487051963806\n",
      "The MSE loss is : 0.1420397311449051\n",
      "The MSE loss is : 0.14202061295509338\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=963\n",
      "The MSE loss is : 0.33616235852241516\n",
      "The MSE loss is : 0.30603542923927307\n",
      "The MSE loss is : 0.3047929108142853\n",
      "The MSE loss is : 0.3044098913669586\n",
      "The MSE loss is : 0.3042568266391754\n",
      "The MSE loss is : 0.30419740080833435\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.30419740080833435\n",
      "The MSE loss is : 0.3041974604129791\n",
      "The MSE loss is : 0.3041974604129791\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.30419740080833435\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.3041975200176239\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.3041974604129791\n",
      "The MSE loss is : 0.30419740080833435\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33616235852241516\n",
      "The MSE loss is : 0.2787180542945862\n",
      "The MSE loss is : 0.2780068814754486\n",
      "The MSE loss is : 0.2778567671775818\n",
      "The MSE loss is : 0.2778053879737854\n",
      "The MSE loss is : 0.2777988612651825\n",
      "The MSE loss is : 0.2777988612651825\n",
      "The MSE loss is : 0.2777988612651825\n",
      "The MSE loss is : 0.2777988612651825\n",
      "The MSE loss is : 0.2777988910675049\n",
      "The MSE loss is : 0.2777988910675049\n",
      "The MSE loss is : 0.2777988612651825\n",
      "The MSE loss is : 0.2777988314628601\n",
      "The MSE loss is : 0.2777988612651825\n",
      "The MSE loss is : 0.2777988612651825\n",
      "The MSE loss is : 0.2777988612651825\n",
      "The MSE loss is : 0.2777988910675049\n",
      "The MSE loss is : 0.2777988910675049\n",
      "The MSE loss is : 0.2777988910675049\n",
      "The MSE loss is : 0.2777988612651825\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33616235852241516\n",
      "The MSE loss is : 0.2637944519519806\n",
      "The MSE loss is : 0.26357680559158325\n",
      "The MSE loss is : 0.2635642886161804\n",
      "The MSE loss is : 0.26356416940689087\n",
      "The MSE loss is : 0.26356419920921326\n",
      "The MSE loss is : 0.26356419920921326\n",
      "The MSE loss is : 0.26356419920921326\n",
      "The MSE loss is : 0.26356419920921326\n",
      "The MSE loss is : 0.26356419920921326\n",
      "The MSE loss is : 0.26356419920921326\n",
      "The MSE loss is : 0.26356419920921326\n",
      "The MSE loss is : 0.26356419920921326\n",
      "The MSE loss is : 0.26356419920921326\n",
      "The MSE loss is : 0.26356416940689087\n",
      "The MSE loss is : 0.26356416940689087\n",
      "The MSE loss is : 0.26356419920921326\n",
      "The MSE loss is : 0.26356419920921326\n",
      "The MSE loss is : 0.26356416940689087\n",
      "The MSE loss is : 0.26356419920921326\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.36459773778915405\n",
      "The MSE loss is : 0.1528962254524231\n",
      "The MSE loss is : 0.14420902729034424\n",
      "The MSE loss is : 0.14090001583099365\n",
      "The MSE loss is : 0.1390603929758072\n",
      "The MSE loss is : 0.13844585418701172\n",
      "The MSE loss is : 0.137589693069458\n",
      "The MSE loss is : 0.13689054548740387\n",
      "The MSE loss is : 0.13674074411392212\n",
      "The MSE loss is : 0.13660335540771484\n",
      "The MSE loss is : 0.13656021654605865\n",
      "The MSE loss is : 0.13651281595230103\n",
      "The MSE loss is : 0.13638003170490265\n",
      "The MSE loss is : 0.13624721765518188\n",
      "The MSE loss is : 0.1361297219991684\n",
      "The MSE loss is : 0.1360657513141632\n",
      "The MSE loss is : 0.13604183495044708\n",
      "The MSE loss is : 0.1360383778810501\n",
      "The MSE loss is : 0.13603751361370087\n",
      "The MSE loss is : 0.1360369622707367\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3364195227622986\n",
      "The MSE loss is : 0.14970771968364716\n",
      "The MSE loss is : 0.14577624201774597\n",
      "The MSE loss is : 0.14402347803115845\n",
      "The MSE loss is : 0.14362108707427979\n",
      "The MSE loss is : 0.14319653809070587\n",
      "The MSE loss is : 0.1428612768650055\n",
      "The MSE loss is : 0.14250129461288452\n",
      "The MSE loss is : 0.14244861900806427\n",
      "The MSE loss is : 0.14208729565143585\n",
      "The MSE loss is : 0.141990527510643\n",
      "The MSE loss is : 0.14183826744556427\n",
      "The MSE loss is : 0.14177969098091125\n",
      "The MSE loss is : 0.1417538970708847\n",
      "The MSE loss is : 0.1419822871685028\n",
      "The MSE loss is : 0.1415950059890747\n",
      "The MSE loss is : 0.14149072766304016\n",
      "The MSE loss is : 0.1416921466588974\n",
      "The MSE loss is : 0.14126792550086975\n",
      "The MSE loss is : 0.14153724908828735\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=159\n",
      "The MSE loss is : 0.3379421830177307\n",
      "The MSE loss is : 0.30750611424446106\n",
      "The MSE loss is : 0.30633658170700073\n",
      "The MSE loss is : 0.30619505047798157\n",
      "The MSE loss is : 0.30615273118019104\n",
      "The MSE loss is : 0.3061524033546448\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614808201789856\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614811182022095\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.3061481714248657\n",
      "The MSE loss is : 0.30614808201789856\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.3379421830177307\n",
      "The MSE loss is : 0.280302494764328\n",
      "The MSE loss is : 0.2795237898826599\n",
      "The MSE loss is : 0.2793924808502197\n",
      "The MSE loss is : 0.27938157320022583\n",
      "The MSE loss is : 0.27938157320022583\n",
      "The MSE loss is : 0.27938154339790344\n",
      "The MSE loss is : 0.27938151359558105\n",
      "The MSE loss is : 0.27938154339790344\n",
      "The MSE loss is : 0.27938151359558105\n",
      "The MSE loss is : 0.27938154339790344\n",
      "The MSE loss is : 0.27938154339790344\n",
      "The MSE loss is : 0.27938157320022583\n",
      "The MSE loss is : 0.27938154339790344\n",
      "The MSE loss is : 0.27938154339790344\n",
      "The MSE loss is : 0.27938154339790344\n",
      "The MSE loss is : 0.27938154339790344\n",
      "The MSE loss is : 0.27938154339790344\n",
      "The MSE loss is : 0.27938157320022583\n",
      "The MSE loss is : 0.27938157320022583\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.3379421830177307\n",
      "The MSE loss is : 0.2665231227874756\n",
      "The MSE loss is : 0.2662047743797302\n",
      "The MSE loss is : 0.26619264483451843\n",
      "The MSE loss is : 0.26619216799736023\n",
      "The MSE loss is : 0.26619213819503784\n",
      "The MSE loss is : 0.26619213819503784\n",
      "The MSE loss is : 0.26619213819503784\n",
      "The MSE loss is : 0.26619213819503784\n",
      "The MSE loss is : 0.26619210839271545\n",
      "The MSE loss is : 0.26619210839271545\n",
      "The MSE loss is : 0.26619213819503784\n",
      "The MSE loss is : 0.26619210839271545\n",
      "The MSE loss is : 0.26619213819503784\n",
      "The MSE loss is : 0.26619210839271545\n",
      "The MSE loss is : 0.26619213819503784\n",
      "The MSE loss is : 0.26619213819503784\n",
      "The MSE loss is : 0.26619213819503784\n",
      "The MSE loss is : 0.26619213819503784\n",
      "The MSE loss is : 0.26619213819503784\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.36587995290756226\n",
      "The MSE loss is : 0.15370208024978638\n",
      "The MSE loss is : 0.1448940485715866\n",
      "The MSE loss is : 0.14239615201950073\n",
      "The MSE loss is : 0.14086118340492249\n",
      "The MSE loss is : 0.13961753249168396\n",
      "The MSE loss is : 0.13886019587516785\n",
      "The MSE loss is : 0.13810795545578003\n",
      "The MSE loss is : 0.13794416189193726\n",
      "The MSE loss is : 0.13784757256507874\n",
      "The MSE loss is : 0.13780046999454498\n",
      "The MSE loss is : 0.13778558373451233\n",
      "The MSE loss is : 0.13769033551216125\n",
      "The MSE loss is : 0.13749893009662628\n",
      "The MSE loss is : 0.13745637238025665\n",
      "The MSE loss is : 0.13745303452014923\n",
      "The MSE loss is : 0.13745275139808655\n",
      "The MSE loss is : 0.13744336366653442\n",
      "The MSE loss is : 0.13739079236984253\n",
      "The MSE loss is : 0.13722467422485352\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3377634286880493\n",
      "The MSE loss is : 0.15006288886070251\n",
      "The MSE loss is : 0.14635884761810303\n",
      "The MSE loss is : 0.14487984776496887\n",
      "The MSE loss is : 0.1439647078514099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.14337819814682007\n",
      "The MSE loss is : 0.14295777678489685\n",
      "The MSE loss is : 0.14264194667339325\n",
      "The MSE loss is : 0.14216813445091248\n",
      "The MSE loss is : 0.14194321632385254\n",
      "The MSE loss is : 0.1417349874973297\n",
      "The MSE loss is : 0.1414845883846283\n",
      "The MSE loss is : 0.1413903534412384\n",
      "The MSE loss is : 0.14121979475021362\n",
      "The MSE loss is : 0.14133107662200928\n",
      "The MSE loss is : 0.14134010672569275\n",
      "The MSE loss is : 0.14112713932991028\n",
      "The MSE loss is : 0.14103932678699493\n",
      "The MSE loss is : 0.14107057452201843\n",
      "The MSE loss is : 0.14093273878097534\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=357\n",
      "The MSE loss is : 0.33726418018341064\n",
      "The MSE loss is : 0.3070529103279114\n",
      "The MSE loss is : 0.30571556091308594\n",
      "The MSE loss is : 0.3053184151649475\n",
      "The MSE loss is : 0.30525755882263184\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.3051893413066864\n",
      "The MSE loss is : 0.3051893413066864\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.3051893413066864\n",
      "The MSE loss is : 0.3051893413066864\n",
      "The MSE loss is : 0.3051893413066864\n",
      "The MSE loss is : 0.3051893711090088\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.3051893413066864\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.30518943071365356\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33726418018341064\n",
      "The MSE loss is : 0.27987581491470337\n",
      "The MSE loss is : 0.2788616716861725\n",
      "The MSE loss is : 0.2787545621395111\n",
      "The MSE loss is : 0.2787177562713623\n",
      "The MSE loss is : 0.2787177562713623\n",
      "The MSE loss is : 0.2787177264690399\n",
      "The MSE loss is : 0.2787177264690399\n",
      "The MSE loss is : 0.2787177562713623\n",
      "The MSE loss is : 0.2787177264690399\n",
      "The MSE loss is : 0.2787177562713623\n",
      "The MSE loss is : 0.2787177562713623\n",
      "The MSE loss is : 0.2787177264690399\n",
      "The MSE loss is : 0.2787177264690399\n",
      "The MSE loss is : 0.2787177562713623\n",
      "The MSE loss is : 0.2787177264690399\n",
      "The MSE loss is : 0.2787177562713623\n",
      "The MSE loss is : 0.2787177264690399\n",
      "The MSE loss is : 0.2787177264690399\n",
      "The MSE loss is : 0.2787177264690399\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33726418018341064\n",
      "The MSE loss is : 0.26501786708831787\n",
      "The MSE loss is : 0.2647448778152466\n",
      "The MSE loss is : 0.2647368013858795\n",
      "The MSE loss is : 0.2647354006767273\n",
      "The MSE loss is : 0.26473528146743774\n",
      "The MSE loss is : 0.26473528146743774\n",
      "The MSE loss is : 0.26473528146743774\n",
      "The MSE loss is : 0.26473528146743774\n",
      "The MSE loss is : 0.26473528146743774\n",
      "The MSE loss is : 0.26473528146743774\n",
      "The MSE loss is : 0.26473528146743774\n",
      "The MSE loss is : 0.26473528146743774\n",
      "The MSE loss is : 0.26473531126976013\n",
      "The MSE loss is : 0.26473528146743774\n",
      "The MSE loss is : 0.26473528146743774\n",
      "The MSE loss is : 0.26473528146743774\n",
      "The MSE loss is : 0.26473528146743774\n",
      "The MSE loss is : 0.26473531126976013\n",
      "The MSE loss is : 0.26473528146743774\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3652098476886749\n",
      "The MSE loss is : 0.1526077687740326\n",
      "The MSE loss is : 0.14345614612102509\n",
      "The MSE loss is : 0.14110183715820312\n",
      "The MSE loss is : 0.13923236727714539\n",
      "The MSE loss is : 0.13836076855659485\n",
      "The MSE loss is : 0.13782891631126404\n",
      "The MSE loss is : 0.13738447427749634\n",
      "The MSE loss is : 0.1369170844554901\n",
      "The MSE loss is : 0.13677097856998444\n",
      "The MSE loss is : 0.13676407933235168\n",
      "The MSE loss is : 0.1367475986480713\n",
      "The MSE loss is : 0.13674470782279968\n",
      "The MSE loss is : 0.136738121509552\n",
      "The MSE loss is : 0.13669796288013458\n",
      "The MSE loss is : 0.13668803870677948\n",
      "The MSE loss is : 0.13659557700157166\n",
      "The MSE loss is : 0.1365307867527008\n",
      "The MSE loss is : 0.13651204109191895\n",
      "The MSE loss is : 0.13648676872253418\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3368745744228363\n",
      "The MSE loss is : 0.14921514689922333\n",
      "The MSE loss is : 0.14554309844970703\n",
      "The MSE loss is : 0.14443045854568481\n",
      "The MSE loss is : 0.1435299962759018\n",
      "The MSE loss is : 0.14305344223976135\n",
      "The MSE loss is : 0.14253507554531097\n",
      "The MSE loss is : 0.1422518640756607\n",
      "The MSE loss is : 0.141971617937088\n",
      "The MSE loss is : 0.1416819840669632\n",
      "The MSE loss is : 0.14163532853126526\n",
      "The MSE loss is : 0.1414642035961151\n",
      "The MSE loss is : 0.14125385880470276\n",
      "The MSE loss is : 0.14104950428009033\n",
      "The MSE loss is : 0.14107970893383026\n",
      "The MSE loss is : 0.14093700051307678\n",
      "The MSE loss is : 0.14089998602867126\n",
      "The MSE loss is : 0.14080235362052917\n",
      "The MSE loss is : 0.14075154066085815\n",
      "The MSE loss is : 0.1406804919242859\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=951\n",
      "The MSE loss is : 0.33734333515167236\n",
      "The MSE loss is : 0.30579227209091187\n",
      "The MSE loss is : 0.30465805530548096\n",
      "The MSE loss is : 0.30437466502189636\n",
      "The MSE loss is : 0.3041991591453552\n",
      "The MSE loss is : 0.3041802942752838\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.3041708171367645\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.3041708767414093\n",
      "The MSE loss is : 0.3041708171367645\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.3041708171367645\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.30417078733444214\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33734333515167236\n",
      "The MSE loss is : 0.27899086475372314\n",
      "The MSE loss is : 0.2783099412918091\n",
      "The MSE loss is : 0.27821314334869385\n",
      "The MSE loss is : 0.2781934142112732\n",
      "The MSE loss is : 0.2781853675842285\n",
      "The MSE loss is : 0.2781853675842285\n",
      "The MSE loss is : 0.2781853675842285\n",
      "The MSE loss is : 0.2781853675842285\n",
      "The MSE loss is : 0.27818533778190613\n",
      "The MSE loss is : 0.2781853675842285\n",
      "The MSE loss is : 0.2781853675842285\n",
      "The MSE loss is : 0.2781853675842285\n",
      "The MSE loss is : 0.2781853675842285\n",
      "The MSE loss is : 0.2781853675842285\n",
      "The MSE loss is : 0.2781853675842285\n",
      "The MSE loss is : 0.27818533778190613\n",
      "The MSE loss is : 0.2781853675842285\n",
      "The MSE loss is : 0.2781853675842285\n",
      "The MSE loss is : 0.2781853675842285\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33734333515167236\n",
      "The MSE loss is : 0.2651156783103943\n",
      "The MSE loss is : 0.2648490071296692\n",
      "The MSE loss is : 0.2648458480834961\n",
      "The MSE loss is : 0.26484572887420654\n",
      "The MSE loss is : 0.26484572887420654\n",
      "The MSE loss is : 0.26484569907188416\n",
      "The MSE loss is : 0.26484572887420654\n",
      "The MSE loss is : 0.26484572887420654\n",
      "The MSE loss is : 0.26484572887420654\n",
      "The MSE loss is : 0.26484572887420654\n",
      "The MSE loss is : 0.26484572887420654\n",
      "The MSE loss is : 0.26484572887420654\n",
      "The MSE loss is : 0.26484572887420654\n",
      "The MSE loss is : 0.26484572887420654\n",
      "The MSE loss is : 0.26484572887420654\n",
      "The MSE loss is : 0.26484569907188416\n",
      "The MSE loss is : 0.26484572887420654\n",
      "The MSE loss is : 0.26484572887420654\n",
      "The MSE loss is : 0.26484572887420654\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3653397560119629\n",
      "The MSE loss is : 0.1517653912305832\n",
      "The MSE loss is : 0.14327676594257355\n",
      "The MSE loss is : 0.14013466238975525\n",
      "The MSE loss is : 0.13887371122837067\n",
      "The MSE loss is : 0.13778291642665863\n",
      "The MSE loss is : 0.13695302605628967\n",
      "The MSE loss is : 0.13682544231414795\n",
      "The MSE loss is : 0.13645334541797638\n",
      "The MSE loss is : 0.13620254397392273\n",
      "The MSE loss is : 0.13612355291843414\n",
      "The MSE loss is : 0.13612326979637146\n",
      "The MSE loss is : 0.13612298667430878\n",
      "The MSE loss is : 0.1361229419708252\n",
      "The MSE loss is : 0.13612273335456848\n",
      "The MSE loss is : 0.1361226886510849\n",
      "The MSE loss is : 0.13612253963947296\n",
      "The MSE loss is : 0.13612255454063416\n",
      "The MSE loss is : 0.13612274825572968\n",
      "The MSE loss is : 0.13612297177314758\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.33624088764190674\n",
      "The MSE loss is : 0.14953665435314178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.14593958854675293\n",
      "The MSE loss is : 0.14463894069194794\n",
      "The MSE loss is : 0.14381062984466553\n",
      "The MSE loss is : 0.14311134815216064\n",
      "The MSE loss is : 0.14279170334339142\n",
      "The MSE loss is : 0.1423427164554596\n",
      "The MSE loss is : 0.14214764535427094\n",
      "The MSE loss is : 0.14183409512043\n",
      "The MSE loss is : 0.14172151684761047\n",
      "The MSE loss is : 0.14185956120491028\n",
      "The MSE loss is : 0.1414274126291275\n",
      "The MSE loss is : 0.1416204571723938\n",
      "The MSE loss is : 0.1411856710910797\n",
      "The MSE loss is : 0.14122214913368225\n",
      "The MSE loss is : 0.1410580277442932\n",
      "The MSE loss is : 0.14102640748023987\n",
      "The MSE loss is : 0.1406698375940323\n",
      "The MSE loss is : 0.1405748724937439\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=753\n",
      "The MSE loss is : 0.33508166670799255\n",
      "The MSE loss is : 0.30500614643096924\n",
      "The MSE loss is : 0.3031643033027649\n",
      "The MSE loss is : 0.30283457040786743\n",
      "The MSE loss is : 0.3027329444885254\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273279547691345\n",
      "The MSE loss is : 0.30273279547691345\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273276567459106\n",
      "The MSE loss is : 0.302732914686203\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273279547691345\n",
      "The MSE loss is : 0.30273279547691345\n",
      "The MSE loss is : 0.30273279547691345\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273282527923584\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33508166670799255\n",
      "The MSE loss is : 0.2779119610786438\n",
      "The MSE loss is : 0.27699339389801025\n",
      "The MSE loss is : 0.27686578035354614\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416702747345\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416404724121\n",
      "The MSE loss is : 0.2768416404724121\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33508166670799255\n",
      "The MSE loss is : 0.26359695196151733\n",
      "The MSE loss is : 0.26340681314468384\n",
      "The MSE loss is : 0.26339471340179443\n",
      "The MSE loss is : 0.26339465379714966\n",
      "The MSE loss is : 0.26339465379714966\n",
      "The MSE loss is : 0.26339465379714966\n",
      "The MSE loss is : 0.26339465379714966\n",
      "The MSE loss is : 0.26339465379714966\n",
      "The MSE loss is : 0.26339465379714966\n",
      "The MSE loss is : 0.26339465379714966\n",
      "The MSE loss is : 0.26339465379714966\n",
      "The MSE loss is : 0.26339462399482727\n",
      "The MSE loss is : 0.26339465379714966\n",
      "The MSE loss is : 0.26339462399482727\n",
      "The MSE loss is : 0.26339465379714966\n",
      "The MSE loss is : 0.26339465379714966\n",
      "The MSE loss is : 0.26339465379714966\n",
      "The MSE loss is : 0.26339465379714966\n",
      "The MSE loss is : 0.26339465379714966\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3648436665534973\n",
      "The MSE loss is : 0.15143850445747375\n",
      "The MSE loss is : 0.14139261841773987\n",
      "The MSE loss is : 0.13857167959213257\n",
      "The MSE loss is : 0.1373213678598404\n",
      "The MSE loss is : 0.1366220861673355\n",
      "The MSE loss is : 0.13614721596240997\n",
      "The MSE loss is : 0.13600648939609528\n",
      "The MSE loss is : 0.13579773902893066\n",
      "The MSE loss is : 0.1353052258491516\n",
      "The MSE loss is : 0.13513946533203125\n",
      "The MSE loss is : 0.1351136863231659\n",
      "The MSE loss is : 0.13492143154144287\n",
      "The MSE loss is : 0.13491426408290863\n",
      "The MSE loss is : 0.13491247594356537\n",
      "The MSE loss is : 0.13491159677505493\n",
      "The MSE loss is : 0.13491295278072357\n",
      "The MSE loss is : 0.13491162657737732\n",
      "The MSE loss is : 0.13490989804267883\n",
      "The MSE loss is : 0.13491186499595642\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.33530348539352417\n",
      "The MSE loss is : 0.15001747012138367\n",
      "The MSE loss is : 0.14635100960731506\n",
      "The MSE loss is : 0.14478614926338196\n",
      "The MSE loss is : 0.1439678966999054\n",
      "The MSE loss is : 0.14337506890296936\n",
      "The MSE loss is : 0.14366699755191803\n",
      "The MSE loss is : 0.14242824912071228\n",
      "The MSE loss is : 0.14213895797729492\n",
      "The MSE loss is : 0.1419631838798523\n",
      "The MSE loss is : 0.14162124693393707\n",
      "The MSE loss is : 0.14169782400131226\n",
      "The MSE loss is : 0.1415465772151947\n",
      "The MSE loss is : 0.1412489414215088\n",
      "The MSE loss is : 0.1409892588853836\n",
      "The MSE loss is : 0.14078325033187866\n",
      "The MSE loss is : 0.140585258603096\n",
      "The MSE loss is : 0.1408909410238266\n",
      "The MSE loss is : 0.14036762714385986\n",
      "The MSE loss is : 0.1404307782649994\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=147\n",
      "The MSE loss is : 0.3339892029762268\n",
      "The MSE loss is : 0.3239596486091614\n",
      "The MSE loss is : 0.32336631417274475\n",
      "The MSE loss is : 0.3231329917907715\n",
      "The MSE loss is : 0.3230177164077759\n",
      "The MSE loss is : 0.3229726254940033\n",
      "The MSE loss is : 0.3229457139968872\n",
      "The MSE loss is : 0.3229377269744873\n",
      "The MSE loss is : 0.3229323923587799\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.3339892029762268\n",
      "The MSE loss is : 0.3035035729408264\n",
      "The MSE loss is : 0.3030964732170105\n",
      "The MSE loss is : 0.3029930293560028\n",
      "The MSE loss is : 0.30295687913894653\n",
      "The MSE loss is : 0.3029400706291199\n",
      "The MSE loss is : 0.3029365539550781\n",
      "The MSE loss is : 0.3029308319091797\n",
      "The MSE loss is : 0.3029308319091797\n",
      "The MSE loss is : 0.3029308319091797\n",
      "The MSE loss is : 0.3029308319091797\n",
      "The MSE loss is : 0.3029308319091797\n",
      "The MSE loss is : 0.3029308021068573\n",
      "The MSE loss is : 0.3029308319091797\n",
      "The MSE loss is : 0.3029308319091797\n",
      "The MSE loss is : 0.3029308021068573\n",
      "The MSE loss is : 0.3029281497001648\n",
      "The MSE loss is : 0.3029281497001648\n",
      "The MSE loss is : 0.3029281497001648\n",
      "The MSE loss is : 0.3029281497001648\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.3339892029762268\n",
      "The MSE loss is : 0.29613587260246277\n",
      "The MSE loss is : 0.2960194945335388\n",
      "The MSE loss is : 0.2960156202316284\n",
      "The MSE loss is : 0.2960154116153717\n",
      "The MSE loss is : 0.29601526260375977\n",
      "The MSE loss is : 0.29601526260375977\n",
      "The MSE loss is : 0.29601526260375977\n",
      "The MSE loss is : 0.2960152328014374\n",
      "The MSE loss is : 0.2960152328014374\n",
      "The MSE loss is : 0.2960152328014374\n",
      "The MSE loss is : 0.2960152328014374\n",
      "The MSE loss is : 0.2960152328014374\n",
      "The MSE loss is : 0.2960152328014374\n",
      "The MSE loss is : 0.2960152328014374\n",
      "The MSE loss is : 0.2960152328014374\n",
      "The MSE loss is : 0.2960152328014374\n",
      "The MSE loss is : 0.2960152328014374\n",
      "The MSE loss is : 0.2960152328014374\n",
      "The MSE loss is : 0.2960152328014374\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34284886717796326\n",
      "The MSE loss is : 0.2482040822505951\n",
      "The MSE loss is : 0.24320247769355774\n",
      "The MSE loss is : 0.24130788445472717\n",
      "The MSE loss is : 0.24032756686210632\n",
      "The MSE loss is : 0.23962590098381042\n",
      "The MSE loss is : 0.23913952708244324\n",
      "The MSE loss is : 0.2388308197259903\n",
      "The MSE loss is : 0.2385815978050232\n",
      "The MSE loss is : 0.23842647671699524\n",
      "The MSE loss is : 0.23830115795135498\n",
      "The MSE loss is : 0.23822930455207825\n",
      "The MSE loss is : 0.23812919855117798\n",
      "The MSE loss is : 0.23809796571731567\n",
      "The MSE loss is : 0.23806241154670715\n",
      "The MSE loss is : 0.23802369832992554\n",
      "The MSE loss is : 0.23796987533569336\n",
      "The MSE loss is : 0.23795247077941895\n",
      "The MSE loss is : 0.23793718218803406\n",
      "The MSE loss is : 0.23792967200279236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.3339969217777252\n",
      "The MSE loss is : 0.24193993210792542\n",
      "The MSE loss is : 0.24014823138713837\n",
      "The MSE loss is : 0.2396032214164734\n",
      "The MSE loss is : 0.23929622769355774\n",
      "The MSE loss is : 0.2390793412923813\n",
      "The MSE loss is : 0.2389078140258789\n",
      "The MSE loss is : 0.23881009221076965\n",
      "The MSE loss is : 0.2386694848537445\n",
      "The MSE loss is : 0.23857776820659637\n",
      "The MSE loss is : 0.23851029574871063\n",
      "The MSE loss is : 0.23845410346984863\n",
      "The MSE loss is : 0.2384072244167328\n",
      "The MSE loss is : 0.23835553228855133\n",
      "The MSE loss is : 0.23833999037742615\n",
      "The MSE loss is : 0.23829805850982666\n",
      "The MSE loss is : 0.23827189207077026\n",
      "The MSE loss is : 0.23824261128902435\n",
      "The MSE loss is : 0.2381986826658249\n",
      "The MSE loss is : 0.23817923665046692\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=258\n",
      "The MSE loss is : 0.3342400789260864\n",
      "The MSE loss is : 0.3241846561431885\n",
      "The MSE loss is : 0.32357677817344666\n",
      "The MSE loss is : 0.3234204947948456\n",
      "The MSE loss is : 0.32332843542099\n",
      "The MSE loss is : 0.32326939702033997\n",
      "The MSE loss is : 0.3231987953186035\n",
      "The MSE loss is : 0.32318323850631714\n",
      "The MSE loss is : 0.3231699764728546\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.3342400789260864\n",
      "The MSE loss is : 0.3037514090538025\n",
      "The MSE loss is : 0.30333369970321655\n",
      "The MSE loss is : 0.3032580614089966\n",
      "The MSE loss is : 0.30320560932159424\n",
      "The MSE loss is : 0.3031812310218811\n",
      "The MSE loss is : 0.3031718134880066\n",
      "The MSE loss is : 0.3031717836856842\n",
      "The MSE loss is : 0.3031718134880066\n",
      "The MSE loss is : 0.3031717836856842\n",
      "The MSE loss is : 0.3031717836856842\n",
      "The MSE loss is : 0.3031717836856842\n",
      "The MSE loss is : 0.3031717836856842\n",
      "The MSE loss is : 0.3031717836856842\n",
      "The MSE loss is : 0.3031718134880066\n",
      "The MSE loss is : 0.3031718134880066\n",
      "The MSE loss is : 0.3031717836856842\n",
      "The MSE loss is : 0.3031717836856842\n",
      "The MSE loss is : 0.3031717836856842\n",
      "The MSE loss is : 0.3031717836856842\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.3342400789260864\n",
      "The MSE loss is : 0.2964353859424591\n",
      "The MSE loss is : 0.2962985336780548\n",
      "The MSE loss is : 0.29629480838775635\n",
      "The MSE loss is : 0.29629451036453247\n",
      "The MSE loss is : 0.29629451036453247\n",
      "The MSE loss is : 0.29629451036453247\n",
      "The MSE loss is : 0.29629451036453247\n",
      "The MSE loss is : 0.29629451036453247\n",
      "The MSE loss is : 0.29629451036453247\n",
      "The MSE loss is : 0.29629451036453247\n",
      "The MSE loss is : 0.29629451036453247\n",
      "The MSE loss is : 0.29629451036453247\n",
      "The MSE loss is : 0.29629451036453247\n",
      "The MSE loss is : 0.29629454016685486\n",
      "The MSE loss is : 0.29629451036453247\n",
      "The MSE loss is : 0.29629451036453247\n",
      "The MSE loss is : 0.29629454016685486\n",
      "The MSE loss is : 0.29629451036453247\n",
      "The MSE loss is : 0.29629454016685486\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34287798404693604\n",
      "The MSE loss is : 0.24848487973213196\n",
      "The MSE loss is : 0.24315112829208374\n",
      "The MSE loss is : 0.24140116572380066\n",
      "The MSE loss is : 0.24051102995872498\n",
      "The MSE loss is : 0.2399352490901947\n",
      "The MSE loss is : 0.2395258992910385\n",
      "The MSE loss is : 0.23922812938690186\n",
      "The MSE loss is : 0.23895138502120972\n",
      "The MSE loss is : 0.23871870338916779\n",
      "The MSE loss is : 0.23855142295360565\n",
      "The MSE loss is : 0.23846188187599182\n",
      "The MSE loss is : 0.23841993510723114\n",
      "The MSE loss is : 0.2383785843849182\n",
      "The MSE loss is : 0.2383466511964798\n",
      "The MSE loss is : 0.23825041949748993\n",
      "The MSE loss is : 0.23818866908550262\n",
      "The MSE loss is : 0.23814024031162262\n",
      "The MSE loss is : 0.23810255527496338\n",
      "The MSE loss is : 0.23807629942893982\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.3342563509941101\n",
      "The MSE loss is : 0.24194759130477905\n",
      "The MSE loss is : 0.24022530019283295\n",
      "The MSE loss is : 0.23960821330547333\n",
      "The MSE loss is : 0.23927894234657288\n",
      "The MSE loss is : 0.23906689882278442\n",
      "The MSE loss is : 0.23891732096672058\n",
      "The MSE loss is : 0.23879626393318176\n",
      "The MSE loss is : 0.23870638012886047\n",
      "The MSE loss is : 0.23859301209449768\n",
      "The MSE loss is : 0.23851732909679413\n",
      "The MSE loss is : 0.2384510040283203\n",
      "The MSE loss is : 0.23840069770812988\n",
      "The MSE loss is : 0.23834528028964996\n",
      "The MSE loss is : 0.23823688924312592\n",
      "The MSE loss is : 0.23818859457969666\n",
      "The MSE loss is : 0.2381364405155182\n",
      "The MSE loss is : 0.23813003301620483\n",
      "The MSE loss is : 0.23813046514987946\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=369\n",
      "The MSE loss is : 0.33462902903556824\n",
      "The MSE loss is : 0.3244115114212036\n",
      "The MSE loss is : 0.32386428117752075\n",
      "The MSE loss is : 0.32367217540740967\n",
      "The MSE loss is : 0.3235931098461151\n",
      "The MSE loss is : 0.3235494792461395\n",
      "The MSE loss is : 0.32353475689888\n",
      "The MSE loss is : 0.3235335946083069\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235335946083069\n",
      "The MSE loss is : 0.3235335946083069\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235335946083069\n",
      "The MSE loss is : 0.32353365421295166\n",
      "The MSE loss is : 0.3235335946083069\n",
      "The MSE loss is : 0.3235335946083069\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235335946083069\n",
      "The MSE loss is : 0.3235336244106293\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.33462902903556824\n",
      "The MSE loss is : 0.30408918857574463\n",
      "The MSE loss is : 0.3036049008369446\n",
      "The MSE loss is : 0.3034723699092865\n",
      "The MSE loss is : 0.3034481108188629\n",
      "The MSE loss is : 0.30343472957611084\n",
      "The MSE loss is : 0.30343469977378845\n",
      "The MSE loss is : 0.30343469977378845\n",
      "The MSE loss is : 0.30343466997146606\n",
      "The MSE loss is : 0.30343466997146606\n",
      "The MSE loss is : 0.30343466997146606\n",
      "The MSE loss is : 0.30343466997146606\n",
      "The MSE loss is : 0.30343466997146606\n",
      "The MSE loss is : 0.30343466997146606\n",
      "The MSE loss is : 0.30343466997146606\n",
      "The MSE loss is : 0.30343466997146606\n",
      "The MSE loss is : 0.30343466997146606\n",
      "The MSE loss is : 0.30343466997146606\n",
      "The MSE loss is : 0.30343466997146606\n",
      "The MSE loss is : 0.30343466997146606\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.33462902903556824\n",
      "The MSE loss is : 0.2967909574508667\n",
      "The MSE loss is : 0.2966585159301758\n",
      "The MSE loss is : 0.29664990305900574\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "The MSE loss is : 0.2966495752334595\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34368622303009033\n",
      "The MSE loss is : 0.2487199455499649\n",
      "The MSE loss is : 0.24342916905879974\n",
      "The MSE loss is : 0.24159958958625793\n",
      "The MSE loss is : 0.2405748963356018\n",
      "The MSE loss is : 0.23999987542629242\n",
      "The MSE loss is : 0.23955050110816956\n",
      "The MSE loss is : 0.2391904890537262\n",
      "The MSE loss is : 0.23894017934799194\n",
      "The MSE loss is : 0.23881009221076965\n",
      "The MSE loss is : 0.23872342705726624\n",
      "The MSE loss is : 0.23862451314926147\n",
      "The MSE loss is : 0.23854497075080872\n",
      "The MSE loss is : 0.2384682595729828\n",
      "The MSE loss is : 0.23844024538993835\n",
      "The MSE loss is : 0.23843717575073242\n",
      "The MSE loss is : 0.23842766880989075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.2383994162082672\n",
      "The MSE loss is : 0.23838704824447632\n",
      "The MSE loss is : 0.2383650839328766\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.33456528186798096\n",
      "The MSE loss is : 0.24219447374343872\n",
      "The MSE loss is : 0.24060510098934174\n",
      "The MSE loss is : 0.24002587795257568\n",
      "The MSE loss is : 0.23970487713813782\n",
      "The MSE loss is : 0.23946300148963928\n",
      "The MSE loss is : 0.23928529024124146\n",
      "The MSE loss is : 0.23916275799274445\n",
      "The MSE loss is : 0.2390400767326355\n",
      "The MSE loss is : 0.2389538288116455\n",
      "The MSE loss is : 0.23888590931892395\n",
      "The MSE loss is : 0.238836407661438\n",
      "The MSE loss is : 0.23875854909420013\n",
      "The MSE loss is : 0.23869265615940094\n",
      "The MSE loss is : 0.23866340517997742\n",
      "The MSE loss is : 0.23860293626785278\n",
      "The MSE loss is : 0.23855778574943542\n",
      "The MSE loss is : 0.23851406574249268\n",
      "The MSE loss is : 0.23847226798534393\n",
      "The MSE loss is : 0.2384553849697113\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=321\n",
      "The MSE loss is : 0.3350902497768402\n",
      "The MSE loss is : 0.32495519518852234\n",
      "The MSE loss is : 0.32437798380851746\n",
      "The MSE loss is : 0.324229896068573\n",
      "The MSE loss is : 0.3240945339202881\n",
      "The MSE loss is : 0.3240191638469696\n",
      "The MSE loss is : 0.32401567697525024\n",
      "The MSE loss is : 0.32397186756134033\n",
      "The MSE loss is : 0.32394999265670776\n",
      "The MSE loss is : 0.3239485025405884\n",
      "The MSE loss is : 0.3239485025405884\n",
      "The MSE loss is : 0.3239485025405884\n",
      "The MSE loss is : 0.323948472738266\n",
      "The MSE loss is : 0.323948472738266\n",
      "The MSE loss is : 0.323948472738266\n",
      "The MSE loss is : 0.323948472738266\n",
      "The MSE loss is : 0.323948472738266\n",
      "The MSE loss is : 0.3239485025405884\n",
      "The MSE loss is : 0.323948472738266\n",
      "The MSE loss is : 0.3239485025405884\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.3350902497768402\n",
      "The MSE loss is : 0.30447566509246826\n",
      "The MSE loss is : 0.30400291085243225\n",
      "The MSE loss is : 0.30394110083580017\n",
      "The MSE loss is : 0.3039069175720215\n",
      "The MSE loss is : 0.3039008378982544\n",
      "The MSE loss is : 0.3038933575153351\n",
      "The MSE loss is : 0.303891122341156\n",
      "The MSE loss is : 0.30388906598091125\n",
      "The MSE loss is : 0.30388906598091125\n",
      "The MSE loss is : 0.30388903617858887\n",
      "The MSE loss is : 0.30388906598091125\n",
      "The MSE loss is : 0.30388906598091125\n",
      "The MSE loss is : 0.30388903617858887\n",
      "The MSE loss is : 0.30388906598091125\n",
      "The MSE loss is : 0.30388906598091125\n",
      "The MSE loss is : 0.30388906598091125\n",
      "The MSE loss is : 0.30388906598091125\n",
      "The MSE loss is : 0.30388906598091125\n",
      "The MSE loss is : 0.30388906598091125\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.3350902497768402\n",
      "The MSE loss is : 0.29707640409469604\n",
      "The MSE loss is : 0.2969386577606201\n",
      "The MSE loss is : 0.29693371057510376\n",
      "The MSE loss is : 0.29693305492401123\n",
      "The MSE loss is : 0.2969329357147217\n",
      "The MSE loss is : 0.2969329059123993\n",
      "The MSE loss is : 0.2969328761100769\n",
      "The MSE loss is : 0.2969328761100769\n",
      "The MSE loss is : 0.2969328761100769\n",
      "The MSE loss is : 0.2969328761100769\n",
      "The MSE loss is : 0.2969328761100769\n",
      "The MSE loss is : 0.2969328761100769\n",
      "The MSE loss is : 0.2969328761100769\n",
      "The MSE loss is : 0.2969328761100769\n",
      "The MSE loss is : 0.2969328761100769\n",
      "The MSE loss is : 0.2969328761100769\n",
      "The MSE loss is : 0.2969328761100769\n",
      "The MSE loss is : 0.2969328761100769\n",
      "The MSE loss is : 0.2969328761100769\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34382301568984985\n",
      "The MSE loss is : 0.24924811720848083\n",
      "The MSE loss is : 0.2438715547323227\n",
      "The MSE loss is : 0.24190866947174072\n",
      "The MSE loss is : 0.24090997874736786\n",
      "The MSE loss is : 0.24038165807724\n",
      "The MSE loss is : 0.23997825384140015\n",
      "The MSE loss is : 0.23969823122024536\n",
      "The MSE loss is : 0.23948633670806885\n",
      "The MSE loss is : 0.23927944898605347\n",
      "The MSE loss is : 0.2390558272600174\n",
      "The MSE loss is : 0.2389707863330841\n",
      "The MSE loss is : 0.23891186714172363\n",
      "The MSE loss is : 0.23883205652236938\n",
      "The MSE loss is : 0.2387775331735611\n",
      "The MSE loss is : 0.2387273758649826\n",
      "The MSE loss is : 0.2387142777442932\n",
      "The MSE loss is : 0.23871362209320068\n",
      "The MSE loss is : 0.2387135922908783\n",
      "The MSE loss is : 0.2387136071920395\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.335043340921402\n",
      "The MSE loss is : 0.2426995038986206\n",
      "The MSE loss is : 0.24100519716739655\n",
      "The MSE loss is : 0.24044233560562134\n",
      "The MSE loss is : 0.24013206362724304\n",
      "The MSE loss is : 0.2399156242609024\n",
      "The MSE loss is : 0.23972633481025696\n",
      "The MSE loss is : 0.2395952045917511\n",
      "The MSE loss is : 0.2394668608903885\n",
      "The MSE loss is : 0.2393689751625061\n",
      "The MSE loss is : 0.23929178714752197\n",
      "The MSE loss is : 0.23921732604503632\n",
      "The MSE loss is : 0.2391546070575714\n",
      "The MSE loss is : 0.23907294869422913\n",
      "The MSE loss is : 0.23905394971370697\n",
      "The MSE loss is : 0.23898282647132874\n",
      "The MSE loss is : 0.23893922567367554\n",
      "The MSE loss is : 0.23888462781906128\n",
      "The MSE loss is : 0.23885822296142578\n",
      "The MSE loss is : 0.23883351683616638\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=654\n",
      "The MSE loss is : 0.33410510420799255\n",
      "The MSE loss is : 0.3239274024963379\n",
      "The MSE loss is : 0.32345110177993774\n",
      "The MSE loss is : 0.32324427366256714\n",
      "The MSE loss is : 0.3231106698513031\n",
      "The MSE loss is : 0.32305413484573364\n",
      "The MSE loss is : 0.32303905487060547\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.33410510420799255\n",
      "The MSE loss is : 0.30344146490097046\n",
      "The MSE loss is : 0.30303454399108887\n",
      "The MSE loss is : 0.3029472529888153\n",
      "The MSE loss is : 0.30293089151382446\n",
      "The MSE loss is : 0.30292320251464844\n",
      "The MSE loss is : 0.30292320251464844\n",
      "The MSE loss is : 0.3029225468635559\n",
      "The MSE loss is : 0.3029225468635559\n",
      "The MSE loss is : 0.3029225468635559\n",
      "The MSE loss is : 0.3029225468635559\n",
      "The MSE loss is : 0.3029225468635559\n",
      "The MSE loss is : 0.3029225468635559\n",
      "The MSE loss is : 0.3029225468635559\n",
      "The MSE loss is : 0.3029225468635559\n",
      "The MSE loss is : 0.3029225468635559\n",
      "The MSE loss is : 0.3029225468635559\n",
      "The MSE loss is : 0.3029225468635559\n",
      "The MSE loss is : 0.3029225468635559\n",
      "The MSE loss is : 0.3029225468635559\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.33410510420799255\n",
      "The MSE loss is : 0.2961576581001282\n",
      "The MSE loss is : 0.2960291802883148\n",
      "The MSE loss is : 0.29602307081222534\n",
      "The MSE loss is : 0.29602235555648804\n",
      "The MSE loss is : 0.29602211713790894\n",
      "The MSE loss is : 0.29602211713790894\n",
      "The MSE loss is : 0.29602211713790894\n",
      "The MSE loss is : 0.2960221469402313\n",
      "The MSE loss is : 0.2960221469402313\n",
      "The MSE loss is : 0.2960221469402313\n",
      "The MSE loss is : 0.2960221469402313\n",
      "The MSE loss is : 0.2960221469402313\n",
      "The MSE loss is : 0.2960221469402313\n",
      "The MSE loss is : 0.2960221469402313\n",
      "The MSE loss is : 0.2960221469402313\n",
      "The MSE loss is : 0.2960221469402313\n",
      "The MSE loss is : 0.2960221469402313\n",
      "The MSE loss is : 0.2960221469402313\n",
      "The MSE loss is : 0.2960221469402313\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34298357367515564\n",
      "The MSE loss is : 0.2485632300376892\n",
      "The MSE loss is : 0.24333816766738892\n",
      "The MSE loss is : 0.2415049970149994\n",
      "The MSE loss is : 0.2405640184879303\n",
      "The MSE loss is : 0.23990482091903687\n",
      "The MSE loss is : 0.23945002257823944\n",
      "The MSE loss is : 0.23908020555973053\n",
      "The MSE loss is : 0.23880015313625336\n",
      "The MSE loss is : 0.2385948747396469\n",
      "The MSE loss is : 0.23844614624977112\n",
      "The MSE loss is : 0.23835238814353943\n",
      "The MSE loss is : 0.2383110225200653\n",
      "The MSE loss is : 0.23826982080936432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.23822221159934998\n",
      "The MSE loss is : 0.23818039894104004\n",
      "The MSE loss is : 0.23812538385391235\n",
      "The MSE loss is : 0.23808737099170685\n",
      "The MSE loss is : 0.23806250095367432\n",
      "The MSE loss is : 0.23804980516433716\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.3341061472892761\n",
      "The MSE loss is : 0.24208979308605194\n",
      "The MSE loss is : 0.240289568901062\n",
      "The MSE loss is : 0.23963133990764618\n",
      "The MSE loss is : 0.23930378258228302\n",
      "The MSE loss is : 0.23906990885734558\n",
      "The MSE loss is : 0.2388789802789688\n",
      "The MSE loss is : 0.2387569099664688\n",
      "The MSE loss is : 0.23867303133010864\n",
      "The MSE loss is : 0.238587886095047\n",
      "The MSE loss is : 0.23851041495800018\n",
      "The MSE loss is : 0.23844921588897705\n",
      "The MSE loss is : 0.23839524388313293\n",
      "The MSE loss is : 0.23833626508712769\n",
      "The MSE loss is : 0.23832055926322937\n",
      "The MSE loss is : 0.23826369643211365\n",
      "The MSE loss is : 0.23825187981128693\n",
      "The MSE loss is : 0.23820191621780396\n",
      "The MSE loss is : 0.23816126585006714\n",
      "The MSE loss is : 0.23812471330165863\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=987\n",
      "The MSE loss is : 0.3345998227596283\n",
      "The MSE loss is : 0.3244805634021759\n",
      "The MSE loss is : 0.32395198941230774\n",
      "The MSE loss is : 0.32379084825515747\n",
      "The MSE loss is : 0.32369184494018555\n",
      "The MSE loss is : 0.32358992099761963\n",
      "The MSE loss is : 0.3235822916030884\n",
      "The MSE loss is : 0.3235705494880676\n",
      "The MSE loss is : 0.32357051968574524\n",
      "The MSE loss is : 0.32357051968574524\n",
      "The MSE loss is : 0.3235705494880676\n",
      "The MSE loss is : 0.32357051968574524\n",
      "The MSE loss is : 0.32357051968574524\n",
      "The MSE loss is : 0.32357051968574524\n",
      "The MSE loss is : 0.3235705494880676\n",
      "The MSE loss is : 0.32357051968574524\n",
      "The MSE loss is : 0.32357051968574524\n",
      "The MSE loss is : 0.32357051968574524\n",
      "The MSE loss is : 0.32357051968574524\n",
      "The MSE loss is : 0.3235705494880676\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.3345998227596283\n",
      "The MSE loss is : 0.304130494594574\n",
      "The MSE loss is : 0.30364012718200684\n",
      "The MSE loss is : 0.30354034900665283\n",
      "The MSE loss is : 0.3035198748111725\n",
      "The MSE loss is : 0.303507924079895\n",
      "The MSE loss is : 0.303507924079895\n",
      "The MSE loss is : 0.303507924079895\n",
      "The MSE loss is : 0.30350756645202637\n",
      "The MSE loss is : 0.30350759625434875\n",
      "The MSE loss is : 0.30350759625434875\n",
      "The MSE loss is : 0.30350759625434875\n",
      "The MSE loss is : 0.30350759625434875\n",
      "The MSE loss is : 0.30350756645202637\n",
      "The MSE loss is : 0.30350756645202637\n",
      "The MSE loss is : 0.30350756645202637\n",
      "The MSE loss is : 0.30350759625434875\n",
      "The MSE loss is : 0.30350756645202637\n",
      "The MSE loss is : 0.30350756645202637\n",
      "The MSE loss is : 0.30350759625434875\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.3345998227596283\n",
      "The MSE loss is : 0.2966952323913574\n",
      "The MSE loss is : 0.29656320810317993\n",
      "The MSE loss is : 0.2965570390224457\n",
      "The MSE loss is : 0.29655683040618896\n",
      "The MSE loss is : 0.2965567409992218\n",
      "The MSE loss is : 0.2965567111968994\n",
      "The MSE loss is : 0.2965567409992218\n",
      "The MSE loss is : 0.2965567111968994\n",
      "The MSE loss is : 0.2965567409992218\n",
      "The MSE loss is : 0.2965567111968994\n",
      "The MSE loss is : 0.2965567111968994\n",
      "The MSE loss is : 0.2965567111968994\n",
      "The MSE loss is : 0.2965567111968994\n",
      "The MSE loss is : 0.2965567111968994\n",
      "The MSE loss is : 0.2965567111968994\n",
      "The MSE loss is : 0.2965567111968994\n",
      "The MSE loss is : 0.2965567111968994\n",
      "The MSE loss is : 0.2965567111968994\n",
      "The MSE loss is : 0.2965567111968994\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34361934661865234\n",
      "The MSE loss is : 0.24876052141189575\n",
      "The MSE loss is : 0.24349969625473022\n",
      "The MSE loss is : 0.24163374304771423\n",
      "The MSE loss is : 0.24066048860549927\n",
      "The MSE loss is : 0.24010701477527618\n",
      "The MSE loss is : 0.23969432711601257\n",
      "The MSE loss is : 0.2393959015607834\n",
      "The MSE loss is : 0.23914316296577454\n",
      "The MSE loss is : 0.23900769650936127\n",
      "The MSE loss is : 0.23892393708229065\n",
      "The MSE loss is : 0.23885563015937805\n",
      "The MSE loss is : 0.23872430622577667\n",
      "The MSE loss is : 0.23864632844924927\n",
      "The MSE loss is : 0.23859235644340515\n",
      "The MSE loss is : 0.23852784931659698\n",
      "The MSE loss is : 0.23848319053649902\n",
      "The MSE loss is : 0.23845931887626648\n",
      "The MSE loss is : 0.2384430170059204\n",
      "The MSE loss is : 0.23842088878154755\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.3346937596797943\n",
      "The MSE loss is : 0.24242451786994934\n",
      "The MSE loss is : 0.24079245328903198\n",
      "The MSE loss is : 0.24010461568832397\n",
      "The MSE loss is : 0.23974135518074036\n",
      "The MSE loss is : 0.23950691521167755\n",
      "The MSE loss is : 0.23931528627872467\n",
      "The MSE loss is : 0.2391849309206009\n",
      "The MSE loss is : 0.239066019654274\n",
      "The MSE loss is : 0.23896822333335876\n",
      "The MSE loss is : 0.23891641199588776\n",
      "The MSE loss is : 0.23886360228061676\n",
      "The MSE loss is : 0.23881790041923523\n",
      "The MSE loss is : 0.23877814412117004\n",
      "The MSE loss is : 0.23871318995952606\n",
      "The MSE loss is : 0.23868274688720703\n",
      "The MSE loss is : 0.23866841197013855\n",
      "The MSE loss is : 0.23864144086837769\n",
      "The MSE loss is : 0.2386024296283722\n",
      "The MSE loss is : 0.23857879638671875\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=741\n",
      "The MSE loss is : 0.3341395854949951\n",
      "The MSE loss is : 0.3238860070705414\n",
      "The MSE loss is : 0.32338133454322815\n",
      "The MSE loss is : 0.32318466901779175\n",
      "The MSE loss is : 0.32307934761047363\n",
      "The MSE loss is : 0.32303211092948914\n",
      "The MSE loss is : 0.32301950454711914\n",
      "The MSE loss is : 0.32301923632621765\n",
      "The MSE loss is : 0.32301920652389526\n",
      "The MSE loss is : 0.32301920652389526\n",
      "The MSE loss is : 0.32301923632621765\n",
      "The MSE loss is : 0.32301920652389526\n",
      "The MSE loss is : 0.32301923632621765\n",
      "The MSE loss is : 0.32301920652389526\n",
      "The MSE loss is : 0.32301920652389526\n",
      "The MSE loss is : 0.32301920652389526\n",
      "The MSE loss is : 0.32301923632621765\n",
      "The MSE loss is : 0.32301923632621765\n",
      "The MSE loss is : 0.32301920652389526\n",
      "The MSE loss is : 0.32301920652389526\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.3341395854949951\n",
      "The MSE loss is : 0.30362266302108765\n",
      "The MSE loss is : 0.3032228648662567\n",
      "The MSE loss is : 0.30310487747192383\n",
      "The MSE loss is : 0.30307501554489136\n",
      "The MSE loss is : 0.3030690550804138\n",
      "The MSE loss is : 0.30306267738342285\n",
      "The MSE loss is : 0.30306267738342285\n",
      "The MSE loss is : 0.30306267738342285\n",
      "The MSE loss is : 0.30306267738342285\n",
      "The MSE loss is : 0.30306267738342285\n",
      "The MSE loss is : 0.30306267738342285\n",
      "The MSE loss is : 0.30306267738342285\n",
      "The MSE loss is : 0.30306267738342285\n",
      "The MSE loss is : 0.30306267738342285\n",
      "The MSE loss is : 0.30306267738342285\n",
      "The MSE loss is : 0.30306267738342285\n",
      "The MSE loss is : 0.30306267738342285\n",
      "The MSE loss is : 0.30306267738342285\n",
      "The MSE loss is : 0.30306267738342285\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.3341395854949951\n",
      "The MSE loss is : 0.296276718378067\n",
      "The MSE loss is : 0.29614561796188354\n",
      "The MSE loss is : 0.296142578125\n",
      "The MSE loss is : 0.2961423993110657\n",
      "The MSE loss is : 0.2961423993110657\n",
      "The MSE loss is : 0.2961423993110657\n",
      "The MSE loss is : 0.2961423695087433\n",
      "The MSE loss is : 0.2961423695087433\n",
      "The MSE loss is : 0.2961423695087433\n",
      "The MSE loss is : 0.2961423695087433\n",
      "The MSE loss is : 0.2961423695087433\n",
      "The MSE loss is : 0.2961423695087433\n",
      "The MSE loss is : 0.2961423695087433\n",
      "The MSE loss is : 0.2961423695087433\n",
      "The MSE loss is : 0.2961423695087433\n",
      "The MSE loss is : 0.2961423695087433\n",
      "The MSE loss is : 0.2961423695087433\n",
      "The MSE loss is : 0.2961423695087433\n",
      "The MSE loss is : 0.2961423695087433\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34278878569602966\n",
      "The MSE loss is : 0.2483053356409073\n",
      "The MSE loss is : 0.24308404326438904\n",
      "The MSE loss is : 0.2411511093378067\n",
      "The MSE loss is : 0.24034422636032104\n",
      "The MSE loss is : 0.23968623578548431\n",
      "The MSE loss is : 0.23922745883464813\n",
      "The MSE loss is : 0.23893240094184875\n",
      "The MSE loss is : 0.2387891262769699\n",
      "The MSE loss is : 0.23865783214569092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.23858864605426788\n",
      "The MSE loss is : 0.23849357664585114\n",
      "The MSE loss is : 0.23839807510375977\n",
      "The MSE loss is : 0.23829175531864166\n",
      "The MSE loss is : 0.23823973536491394\n",
      "The MSE loss is : 0.23820337653160095\n",
      "The MSE loss is : 0.2381848394870758\n",
      "The MSE loss is : 0.23816931247711182\n",
      "The MSE loss is : 0.2381654977798462\n",
      "The MSE loss is : 0.23816552758216858\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.33412766456604004\n",
      "The MSE loss is : 0.24180658161640167\n",
      "The MSE loss is : 0.240188866853714\n",
      "The MSE loss is : 0.239547997713089\n",
      "The MSE loss is : 0.23920869827270508\n",
      "The MSE loss is : 0.23897528648376465\n",
      "The MSE loss is : 0.238784521818161\n",
      "The MSE loss is : 0.23860278725624084\n",
      "The MSE loss is : 0.2385069727897644\n",
      "The MSE loss is : 0.23840048909187317\n",
      "The MSE loss is : 0.23829424381256104\n",
      "The MSE loss is : 0.23824334144592285\n",
      "The MSE loss is : 0.23821057379245758\n",
      "The MSE loss is : 0.23814068734645844\n",
      "The MSE loss is : 0.23811954259872437\n",
      "The MSE loss is : 0.2380819469690323\n",
      "The MSE loss is : 0.2380584329366684\n",
      "The MSE loss is : 0.23801566660404205\n",
      "The MSE loss is : 0.23799052834510803\n",
      "The MSE loss is : 0.23797522485256195\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=852\n",
      "The MSE loss is : 0.3343210816383362\n",
      "The MSE loss is : 0.3241903781890869\n",
      "The MSE loss is : 0.32361194491386414\n",
      "The MSE loss is : 0.3234328031539917\n",
      "The MSE loss is : 0.32331404089927673\n",
      "The MSE loss is : 0.32328349351882935\n",
      "The MSE loss is : 0.32326582074165344\n",
      "The MSE loss is : 0.3232600688934326\n",
      "The MSE loss is : 0.3232600688934326\n",
      "The MSE loss is : 0.3232600688934326\n",
      "The MSE loss is : 0.3232600688934326\n",
      "The MSE loss is : 0.3232600688934326\n",
      "The MSE loss is : 0.3232600688934326\n",
      "The MSE loss is : 0.3232600688934326\n",
      "The MSE loss is : 0.3232600688934326\n",
      "The MSE loss is : 0.3232600688934326\n",
      "The MSE loss is : 0.3232600688934326\n",
      "The MSE loss is : 0.3232600688934326\n",
      "The MSE loss is : 0.3232600688934326\n",
      "The MSE loss is : 0.3232600688934326\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.3343210816383362\n",
      "The MSE loss is : 0.30379998683929443\n",
      "The MSE loss is : 0.3033679723739624\n",
      "The MSE loss is : 0.3032519221305847\n",
      "The MSE loss is : 0.30323195457458496\n",
      "The MSE loss is : 0.30322641134262085\n",
      "The MSE loss is : 0.30322641134262085\n",
      "The MSE loss is : 0.3032257854938507\n",
      "The MSE loss is : 0.3032257854938507\n",
      "The MSE loss is : 0.3032257854938507\n",
      "The MSE loss is : 0.3032257854938507\n",
      "The MSE loss is : 0.3032257854938507\n",
      "The MSE loss is : 0.3032257854938507\n",
      "The MSE loss is : 0.3032257854938507\n",
      "The MSE loss is : 0.3032257854938507\n",
      "The MSE loss is : 0.3032257854938507\n",
      "The MSE loss is : 0.3032257854938507\n",
      "The MSE loss is : 0.3032257854938507\n",
      "The MSE loss is : 0.3032257854938507\n",
      "The MSE loss is : 0.3032257854938507\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.3343210816383362\n",
      "The MSE loss is : 0.2965843677520752\n",
      "The MSE loss is : 0.2964633107185364\n",
      "The MSE loss is : 0.2964595854282379\n",
      "The MSE loss is : 0.2964593470096588\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "The MSE loss is : 0.2964593172073364\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34327587485313416\n",
      "The MSE loss is : 0.24859677255153656\n",
      "The MSE loss is : 0.24348096549510956\n",
      "The MSE loss is : 0.24166831374168396\n",
      "The MSE loss is : 0.2407499998807907\n",
      "The MSE loss is : 0.240043044090271\n",
      "The MSE loss is : 0.2395794689655304\n",
      "The MSE loss is : 0.23924653232097626\n",
      "The MSE loss is : 0.23903238773345947\n",
      "The MSE loss is : 0.23886102437973022\n",
      "The MSE loss is : 0.2387607991695404\n",
      "The MSE loss is : 0.23865316808223724\n",
      "The MSE loss is : 0.23856858909130096\n",
      "The MSE loss is : 0.23850467801094055\n",
      "The MSE loss is : 0.23842985928058624\n",
      "The MSE loss is : 0.23837566375732422\n",
      "The MSE loss is : 0.23830345273017883\n",
      "The MSE loss is : 0.23824527859687805\n",
      "The MSE loss is : 0.23818959295749664\n",
      "The MSE loss is : 0.23815080523490906\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.33433109521865845\n",
      "The MSE loss is : 0.24174213409423828\n",
      "The MSE loss is : 0.24014179408550262\n",
      "The MSE loss is : 0.23953691124916077\n",
      "The MSE loss is : 0.23922781646251678\n",
      "The MSE loss is : 0.2389914095401764\n",
      "The MSE loss is : 0.2387966513633728\n",
      "The MSE loss is : 0.23866453766822815\n",
      "The MSE loss is : 0.23854273557662964\n",
      "The MSE loss is : 0.23843783140182495\n",
      "The MSE loss is : 0.23836874961853027\n",
      "The MSE loss is : 0.23832449316978455\n",
      "The MSE loss is : 0.2382439374923706\n",
      "The MSE loss is : 0.2381821572780609\n",
      "The MSE loss is : 0.2381206601858139\n",
      "The MSE loss is : 0.23808425664901733\n",
      "The MSE loss is : 0.2380482256412506\n",
      "The MSE loss is : 0.2380237579345703\n",
      "The MSE loss is : 0.23797178268432617\n",
      "The MSE loss is : 0.23794300854206085\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=963\n",
      "The MSE loss is : 0.33430367708206177\n",
      "The MSE loss is : 0.32424798607826233\n",
      "The MSE loss is : 0.3236672282218933\n",
      "The MSE loss is : 0.3234800696372986\n",
      "The MSE loss is : 0.3234129846096039\n",
      "The MSE loss is : 0.32334819436073303\n",
      "The MSE loss is : 0.3233320116996765\n",
      "The MSE loss is : 0.3233221173286438\n",
      "The MSE loss is : 0.32331255078315735\n",
      "The MSE loss is : 0.32331255078315735\n",
      "The MSE loss is : 0.32331255078315735\n",
      "The MSE loss is : 0.32331255078315735\n",
      "The MSE loss is : 0.32331255078315735\n",
      "The MSE loss is : 0.32331255078315735\n",
      "The MSE loss is : 0.32331255078315735\n",
      "The MSE loss is : 0.32331255078315735\n",
      "The MSE loss is : 0.32331255078315735\n",
      "The MSE loss is : 0.32331255078315735\n",
      "The MSE loss is : 0.32331255078315735\n",
      "The MSE loss is : 0.32331255078315735\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.33430367708206177\n",
      "The MSE loss is : 0.303809255361557\n",
      "The MSE loss is : 0.303308367729187\n",
      "The MSE loss is : 0.3032439351081848\n",
      "The MSE loss is : 0.3032197952270508\n",
      "The MSE loss is : 0.30321958661079407\n",
      "The MSE loss is : 0.30320513248443604\n",
      "The MSE loss is : 0.3032051622867584\n",
      "The MSE loss is : 0.30320513248443604\n",
      "The MSE loss is : 0.3032051622867584\n",
      "The MSE loss is : 0.3032051622867584\n",
      "The MSE loss is : 0.3032051622867584\n",
      "The MSE loss is : 0.3032051622867584\n",
      "The MSE loss is : 0.3032051622867584\n",
      "The MSE loss is : 0.3032051622867584\n",
      "The MSE loss is : 0.3032051622867584\n",
      "The MSE loss is : 0.3032051622867584\n",
      "The MSE loss is : 0.3032051622867584\n",
      "The MSE loss is : 0.3032051622867584\n",
      "The MSE loss is : 0.3032051622867584\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.33430367708206177\n",
      "The MSE loss is : 0.29641884565353394\n",
      "The MSE loss is : 0.29628878831863403\n",
      "The MSE loss is : 0.29628491401672363\n",
      "The MSE loss is : 0.29628390073776245\n",
      "The MSE loss is : 0.29628390073776245\n",
      "The MSE loss is : 0.29628387093544006\n",
      "The MSE loss is : 0.29628387093544006\n",
      "The MSE loss is : 0.29628387093544006\n",
      "The MSE loss is : 0.29628387093544006\n",
      "The MSE loss is : 0.29628387093544006\n",
      "The MSE loss is : 0.29628387093544006\n",
      "The MSE loss is : 0.29628387093544006\n",
      "The MSE loss is : 0.29628390073776245\n",
      "The MSE loss is : 0.29628390073776245\n",
      "The MSE loss is : 0.29628387093544006\n",
      "The MSE loss is : 0.29628387093544006\n",
      "The MSE loss is : 0.29628390073776245\n",
      "The MSE loss is : 0.29628387093544006\n",
      "The MSE loss is : 0.29628387093544006\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34303462505340576\n",
      "The MSE loss is : 0.24865341186523438\n",
      "The MSE loss is : 0.2435859590768814\n",
      "The MSE loss is : 0.24165493249893188\n",
      "The MSE loss is : 0.24050816893577576\n",
      "The MSE loss is : 0.23985421657562256\n",
      "The MSE loss is : 0.23924556374549866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.23888251185417175\n",
      "The MSE loss is : 0.23873570561408997\n",
      "The MSE loss is : 0.2385813295841217\n",
      "The MSE loss is : 0.23837792873382568\n",
      "The MSE loss is : 0.23827508091926575\n",
      "The MSE loss is : 0.23819948732852936\n",
      "The MSE loss is : 0.2381400465965271\n",
      "The MSE loss is : 0.23812104761600494\n",
      "The MSE loss is : 0.23811529576778412\n",
      "The MSE loss is : 0.23811423778533936\n",
      "The MSE loss is : 0.23810191452503204\n",
      "The MSE loss is : 0.23805217444896698\n",
      "The MSE loss is : 0.2380077987909317\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.3343338370323181\n",
      "The MSE loss is : 0.24191859364509583\n",
      "The MSE loss is : 0.24052809178829193\n",
      "The MSE loss is : 0.23994970321655273\n",
      "The MSE loss is : 0.23957128822803497\n",
      "The MSE loss is : 0.23929941654205322\n",
      "The MSE loss is : 0.239085391163826\n",
      "The MSE loss is : 0.23895803093910217\n",
      "The MSE loss is : 0.23885370790958405\n",
      "The MSE loss is : 0.23876887559890747\n",
      "The MSE loss is : 0.23868012428283691\n",
      "The MSE loss is : 0.23860609531402588\n",
      "The MSE loss is : 0.238521009683609\n",
      "The MSE loss is : 0.23846285045146942\n",
      "The MSE loss is : 0.23840181529521942\n",
      "The MSE loss is : 0.23836424946784973\n",
      "The MSE loss is : 0.23832447826862335\n",
      "The MSE loss is : 0.23830482363700867\n",
      "The MSE loss is : 0.23827244341373444\n",
      "The MSE loss is : 0.23826183378696442\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=159\n",
      "The MSE loss is : 0.3346775472164154\n",
      "The MSE loss is : 0.32455378770828247\n",
      "The MSE loss is : 0.3239768147468567\n",
      "The MSE loss is : 0.32383185625076294\n",
      "The MSE loss is : 0.32374951243400574\n",
      "The MSE loss is : 0.3236733376979828\n",
      "The MSE loss is : 0.32359084486961365\n",
      "The MSE loss is : 0.32350611686706543\n",
      "The MSE loss is : 0.32349956035614014\n",
      "The MSE loss is : 0.3234938383102417\n",
      "The MSE loss is : 0.3234938383102417\n",
      "The MSE loss is : 0.3234938383102417\n",
      "The MSE loss is : 0.3234938383102417\n",
      "The MSE loss is : 0.3234938383102417\n",
      "The MSE loss is : 0.3234938383102417\n",
      "The MSE loss is : 0.3234938383102417\n",
      "The MSE loss is : 0.3234938383102417\n",
      "The MSE loss is : 0.3234938383102417\n",
      "The MSE loss is : 0.3234938383102417\n",
      "The MSE loss is : 0.3234938383102417\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.3346775472164154\n",
      "The MSE loss is : 0.3040618598461151\n",
      "The MSE loss is : 0.3036150634288788\n",
      "The MSE loss is : 0.30356842279434204\n",
      "The MSE loss is : 0.3035401701927185\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "The MSE loss is : 0.3035363554954529\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.3346775472164154\n",
      "The MSE loss is : 0.2968142628669739\n",
      "The MSE loss is : 0.29667866230010986\n",
      "The MSE loss is : 0.2966744303703308\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "The MSE loss is : 0.2966741919517517\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34379130601882935\n",
      "The MSE loss is : 0.24876464903354645\n",
      "The MSE loss is : 0.2437538206577301\n",
      "The MSE loss is : 0.2418856918811798\n",
      "The MSE loss is : 0.24089443683624268\n",
      "The MSE loss is : 0.24030938744544983\n",
      "The MSE loss is : 0.2398211508989334\n",
      "The MSE loss is : 0.23946909606456757\n",
      "The MSE loss is : 0.23925618827342987\n",
      "The MSE loss is : 0.23907676339149475\n",
      "The MSE loss is : 0.2389705777168274\n",
      "The MSE loss is : 0.23885954916477203\n",
      "The MSE loss is : 0.2387513965368271\n",
      "The MSE loss is : 0.23868219554424286\n",
      "The MSE loss is : 0.2386155128479004\n",
      "The MSE loss is : 0.2385542392730713\n",
      "The MSE loss is : 0.2385149598121643\n",
      "The MSE loss is : 0.23845545947551727\n",
      "The MSE loss is : 0.23842555284500122\n",
      "The MSE loss is : 0.2384181022644043\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.33474600315093994\n",
      "The MSE loss is : 0.24230393767356873\n",
      "The MSE loss is : 0.24064628779888153\n",
      "The MSE loss is : 0.23998594284057617\n",
      "The MSE loss is : 0.23962022364139557\n",
      "The MSE loss is : 0.2393801063299179\n",
      "The MSE loss is : 0.23917442560195923\n",
      "The MSE loss is : 0.23904383182525635\n",
      "The MSE loss is : 0.23897784948349\n",
      "The MSE loss is : 0.2389206439256668\n",
      "The MSE loss is : 0.23884400725364685\n",
      "The MSE loss is : 0.23876053094863892\n",
      "The MSE loss is : 0.23872406780719757\n",
      "The MSE loss is : 0.238677516579628\n",
      "The MSE loss is : 0.23862752318382263\n",
      "The MSE loss is : 0.23858210444450378\n",
      "The MSE loss is : 0.2385530322790146\n",
      "The MSE loss is : 0.2385350465774536\n",
      "The MSE loss is : 0.23850971460342407\n",
      "The MSE loss is : 0.23849016427993774\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=357\n",
      "The MSE loss is : 0.33426403999328613\n",
      "The MSE loss is : 0.3241087794303894\n",
      "The MSE loss is : 0.3235016465187073\n",
      "The MSE loss is : 0.3232976198196411\n",
      "The MSE loss is : 0.32320255041122437\n",
      "The MSE loss is : 0.323153018951416\n",
      "The MSE loss is : 0.32314130663871765\n",
      "The MSE loss is : 0.32313770055770874\n",
      "The MSE loss is : 0.32313722372055054\n",
      "The MSE loss is : 0.3231372535228729\n",
      "The MSE loss is : 0.32313722372055054\n",
      "The MSE loss is : 0.32313722372055054\n",
      "The MSE loss is : 0.32313722372055054\n",
      "The MSE loss is : 0.3231372535228729\n",
      "The MSE loss is : 0.3231372535228729\n",
      "The MSE loss is : 0.3231372535228729\n",
      "The MSE loss is : 0.32313722372055054\n",
      "The MSE loss is : 0.3231372535228729\n",
      "The MSE loss is : 0.3231372535228729\n",
      "The MSE loss is : 0.3231372535228729\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.33426403999328613\n",
      "The MSE loss is : 0.30376094579696655\n",
      "The MSE loss is : 0.30327990651130676\n",
      "The MSE loss is : 0.30317679047584534\n",
      "The MSE loss is : 0.3031485378742218\n",
      "The MSE loss is : 0.3031480312347412\n",
      "The MSE loss is : 0.3031480312347412\n",
      "The MSE loss is : 0.30314797163009644\n",
      "The MSE loss is : 0.30314794182777405\n",
      "The MSE loss is : 0.30314794182777405\n",
      "The MSE loss is : 0.30314794182777405\n",
      "The MSE loss is : 0.30314794182777405\n",
      "The MSE loss is : 0.30314794182777405\n",
      "The MSE loss is : 0.30314794182777405\n",
      "The MSE loss is : 0.30314794182777405\n",
      "The MSE loss is : 0.30314794182777405\n",
      "The MSE loss is : 0.30314794182777405\n",
      "The MSE loss is : 0.30314794182777405\n",
      "The MSE loss is : 0.30314794182777405\n",
      "The MSE loss is : 0.30314794182777405\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.33426403999328613\n",
      "The MSE loss is : 0.2963927984237671\n",
      "The MSE loss is : 0.29624712467193604\n",
      "The MSE loss is : 0.2962416410446167\n",
      "The MSE loss is : 0.29624098539352417\n",
      "The MSE loss is : 0.2962408661842346\n",
      "The MSE loss is : 0.29624083638191223\n",
      "The MSE loss is : 0.29624083638191223\n",
      "The MSE loss is : 0.29624080657958984\n",
      "The MSE loss is : 0.29624083638191223\n",
      "The MSE loss is : 0.29624080657958984\n",
      "The MSE loss is : 0.29624083638191223\n",
      "The MSE loss is : 0.29624083638191223\n",
      "The MSE loss is : 0.29624083638191223\n",
      "The MSE loss is : 0.29624083638191223\n",
      "The MSE loss is : 0.29624083638191223\n",
      "The MSE loss is : 0.29624083638191223\n",
      "The MSE loss is : 0.29624083638191223\n",
      "The MSE loss is : 0.29624083638191223\n",
      "The MSE loss is : 0.29624083638191223\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34316784143447876\n",
      "The MSE loss is : 0.24868255853652954\n",
      "The MSE loss is : 0.24357390403747559\n",
      "The MSE loss is : 0.2417854517698288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.24067652225494385\n",
      "The MSE loss is : 0.23997677862644196\n",
      "The MSE loss is : 0.23954518139362335\n",
      "The MSE loss is : 0.23922672867774963\n",
      "The MSE loss is : 0.2389223575592041\n",
      "The MSE loss is : 0.2387000322341919\n",
      "The MSE loss is : 0.2384951412677765\n",
      "The MSE loss is : 0.23837873339653015\n",
      "The MSE loss is : 0.23833446204662323\n",
      "The MSE loss is : 0.23829388618469238\n",
      "The MSE loss is : 0.23826435208320618\n",
      "The MSE loss is : 0.23822703957557678\n",
      "The MSE loss is : 0.23818735778331757\n",
      "The MSE loss is : 0.23816338181495667\n",
      "The MSE loss is : 0.23814606666564941\n",
      "The MSE loss is : 0.23813439905643463\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.3342505097389221\n",
      "The MSE loss is : 0.2419847697019577\n",
      "The MSE loss is : 0.24023570120334625\n",
      "The MSE loss is : 0.239616259932518\n",
      "The MSE loss is : 0.23927196860313416\n",
      "The MSE loss is : 0.2390117347240448\n",
      "The MSE loss is : 0.23883455991744995\n",
      "The MSE loss is : 0.23867499828338623\n",
      "The MSE loss is : 0.23856410384178162\n",
      "The MSE loss is : 0.23847632110118866\n",
      "The MSE loss is : 0.23839928209781647\n",
      "The MSE loss is : 0.23834413290023804\n",
      "The MSE loss is : 0.2382661998271942\n",
      "The MSE loss is : 0.2382132112979889\n",
      "The MSE loss is : 0.23814402520656586\n",
      "The MSE loss is : 0.2381305694580078\n",
      "The MSE loss is : 0.23807738721370697\n",
      "The MSE loss is : 0.23802293837070465\n",
      "The MSE loss is : 0.2380077987909317\n",
      "The MSE loss is : 0.23797212541103363\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=951\n",
      "The MSE loss is : 0.3343609571456909\n",
      "The MSE loss is : 0.32424312829971313\n",
      "The MSE loss is : 0.3237766623497009\n",
      "The MSE loss is : 0.32353097200393677\n",
      "The MSE loss is : 0.3234405219554901\n",
      "The MSE loss is : 0.32339799404144287\n",
      "The MSE loss is : 0.3233449459075928\n",
      "The MSE loss is : 0.3233277499675751\n",
      "The MSE loss is : 0.32332539558410645\n",
      "The MSE loss is : 0.32332056760787964\n",
      "The MSE loss is : 0.32332056760787964\n",
      "The MSE loss is : 0.32332056760787964\n",
      "The MSE loss is : 0.32332056760787964\n",
      "The MSE loss is : 0.32332056760787964\n",
      "The MSE loss is : 0.32332056760787964\n",
      "The MSE loss is : 0.32332056760787964\n",
      "The MSE loss is : 0.32332056760787964\n",
      "The MSE loss is : 0.32332056760787964\n",
      "The MSE loss is : 0.32332056760787964\n",
      "The MSE loss is : 0.32332056760787964\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.3343609571456909\n",
      "The MSE loss is : 0.30375605821609497\n",
      "The MSE loss is : 0.3033792972564697\n",
      "The MSE loss is : 0.3032832443714142\n",
      "The MSE loss is : 0.3032572567462921\n",
      "The MSE loss is : 0.3032539486885071\n",
      "The MSE loss is : 0.30325332283973694\n",
      "The MSE loss is : 0.3032533526420593\n",
      "The MSE loss is : 0.30325332283973694\n",
      "The MSE loss is : 0.3032533526420593\n",
      "The MSE loss is : 0.3032533526420593\n",
      "The MSE loss is : 0.30325332283973694\n",
      "The MSE loss is : 0.3032533526420593\n",
      "The MSE loss is : 0.3032533526420593\n",
      "The MSE loss is : 0.3032533526420593\n",
      "The MSE loss is : 0.3032533526420593\n",
      "The MSE loss is : 0.3032533526420593\n",
      "The MSE loss is : 0.3032533526420593\n",
      "The MSE loss is : 0.3032533526420593\n",
      "The MSE loss is : 0.3032533526420593\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.3343609571456909\n",
      "The MSE loss is : 0.2966626286506653\n",
      "The MSE loss is : 0.29650992155075073\n",
      "The MSE loss is : 0.29650330543518066\n",
      "The MSE loss is : 0.2965024411678314\n",
      "The MSE loss is : 0.2965022921562195\n",
      "The MSE loss is : 0.2965022623538971\n",
      "The MSE loss is : 0.2965022325515747\n",
      "The MSE loss is : 0.2965022623538971\n",
      "The MSE loss is : 0.2965022623538971\n",
      "The MSE loss is : 0.2965022623538971\n",
      "The MSE loss is : 0.2965022623538971\n",
      "The MSE loss is : 0.2965022623538971\n",
      "The MSE loss is : 0.2965022623538971\n",
      "The MSE loss is : 0.2965022623538971\n",
      "The MSE loss is : 0.2965022623538971\n",
      "The MSE loss is : 0.2965022623538971\n",
      "The MSE loss is : 0.2965022623538971\n",
      "The MSE loss is : 0.2965022623538971\n",
      "The MSE loss is : 0.2965022623538971\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.3431253433227539\n",
      "The MSE loss is : 0.24867722392082214\n",
      "The MSE loss is : 0.24342234432697296\n",
      "The MSE loss is : 0.24156847596168518\n",
      "The MSE loss is : 0.24062037467956543\n",
      "The MSE loss is : 0.23989591002464294\n",
      "The MSE loss is : 0.239516943693161\n",
      "The MSE loss is : 0.23921464383602142\n",
      "The MSE loss is : 0.23899471759796143\n",
      "The MSE loss is : 0.23875561356544495\n",
      "The MSE loss is : 0.23859825730323792\n",
      "The MSE loss is : 0.23846332728862762\n",
      "The MSE loss is : 0.2384207546710968\n",
      "The MSE loss is : 0.23833604156970978\n",
      "The MSE loss is : 0.23827233910560608\n",
      "The MSE loss is : 0.23823994398117065\n",
      "The MSE loss is : 0.2382221817970276\n",
      "The MSE loss is : 0.23820558190345764\n",
      "The MSE loss is : 0.23817531764507294\n",
      "The MSE loss is : 0.23817205429077148\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.3344425857067108\n",
      "The MSE loss is : 0.24195435643196106\n",
      "The MSE loss is : 0.24034525454044342\n",
      "The MSE loss is : 0.2397042214870453\n",
      "The MSE loss is : 0.2393648326396942\n",
      "The MSE loss is : 0.23912017047405243\n",
      "The MSE loss is : 0.2389438897371292\n",
      "The MSE loss is : 0.23880387842655182\n",
      "The MSE loss is : 0.23869338631629944\n",
      "The MSE loss is : 0.2385859191417694\n",
      "The MSE loss is : 0.238530695438385\n",
      "The MSE loss is : 0.2384900003671646\n",
      "The MSE loss is : 0.23842386901378632\n",
      "The MSE loss is : 0.23836974799633026\n",
      "The MSE loss is : 0.23834052681922913\n",
      "The MSE loss is : 0.2382902204990387\n",
      "The MSE loss is : 0.23826555907726288\n",
      "The MSE loss is : 0.23823291063308716\n",
      "The MSE loss is : 0.23821046948432922\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=753\n",
      "The MSE loss is : 0.33425450325012207\n",
      "The MSE loss is : 0.32413527369499207\n",
      "The MSE loss is : 0.32356375455856323\n",
      "The MSE loss is : 0.32335343956947327\n",
      "The MSE loss is : 0.3232828378677368\n",
      "The MSE loss is : 0.3232150673866272\n",
      "The MSE loss is : 0.3231915533542633\n",
      "The MSE loss is : 0.32315757870674133\n",
      "The MSE loss is : 0.3231489062309265\n",
      "The MSE loss is : 0.3231486976146698\n",
      "The MSE loss is : 0.3231486976146698\n",
      "The MSE loss is : 0.3231486678123474\n",
      "The MSE loss is : 0.3231486976146698\n",
      "The MSE loss is : 0.3231486678123474\n",
      "The MSE loss is : 0.3231486678123474\n",
      "The MSE loss is : 0.3231486678123474\n",
      "The MSE loss is : 0.3231486678123474\n",
      "The MSE loss is : 0.3231486678123474\n",
      "The MSE loss is : 0.3231486678123474\n",
      "The MSE loss is : 0.3231486976146698\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.33425450325012207\n",
      "The MSE loss is : 0.30375057458877563\n",
      "The MSE loss is : 0.3033630847930908\n",
      "The MSE loss is : 0.30329403281211853\n",
      "The MSE loss is : 0.30327945947647095\n",
      "The MSE loss is : 0.30326610803604126\n",
      "The MSE loss is : 0.3032638430595398\n",
      "The MSE loss is : 0.3032638430595398\n",
      "The MSE loss is : 0.3032638430595398\n",
      "The MSE loss is : 0.3032638430595398\n",
      "The MSE loss is : 0.3032638430595398\n",
      "The MSE loss is : 0.3032638430595398\n",
      "The MSE loss is : 0.3032638430595398\n",
      "The MSE loss is : 0.3032638430595398\n",
      "The MSE loss is : 0.3032638430595398\n",
      "The MSE loss is : 0.3032638430595398\n",
      "The MSE loss is : 0.3032638430595398\n",
      "The MSE loss is : 0.3032638430595398\n",
      "The MSE loss is : 0.3032638430595398\n",
      "The MSE loss is : 0.3032638430595398\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.33425450325012207\n",
      "The MSE loss is : 0.29636338353157043\n",
      "The MSE loss is : 0.29622602462768555\n",
      "The MSE loss is : 0.29621967673301697\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "The MSE loss is : 0.2962195873260498\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34311458468437195\n",
      "The MSE loss is : 0.24859613180160522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.24348050355911255\n",
      "The MSE loss is : 0.24151992797851562\n",
      "The MSE loss is : 0.240486279129982\n",
      "The MSE loss is : 0.2398311346769333\n",
      "The MSE loss is : 0.2393900752067566\n",
      "The MSE loss is : 0.23911970853805542\n",
      "The MSE loss is : 0.23894217610359192\n",
      "The MSE loss is : 0.23876596987247467\n",
      "The MSE loss is : 0.2386452555656433\n",
      "The MSE loss is : 0.23853203654289246\n",
      "The MSE loss is : 0.23846158385276794\n",
      "The MSE loss is : 0.2383832335472107\n",
      "The MSE loss is : 0.2382993847131729\n",
      "The MSE loss is : 0.23824942111968994\n",
      "The MSE loss is : 0.23819899559020996\n",
      "The MSE loss is : 0.23815178871154785\n",
      "The MSE loss is : 0.23812557756900787\n",
      "The MSE loss is : 0.23810677230358124\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.3342490494251251\n",
      "The MSE loss is : 0.24181880056858063\n",
      "The MSE loss is : 0.2401392161846161\n",
      "The MSE loss is : 0.239535853266716\n",
      "The MSE loss is : 0.23919445276260376\n",
      "The MSE loss is : 0.23897197842597961\n",
      "The MSE loss is : 0.23878422379493713\n",
      "The MSE loss is : 0.23868370056152344\n",
      "The MSE loss is : 0.23856553435325623\n",
      "The MSE loss is : 0.238489031791687\n",
      "The MSE loss is : 0.23838192224502563\n",
      "The MSE loss is : 0.23829910159111023\n",
      "The MSE loss is : 0.2382439225912094\n",
      "The MSE loss is : 0.23817528784275055\n",
      "The MSE loss is : 0.2381429374217987\n",
      "The MSE loss is : 0.23810617625713348\n",
      "The MSE loss is : 0.23807552456855774\n",
      "The MSE loss is : 0.23802363872528076\n",
      "The MSE loss is : 0.23799866437911987\n",
      "The MSE loss is : 0.23794355988502502\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=4096 SEED=147\n",
      "The MSE loss is : 0.3335611820220947\n",
      "The MSE loss is : 0.3304746747016907\n",
      "The MSE loss is : 0.3302306532859802\n",
      "The MSE loss is : 0.33015069365501404\n",
      "The MSE loss is : 0.33011242747306824\n",
      "The MSE loss is : 0.3300848603248596\n",
      "The MSE loss is : 0.3300665616989136\n",
      "The MSE loss is : 0.3300548791885376\n",
      "The MSE loss is : 0.33004599809646606\n",
      "The MSE loss is : 0.3300381898880005\n",
      "The MSE loss is : 0.33003178238868713\n",
      "The MSE loss is : 0.3300265669822693\n",
      "The MSE loss is : 0.33002185821533203\n",
      "The MSE loss is : 0.3300183415412903\n",
      "The MSE loss is : 0.33001530170440674\n",
      "The MSE loss is : 0.3300113081932068\n",
      "The MSE loss is : 0.33000868558883667\n",
      "The MSE loss is : 0.33000612258911133\n",
      "The MSE loss is : 0.3300042748451233\n",
      "The MSE loss is : 0.3300030827522278\n",
      "Saving... file:record_err_4096 method:pair\n",
      "The MSE loss is : 0.3335611820220947\n",
      "The MSE loss is : 0.31779569387435913\n",
      "The MSE loss is : 0.3175411820411682\n",
      "The MSE loss is : 0.3174707293510437\n",
      "The MSE loss is : 0.3174399733543396\n",
      "The MSE loss is : 0.31742388010025024\n",
      "The MSE loss is : 0.31741416454315186\n",
      "The MSE loss is : 0.3174099922180176\n",
      "The MSE loss is : 0.31740790605545044\n",
      "The MSE loss is : 0.3174060583114624\n",
      "The MSE loss is : 0.3174056112766266\n",
      "The MSE loss is : 0.31740471720695496\n",
      "The MSE loss is : 0.31740421056747437\n",
      "The MSE loss is : 0.3174038529396057\n",
      "The MSE loss is : 0.3174034655094147\n",
      "The MSE loss is : 0.3174031376838684\n",
      "The MSE loss is : 0.31740307807922363\n",
      "The MSE loss is : 0.31740280985832214\n",
      "The MSE loss is : 0.31740280985832214\n",
      "The MSE loss is : 0.317402720451355\n",
      "Saving... file:record_err_4096 method:block-sqrt-half\n",
      "The MSE loss is : 0.3335611820220947\n",
      "The MSE loss is : 0.31403595209121704\n",
      "The MSE loss is : 0.3139147162437439\n",
      "The MSE loss is : 0.3139057755470276\n",
      "The MSE loss is : 0.3139042258262634\n",
      "The MSE loss is : 0.31390389800071716\n",
      "The MSE loss is : 0.31390380859375\n",
      "The MSE loss is : 0.31390380859375\n",
      "The MSE loss is : 0.3139037787914276\n",
      "The MSE loss is : 0.3139037489891052\n",
      "The MSE loss is : 0.3139037787914276\n",
      "The MSE loss is : 0.3139037787914276\n",
      "The MSE loss is : 0.3139037489891052\n",
      "The MSE loss is : 0.3139037787914276\n",
      "The MSE loss is : 0.3139037787914276\n",
      "The MSE loss is : 0.3139037489891052\n",
      "The MSE loss is : 0.3139037489891052\n",
      "The MSE loss is : 0.3139037489891052\n",
      "The MSE loss is : 0.3139037787914276\n",
      "The MSE loss is : 0.3139037787914276\n",
      "Saving... file:record_err_4096 method:block-sqrt\n",
      "Saving... file:record_err_4096 method:lowR-same-param\n",
      "Saving... file:record_err_4096 method:lowR-samex2\n",
      "Saving... file:record_err_4096 method:lowR-half\n",
      "\n",
      "Experiment N=4096 SEED=258\n",
      "The MSE loss is : 0.3335675597190857\n",
      "The MSE loss is : 0.3304841220378876\n",
      "The MSE loss is : 0.3302519917488098\n",
      "The MSE loss is : 0.3301750421524048\n",
      "The MSE loss is : 0.3301287889480591\n",
      "The MSE loss is : 0.33010250329971313\n",
      "The MSE loss is : 0.3300849199295044\n",
      "The MSE loss is : 0.3300743103027344\n",
      "The MSE loss is : 0.3300633728504181\n",
      "The MSE loss is : 0.3300558924674988\n",
      "The MSE loss is : 0.3300509452819824\n",
      "The MSE loss is : 0.3300468325614929\n",
      "The MSE loss is : 0.3300424814224243\n",
      "The MSE loss is : 0.3300393223762512\n",
      "The MSE loss is : 0.33003664016723633\n",
      "The MSE loss is : 0.3300352096557617\n",
      "The MSE loss is : 0.33003389835357666\n",
      "The MSE loss is : 0.3300320506095886\n",
      "The MSE loss is : 0.33003073930740356\n",
      "The MSE loss is : 0.3300299644470215\n",
      "Saving... file:record_err_4096 method:pair\n",
      "The MSE loss is : 0.3335675597190857\n",
      "The MSE loss is : 0.31777793169021606\n",
      "The MSE loss is : 0.31751832365989685\n",
      "The MSE loss is : 0.3174535930156708\n",
      "The MSE loss is : 0.31742727756500244\n",
      "The MSE loss is : 0.31741470098495483\n",
      "The MSE loss is : 0.31740865111351013\n",
      "The MSE loss is : 0.317404568195343\n",
      "The MSE loss is : 0.31740251183509827\n",
      "The MSE loss is : 0.3174011707305908\n",
      "The MSE loss is : 0.3173999786376953\n",
      "The MSE loss is : 0.31739866733551025\n",
      "The MSE loss is : 0.31739699840545654\n",
      "The MSE loss is : 0.31739673018455505\n",
      "The MSE loss is : 0.31739670038223267\n",
      "The MSE loss is : 0.3173964023590088\n",
      "The MSE loss is : 0.3173963725566864\n",
      "The MSE loss is : 0.3173961639404297\n",
      "The MSE loss is : 0.3173961639404297\n",
      "The MSE loss is : 0.3173961639404297\n",
      "Saving... file:record_err_4096 method:block-sqrt-half\n",
      "The MSE loss is : 0.3335675597190857\n",
      "The MSE loss is : 0.314068466424942\n",
      "The MSE loss is : 0.31393828988075256\n",
      "The MSE loss is : 0.313928484916687\n",
      "The MSE loss is : 0.3139269948005676\n",
      "The MSE loss is : 0.3139267861843109\n",
      "The MSE loss is : 0.31392669677734375\n",
      "The MSE loss is : 0.313926637172699\n",
      "The MSE loss is : 0.313926637172699\n",
      "The MSE loss is : 0.3139266073703766\n",
      "The MSE loss is : 0.3139266073703766\n",
      "The MSE loss is : 0.3139266073703766\n",
      "The MSE loss is : 0.3139266073703766\n",
      "The MSE loss is : 0.3139265775680542\n",
      "The MSE loss is : 0.3139266073703766\n",
      "The MSE loss is : 0.3139265775680542\n",
      "The MSE loss is : 0.3139265775680542\n",
      "The MSE loss is : 0.3139265775680542\n",
      "The MSE loss is : 0.3139265775680542\n",
      "The MSE loss is : 0.3139266073703766\n",
      "Saving... file:record_err_4096 method:block-sqrt\n",
      "Saving... file:record_err_4096 method:lowR-same-param\n",
      "Saving... file:record_err_4096 method:lowR-samex2\n",
      "Saving... file:record_err_4096 method:lowR-half\n",
      "\n",
      "Experiment N=4096 SEED=369\n",
      "The MSE loss is : 0.33348625898361206\n",
      "The MSE loss is : 0.3303873538970947\n",
      "The MSE loss is : 0.33017027378082275\n",
      "The MSE loss is : 0.33009132742881775\n",
      "The MSE loss is : 0.33004552125930786\n",
      "The MSE loss is : 0.3300183415412903\n",
      "The MSE loss is : 0.32999980449676514\n",
      "The MSE loss is : 0.3299863338470459\n",
      "The MSE loss is : 0.3299795091152191\n",
      "The MSE loss is : 0.3299753665924072\n",
      "The MSE loss is : 0.3299705684185028\n",
      "The MSE loss is : 0.32996636629104614\n",
      "The MSE loss is : 0.32996219396591187\n",
      "The MSE loss is : 0.3299582302570343\n",
      "The MSE loss is : 0.32995519042015076\n",
      "The MSE loss is : 0.32995301485061646\n",
      "The MSE loss is : 0.32995057106018066\n",
      "The MSE loss is : 0.32994896173477173\n",
      "The MSE loss is : 0.3299463987350464\n",
      "The MSE loss is : 0.32994344830513\n",
      "Saving... file:record_err_4096 method:pair\n",
      "The MSE loss is : 0.33348625898361206\n",
      "The MSE loss is : 0.3177136778831482\n",
      "The MSE loss is : 0.31744974851608276\n",
      "The MSE loss is : 0.3173849582672119\n",
      "The MSE loss is : 0.3173542022705078\n",
      "The MSE loss is : 0.3173395097255707\n",
      "The MSE loss is : 0.31733226776123047\n",
      "The MSE loss is : 0.3173291087150574\n",
      "The MSE loss is : 0.31732749938964844\n",
      "The MSE loss is : 0.3173266053199768\n",
      "The MSE loss is : 0.3173258304595947\n",
      "The MSE loss is : 0.3173254132270813\n",
      "The MSE loss is : 0.3173251748085022\n",
      "The MSE loss is : 0.3173249363899231\n",
      "The MSE loss is : 0.3173249363899231\n",
      "The MSE loss is : 0.3173249363899231\n",
      "The MSE loss is : 0.3173249661922455\n",
      "The MSE loss is : 0.3173249363899231\n",
      "The MSE loss is : 0.3173249363899231\n",
      "The MSE loss is : 0.3173249363899231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving... file:record_err_4096 method:block-sqrt-half\n",
      "The MSE loss is : 0.33348625898361206\n",
      "The MSE loss is : 0.31396129727363586\n",
      "The MSE loss is : 0.3138315975666046\n",
      "The MSE loss is : 0.3138234317302704\n",
      "The MSE loss is : 0.3138222396373749\n",
      "The MSE loss is : 0.3138219118118286\n",
      "The MSE loss is : 0.31382179260253906\n",
      "The MSE loss is : 0.3138217329978943\n",
      "The MSE loss is : 0.3138216733932495\n",
      "The MSE loss is : 0.3138216733932495\n",
      "The MSE loss is : 0.3138216733932495\n",
      "The MSE loss is : 0.3138216733932495\n",
      "The MSE loss is : 0.3138216733932495\n",
      "The MSE loss is : 0.3138216733932495\n",
      "The MSE loss is : 0.3138216733932495\n",
      "The MSE loss is : 0.3138216733932495\n",
      "The MSE loss is : 0.3138216733932495\n",
      "The MSE loss is : 0.3138216733932495\n",
      "The MSE loss is : 0.3138216733932495\n",
      "The MSE loss is : 0.3138216733932495\n",
      "Saving... file:record_err_4096 method:block-sqrt\n",
      "Saving... file:record_err_4096 method:lowR-same-param\n",
      "Saving... file:record_err_4096 method:lowR-samex2\n",
      "Saving... file:record_err_4096 method:lowR-half\n",
      "\n",
      "Experiment N=4096 SEED=321\n",
      "The MSE loss is : 0.33357536792755127\n",
      "The MSE loss is : 0.33048486709594727\n",
      "The MSE loss is : 0.33025574684143066\n",
      "The MSE loss is : 0.3301788568496704\n",
      "The MSE loss is : 0.3301351070404053\n",
      "The MSE loss is : 0.3301074504852295\n",
      "The MSE loss is : 0.3300935626029968\n",
      "The MSE loss is : 0.33008134365081787\n",
      "The MSE loss is : 0.33007389307022095\n",
      "The MSE loss is : 0.3300682306289673\n",
      "The MSE loss is : 0.33006325364112854\n",
      "The MSE loss is : 0.3300594091415405\n",
      "The MSE loss is : 0.330055296421051\n",
      "The MSE loss is : 0.3300505578517914\n",
      "The MSE loss is : 0.33004677295684814\n",
      "The MSE loss is : 0.33004289865493774\n",
      "The MSE loss is : 0.33004122972488403\n",
      "The MSE loss is : 0.33003944158554077\n",
      "The MSE loss is : 0.3300381600856781\n",
      "The MSE loss is : 0.33003735542297363\n",
      "Saving... file:record_err_4096 method:pair\n",
      "The MSE loss is : 0.33357536792755127\n",
      "The MSE loss is : 0.31780552864074707\n",
      "The MSE loss is : 0.31753870844841003\n",
      "The MSE loss is : 0.3174736201763153\n",
      "The MSE loss is : 0.317447692155838\n",
      "The MSE loss is : 0.3174334764480591\n",
      "The MSE loss is : 0.31742626428604126\n",
      "The MSE loss is : 0.3174215853214264\n",
      "The MSE loss is : 0.31741827726364136\n",
      "The MSE loss is : 0.3174164295196533\n",
      "The MSE loss is : 0.31741586327552795\n",
      "The MSE loss is : 0.3174155354499817\n",
      "The MSE loss is : 0.31741446256637573\n",
      "The MSE loss is : 0.31741422414779663\n",
      "The MSE loss is : 0.31741398572921753\n",
      "The MSE loss is : 0.31741389632225037\n",
      "The MSE loss is : 0.3174138367176056\n",
      "The MSE loss is : 0.3174138367176056\n",
      "The MSE loss is : 0.3174138367176056\n",
      "The MSE loss is : 0.3174138069152832\n",
      "Saving... file:record_err_4096 method:block-sqrt-half\n",
      "The MSE loss is : 0.33357536792755127\n",
      "The MSE loss is : 0.3140749931335449\n",
      "The MSE loss is : 0.31394702196121216\n",
      "The MSE loss is : 0.3139372766017914\n",
      "The MSE loss is : 0.3139355778694153\n",
      "The MSE loss is : 0.31393516063690186\n",
      "The MSE loss is : 0.3139350116252899\n",
      "The MSE loss is : 0.31393495202064514\n",
      "The MSE loss is : 0.31393498182296753\n",
      "The MSE loss is : 0.31393495202064514\n",
      "The MSE loss is : 0.31393495202064514\n",
      "The MSE loss is : 0.31393492221832275\n",
      "The MSE loss is : 0.31393495202064514\n",
      "The MSE loss is : 0.31393495202064514\n",
      "The MSE loss is : 0.31393492221832275\n",
      "The MSE loss is : 0.31393492221832275\n",
      "The MSE loss is : 0.31393492221832275\n",
      "The MSE loss is : 0.31393492221832275\n",
      "The MSE loss is : 0.31393492221832275\n",
      "The MSE loss is : 0.31393492221832275\n",
      "Saving... file:record_err_4096 method:block-sqrt\n",
      "Saving... file:record_err_4096 method:lowR-same-param\n",
      "Saving... file:record_err_4096 method:lowR-samex2\n",
      "Saving... file:record_err_4096 method:lowR-half\n",
      "\n",
      "Experiment N=4096 SEED=654\n",
      "The MSE loss is : 0.33360356092453003\n",
      "The MSE loss is : 0.33051013946533203\n",
      "The MSE loss is : 0.3302743434906006\n",
      "The MSE loss is : 0.33018583059310913\n",
      "The MSE loss is : 0.3301408886909485\n",
      "The MSE loss is : 0.3301118314266205\n",
      "The MSE loss is : 0.3300960659980774\n",
      "The MSE loss is : 0.33008474111557007\n",
      "The MSE loss is : 0.33007684350013733\n",
      "The MSE loss is : 0.3300708830356598\n",
      "The MSE loss is : 0.33006736636161804\n",
      "The MSE loss is : 0.3300609886646271\n",
      "The MSE loss is : 0.33005693554878235\n",
      "The MSE loss is : 0.33005383610725403\n",
      "The MSE loss is : 0.33005213737487793\n",
      "The MSE loss is : 0.33005040884017944\n",
      "The MSE loss is : 0.33004939556121826\n",
      "The MSE loss is : 0.330048143863678\n",
      "The MSE loss is : 0.33004677295684814\n",
      "The MSE loss is : 0.33004599809646606\n",
      "Saving... file:record_err_4096 method:pair\n",
      "The MSE loss is : 0.33360356092453003\n",
      "The MSE loss is : 0.31783512234687805\n",
      "The MSE loss is : 0.31756535172462463\n",
      "The MSE loss is : 0.317496120929718\n",
      "The MSE loss is : 0.3174695372581482\n",
      "The MSE loss is : 0.31745773553848267\n",
      "The MSE loss is : 0.3174517750740051\n",
      "The MSE loss is : 0.3174472451210022\n",
      "The MSE loss is : 0.31744521856307983\n",
      "The MSE loss is : 0.3174431622028351\n",
      "The MSE loss is : 0.3174411356449127\n",
      "The MSE loss is : 0.3174402713775635\n",
      "The MSE loss is : 0.3174401521682739\n",
      "The MSE loss is : 0.31744009256362915\n",
      "The MSE loss is : 0.3174400329589844\n",
      "The MSE loss is : 0.31743985414505005\n",
      "The MSE loss is : 0.3174397945404053\n",
      "The MSE loss is : 0.3174397647380829\n",
      "The MSE loss is : 0.3174397647380829\n",
      "The MSE loss is : 0.3174397647380829\n",
      "Saving... file:record_err_4096 method:block-sqrt-half\n",
      "The MSE loss is : 0.33360356092453003\n",
      "The MSE loss is : 0.31410613656044006\n",
      "The MSE loss is : 0.31397509574890137\n",
      "The MSE loss is : 0.3139660656452179\n",
      "The MSE loss is : 0.3139646649360657\n",
      "The MSE loss is : 0.313964307308197\n",
      "The MSE loss is : 0.31396418809890747\n",
      "The MSE loss is : 0.3139641582965851\n",
      "The MSE loss is : 0.3139641284942627\n",
      "The MSE loss is : 0.3139641284942627\n",
      "The MSE loss is : 0.3139641284942627\n",
      "The MSE loss is : 0.3139641284942627\n",
      "The MSE loss is : 0.3139641284942627\n",
      "The MSE loss is : 0.3139641284942627\n",
      "The MSE loss is : 0.3139640986919403\n",
      "The MSE loss is : 0.3139640688896179\n",
      "The MSE loss is : 0.3139640688896179\n",
      "The MSE loss is : 0.3139640688896179\n",
      "The MSE loss is : 0.3139640986919403\n",
      "The MSE loss is : 0.3139640688896179\n",
      "Saving... file:record_err_4096 method:block-sqrt\n",
      "Saving... file:record_err_4096 method:lowR-same-param\n",
      "Saving... file:record_err_4096 method:lowR-samex2\n",
      "Saving... file:record_err_4096 method:lowR-half\n",
      "\n",
      "Experiment N=4096 SEED=987\n",
      "The MSE loss is : 0.3335164785385132\n",
      "The MSE loss is : 0.3304218053817749\n",
      "The MSE loss is : 0.330193430185318\n",
      "The MSE loss is : 0.3301067650318146\n",
      "The MSE loss is : 0.33006393909454346\n",
      "The MSE loss is : 0.33004024624824524\n",
      "The MSE loss is : 0.33002451062202454\n",
      "The MSE loss is : 0.3300114870071411\n",
      "The MSE loss is : 0.33000409603118896\n",
      "The MSE loss is : 0.3299965560436249\n",
      "The MSE loss is : 0.3299912214279175\n",
      "The MSE loss is : 0.3299868106842041\n",
      "The MSE loss is : 0.3299826383590698\n",
      "The MSE loss is : 0.3299790918827057\n",
      "The MSE loss is : 0.32997703552246094\n",
      "The MSE loss is : 0.3299744725227356\n",
      "The MSE loss is : 0.3299729526042938\n",
      "The MSE loss is : 0.3299716114997864\n",
      "The MSE loss is : 0.3299707770347595\n",
      "The MSE loss is : 0.32997018098831177\n",
      "Saving... file:record_err_4096 method:pair\n",
      "The MSE loss is : 0.3335164785385132\n",
      "The MSE loss is : 0.31774449348449707\n",
      "The MSE loss is : 0.31748372316360474\n",
      "The MSE loss is : 0.3174164295196533\n",
      "The MSE loss is : 0.31738805770874023\n",
      "The MSE loss is : 0.3173729181289673\n",
      "The MSE loss is : 0.31736552715301514\n",
      "The MSE loss is : 0.31736207008361816\n",
      "The MSE loss is : 0.31735965609550476\n",
      "The MSE loss is : 0.31735795736312866\n",
      "The MSE loss is : 0.31735682487487793\n",
      "The MSE loss is : 0.3173561096191406\n",
      "The MSE loss is : 0.31735512614250183\n",
      "The MSE loss is : 0.3173549175262451\n",
      "The MSE loss is : 0.3173547387123108\n",
      "The MSE loss is : 0.31735455989837646\n",
      "The MSE loss is : 0.3173544704914093\n",
      "The MSE loss is : 0.3173544406890869\n",
      "The MSE loss is : 0.3173544108867645\n",
      "The MSE loss is : 0.3173544406890869\n",
      "Saving... file:record_err_4096 method:block-sqrt-half\n",
      "The MSE loss is : 0.3335164785385132\n",
      "The MSE loss is : 0.3139992356300354\n",
      "The MSE loss is : 0.31387558579444885\n",
      "The MSE loss is : 0.31386786699295044\n",
      "The MSE loss is : 0.31386691331863403\n",
      "The MSE loss is : 0.31386658549308777\n",
      "The MSE loss is : 0.31386643648147583\n",
      "The MSE loss is : 0.31386640667915344\n",
      "The MSE loss is : 0.31386637687683105\n",
      "The MSE loss is : 0.31386637687683105\n",
      "The MSE loss is : 0.31386637687683105\n",
      "The MSE loss is : 0.31386637687683105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.31386634707450867\n",
      "The MSE loss is : 0.31386634707450867\n",
      "The MSE loss is : 0.31386634707450867\n",
      "The MSE loss is : 0.31386634707450867\n",
      "The MSE loss is : 0.31386634707450867\n",
      "The MSE loss is : 0.31386634707450867\n",
      "The MSE loss is : 0.31386637687683105\n",
      "The MSE loss is : 0.31386634707450867\n",
      "Saving... file:record_err_4096 method:block-sqrt\n",
      "Saving... file:record_err_4096 method:lowR-same-param\n",
      "Saving... file:record_err_4096 method:lowR-samex2\n",
      "Saving... file:record_err_4096 method:lowR-half\n",
      "\n",
      "Experiment N=4096 SEED=741\n",
      "The MSE loss is : 0.3335869312286377\n",
      "The MSE loss is : 0.3304900527000427\n",
      "The MSE loss is : 0.33026060461997986\n",
      "The MSE loss is : 0.33017390966415405\n",
      "The MSE loss is : 0.33013594150543213\n",
      "The MSE loss is : 0.3301108479499817\n",
      "The MSE loss is : 0.3300960659980774\n",
      "The MSE loss is : 0.33008503913879395\n",
      "The MSE loss is : 0.33007460832595825\n",
      "The MSE loss is : 0.3300674259662628\n",
      "The MSE loss is : 0.33006152510643005\n",
      "The MSE loss is : 0.3300575315952301\n",
      "The MSE loss is : 0.33005237579345703\n",
      "The MSE loss is : 0.3300483822822571\n",
      "The MSE loss is : 0.330045223236084\n",
      "The MSE loss is : 0.33004170656204224\n",
      "The MSE loss is : 0.33003973960876465\n",
      "The MSE loss is : 0.33003801107406616\n",
      "The MSE loss is : 0.3300369083881378\n",
      "The MSE loss is : 0.330036461353302\n",
      "Saving... file:record_err_4096 method:pair\n",
      "The MSE loss is : 0.3335869312286377\n",
      "The MSE loss is : 0.3178236484527588\n",
      "The MSE loss is : 0.3175676167011261\n",
      "The MSE loss is : 0.31749963760375977\n",
      "The MSE loss is : 0.31746533513069153\n",
      "The MSE loss is : 0.3174469470977783\n",
      "The MSE loss is : 0.3174360394477844\n",
      "The MSE loss is : 0.3174293637275696\n",
      "The MSE loss is : 0.317427396774292\n",
      "The MSE loss is : 0.31742581725120544\n",
      "The MSE loss is : 0.3174249529838562\n",
      "The MSE loss is : 0.3174241781234741\n",
      "The MSE loss is : 0.3174237012863159\n",
      "The MSE loss is : 0.3174234926700592\n",
      "The MSE loss is : 0.31742286682128906\n",
      "The MSE loss is : 0.3174227774143219\n",
      "The MSE loss is : 0.3174227774143219\n",
      "The MSE loss is : 0.3174225687980652\n",
      "The MSE loss is : 0.3174225687980652\n",
      "The MSE loss is : 0.3174225687980652\n",
      "Saving... file:record_err_4096 method:block-sqrt-half\n",
      "The MSE loss is : 0.3335869312286377\n",
      "The MSE loss is : 0.31407132744789124\n",
      "The MSE loss is : 0.31394296884536743\n",
      "The MSE loss is : 0.3139345049858093\n",
      "The MSE loss is : 0.31393328309059143\n",
      "The MSE loss is : 0.31393301486968994\n",
      "The MSE loss is : 0.31393298506736755\n",
      "The MSE loss is : 0.31393295526504517\n",
      "The MSE loss is : 0.31393295526504517\n",
      "The MSE loss is : 0.3139329254627228\n",
      "The MSE loss is : 0.3139329254627228\n",
      "The MSE loss is : 0.3139328956604004\n",
      "The MSE loss is : 0.3139328956604004\n",
      "The MSE loss is : 0.3139328956604004\n",
      "The MSE loss is : 0.3139328956604004\n",
      "The MSE loss is : 0.3139328956604004\n",
      "The MSE loss is : 0.3139328956604004\n",
      "The MSE loss is : 0.3139328956604004\n",
      "The MSE loss is : 0.3139329254627228\n",
      "The MSE loss is : 0.3139329254627228\n",
      "Saving... file:record_err_4096 method:block-sqrt\n",
      "Saving... file:record_err_4096 method:lowR-same-param\n",
      "Saving... file:record_err_4096 method:lowR-samex2\n",
      "Saving... file:record_err_4096 method:lowR-half\n",
      "\n",
      "Experiment N=4096 SEED=852\n",
      "The MSE loss is : 0.333527147769928\n",
      "The MSE loss is : 0.33043843507766724\n",
      "The MSE loss is : 0.33020448684692383\n",
      "The MSE loss is : 0.3301200270652771\n",
      "The MSE loss is : 0.3300839364528656\n",
      "The MSE loss is : 0.3300550878047943\n",
      "The MSE loss is : 0.3300364911556244\n",
      "The MSE loss is : 0.33002614974975586\n",
      "The MSE loss is : 0.33001890778541565\n",
      "The MSE loss is : 0.33001336455345154\n",
      "The MSE loss is : 0.3300093114376068\n",
      "The MSE loss is : 0.33000534772872925\n",
      "The MSE loss is : 0.33000296354293823\n",
      "The MSE loss is : 0.3300008177757263\n",
      "The MSE loss is : 0.32999885082244873\n",
      "The MSE loss is : 0.3299962282180786\n",
      "The MSE loss is : 0.32999444007873535\n",
      "The MSE loss is : 0.32999375462532043\n",
      "The MSE loss is : 0.3299923837184906\n",
      "The MSE loss is : 0.32999187707901\n",
      "Saving... file:record_err_4096 method:pair\n",
      "The MSE loss is : 0.333527147769928\n",
      "The MSE loss is : 0.31774550676345825\n",
      "The MSE loss is : 0.3174821734428406\n",
      "The MSE loss is : 0.31742024421691895\n",
      "The MSE loss is : 0.317394882440567\n",
      "The MSE loss is : 0.3173793852329254\n",
      "The MSE loss is : 0.3173723816871643\n",
      "The MSE loss is : 0.3173691928386688\n",
      "The MSE loss is : 0.31736668944358826\n",
      "The MSE loss is : 0.31736546754837036\n",
      "The MSE loss is : 0.31736505031585693\n",
      "The MSE loss is : 0.3173644542694092\n",
      "The MSE loss is : 0.3173629641532898\n",
      "The MSE loss is : 0.3173624277114868\n",
      "The MSE loss is : 0.3173620104789734\n",
      "The MSE loss is : 0.31736117601394653\n",
      "The MSE loss is : 0.31736093759536743\n",
      "The MSE loss is : 0.31736093759536743\n",
      "The MSE loss is : 0.31736090779304504\n",
      "The MSE loss is : 0.31736087799072266\n",
      "Saving... file:record_err_4096 method:block-sqrt-half\n",
      "The MSE loss is : 0.333527147769928\n",
      "The MSE loss is : 0.3140047490596771\n",
      "The MSE loss is : 0.3138781189918518\n",
      "The MSE loss is : 0.3138691782951355\n",
      "The MSE loss is : 0.31386804580688477\n",
      "The MSE loss is : 0.31386780738830566\n",
      "The MSE loss is : 0.3138676881790161\n",
      "The MSE loss is : 0.3138676583766937\n",
      "The MSE loss is : 0.31386762857437134\n",
      "The MSE loss is : 0.31386762857437134\n",
      "The MSE loss is : 0.31386762857437134\n",
      "The MSE loss is : 0.31386762857437134\n",
      "The MSE loss is : 0.31386762857437134\n",
      "The MSE loss is : 0.31386762857437134\n",
      "The MSE loss is : 0.31386762857437134\n",
      "The MSE loss is : 0.31386762857437134\n",
      "The MSE loss is : 0.31386762857437134\n",
      "The MSE loss is : 0.31386762857437134\n",
      "The MSE loss is : 0.31386762857437134\n",
      "The MSE loss is : 0.31386762857437134\n",
      "Saving... file:record_err_4096 method:block-sqrt\n",
      "Saving... file:record_err_4096 method:lowR-same-param\n",
      "Saving... file:record_err_4096 method:lowR-samex2\n",
      "Saving... file:record_err_4096 method:lowR-half\n",
      "\n",
      "Experiment N=4096 SEED=963\n",
      "The MSE loss is : 0.333729088306427\n",
      "The MSE loss is : 0.3306407630443573\n",
      "The MSE loss is : 0.33040016889572144\n",
      "The MSE loss is : 0.3303143084049225\n",
      "The MSE loss is : 0.3302730917930603\n",
      "The MSE loss is : 0.33025243878364563\n",
      "The MSE loss is : 0.3302352726459503\n",
      "The MSE loss is : 0.3302246928215027\n",
      "The MSE loss is : 0.330217570066452\n",
      "The MSE loss is : 0.3302105665206909\n",
      "The MSE loss is : 0.33020442724227905\n",
      "The MSE loss is : 0.33020123839378357\n",
      "The MSE loss is : 0.3301985263824463\n",
      "The MSE loss is : 0.3301948308944702\n",
      "The MSE loss is : 0.33019140362739563\n",
      "The MSE loss is : 0.3301902413368225\n",
      "The MSE loss is : 0.3301885724067688\n",
      "The MSE loss is : 0.33018675446510315\n",
      "The MSE loss is : 0.3301849961280823\n",
      "The MSE loss is : 0.3301839232444763\n",
      "Saving... file:record_err_4096 method:pair\n",
      "The MSE loss is : 0.333729088306427\n",
      "The MSE loss is : 0.31796398758888245\n",
      "The MSE loss is : 0.31770119071006775\n",
      "The MSE loss is : 0.31763964891433716\n",
      "The MSE loss is : 0.31761085987091064\n",
      "The MSE loss is : 0.3175967335700989\n",
      "The MSE loss is : 0.31759002804756165\n",
      "The MSE loss is : 0.31758517026901245\n",
      "The MSE loss is : 0.3175809979438782\n",
      "The MSE loss is : 0.3175790309906006\n",
      "The MSE loss is : 0.3175775408744812\n",
      "The MSE loss is : 0.3175765872001648\n",
      "The MSE loss is : 0.3175751566886902\n",
      "The MSE loss is : 0.31757473945617676\n",
      "The MSE loss is : 0.3175746202468872\n",
      "The MSE loss is : 0.31757453083992004\n",
      "The MSE loss is : 0.31757432222366333\n",
      "The MSE loss is : 0.31757426261901855\n",
      "The MSE loss is : 0.31757423281669617\n",
      "The MSE loss is : 0.31757423281669617\n",
      "Saving... file:record_err_4096 method:block-sqrt-half\n",
      "The MSE loss is : 0.333729088306427\n",
      "The MSE loss is : 0.3142193555831909\n",
      "The MSE loss is : 0.31408435106277466\n",
      "The MSE loss is : 0.3140755891799927\n",
      "The MSE loss is : 0.31407445669174194\n",
      "The MSE loss is : 0.31407421827316284\n",
      "The MSE loss is : 0.31407415866851807\n",
      "The MSE loss is : 0.31407415866851807\n",
      "The MSE loss is : 0.31407415866851807\n",
      "The MSE loss is : 0.31407415866851807\n",
      "The MSE loss is : 0.3140741288661957\n",
      "The MSE loss is : 0.31407415866851807\n",
      "The MSE loss is : 0.3140741288661957\n",
      "The MSE loss is : 0.3140741288661957\n",
      "The MSE loss is : 0.31407415866851807\n",
      "The MSE loss is : 0.31407415866851807\n",
      "The MSE loss is : 0.31407415866851807\n",
      "The MSE loss is : 0.31407415866851807\n",
      "The MSE loss is : 0.31407415866851807\n",
      "The MSE loss is : 0.3140741288661957\n",
      "Saving... file:record_err_4096 method:block-sqrt\n",
      "Saving... file:record_err_4096 method:lowR-same-param\n",
      "Saving... file:record_err_4096 method:lowR-samex2\n",
      "Saving... file:record_err_4096 method:lowR-half\n",
      "\n",
      "Experiment N=4096 SEED=159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.3336431384086609\n",
      "The MSE loss is : 0.33054473996162415\n",
      "The MSE loss is : 0.3303200900554657\n",
      "The MSE loss is : 0.33023762702941895\n",
      "The MSE loss is : 0.33019205927848816\n",
      "The MSE loss is : 0.3301633894443512\n",
      "The MSE loss is : 0.33014827966690063\n",
      "The MSE loss is : 0.33013981580734253\n",
      "The MSE loss is : 0.3301314413547516\n",
      "The MSE loss is : 0.3301262855529785\n",
      "The MSE loss is : 0.3301231861114502\n",
      "The MSE loss is : 0.33012038469314575\n",
      "The MSE loss is : 0.33011820912361145\n",
      "The MSE loss is : 0.33011579513549805\n",
      "The MSE loss is : 0.33011338114738464\n",
      "The MSE loss is : 0.33011162281036377\n",
      "The MSE loss is : 0.3301088213920593\n",
      "The MSE loss is : 0.33010613918304443\n",
      "The MSE loss is : 0.3301032483577728\n",
      "The MSE loss is : 0.3301007151603699\n",
      "Saving... file:record_err_4096 method:pair\n",
      "The MSE loss is : 0.3336431384086609\n",
      "The MSE loss is : 0.3178573250770569\n",
      "The MSE loss is : 0.31760114431381226\n",
      "The MSE loss is : 0.3175390958786011\n",
      "The MSE loss is : 0.3175106644630432\n",
      "The MSE loss is : 0.3174939751625061\n",
      "The MSE loss is : 0.3174861967563629\n",
      "The MSE loss is : 0.3174826204776764\n",
      "The MSE loss is : 0.31747931241989136\n",
      "The MSE loss is : 0.3174765110015869\n",
      "The MSE loss is : 0.31747522950172424\n",
      "The MSE loss is : 0.3174739480018616\n",
      "The MSE loss is : 0.3174731135368347\n",
      "The MSE loss is : 0.31747299432754517\n",
      "The MSE loss is : 0.31747251749038696\n",
      "The MSE loss is : 0.31747207045555115\n",
      "The MSE loss is : 0.31747180223464966\n",
      "The MSE loss is : 0.31747156381607056\n",
      "The MSE loss is : 0.31747108697891235\n",
      "The MSE loss is : 0.31747084856033325\n",
      "Saving... file:record_err_4096 method:block-sqrt-half\n",
      "The MSE loss is : 0.3336431384086609\n",
      "The MSE loss is : 0.3141287565231323\n",
      "The MSE loss is : 0.3140069246292114\n",
      "The MSE loss is : 0.31399762630462646\n",
      "The MSE loss is : 0.3139963746070862\n",
      "The MSE loss is : 0.3139960765838623\n",
      "The MSE loss is : 0.31399601697921753\n",
      "The MSE loss is : 0.31399601697921753\n",
      "The MSE loss is : 0.31399595737457275\n",
      "The MSE loss is : 0.31399595737457275\n",
      "The MSE loss is : 0.31399595737457275\n",
      "The MSE loss is : 0.31399595737457275\n",
      "The MSE loss is : 0.31399595737457275\n",
      "The MSE loss is : 0.31399595737457275\n",
      "The MSE loss is : 0.31399595737457275\n",
      "The MSE loss is : 0.31399598717689514\n",
      "The MSE loss is : 0.31399595737457275\n",
      "The MSE loss is : 0.31399595737457275\n",
      "The MSE loss is : 0.31399598717689514\n",
      "The MSE loss is : 0.31399598717689514\n",
      "Saving... file:record_err_4096 method:block-sqrt\n",
      "Saving... file:record_err_4096 method:lowR-same-param\n",
      "Saving... file:record_err_4096 method:lowR-samex2\n",
      "Saving... file:record_err_4096 method:lowR-half\n",
      "\n",
      "Experiment N=4096 SEED=357\n",
      "The MSE loss is : 0.3335422873497009\n",
      "The MSE loss is : 0.3304395079612732\n",
      "The MSE loss is : 0.33022332191467285\n",
      "The MSE loss is : 0.33014175295829773\n",
      "The MSE loss is : 0.3300968110561371\n",
      "The MSE loss is : 0.33007049560546875\n",
      "The MSE loss is : 0.3300514817237854\n",
      "The MSE loss is : 0.3300389349460602\n",
      "The MSE loss is : 0.33002907037734985\n",
      "The MSE loss is : 0.33002063632011414\n",
      "The MSE loss is : 0.3300143778324127\n",
      "The MSE loss is : 0.33000892400741577\n",
      "The MSE loss is : 0.3300054371356964\n",
      "The MSE loss is : 0.3300014138221741\n",
      "The MSE loss is : 0.32999756932258606\n",
      "The MSE loss is : 0.3299953043460846\n",
      "The MSE loss is : 0.32999172806739807\n",
      "The MSE loss is : 0.32998865842819214\n",
      "The MSE loss is : 0.32998648285865784\n",
      "The MSE loss is : 0.3299846053123474\n",
      "Saving... file:record_err_4096 method:pair\n",
      "The MSE loss is : 0.3335422873497009\n",
      "The MSE loss is : 0.3177688717842102\n",
      "The MSE loss is : 0.3174959123134613\n",
      "The MSE loss is : 0.3174285292625427\n",
      "The MSE loss is : 0.31740230321884155\n",
      "The MSE loss is : 0.3173898458480835\n",
      "The MSE loss is : 0.31738102436065674\n",
      "The MSE loss is : 0.31737515330314636\n",
      "The MSE loss is : 0.3173723816871643\n",
      "The MSE loss is : 0.3173708915710449\n",
      "The MSE loss is : 0.31737005710601807\n",
      "The MSE loss is : 0.31736934185028076\n",
      "The MSE loss is : 0.317368745803833\n",
      "The MSE loss is : 0.31736862659454346\n",
      "The MSE loss is : 0.31736764311790466\n",
      "The MSE loss is : 0.3173675239086151\n",
      "The MSE loss is : 0.3173673748970032\n",
      "The MSE loss is : 0.3173673152923584\n",
      "The MSE loss is : 0.3173673152923584\n",
      "The MSE loss is : 0.3173673152923584\n",
      "Saving... file:record_err_4096 method:block-sqrt-half\n",
      "The MSE loss is : 0.3335422873497009\n",
      "The MSE loss is : 0.31400197744369507\n",
      "The MSE loss is : 0.31387630105018616\n",
      "The MSE loss is : 0.31386798620224\n",
      "The MSE loss is : 0.31386706233024597\n",
      "The MSE loss is : 0.3138667345046997\n",
      "The MSE loss is : 0.31386664509773254\n",
      "The MSE loss is : 0.3138665556907654\n",
      "The MSE loss is : 0.3138665556907654\n",
      "The MSE loss is : 0.3138665556907654\n",
      "The MSE loss is : 0.3138665556907654\n",
      "The MSE loss is : 0.3138665556907654\n",
      "The MSE loss is : 0.3138665556907654\n",
      "The MSE loss is : 0.3138665556907654\n",
      "The MSE loss is : 0.3138665556907654\n",
      "The MSE loss is : 0.3138665556907654\n",
      "The MSE loss is : 0.3138665556907654\n",
      "The MSE loss is : 0.3138665556907654\n",
      "The MSE loss is : 0.3138665556907654\n",
      "The MSE loss is : 0.3138665556907654\n",
      "Saving... file:record_err_4096 method:block-sqrt\n",
      "Saving... file:record_err_4096 method:lowR-same-param\n",
      "Saving... file:record_err_4096 method:lowR-samex2\n",
      "Saving... file:record_err_4096 method:lowR-half\n",
      "\n",
      "Experiment N=4096 SEED=951\n",
      "The MSE loss is : 0.3336296081542969\n",
      "The MSE loss is : 0.3305491507053375\n",
      "The MSE loss is : 0.3303122818470001\n",
      "The MSE loss is : 0.33023104071617126\n",
      "The MSE loss is : 0.33019202947616577\n",
      "The MSE loss is : 0.3301679790019989\n",
      "The MSE loss is : 0.33015191555023193\n",
      "The MSE loss is : 0.33014076948165894\n",
      "The MSE loss is : 0.3301313519477844\n",
      "The MSE loss is : 0.3301255702972412\n",
      "The MSE loss is : 0.33011993765830994\n",
      "The MSE loss is : 0.3301147520542145\n",
      "The MSE loss is : 0.3301122188568115\n",
      "The MSE loss is : 0.33011066913604736\n",
      "The MSE loss is : 0.3301081359386444\n",
      "The MSE loss is : 0.3301059901714325\n",
      "The MSE loss is : 0.33010411262512207\n",
      "The MSE loss is : 0.33010149002075195\n",
      "The MSE loss is : 0.33009976148605347\n",
      "The MSE loss is : 0.33009839057922363\n",
      "Saving... file:record_err_4096 method:pair\n",
      "The MSE loss is : 0.3336296081542969\n",
      "The MSE loss is : 0.3178732991218567\n",
      "The MSE loss is : 0.3176117539405823\n",
      "The MSE loss is : 0.3175395131111145\n",
      "The MSE loss is : 0.31751078367233276\n",
      "The MSE loss is : 0.3174985647201538\n",
      "The MSE loss is : 0.3174925446510315\n",
      "The MSE loss is : 0.3174893260002136\n",
      "The MSE loss is : 0.31748664379119873\n",
      "The MSE loss is : 0.3174844980239868\n",
      "The MSE loss is : 0.3174836337566376\n",
      "The MSE loss is : 0.3174830675125122\n",
      "The MSE loss is : 0.31748244166374207\n",
      "The MSE loss is : 0.31748223304748535\n",
      "The MSE loss is : 0.3174811601638794\n",
      "Saving... file:record_err_4096 method:block-sqrt-half\n",
      "The MSE loss is : 0.3336296081542969\n",
      "The MSE loss is : 0.31413084268569946\n",
      "The MSE loss is : 0.3140055537223816\n",
      "The MSE loss is : 0.31399601697921753\n",
      "The MSE loss is : 0.31399446725845337\n",
      "The MSE loss is : 0.3139941394329071\n",
      "The MSE loss is : 0.31399405002593994\n",
      "The MSE loss is : 0.31399405002593994\n",
      "The MSE loss is : 0.31399402022361755\n",
      "The MSE loss is : 0.31399405002593994\n",
      "The MSE loss is : 0.31399405002593994\n",
      "The MSE loss is : 0.31399402022361755\n",
      "The MSE loss is : 0.31399402022361755\n",
      "The MSE loss is : 0.31399402022361755\n",
      "The MSE loss is : 0.31399399042129517\n",
      "The MSE loss is : 0.31399402022361755\n",
      "The MSE loss is : 0.31399402022361755\n",
      "The MSE loss is : 0.31399402022361755\n",
      "The MSE loss is : 0.31399402022361755\n",
      "The MSE loss is : 0.31399402022361755\n",
      "Saving... file:record_err_4096 method:block-sqrt\n",
      "Saving... file:record_err_4096 method:lowR-same-param\n",
      "Saving... file:record_err_4096 method:lowR-samex2\n",
      "Saving... file:record_err_4096 method:lowR-half\n",
      "\n",
      "Experiment N=4096 SEED=753\n",
      "The MSE loss is : 0.33361801505088806\n",
      "The MSE loss is : 0.33051520586013794\n",
      "The MSE loss is : 0.3302970826625824\n",
      "The MSE loss is : 0.33022403717041016\n",
      "The MSE loss is : 0.3301815688610077\n",
      "The MSE loss is : 0.330158531665802\n",
      "The MSE loss is : 0.33014237880706787\n",
      "The MSE loss is : 0.33012980222702026\n",
      "The MSE loss is : 0.330120325088501\n",
      "The MSE loss is : 0.3301125764846802\n",
      "The MSE loss is : 0.3301076292991638\n",
      "The MSE loss is : 0.3301032483577728\n",
      "The MSE loss is : 0.33009862899780273\n",
      "The MSE loss is : 0.3300934135913849\n",
      "The MSE loss is : 0.3300896883010864\n",
      "The MSE loss is : 0.3300870656967163\n",
      "The MSE loss is : 0.33008435368537903\n",
      "The MSE loss is : 0.3300819993019104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.33008068799972534\n",
      "The MSE loss is : 0.33007800579071045\n",
      "Saving... file:record_err_4096 method:pair\n",
      "The MSE loss is : 0.33361801505088806\n",
      "The MSE loss is : 0.31783896684646606\n",
      "The MSE loss is : 0.3175688683986664\n",
      "The MSE loss is : 0.3174973130226135\n",
      "The MSE loss is : 0.31747132539749146\n",
      "The MSE loss is : 0.3174574375152588\n",
      "The MSE loss is : 0.3174476623535156\n",
      "The MSE loss is : 0.31744107604026794\n",
      "The MSE loss is : 0.3174390196800232\n",
      "The MSE loss is : 0.31743794679641724\n",
      "The MSE loss is : 0.31743741035461426\n",
      "The MSE loss is : 0.31743723154067993\n",
      "The MSE loss is : 0.31743714213371277\n",
      "The MSE loss is : 0.3174371123313904\n",
      "The MSE loss is : 0.3174370229244232\n",
      "The MSE loss is : 0.3174370229244232\n",
      "The MSE loss is : 0.31743696331977844\n",
      "The MSE loss is : 0.31743696331977844\n",
      "The MSE loss is : 0.31743696331977844\n",
      "The MSE loss is : 0.31743693351745605\n",
      "Saving... file:record_err_4096 method:block-sqrt-half\n",
      "The MSE loss is : 0.33361801505088806\n",
      "The MSE loss is : 0.314075231552124\n",
      "The MSE loss is : 0.313953161239624\n",
      "The MSE loss is : 0.3139457702636719\n",
      "The MSE loss is : 0.31394442915916443\n",
      "The MSE loss is : 0.31394413113594055\n",
      "The MSE loss is : 0.3139440417289734\n",
      "The MSE loss is : 0.313944011926651\n",
      "The MSE loss is : 0.313944011926651\n",
      "The MSE loss is : 0.313944011926651\n",
      "The MSE loss is : 0.313944011926651\n",
      "The MSE loss is : 0.3139439821243286\n",
      "The MSE loss is : 0.313944011926651\n",
      "The MSE loss is : 0.313944011926651\n",
      "The MSE loss is : 0.313944011926651\n",
      "The MSE loss is : 0.313944011926651\n",
      "The MSE loss is : 0.3139439821243286\n",
      "The MSE loss is : 0.313944011926651\n",
      "The MSE loss is : 0.3139439821243286\n",
      "The MSE loss is : 0.313944011926651\n",
      "Saving... file:record_err_4096 method:block-sqrt\n",
      "Saving... file:record_err_4096 method:lowR-same-param\n",
      "Saving... file:record_err_4096 method:lowR-samex2\n",
      "Saving... file:record_err_4096 method:lowR-half\n"
     ]
    }
   ],
   "source": [
    "A = None\n",
    "for N in Ns:\n",
    "# for N in [4096]:\n",
    "#     torch.cuda.empty_cache()\n",
    "    X = torch.eye(N).to(device)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['method', 'seed', 'mse', 'mean', 'std', 'params', 'time'])\n",
    "    file_name = f'record_err_{N}'\n",
    "        \n",
    "#     for SEED in [147]:\n",
    "    for SEED in seeds:\n",
    "#         torch.cuda.empty_cache()\n",
    "        print()\n",
    "        print(f\"Experiment N={N} SEED={SEED}\")\n",
    "        \n",
    "        torch.manual_seed(SEED)\n",
    "        \n",
    "        del A\n",
    "        \n",
    "        A = torch.rand(N, N).to(device)*2-1\n",
    "        ### For each method compute the stats\n",
    "        \n",
    "        #####################################################\n",
    "        ##### First 2x2 factorization\n",
    "        model = sll.PairLinear_MixerBlock(N, N).to(device)        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "        \n",
    "        #### Train model\n",
    "        out, tim = train_model(model, optimizer, X, A)\n",
    "        _n_params = sum(p.numel() for p in model.parameters())\n",
    "        df = save_stats(df, out, A, 'pair', SEED, _n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        del model, optimizer\n",
    "        \n",
    "        #####################################################\n",
    "        ##### First log(N) factorization\n",
    "#         _m = int(np.ceil(np.log2(N)))\n",
    "\n",
    "        #### sqrt(N)/2 \n",
    "        _m = int(np.ceil(np.sqrt(N)/2))\n",
    "        model = sll.BlockLinear_MixerBlock(N, _m).to(device)        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "        \n",
    "        #### Train model\n",
    "        out, tim = train_model(model, optimizer, X, A)\n",
    "        _n_params = sum(p.numel() for p in model.parameters())\n",
    "        df = save_stats(df, out, A, 'block-sqrt-half', SEED, _n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        del model, optimizer\n",
    "        \n",
    "        \n",
    "        #####################################################\n",
    "        ##### Second sqrt(N) factorization\n",
    "        _m = int(np.ceil(np.sqrt(N)))\n",
    "        model = sll.BlockLinear_MixerBlock(N, _m).to(device)        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "        \n",
    "        #### Train model\n",
    "        out, tim = train_model(model, optimizer, X, A)\n",
    "        _n_params = sum(p.numel() for p in model.parameters())\n",
    "        df = save_stats(df, out, A, 'block-sqrt', SEED, _n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        del model, optimizer\n",
    "        \n",
    "        \n",
    "        #####################################################\n",
    "        _m = int(np.ceil(_n_params/(N*2)))\n",
    "        out, tim = get_svd_output(A, _m)\n",
    "\n",
    "        n_params = N*_m*2\n",
    "        df = save_stats(df, out, A, 'lowR-same-param', SEED, n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        \n",
    "        #####################################################\n",
    "        _m = int(np.ceil(_n_params/N))\n",
    "        out, tim = get_svd_output(A, _m)\n",
    "\n",
    "        n_params = N*_m\n",
    "        df = save_stats(df, out, A, 'lowR-samex2', SEED, n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        \n",
    "        #####################################################\n",
    "        _m = N // 2\n",
    "        out, tim = get_svd_output(A, _m)\n",
    "\n",
    "        n_params = N*_m*2\n",
    "        df = save_stats(df, out, A, 'lowR-half', SEED, n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        \n",
    "        #####################################################\n",
    "#         torch.cuda.empty_cache()\n",
    "        if N > 1024: continue\n",
    "\n",
    "        ##### Pair Linear models parallel addition\n",
    "        _m = int(np.ceil(np.log2(N)))\n",
    "        model = Add_PairLinears(N, _m).to(device)        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "        \n",
    "        #### Train model\n",
    "        out, tim = train_model(model, optimizer, X, A)\n",
    "        _n_params = sum(p.numel() for p in model.parameters())\n",
    "        df = save_stats(df, out, A, 'pair-Add', SEED, _n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        del model, optimizer\n",
    "        \n",
    "        #####################################################\n",
    "        \n",
    "        ##### Pair Linear models sequential composition\n",
    "        _m = int(np.ceil(np.log2(N)))\n",
    "        model = Stack_PairLinears(N, _m).to(device)        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "        \n",
    "        #### Train model\n",
    "        out, tim = train_model(model, optimizer, X, A)\n",
    "        _n_params = sum(p.numel() for p in model.parameters())\n",
    "        df = save_stats(df, out, A, 'pair-Seq', SEED, _n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        del model, optimizer\n",
    "#         torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e51a00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "638b6b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.ceil(np.log2(64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5845c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d69f3ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asfsdfasdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43masfsdfasdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asfsdfasdf' is not defined"
     ]
    }
   ],
   "source": [
    "asfsdfasdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136ea42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
