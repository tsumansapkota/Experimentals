{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mylibrary.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cuda:1\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.FashionMNIST()\n",
    "# mnist.download_mnist()\n",
    "# mnist.save_mnist()\n",
    "train_data, train_label_, test_data, test_label_ = mnist.load()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "train_size = len(train_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting data to pytorch format\n",
    "train_data = torch.Tensor(train_data)\n",
    "test_data = torch.Tensor(test_data)\n",
    "train_label = torch.LongTensor(train_label_)\n",
    "test_label = torch.LongTensor(test_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting data to pytorch format\n",
    "train_data = torch.Tensor(train_data)\n",
    "test_data = torch.Tensor(test_data)\n",
    "train_label = torch.LongTensor(train_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        \n",
    "#         self.label = mask.type(torch.float32).reshape(-1,1)\n",
    "        self._shuffle_data_()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _shuffle_data_(self):\n",
    "        randidx = random.sample(range(len(self.data)), k=len(self.data))\n",
    "        self.data = self.data[randidx]\n",
    "        self.label = self.label[randidx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, lbl = self.data[idx], self.label[idx]\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST_Dataset(train_data, train_label)\n",
    "test_dataset = MNIST_Dataset(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0003\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making of matrix factorized layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupLinear(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, group_size=2, bias=True):\n",
    "        super().__init__()\n",
    "        assert input_dim >= group_size, \\\n",
    "                    f\"Input dim:{input_dim} must be >= Group size: {group_size}\"\n",
    "        if output_dim < input_dim/group_size:\n",
    "            print(\"Some inputs are ignored in the output\")\n",
    "            \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.group_size = group_size\n",
    "        \n",
    "        self.weight = torch.randn(group_size, 1).unsqueeze(0).repeat_interleave(output_dim, dim=0)\n",
    "        self.weight = nn.Parameter(self.weight)\n",
    "        self.bias = None\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(output_dim))\n",
    "            \n",
    "        self.order = self.get_random_groups()\n",
    "#         print(self.order)\n",
    "#         print(np.unique(self.order, return_counts=True))\n",
    "        \n",
    "    def get_random_groups(self):\n",
    "        rand_order = np.random.permutation(self.input_dim) ## all inputs are included\n",
    "        if self.output_dim*self.group_size < self.input_dim:\n",
    "            rand_order = rand_order[:self.output_dim*self.group_size]\n",
    "#         print(rand_order)\n",
    "        \n",
    "        ord0 = []\n",
    "        for i in range(self.output_dim):\n",
    "            v = np.random.permutation(self.input_dim)[:self.group_size]\n",
    "            ord0.append(v)\n",
    "        ord0 = np.array(ord0)\n",
    "        \n",
    "#         print(ord0.shape)\n",
    "#         print(ord0.T)\n",
    "        \n",
    "        ord0 = ord0.T.reshape(-1)\n",
    "        ord0[:len(rand_order)] = rand_order\n",
    "        ord0 = ord0.reshape(self.group_size, -1).T\n",
    "#         print(ord0)\n",
    "        \n",
    "        return ord0.reshape(-1)\n",
    "\n",
    "#     def get_random_groups(self):\n",
    "#         if self.output_dim*self.group_size < self.input_dim:\n",
    "#             return np.random.permutation(self.input_dim)[:self.output_dim*self.group_size]\n",
    "        \n",
    "#         rand_order = np.random.permutation(self.input_dim)\n",
    "#         _temp = np.random.permutation(self.output_dim*self.group_size-input_dim)%self.input_dim\n",
    "#         rand_order.\n",
    "#         print(rand_order)\n",
    "#         rand_order = rand_order.reshape(self.group_size, -1)\n",
    "#         print(rand_order)\n",
    "#         ### change the order if group contains same units\n",
    "#         pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, gs = x.shape[0], self.group_size\n",
    "        x = x[:, self.order]\n",
    "        \n",
    "        x = x.view(bs, -1, gs).transpose(0,1)\n",
    "        x = torch.bmm(x, self.weight)\n",
    "        x = x.squeeze(2).transpose(1,0)\n",
    "        if self.bias is not None:\n",
    "            x = x + self.bias\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairWeight(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        assert input_dim%2 == 0, \"Input dim must be even number\"\n",
    "        self.weight = torch.eye(2).unsqueeze(0).repeat_interleave(input_dim//2, dim=0)\n",
    "        self.weight = nn.Parameter(self.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, dim = x.shape[0], x.shape[1]\n",
    "        x = x.view(bs, -1, 2).transpose(0,1)\n",
    "        x = torch.bmm(x, self.weight)\n",
    "        x = x.transpose(1,0).reshape(bs, -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairFactorizedLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, bias=True):\n",
    "        super().__init__()\n",
    "        assert input_dim%2 == 0, \"Input dim must be even number\"\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        num_layers = int(np.ceil(np.log2(input_dim)))\n",
    "            \n",
    "        self.facto_nets = []\n",
    "        self.idx_revidx = []\n",
    "        for i in range(num_layers):\n",
    "            idrid = self.get_pair(self.input_dim, i+1)\n",
    "            net = PairWeight(self.input_dim)\n",
    "            self.facto_nets.append(net)\n",
    "            self.idx_revidx.append(idrid)\n",
    "        self.facto_nets = nn.ModuleList(self.facto_nets)\n",
    "        \n",
    "        self.bias = None\n",
    "        if bias: self.bias = nn.Parameter(torch.zeros(self.input_dim))\n",
    "            \n",
    "    def get_pair(self, inp_dim, step=1):\n",
    "        dim = 2**int(np.ceil(np.log2(inp_dim)))\n",
    "        assert isinstance(step, int), \"Step must be integer\"\n",
    "\n",
    "        blocks = (2**step)\n",
    "        range_ = dim//blocks\n",
    "        adder_ = torch.arange(0, range_)*blocks\n",
    "\n",
    "        pairs_ = torch.Tensor([0, blocks//2])\n",
    "        repeat_ = torch.arange(0, blocks//2).reshape(-1,1)\n",
    "        block_map = (pairs_+repeat_).reshape(-1)\n",
    "\n",
    "        reorder_for_pair = (block_map+adder_.reshape(-1,1)).reshape(-1)\n",
    "        indx = reorder_for_pair.type(torch.long)\n",
    "        indx = indx[indx<inp_dim]\n",
    "\n",
    "        rev_indx = torch.argsort(indx)\n",
    "        return indx, rev_indx\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## swap first and then forward and reverse-swap\n",
    "        y = self.facto_nets[0](x)\n",
    "        for i in range(1, len(self.facto_nets)):\n",
    "            idx, revidx = self.idx_revidx[i]\n",
    "            y = self.facto_nets[i](y[:, idx])[:, revidx]\n",
    "        if self.bias is not None: \n",
    "            y = y+self.bias\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.la1 = GroupLinear(784, 2**15, group_size=10, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(2**15)\n",
    "        self.la2 = PairFactorizedLinear(2**15)\n",
    "        self.bn2 = nn.BatchNorm1d(2**15)\n",
    "        self.la3 = PairFactorizedLinear(2**15)\n",
    "        self.bn3 = nn.BatchNorm1d(2**15)\n",
    "        self.la4 = GroupLinear(2**15, 2**9, group_size=2**6, bias=False)\n",
    "        self.bn4 = nn.BatchNorm1d(2**9)\n",
    "        self.fc = nn.Linear(2**9, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.la1(x))\n",
    "        x = torch.relu(x)\n",
    "        x = self.bn2(self.la2(x))\n",
    "        x = torch.relu(x)\n",
    "        x = self.bn3(self.la3(x))\n",
    "        x = torch.relu(x)\n",
    "        x = self.bn4(self.la4(x))\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinaryNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.la1 = nn.Linear(784, 784, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(784)\n",
    "        self.la2 = nn.Linear(784, 784, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(784)\n",
    "        self.la3 = nn.Linear(784, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.la1(x))\n",
    "        x = torch.relu(x)\n",
    "        x = self.bn2(self.la2(x))\n",
    "        x = torch.relu(x)\n",
    "        x = self.la3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2594826"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FactorNet()\n",
    "param_count = sum([torch.numel(p) for p in model.parameters()])\n",
    "param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240298, 0.4779888901991887)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OrdinaryNet()\n",
    "param_count1 = sum([torch.numel(p) for p in model.parameters()])\n",
    "param_count1, param_count1/param_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorNet(\n",
       "  (la1): GroupLinear()\n",
       "  (bn1): BatchNorm1d(32768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (la2): PairFactorizedLinear(\n",
       "    (facto_nets): ModuleList(\n",
       "      (0): PairWeight()\n",
       "      (1): PairWeight()\n",
       "      (2): PairWeight()\n",
       "      (3): PairWeight()\n",
       "      (4): PairWeight()\n",
       "      (5): PairWeight()\n",
       "      (6): PairWeight()\n",
       "      (7): PairWeight()\n",
       "      (8): PairWeight()\n",
       "      (9): PairWeight()\n",
       "      (10): PairWeight()\n",
       "      (11): PairWeight()\n",
       "      (12): PairWeight()\n",
       "      (13): PairWeight()\n",
       "      (14): PairWeight()\n",
       "    )\n",
       "  )\n",
       "  (bn2): BatchNorm1d(32768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (la3): PairFactorizedLinear(\n",
       "    (facto_nets): ModuleList(\n",
       "      (0): PairWeight()\n",
       "      (1): PairWeight()\n",
       "      (2): PairWeight()\n",
       "      (3): PairWeight()\n",
       "      (4): PairWeight()\n",
       "      (5): PairWeight()\n",
       "      (6): PairWeight()\n",
       "      (7): PairWeight()\n",
       "      (8): PairWeight()\n",
       "      (9): PairWeight()\n",
       "      (10): PairWeight()\n",
       "      (11): PairWeight()\n",
       "      (12): PairWeight()\n",
       "      (13): PairWeight()\n",
       "      (14): PairWeight()\n",
       "    )\n",
       "  )\n",
       "  (bn3): BatchNorm1d(32768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (la4): GroupLinear()\n",
       "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = FactorNet().to(device)\n",
    "# model = OrdinaryNet().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([268, 705, 721, ..., 343, 103, 257])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.la1.order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  2594826\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [07:57<00:00,  2.51it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0,  Loss:0.25316715240478516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:11<00:00, 16.70it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:82.22%, Test Acc:86.19%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [07:58<00:00,  2.51it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1,  Loss:0.274682879447937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:11<00:00, 16.68it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:88.70%, Test Acc:87.60%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [07:58<00:00,  2.51it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2,  Loss:0.5031993985176086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:11<00:00, 16.69it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:90.91%, Test Acc:88.10%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [07:59<00:00,  2.51it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3,  Loss:0.18634822964668274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.61it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.64%, Test Acc:88.65%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4,  Loss:0.29451826214790344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.61it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.81%, Test Acc:88.91%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5,  Loss:0.12445548176765442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.64it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.04%, Test Acc:89.02%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6,  Loss:0.15430307388305664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.63it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:96.01%, Test Acc:89.13%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7,  Loss:0.08230007439851761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.62it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:96.74%, Test Acc:88.94%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8,  Loss:0.17422203719615936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.62it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:97.39%, Test Acc:89.25%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9,  Loss:0.047530338168144226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.62it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:97.71%, Test Acc:89.40%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10,  Loss:0.03348413109779358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.62it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:98.18%, Test Acc:89.10%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11,  Loss:0.15867704153060913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.63it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:98.39%, Test Acc:88.91%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12,  Loss:0.01151068601757288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.62it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:98.66%, Test Acc:89.13%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13,  Loss:0.06058363988995552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.64it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:98.86%, Test Acc:89.16%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14,  Loss:0.019555795937776566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.61it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:98.84%, Test Acc:89.31%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15,  Loss:0.01619919016957283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.63it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:99.08%, Test Acc:89.18%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16,  Loss:0.03674845024943352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.63it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:99.17%, Test Acc:89.16%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17,  Loss:0.014013567939400673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.61it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:99.22%, Test Acc:89.01%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18,  Loss:0.021400120109319687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.61it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:99.36%, Test Acc:89.15%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19,  Loss:0.007401998154819012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 16.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:99.24%, Test Acc:89.27%\n",
      "\n",
      "\t-> Train Acc 99.35666666666667 ; Test Acc 89.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "    for xx, yy in tqdm(train_loader):\n",
    "        xx, yy = xx.to(device), yy.to(device)\n",
    "\n",
    "        yout = model(xx)\n",
    "        loss = criterion(yout, yy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(float(loss))\n",
    "\n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        train_acc += correct\n",
    "        train_count += len(outputs)\n",
    "\n",
    "    train_accs.append(float(train_acc)/train_count*100)\n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "\n",
    "    print(f'Epoch: {epoch},  Loss:{float(loss)}')\n",
    "    test_count = 0\n",
    "    test_acc = 0\n",
    "    for xx, yy in tqdm(test_loader):\n",
    "        xx, yy = xx.to(device), yy.to(device)\n",
    "        with torch.no_grad():\n",
    "            yout = model(xx)\n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        test_acc += correct\n",
    "        test_count += len(xx)\n",
    "    test_accs.append(float(test_acc)/test_count*100)\n",
    "    print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "    print()\n",
    "\n",
    "### after each class index is finished training\n",
    "print(f'\\t-> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Big Network Accuracy\n",
    "100%|██████████| 1200/1200 [08:00<00:00,  2.50it/s]\n",
    "\t-> Train Acc 99.35666666666667 ; Test Acc 89.4\n",
    "\n",
    "    \n",
    "FactorNet(\n",
    "  (la1): GroupLinear()\n",
    "  (bn1): BatchNorm1d(32768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (la2): PairFactorizedLinear(\n",
    "    (facto_nets): ModuleList(\n",
    "      (0): PairWeight()\n",
    "      (1): PairWeight()\n",
    "      (2): PairWeight()\n",
    "      (3): PairWeight()\n",
    "      (4): PairWeight()\n",
    "      (5): PairWeight()\n",
    "      (6): PairWeight()\n",
    "      (7): PairWeight()\n",
    "      (8): PairWeight()\n",
    "      (9): PairWeight()\n",
    "      (10): PairWeight()\n",
    "      (11): PairWeight()\n",
    "      (12): PairWeight()\n",
    "      (13): PairWeight()\n",
    "      (14): PairWeight()\n",
    "    )\n",
    "  )\n",
    "  (bn2): BatchNorm1d(32768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (la3): PairFactorizedLinear(\n",
    "    (facto_nets): ModuleList(\n",
    "      (0): PairWeight()\n",
    "      (1): PairWeight()\n",
    "      (2): PairWeight()\n",
    "      (3): PairWeight()\n",
    "      (4): PairWeight()\n",
    "      (5): PairWeight()\n",
    "      (6): PairWeight()\n",
    "      (7): PairWeight()\n",
    "      (8): PairWeight()\n",
    "      (9): PairWeight()\n",
    "      (10): PairWeight()\n",
    "      (11): PairWeight()\n",
    "      (12): PairWeight()\n",
    "      (13): PairWeight()\n",
    "      (14): PairWeight()\n",
    "    )\n",
    "  )\n",
    "  (bn3): BatchNorm1d(32768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (la4): GroupLinear()\n",
    "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
