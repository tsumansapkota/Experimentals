{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83895260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba98bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b926b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80cd2f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "X = torch.randn(1, N)\n",
    "### N+1 does not converge the X to exact values, but still have same scaled distance\n",
    "# C = torch.randn(N+1, N) ?? Impossible to reconstruct with scaled distance\n",
    "### Normalized/scaled distance is invertible with N+2 total distances\n",
    "C = torch.randn(N+2, N)\n",
    "dists = torch.cdist(X, C, p=2)\n",
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26cf6272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_inverse(C, dists):\n",
    "    A = 2*(C[1:]-C[:-1])\n",
    "    c2 = C**2\n",
    "    Z = (c2[:-1]-c2[1:]).sum(dim=1, keepdim=True)\n",
    "    invA = torch.pinverse(A)\n",
    "\n",
    "    d2 = dists**2\n",
    "    D = d2[:, :-1]-d2[:, 1:]\n",
    "\n",
    "    xrec = torch.matmul(invA, D.t()-Z).t()\n",
    "    return xrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0a88f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_inverse(C, dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d353660e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58f0062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0057,  0.3833,  2.2899,  0.2737, -0.6862]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_n = dists/dists.sum()\n",
    "X_n = compute_inverse(C, dists_n)\n",
    "X_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb1b9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.5869, 3.5838, 3.5827, 3.5776, 3.5755, 3.5695, 3.5689]]),\n",
       " tensor([[3.1373, 3.0464, 3.4614, 2.4063, 3.2618, 1.6331, 3.1386]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(X_n, C, p=2), dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45c77061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS = 9000\n",
    "# scale = torch.nn.Parameter(torch.Tensor([1.]))\n",
    "# optimizer = torch.optim.Adam([scale], lr=0.001)\n",
    "\n",
    "# for step in range(STEPS):\n",
    "# #     dists_n = dists/dists.sum()\n",
    "#     X_n = compute_inverse(C, dists_n*scale)\n",
    "#     dists_rec = torch.cdist(X_n, C, p=2)\n",
    "#     error = ((dists_rec - dists)**2).sum()\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     error.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     if (step+1)%500 == 0:\n",
    "#         print(f\"Step {step}; scale: {scale}; error:{error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7815c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 499; scale: Parameter containing:\n",
      "tensor([8.3194], requires_grad=True); error:0.004666309338063002\n",
      "Step 999; scale: Parameter containing:\n",
      "tensor([16.0105], requires_grad=True); error:0.0008479394600726664\n",
      "Step 1499; scale: Parameter containing:\n",
      "tensor([18.9528], requires_grad=True); error:4.209283724776469e-05\n",
      "Step 1999; scale: Parameter containing:\n",
      "tensor([19.7109], requires_grad=True); error:3.540022362358286e-06\n",
      "Step 2499; scale: Parameter containing:\n",
      "tensor([19.9677], requires_grad=True); error:3.122217151485529e-07\n",
      "Step 2999; scale: Parameter containing:\n",
      "tensor([20.0556], requires_grad=True); error:1.891223533334596e-08\n",
      "Step 3499; scale: Parameter containing:\n",
      "tensor([20.0799], requires_grad=True); error:5.652776025044659e-10\n",
      "Step 3999; scale: Parameter containing:\n",
      "tensor([20.0845], requires_grad=True); error:5.886180431957655e-12\n",
      "Step 4499; scale: Parameter containing:\n",
      "tensor([20.0848], requires_grad=True); error:4.867217739956686e-13\n",
      "Step 4999; scale: Parameter containing:\n",
      "tensor([20.0849], requires_grad=True); error:2.671751708760439e-13\n",
      "Step 5499; scale: Parameter containing:\n",
      "tensor([20.0849], requires_grad=True); error:1.7219559111936178e-13\n",
      "Step 5999; scale: Parameter containing:\n",
      "tensor([20.0849], requires_grad=True); error:1.0480505352461478e-13\n",
      "Step 6499; scale: Parameter containing:\n",
      "tensor([20.0849], requires_grad=True); error:6.339373470609644e-14\n",
      "Step 6999; scale: Parameter containing:\n",
      "tensor([20.0849], requires_grad=True); error:3.93574062229618e-14\n",
      "Step 7499; scale: Parameter containing:\n",
      "tensor([20.0850], requires_grad=True); error:2.4868995751603507e-14\n",
      "Step 7999; scale: Parameter containing:\n",
      "tensor([20.0850], requires_grad=True); error:1.3822276656583199e-14\n",
      "Step 8499; scale: Parameter containing:\n",
      "tensor([20.0850], requires_grad=True); error:8.770761894538737e-15\n",
      "Step 8999; scale: Parameter containing:\n",
      "tensor([20.0850], requires_grad=True); error:5.662137425588298e-15\n",
      "Step 9499; scale: Parameter containing:\n",
      "tensor([20.0850], requires_grad=True); error:4.052314039881821e-15\n",
      "Step 9999; scale: Parameter containing:\n",
      "tensor([20.0850], requires_grad=True); error:2.7200464103316335e-15\n"
     ]
    }
   ],
   "source": [
    "STEPS = 10000\n",
    "scale = torch.nn.Parameter(torch.Tensor([1.]))\n",
    "optimizer = torch.optim.Adam([scale], lr=0.01)\n",
    "\n",
    "for step in range(STEPS):\n",
    "#     dists_n = dists/dists.sum()\n",
    "    X_n = compute_inverse(C, dists_n*scale)\n",
    "    dists_rec = torch.cdist(X_n, C, p=2)\n",
    "    dists_rec = dists_rec/dists_rec.sum()\n",
    "    error = ((dists_rec - dists_n)**2).sum()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    error.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (step+1)%500 == 0:\n",
    "        print(f\"Step {step}; scale: {scale}; error:{error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "905b75d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.1373, 3.0464, 3.4614, 2.4063, 3.2618, 1.6331, 3.1386]],\n",
       "        grad_fn=<MulBackward0>),\n",
       " tensor([[3.1373, 3.0464, 3.4614, 2.4063, 3.2618, 1.6331, 3.1386]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_n*scale, dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91eb8e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]], grad_fn=<TBackward0>)\n",
      "tensor([[0.1562, 0.1517, 0.1723, 0.1198, 0.1624, 0.0813, 0.1563]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X_n = compute_inverse(C, dists_n*scale)\n",
    "print(X_n)\n",
    "dists_rec = torch.cdist(X_n, C, p=2)\n",
    "dists_rec = dists_rec/dists_rec.sum()\n",
    "print(dists_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21265a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1562, 0.1517, 0.1723, 0.1198, 0.1624, 0.0813, 0.1563]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0657f739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]]),\n",
       " tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]], grad_fn=<TBackward0>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afe70f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The normalized distance are same for both X and X_n which are different pints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56473b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 499; error:2.283181174789206e-06\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.168552    0.5258709  -0.2790756   0.66481483 -0.72627527]]\n",
      "Step 999; error:1.795026882689399e-08\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.203882    0.5474053  -0.3744936   0.68865    -0.74083066]]\n",
      "Step 1499; error:3.661937419963124e-11\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2073299   0.549246   -0.38509023  0.690873   -0.7423272 ]]\n",
      "Step 1999; error:1.715294573045867e-14\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074907   0.5493308  -0.3855891   0.6909761  -0.74239683]]\n",
      "Step 2499; error:5.162537064506978e-15\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074925   0.5493317  -0.3855934   0.69097745 -0.7423974 ]]\n",
      "Step 2999; error:2.55351295663786e-15\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074928   0.54933184 -0.385595    0.6909776  -0.7423978 ]]\n",
      "Step 3499; error:1.8318679906315083e-15\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074931   0.549332   -0.38559553  0.69097793 -0.74239796]]\n",
      "Step 3999; error:1.1102230246251565e-15\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074938   0.54933244 -0.38559738  0.69097835 -0.74239796]]\n",
      "Step 4499; error:8.881784197001252e-16\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074939   0.54933244 -0.38559696  0.6909782  -0.74239814]]\n",
      "Step 4999; error:2.220446049250313e-16\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074941   0.5493325  -0.3855968   0.69097847 -0.74239814]]\n",
      "Step 5499; error:0.0\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074945   0.5493331  -0.38559675  0.69097865 -0.7423983 ]]\n",
      "Step 5999; error:4.440892098500626e-16\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074945   0.5493329  -0.38559732  0.6909786  -0.7423982 ]]\n",
      "Step 6499; error:0.0\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074946   0.5493331  -0.38559753  0.6909787  -0.7423984 ]]\n",
      "Step 6999; error:0.0\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074946   0.5493331  -0.38559753  0.6909787  -0.7423984 ]]\n",
      "Step 7499; error:0.0\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074946   0.5493331  -0.38559753  0.6909787  -0.7423984 ]]\n",
      "Step 7999; error:0.0\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074946   0.5493331  -0.38559753  0.6909787  -0.7423984 ]]\n",
      "Step 8499; error:0.0\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074946   0.5493331  -0.38559753  0.6909787  -0.7423984 ]]\n",
      "Step 8999; error:0.0\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074946   0.5493331  -0.38559753  0.6909787  -0.7423984 ]]\n",
      "Step 9499; error:0.0\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074946   0.5493331  -0.38559753  0.6909787  -0.7423984 ]]\n",
      "Step 9999; error:0.0\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-1.2074946   0.5493331  -0.38559753  0.6909787  -0.7423984 ]]\n"
     ]
    }
   ],
   "source": [
    "STEPS = 10000\n",
    "X_guess = torch.nn.Parameter(torch.zeros_like(X))\n",
    "optimizer = torch.optim.Adam([X_guess], lr=0.01)\n",
    "\n",
    "for step in range(STEPS):\n",
    "    dists_g = torch.cdist(X_guess, C, p=2)\n",
    "    dists_g = dists_g/dists_g.sum()\n",
    "    error = ((dists_g - dists_n)**2).sum()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    error.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (step+1)%500 == 0:\n",
    "        print(f\"Step {step}; error:{error}\")\n",
    "        print(f\"Original:{X.numpy()}; \\nReconstructed:{X_guess.data.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "192f5747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(X_guess, C, p=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a38c1072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]], requires_grad=True),\n",
       " tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_guess, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2206040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1562, 0.1517, 0.1723, 0.1198, 0.1624, 0.0813, 0.1563]],\n",
       "        grad_fn=<DivBackward0>),\n",
       " tensor([[0.1562, 0.1517, 0.1723, 0.1198, 0.1624, 0.0813, 0.1563]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_g, dists_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61b971ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Again, same distance ratio but with different points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68b8fe2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]], grad_fn=<TBackward0>),\n",
       " Parameter containing:\n",
       " tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]], requires_grad=True),\n",
       " tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_n, X_guess, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c963eb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.0850)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa515d",
   "metadata": {},
   "source": [
    "## Now, scaling the C similar to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdafe362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 499; scale: Parameter containing:\n",
      "tensor([5.9606], requires_grad=True); error:46.62229537963867\n",
      "Step 999; scale: Parameter containing:\n",
      "tensor([10.3406], requires_grad=True); error:19.973737716674805\n",
      "Step 1499; scale: Parameter containing:\n",
      "tensor([13.6283], requires_grad=True); error:7.002164840698242\n",
      "Step 1999; scale: Parameter containing:\n",
      "tensor([15.8327], requires_grad=True); error:2.3078818321228027\n",
      "Step 2499; scale: Parameter containing:\n",
      "tensor([17.2569], requires_grad=True); error:0.7844226360321045\n",
      "Step 2999; scale: Parameter containing:\n",
      "tensor([18.1897], requires_grad=True); error:0.2808089852333069\n",
      "Step 3499; scale: Parameter containing:\n",
      "tensor([18.8191], requires_grad=True); error:0.10404705256223679\n",
      "Step 3999; scale: Parameter containing:\n",
      "tensor([19.2545], requires_grad=True); error:0.03864260017871857\n",
      "Step 4499; scale: Parameter containing:\n",
      "tensor([19.5589], requires_grad=True); error:0.013836178928613663\n",
      "Step 4999; scale: Parameter containing:\n",
      "tensor([19.7698], requires_grad=True); error:0.004560063127428293\n",
      "Step 5499; scale: Parameter containing:\n",
      "tensor([19.9112], requires_grad=True); error:0.0013056716416031122\n",
      "Step 5999; scale: Parameter containing:\n",
      "tensor([19.9999], requires_grad=True); error:0.0003012517699971795\n",
      "Step 6499; scale: Parameter containing:\n",
      "tensor([20.0497], requires_grad=True); error:5.070569386589341e-05\n",
      "Step 6999; scale: Parameter containing:\n",
      "tensor([20.0733], requires_grad=True); error:5.4681158871972e-06\n",
      "Step 7499; scale: Parameter containing:\n",
      "tensor([20.0822], requires_grad=True); error:3.194996907041059e-07\n",
      "Step 7999; scale: Parameter containing:\n",
      "tensor([20.0845], requires_grad=True); error:9.641496490075951e-09\n",
      "Step 8499; scale: Parameter containing:\n",
      "tensor([20.0848], requires_grad=True); error:1.3749286154052243e-09\n",
      "Step 8999; scale: Parameter containing:\n",
      "tensor([20.0848], requires_grad=True); error:8.352714075954282e-10\n",
      "Step 9499; scale: Parameter containing:\n",
      "tensor([20.0849], requires_grad=True); error:4.966551614415948e-10\n",
      "Step 9999; scale: Parameter containing:\n",
      "tensor([20.0849], requires_grad=True); error:3.041833451788989e-10\n"
     ]
    }
   ],
   "source": [
    "STEPS = 10000\n",
    "scale = torch.nn.Parameter(torch.Tensor([1.]))\n",
    "optimizer = torch.optim.Adam([scale], lr=0.01)\n",
    "\n",
    "for step in range(STEPS):\n",
    "#     dists_n = dists/dists.sum()\n",
    "    X_n = compute_inverse(C, dists_n*scale)\n",
    "    dists_rec = torch.cdist(X_n, C, p=2)\n",
    "#     dists_rec = dists_rec/dists_rec.sum()\n",
    "    error = ((dists_rec - dists_n*scale)**2).sum()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    error.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (step+1)%500 == 0:\n",
    "        print(f\"Step {step}; scale: {scale}; error:{error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e28bf8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]], grad_fn=<TBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bccc650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac40028",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Softmax and Layernorm also have some scaling/division .. following similar trend for reconstruction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
