{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mylibrary.nnlib as tnn\n",
    "import mylibrary.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST()\n",
    "train_data, train_label_, test_data, test_label_ = mnist.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa95e600650>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[0].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "input_size = 784\n",
    "hidden_1 = 10\n",
    "output_size = 10\n",
    "\n",
    "batch_size = 64#300\n",
    "\n",
    "train_label = tnn.Logits.index_to_logit(train_label_)\n",
    "train_size = len(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tnn.Adam(0.001)\n",
    "net = tnn.AutoForm(new_layers=True)\n",
    "linear1 = tnn.WeightsLayer(784, 250, optimizer=optim)\n",
    "# bn1 = tnn.BatchNormalization(250, optimizer=optim)\n",
    "bias1 = tnn.BiasLayer(250, optimizer=optim)\n",
    "relu1 = tnn.Relu()\n",
    "linear2 = tnn.WeightsLayer(250, 100, optimizer=optim)\n",
    "# bn2 = tnn.BatchNormalization(100, optimizer=optim)\n",
    "bias2 = tnn.BiasLayer(100, optimizer=optim)\n",
    "relu2 = tnn.Relu()\n",
    "linear3 = tnn.LinearLayer(100, 10, optimizer=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN 0 ->  6.5023150641770595\n",
      "EPOCH =  0 accuracy =  16.265\n",
      "9759 / 60000\n",
      "   TEST   accuracy =  16.38\n",
      "1638 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.757386964283628\n",
      "EPOCH =  0 accuracy =  89.46666666666667\n",
      "53680 / 60000\n",
      "   TEST   accuracy =  89.72\n",
      "8972 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.758625604744358\n",
      "EPOCH =  0 accuracy =  92.38666666666666\n",
      "55432 / 60000\n",
      "   TEST   accuracy =  92.4\n",
      "9240 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.702176671788985\n",
      "EPOCH =  0 accuracy =  94.935\n",
      "56961 / 60000\n",
      "   TEST   accuracy =  94.86\n",
      "9486 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.690284175203955\n",
      "EPOCH =  0 accuracy =  95.46\n",
      "57276 / 60000\n",
      "   TEST   accuracy =  95.05\n",
      "9505 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.725327184764171\n",
      "EPOCH =  0 accuracy =  95.90166666666666\n",
      "57541 / 60000\n",
      "   TEST   accuracy =  95.58\n",
      "9558 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.686185860956017\n",
      "EPOCH =  0 accuracy =  95.43166666666667\n",
      "57259 / 60000\n",
      "   TEST   accuracy =  95.11\n",
      "9511 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.73984489166563\n",
      "EPOCH =  0 accuracy =  96.50166666666667\n",
      "57901 / 60000\n",
      "   TEST   accuracy =  96.06\n",
      "9606 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.7214172496754365\n",
      "EPOCH =  0 accuracy =  96.53833333333334\n",
      "57923 / 60000\n",
      "   TEST   accuracy =  96.26\n",
      "9626 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.691179630962582\n",
      "EPOCH =  0 accuracy =  97.155\n",
      "58293 / 60000\n",
      "   TEST   accuracy =  96.47\n",
      "9647 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.665291697230559\n",
      "EPOCH =  1 accuracy =  96.63333333333334\n",
      "57980 / 60000\n",
      "   TEST   accuracy =  96.0\n",
      "9600 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.674899607606191\n",
      "EPOCH =  1 accuracy =  96.90166666666667\n",
      "58141 / 60000\n",
      "   TEST   accuracy =  96.23\n",
      "9623 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.678797615063289\n",
      "EPOCH =  1 accuracy =  96.78999999999999\n",
      "58074 / 60000\n",
      "   TEST   accuracy =  96.02000000000001\n",
      "9602 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.66015647576771\n",
      "EPOCH =  1 accuracy =  97.60166666666666\n",
      "58561 / 60000\n",
      "   TEST   accuracy =  97.03\n",
      "9703 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.658867186733364\n",
      "EPOCH =  1 accuracy =  97.81666666666666\n",
      "58690 / 60000\n",
      "   TEST   accuracy =  96.97\n",
      "9697 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.684471112137683\n",
      "EPOCH =  1 accuracy =  98.02166666666666\n",
      "58813 / 60000\n",
      "   TEST   accuracy =  97.05\n",
      "9705 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.654770067516449\n",
      "EPOCH =  1 accuracy =  97.71666666666667\n",
      "58630 / 60000\n",
      "   TEST   accuracy =  96.85000000000001\n",
      "9685 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.685717164578756\n",
      "EPOCH =  1 accuracy =  97.86166666666666\n",
      "58717 / 60000\n",
      "   TEST   accuracy =  97.07000000000001\n",
      "9707 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.688014000184175\n",
      "EPOCH =  1 accuracy =  97.89833333333333\n",
      "58739 / 60000\n",
      "   TEST   accuracy =  97.17\n",
      "9717 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.667069436130528\n",
      "EPOCH =  1 accuracy =  98.21333333333332\n",
      "58928 / 60000\n",
      "   TEST   accuracy =  97.04\n",
      "9704 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.654005871806459\n",
      "EPOCH =  2 accuracy =  97.97833333333334\n",
      "58787 / 60000\n",
      "   TEST   accuracy =  97.08\n",
      "9708 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.657957897572594\n",
      "EPOCH =  2 accuracy =  98.16833333333334\n",
      "58901 / 60000\n",
      "   TEST   accuracy =  97.04\n",
      "9704 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.680390905179898\n",
      "EPOCH =  2 accuracy =  97.08\n",
      "58248 / 60000\n",
      "   TEST   accuracy =  96.05\n",
      "9605 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.65706526280948\n",
      "EPOCH =  2 accuracy =  98.24666666666667\n",
      "58948 / 60000\n",
      "   TEST   accuracy =  97.50999999999999\n",
      "9751 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.65259771157694\n",
      "EPOCH =  2 accuracy =  98.52333333333333\n",
      "59114 / 60000\n",
      "   TEST   accuracy =  97.58\n",
      "9758 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.654476176206453\n",
      "EPOCH =  2 accuracy =  98.455\n",
      "59073 / 60000\n",
      "   TEST   accuracy =  97.36\n",
      "9736 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.648417750121336\n",
      "EPOCH =  2 accuracy =  98.59333333333333\n",
      "59156 / 60000\n",
      "   TEST   accuracy =  97.55\n",
      "9755 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.674117690793855\n",
      "EPOCH =  2 accuracy =  98.42333333333333\n",
      "59054 / 60000\n",
      "   TEST   accuracy =  97.50999999999999\n",
      "9751 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.6651378216257005\n",
      "EPOCH =  2 accuracy =  98.29\n",
      "58974 / 60000\n",
      "   TEST   accuracy =  97.57000000000001\n",
      "9757 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.657992233945632\n",
      "EPOCH =  2 accuracy =  98.53\n",
      "59118 / 60000\n",
      "   TEST   accuracy =  97.00999999999999\n",
      "9701 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.6493711419229395\n",
      "EPOCH =  3 accuracy =  97.79666666666667\n",
      "58678 / 60000\n",
      "   TEST   accuracy =  96.48\n",
      "9648 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.652074053237271\n",
      "EPOCH =  3 accuracy =  98.66833333333334\n",
      "59201 / 60000\n",
      "   TEST   accuracy =  97.28999999999999\n",
      "9729 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.658463190817692\n",
      "EPOCH =  3 accuracy =  98.04166666666667\n",
      "58825 / 60000\n",
      "   TEST   accuracy =  96.89999999999999\n",
      "9690 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.646820025351493\n",
      "EPOCH =  3 accuracy =  98.725\n",
      "59235 / 60000\n",
      "   TEST   accuracy =  97.64\n",
      "9764 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.639245657226546\n",
      "EPOCH =  3 accuracy =  98.83833333333332\n",
      "59303 / 60000\n",
      "   TEST   accuracy =  97.72\n",
      "9772 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.648619009087561\n",
      "EPOCH =  3 accuracy =  99.00999999999999\n",
      "59406 / 60000\n",
      "   TEST   accuracy =  97.76\n",
      "9776 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.629997870462159\n",
      "EPOCH =  3 accuracy =  98.875\n",
      "59325 / 60000\n",
      "   TEST   accuracy =  97.63\n",
      "9763 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.653994743786903\n",
      "EPOCH =  3 accuracy =  98.83333333333333\n",
      "59300 / 60000\n",
      "   TEST   accuracy =  97.63\n",
      "9763 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.6534567703941905\n",
      "EPOCH =  3 accuracy =  98.63\n",
      "59178 / 60000\n",
      "   TEST   accuracy =  97.50999999999999\n",
      "9751 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.650862064647605\n",
      "EPOCH =  3 accuracy =  98.90833333333333\n",
      "59345 / 60000\n",
      "   TEST   accuracy =  97.33000000000001\n",
      "9733 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.6353775068314285\n",
      "EPOCH =  4 accuracy =  98.88166666666666\n",
      "59329 / 60000\n",
      "   TEST   accuracy =  97.54\n",
      "9754 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.641930966221645\n",
      "EPOCH =  4 accuracy =  98.91333333333333\n",
      "59348 / 60000\n",
      "   TEST   accuracy =  97.64\n",
      "9764 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.65286145949215\n",
      "EPOCH =  4 accuracy =  98.89166666666667\n",
      "59335 / 60000\n",
      "   TEST   accuracy =  97.6\n",
      "9760 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.64971046680318\n",
      "EPOCH =  4 accuracy =  98.97\n",
      "59382 / 60000\n",
      "   TEST   accuracy =  97.69\n",
      "9769 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.631284409749763\n",
      "EPOCH =  4 accuracy =  98.69\n",
      "59214 / 60000\n",
      "   TEST   accuracy =  97.28999999999999\n",
      "9729 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.650913939717996\n",
      "EPOCH =  4 accuracy =  99.12333333333333\n",
      "59474 / 60000\n",
      "   TEST   accuracy =  97.7\n",
      "9770 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.633365709908895\n",
      "EPOCH =  4 accuracy =  99.15333333333334\n",
      "59492 / 60000\n",
      "   TEST   accuracy =  97.61999999999999\n",
      "9762 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.6441182575662925\n",
      "EPOCH =  4 accuracy =  98.63\n",
      "59178 / 60000\n",
      "   TEST   accuracy =  97.25\n",
      "9725 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.6369474834973925\n",
      "EPOCH =  4 accuracy =  98.65333333333334\n",
      "59192 / 60000\n",
      "   TEST   accuracy =  97.38\n",
      "9738 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.647434131562069\n",
      "EPOCH =  4 accuracy =  98.80499999999999\n",
      "59283 / 60000\n",
      "   TEST   accuracy =  97.33000000000001\n",
      "9733 / 10000\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "loss_list = []\n",
    "for epoch in range(5):\n",
    "    for index in range(train_size // batch_size):\n",
    "        train_x = train_data[index * batch_size:(index + 1) * batch_size]\n",
    "        train_y = train_label[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "        yout = net.forward(train_x)\n",
    "\n",
    "        dy = tnn.SoftmaxCrossEntropy.del_loss(yout, train_y)\n",
    "        loss = tnn.SoftmaxCrossEntropy.loss(yout, train_y)\n",
    "        loss_list.append(loss)\n",
    "\n",
    "        dx = net.backward(dy)\n",
    "        net.update()\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            \n",
    "            print('\\nTRAIN',index, '-> ', loss)\n",
    "            yout = net.forward(train_data)\n",
    "            outputs = tnn.Logits.logit_to_index(yout)\n",
    "            correct = (outputs == np.array(train_label_)).astype(int).sum()\n",
    "            accuracy = correct / len(train_label_) * 100.\n",
    "            print('EPOCH = ',epoch,'accuracy = ', accuracy)\n",
    "            print(correct, '/', len(train_label_))\n",
    "            \n",
    "            yout = net.forward(test_data)\n",
    "            outputs = tnn.Logits.logit_to_index(yout)\n",
    "            correct = (outputs == np.array(test_label_)).astype(int).sum()\n",
    "            accuracy = correct / len(test_label_) * 100.\n",
    "            accuracy_list.append(accuracy)\n",
    "            print('   TEST  ','accuracy = ', accuracy)\n",
    "            print(correct, '/', len(test_label_))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tnn.Adam(0.005)\n",
    "net = tnn.AutoForm(new_layers=True)\n",
    "linear1 = tnn.WeightsLayer(784, 250, optimizer=optim)\n",
    "bn1 = tnn.BatchNormalization(250, optimizer=optim)\n",
    "# bias1 = tnn.BiasLayer(250, optimizer=optim)\n",
    "relu1 = tnn.Relu()\n",
    "linear2 = tnn.WeightsLayer(250, 100, optimizer=optim)\n",
    "bn2 = tnn.BatchNormalization(100, optimizer=optim)\n",
    "# bias2 = tnn.BiasLayer(100, optimizer=optim)\n",
    "relu2 = tnn.Relu()\n",
    "linear3 = tnn.LinearLayer(100, 10, optimizer=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN 0 ->  6.493155982537698\n",
      "EPOCH =  0 accuracy =  34.34166666666666\n",
      "20605 / 60000\n",
      "   TEST   accuracy =  33.26\n",
      "3326 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.749403985985627\n",
      "EPOCH =  0 accuracy =  85.01666666666667\n",
      "51010 / 60000\n",
      "   TEST   accuracy =  85.9\n",
      "8590 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.737065137422751\n",
      "EPOCH =  0 accuracy =  93.315\n",
      "55989 / 60000\n",
      "   TEST   accuracy =  92.92\n",
      "9292 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.718863020534515\n",
      "EPOCH =  0 accuracy =  95.54833333333333\n",
      "57329 / 60000\n",
      "   TEST   accuracy =  95.19\n",
      "9519 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.690198839859225\n",
      "EPOCH =  0 accuracy =  94.80833333333332\n",
      "56885 / 60000\n",
      "   TEST   accuracy =  94.6\n",
      "9460 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.748414489209194\n",
      "EPOCH =  0 accuracy =  96.22333333333334\n",
      "57734 / 60000\n",
      "   TEST   accuracy =  96.03\n",
      "9603 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.672910785149014\n",
      "EPOCH =  0 accuracy =  96.66666666666667\n",
      "58000 / 60000\n",
      "   TEST   accuracy =  96.27\n",
      "9627 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.73369754786368\n",
      "EPOCH =  0 accuracy =  96.94333333333334\n",
      "58166 / 60000\n",
      "   TEST   accuracy =  96.5\n",
      "9650 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.695193149704523\n",
      "EPOCH =  0 accuracy =  96.75333333333333\n",
      "58052 / 60000\n",
      "   TEST   accuracy =  96.33\n",
      "9633 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.696585699297341\n",
      "EPOCH =  0 accuracy =  97.615\n",
      "58569 / 60000\n",
      "   TEST   accuracy =  96.93\n",
      "9693 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.676561937404728\n",
      "EPOCH =  1 accuracy =  96.64\n",
      "57984 / 60000\n",
      "   TEST   accuracy =  96.02000000000001\n",
      "9602 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.692816369079463\n",
      "EPOCH =  1 accuracy =  97.40333333333334\n",
      "58442 / 60000\n",
      "   TEST   accuracy =  96.57\n",
      "9657 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.696073201126043\n",
      "EPOCH =  1 accuracy =  97.25\n",
      "58350 / 60000\n",
      "   TEST   accuracy =  96.27\n",
      "9627 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.683692739144322\n",
      "EPOCH =  1 accuracy =  97.63\n",
      "58578 / 60000\n",
      "   TEST   accuracy =  96.77\n",
      "9677 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.655076273970358\n",
      "EPOCH =  1 accuracy =  97.51333333333334\n",
      "58508 / 60000\n",
      "   TEST   accuracy =  96.76\n",
      "9676 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.723592014573224\n",
      "EPOCH =  1 accuracy =  97.655\n",
      "58593 / 60000\n",
      "   TEST   accuracy =  97.1\n",
      "9710 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.653531909374033\n",
      "EPOCH =  1 accuracy =  97.77833333333334\n",
      "58667 / 60000\n",
      "   TEST   accuracy =  96.84\n",
      "9684 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.708816227148834\n",
      "EPOCH =  1 accuracy =  98.16166666666668\n",
      "58897 / 60000\n",
      "   TEST   accuracy =  97.32\n",
      "9732 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.671269995084289\n",
      "EPOCH =  1 accuracy =  97.61999999999999\n",
      "58572 / 60000\n",
      "   TEST   accuracy =  96.74000000000001\n",
      "9674 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.676941079324638\n",
      "EPOCH =  1 accuracy =  98.28\n",
      "58968 / 60000\n",
      "   TEST   accuracy =  97.38\n",
      "9738 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.658329105045048\n",
      "EPOCH =  2 accuracy =  97.405\n",
      "58443 / 60000\n",
      "   TEST   accuracy =  96.65\n",
      "9665 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.6732212718475035\n",
      "EPOCH =  2 accuracy =  98.03166666666667\n",
      "58819 / 60000\n",
      "   TEST   accuracy =  97.11\n",
      "9711 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.666427874443473\n",
      "EPOCH =  2 accuracy =  98.08833333333334\n",
      "58853 / 60000\n",
      "   TEST   accuracy =  97.11\n",
      "9711 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.682197666466835\n",
      "EPOCH =  2 accuracy =  98.09166666666667\n",
      "58855 / 60000\n",
      "   TEST   accuracy =  97.11999999999999\n",
      "9712 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.647664687824857\n",
      "EPOCH =  2 accuracy =  97.84833333333334\n",
      "58709 / 60000\n",
      "   TEST   accuracy =  97.03\n",
      "9703 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.684772154135363\n",
      "EPOCH =  2 accuracy =  98.33833333333334\n",
      "59003 / 60000\n",
      "   TEST   accuracy =  97.45\n",
      "9745 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.649615017296145\n",
      "EPOCH =  2 accuracy =  98.13333333333333\n",
      "58880 / 60000\n",
      "   TEST   accuracy =  97.08\n",
      "9708 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.69755405201467\n",
      "EPOCH =  2 accuracy =  98.64333333333335\n",
      "59186 / 60000\n",
      "   TEST   accuracy =  97.32\n",
      "9732 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.6528732398346575\n",
      "EPOCH =  2 accuracy =  98.28666666666666\n",
      "58972 / 60000\n",
      "   TEST   accuracy =  96.89999999999999\n",
      "9690 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.648055369448937\n",
      "EPOCH =  2 accuracy =  98.695\n",
      "59217 / 60000\n",
      "   TEST   accuracy =  97.53\n",
      "9753 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.659666635352462\n",
      "EPOCH =  3 accuracy =  98.14666666666668\n",
      "58888 / 60000\n",
      "   TEST   accuracy =  97.05\n",
      "9705 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.6611384027435445\n",
      "EPOCH =  3 accuracy =  98.19166666666666\n",
      "58915 / 60000\n",
      "   TEST   accuracy =  96.84\n",
      "9684 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.654839595490909\n",
      "EPOCH =  3 accuracy =  98.53\n",
      "59118 / 60000\n",
      "   TEST   accuracy =  97.34\n",
      "9734 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.6760148837841315\n",
      "EPOCH =  3 accuracy =  98.36\n",
      "59016 / 60000\n",
      "   TEST   accuracy =  97.31\n",
      "9731 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.633954856872557\n",
      "EPOCH =  3 accuracy =  97.85833333333333\n",
      "58715 / 60000\n",
      "   TEST   accuracy =  96.89\n",
      "9689 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.658387059854659\n",
      "EPOCH =  3 accuracy =  98.61999999999999\n",
      "59172 / 60000\n",
      "   TEST   accuracy =  97.41\n",
      "9741 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.65708235701612\n",
      "EPOCH =  3 accuracy =  98.65333333333334\n",
      "59192 / 60000\n",
      "   TEST   accuracy =  97.57000000000001\n",
      "9757 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.680411554344758\n",
      "EPOCH =  3 accuracy =  98.85000000000001\n",
      "59310 / 60000\n",
      "   TEST   accuracy =  97.52\n",
      "9752 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.6591076467774455\n",
      "EPOCH =  3 accuracy =  98.65333333333334\n",
      "59192 / 60000\n",
      "   TEST   accuracy =  97.35000000000001\n",
      "9735 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.654074786709152\n",
      "EPOCH =  3 accuracy =  98.70666666666666\n",
      "59224 / 60000\n",
      "   TEST   accuracy =  97.50999999999999\n",
      "9751 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.6419919052026\n",
      "EPOCH =  4 accuracy =  98.23833333333334\n",
      "58943 / 60000\n",
      "   TEST   accuracy =  97.03\n",
      "9703 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.653442046215634\n",
      "EPOCH =  4 accuracy =  98.64\n",
      "59184 / 60000\n",
      "   TEST   accuracy =  97.33000000000001\n",
      "9733 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.652503334568776\n",
      "EPOCH =  4 accuracy =  98.81166666666667\n",
      "59287 / 60000\n",
      "   TEST   accuracy =  97.55\n",
      "9755 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.635949682067887\n",
      "EPOCH =  4 accuracy =  98.715\n",
      "59229 / 60000\n",
      "   TEST   accuracy =  97.39999999999999\n",
      "9740 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.637337624045926\n",
      "EPOCH =  4 accuracy =  98.74333333333334\n",
      "59246 / 60000\n",
      "   TEST   accuracy =  97.47\n",
      "9747 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.661725296236183\n",
      "EPOCH =  4 accuracy =  98.68833333333333\n",
      "59213 / 60000\n",
      "   TEST   accuracy =  97.19\n",
      "9719 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.63820479277594\n",
      "EPOCH =  4 accuracy =  98.82166666666666\n",
      "59293 / 60000\n",
      "   TEST   accuracy =  97.64\n",
      "9764 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.64787552249491\n",
      "EPOCH =  4 accuracy =  98.83166666666666\n",
      "59299 / 60000\n",
      "   TEST   accuracy =  97.39\n",
      "9739 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.646390069561572\n",
      "EPOCH =  4 accuracy =  98.77166666666668\n",
      "59263 / 60000\n",
      "   TEST   accuracy =  97.14\n",
      "9714 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.631978106225211\n",
      "EPOCH =  4 accuracy =  98.91666666666666\n",
      "59350 / 60000\n",
      "   TEST   accuracy =  97.59\n",
      "9759 / 10000\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(5):\n",
    "    for index in range(train_size // batch_size):\n",
    "        train_x = train_data[index * batch_size:(index + 1) * batch_size]\n",
    "        train_y = train_label[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "        yout = net.forward(train_x)\n",
    "\n",
    "        dy = tnn.SoftmaxCrossEntropy.del_loss(yout, train_y)\n",
    "        loss = tnn.SoftmaxCrossEntropy.loss(yout, train_y)\n",
    "        loss_list.append(loss)\n",
    "\n",
    "        dx = net.backward(dy)\n",
    "        net.update()\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            \n",
    "            bn1.training = False\n",
    "            bn2.training = False\n",
    "            \n",
    "            print('\\nTRAIN',index, '-> ', loss)\n",
    "            yout = net.forward(train_data)\n",
    "            outputs = tnn.Logits.logit_to_index(yout)\n",
    "            correct = (outputs == np.array(train_label_)).astype(int).sum()\n",
    "            accuracy = correct / len(train_label_) * 100.\n",
    "            print('EPOCH = ',epoch,'accuracy = ', accuracy)\n",
    "            print(correct, '/', len(train_label_))\n",
    "            \n",
    "            yout = net.forward(test_data)\n",
    "            outputs = tnn.Logits.logit_to_index(yout)\n",
    "            correct = (outputs == np.array(test_label_)).astype(int).sum()\n",
    "            accuracy = correct / len(test_label_) * 100.\n",
    "            accuracy_list.append(accuracy)\n",
    "            print('   TEST  ','accuracy = ', accuracy)\n",
    "            print(correct, '/', len(test_label_))\n",
    "            \n",
    "            \n",
    "            bn1.training = True\n",
    "            bn2.training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa95e5a7d90>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.22665388, 4.7932811 , 3.89808014, 5.06748982, 4.18821738,\n",
       "       4.74964861, 4.16698334, 4.94509039, 3.5953083 , 3.95572047,\n",
       "       4.59437361, 4.1242208 , 3.8723101 , 3.35848642, 2.99134678,\n",
       "       4.02380929, 3.98013907, 4.04643423, 4.32991779, 4.74337761,\n",
       "       5.58543622, 4.5448307 , 4.19742279, 4.50087767, 2.97669342,\n",
       "       4.37688411, 4.0035629 , 4.87348946, 3.41846845, 4.06794735,\n",
       "       4.28061178, 5.23213608, 3.89814096, 4.89233721, 4.57013414,\n",
       "       5.53508977, 3.95835764, 4.23319661, 4.15784366, 3.63046506,\n",
       "       3.65894877, 4.72895913, 4.40466433, 4.05468358, 4.77441923,\n",
       "       3.65206007, 4.17849744, 5.30565381, 3.4097498 , 4.14232482,\n",
       "       4.74744775, 4.27596506, 3.51506471, 4.75409082, 4.16046689,\n",
       "       5.09869542, 4.48428172, 4.86873335, 3.37756127, 4.27031929,\n",
       "       4.45141479, 3.38742515, 3.63828376, 3.71167355, 4.58675568,\n",
       "       3.98441102, 3.53993935, 4.44888036, 4.01641745, 3.31856555,\n",
       "       4.6032413 , 4.40569762, 5.80062831, 4.83959462, 3.38000512,\n",
       "       4.45286034, 3.841333  , 4.20058656, 4.11410231, 4.40402912,\n",
       "       4.31447302, 4.8170269 , 3.15437572, 4.99154888, 4.47417003,\n",
       "       4.30324696, 3.84516794, 4.24923684, 4.42810989, 4.50665467,\n",
       "       3.72812834, 3.77016052, 4.23904447, 4.59263009, 4.21332207,\n",
       "       4.15294798, 3.90213423, 3.64855537, 4.4060891 , 4.13171927,\n",
       "       3.7440425 , 3.81557071, 5.66407712, 3.09871186, 4.76215272,\n",
       "       4.58198267, 4.52242508, 4.00485892, 4.18168052, 3.95034852,\n",
       "       3.77691107, 3.50278009, 3.32198791, 4.10783645, 4.22723339,\n",
       "       3.94101886, 3.49254101, 3.29734091, 4.28288854, 4.93277648,\n",
       "       4.14432729, 4.39853361, 3.35593912, 3.95130206, 3.70366826,\n",
       "       4.31707087, 4.37110263, 4.16775227, 4.04401126, 3.79117024,\n",
       "       4.40575751, 4.63255378, 3.43657832, 3.81574982, 4.1118394 ,\n",
       "       3.72534307, 3.32319801, 4.41302677, 4.59875499, 3.81523213,\n",
       "       3.50958439, 3.44729729, 4.07496074, 3.82503024, 3.93950151,\n",
       "       4.70760575, 3.18918104, 3.87821141, 3.69110413, 3.62634249,\n",
       "       4.61299127, 4.66156161, 4.41082019, 4.78645762, 3.81647398,\n",
       "       3.82238812, 4.00700188, 4.80621313, 4.58922623, 4.22191583,\n",
       "       4.67724121, 3.87013621, 3.80950158, 4.10674108, 4.06974327,\n",
       "       4.14455059, 3.68681491, 4.24933083, 3.83065446, 4.34186204,\n",
       "       3.87180009, 4.32824986, 4.58383421, 3.52850625, 3.65388373,\n",
       "       3.09861537, 4.28291234, 3.74120367, 3.94642074, 3.15286045,\n",
       "       4.52840439, 4.08216839, 4.82400909, 4.72628416, 4.63557058,\n",
       "       4.37495734, 3.63505665, 5.53883812, 5.10101802, 3.9847995 ,\n",
       "       4.00966865, 4.14894584, 3.98982639, 3.68977562, 4.37060142,\n",
       "       4.06057658, 3.56247217, 4.04109953, 4.20912879, 4.75273636,\n",
       "       4.40671609, 4.17571885, 4.43636982, 4.20882883, 4.43833288,\n",
       "       3.86457943, 4.11133321, 5.13709428, 4.6575593 , 5.0890061 ,\n",
       "       3.87653568, 4.12746812, 4.17480795, 3.72503807, 4.21316347,\n",
       "       4.41163829, 4.34735713, 4.7805264 , 3.64293442, 4.34248123,\n",
       "       4.93996679, 4.23887777, 4.17113886, 4.61630297, 4.22423072,\n",
       "       5.45716643, 3.16884872, 4.55456519, 4.02657754, 4.0606728 ,\n",
       "       4.30272978, 4.83475456, 3.96853837, 3.2689358 , 4.01439282,\n",
       "       4.26779857, 4.74876801, 4.38364555, 3.37831369, 4.73245751,\n",
       "       3.7354052 , 4.3742231 , 4.73265867, 3.93866716, 4.24494096,\n",
       "       5.25289051, 4.60877654, 4.15174168, 4.71249132, 4.58675099])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(linear1.weights, ord=2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
