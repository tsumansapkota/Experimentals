{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_circles, make_moons\n",
    "\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mean = nn.Parameter(torch.tensor([0], dtype=torch.float32, requires_grad=True))\n",
    "        self.var = nn.Parameter(torch.tensor([1], dtype=torch.float32, requires_grad=True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.exp(-0.5*(x-self.mean)**2/self.var) / torch.sqrt(2*self.var*np.pi)\n",
    "    \n",
    "    def NLL(self, x):\n",
    "        t1 = -1/(2*self.var)*torch.mean((x-self.mean)**2) - torch.log(self.var)/2\n",
    "        return t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = torch.randn(200,1)*3-1\n",
    "inp = torch.rand(200)*5-1\n",
    "targ = torch.ones_like(inp)/len(inp) \n",
    "gaus = Gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(gaus.parameters(), lr=0.5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL:  2.047778844833374\n",
      "Mean: 0.7194718718528748, Variance: 1.773889422416687\n",
      "NLL:  0.8537141680717468\n",
      "Mean: 1.4055497646331787, Variance: 1.9505282640457153\n",
      "NLL:  0.8528896570205688\n",
      "Mean: 1.4371598958969116, Variance: 1.9868594408035278\n",
      "NLL:  0.8528124094009399\n",
      "Mean: 1.438844084739685, Variance: 2.005049467086792\n",
      "NLL:  0.8527920842170715\n",
      "Mean: 1.4389382600784302, Variance: 2.01446795463562\n",
      "NLL:  0.8527865409851074\n",
      "Mean: 1.43894362449646, Variance: 2.019413471221924\n",
      "NLL:  0.8527848720550537\n",
      "Mean: 1.4389437437057495, Variance: 2.022028923034668\n",
      "NLL:  0.8527845144271851\n",
      "Mean: 1.4389437437057495, Variance: 2.0234172344207764\n",
      "NLL:  0.8527843356132507\n",
      "Mean: 1.4389437437057495, Variance: 2.024155616760254\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.0245490074157715\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.0247585773468018\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.0248703956604004\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024930000305176\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024961471557617\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.0249783992767334\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.0249874591827393\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.0249922275543213\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.0249946117401123\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "NLL:  0.852784276008606\n",
      "Mean: 1.4389437437057495, Variance: 2.024995803833008\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    NLL = -gaus.NLL(inp)\n",
    "    optim.zero_grad()\n",
    "    NLL.backward()\n",
    "    optim.step()\n",
    "    if i%10 == 0:\n",
    "        print(\"NLL: \", float(NLL))\n",
    "        print(f\"Mean: {gaus.mean.data[0]}, Variance: {gaus.var.data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout = gaus(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f71ec6e5f90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(inp.data.numpy(), yout.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD   -> Mean: 1.4389437437057495, Variance: 2.024995803833008\n",
      "Torch-> Mean: 1.4389439821243286, Variance: 2.0351738929748535\n"
     ]
    }
   ],
   "source": [
    "print(f\"GD   -> Mean: {gaus.mean.data[0]}, Variance: {gaus.var.data[0]}\")\n",
    "print(f\"Torch-> Mean: {torch.mean(inp)}, Variance: {torch.var(inp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(37.4341, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(yout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mhdadk/Maximum-Likelihood-Estimation/blob/master/mle_gaussian.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Bandpass Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit math.gamma(1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit scipy.special.gamma(1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = torch.tensor([1/4])\n",
    "# math.gamma(1/4), scipy.special.gamma(1/4), float(torch.lgamma(v).exp()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit torch.lgamma(v).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Bandpass(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         ##mean, var, a\n",
    "#         self.params = nn.Parameter(torch.tensor([0, 1, 1], dtype=torch.float32, requires_grad=True))\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         n1 = torch.exp(-((torch.abs(x-self.params[0]))/self.params[1])**(4*self.params[2]))\n",
    "#         d1 = self.params[1]*0.25/self.params[2] * math.gamma(0.25/float(self.params[2]))\n",
    "# #         d1 = self.params[1]*0.25/self.params[2] * torch.lgamma(0.25/self.params[2]).exp()\n",
    "#         return  n1/d1\n",
    "    \n",
    "#     def NLL(self, x):\n",
    "#         t1 = torch.mean(((torch.abs(x-self.params[0]))/self.params[1])**(4*self.params[2]))\n",
    "# #         t2 = torch.log(0.25/self.params[2] * math.gamma(0.25/float(self.params[2])))\n",
    "#         t2 = torch.log(0.25/self.params[2] * math.gamma(0.25/self.params[2]))\n",
    "# #         t2 = torch.log(0.25/self.params[2] * torch.lgamma(0.25/self.params[2]).exp())\n",
    "# #         t2 = torch.log(0.25/self.params[2]) + torch.lgamma(0.25/self.params[2]+1e-4)\n",
    "#         t3 = torch.log(self.params[1])\n",
    "#         return -t1-t2-t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandpass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        ##mean, var, a\n",
    "        self.params = nn.Parameter(torch.tensor([0, 1, 1], dtype=torch.float32, requires_grad=True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        n1 = torch.exp(-(((x-self.params[0])**2)*(self.params[1]**2))**self.params[2])\n",
    "        n2 = self.params[1]*self.params[2]\n",
    "        d1 = math.gamma(0.5/float(self.params[2]))\n",
    "#         d1 = torch.lgamma(0.5/self.params[2]).exp()\n",
    "        return  n1*n2/d1\n",
    "    \n",
    "    def NLL(self, x):\n",
    "        t1 = torch.mean((((x-self.params[0])**2)*(self.params[1]**2))**self.params[2])\n",
    "        t2 = torch.log(self.params[1]*self.params[2])\n",
    "#         t3 = torch.log(math.gamma(0.5/self.params[2]))\n",
    "#         t3 = torch.log(math.gamma(0.5/float(self.params[2])))\n",
    "        t3 = torch.lgamma(0.5/self.params[2])\n",
    "        \n",
    "        return -t1+t2-t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = torch.randn(200,1)*3-1\n",
    "# inp = torch.rand(200)*5-1\n",
    "targ = torch.ones_like(inp)/len(inp)\n",
    "bpas = Bandpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(bpas.parameters(), lr=0.03)\n",
    "# optim = torch.optim.SGD(bpas.parameters(), lr=0.5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL:  4.667922496795654\n",
      "Params: Parameter containing:\n",
      "tensor([0.0300, 0.9700, 0.9700], requires_grad=True)\n",
      "NLL:  1.8039336204528809\n",
      "Params: Parameter containing:\n",
      "tensor([1.2397, 0.5261, 0.8651], requires_grad=True)\n",
      "NLL:  1.748281717300415\n",
      "Params: Parameter containing:\n",
      "tensor([1.4300, 0.4680, 1.2076], requires_grad=True)\n",
      "NLL:  1.725970983505249\n",
      "Params: Parameter containing:\n",
      "tensor([1.4103, 0.4451, 1.4869], requires_grad=True)\n",
      "NLL:  1.71206796169281\n",
      "Params: Parameter containing:\n",
      "tensor([1.4009, 0.4335, 1.7301], requires_grad=True)\n",
      "NLL:  1.7022950649261475\n",
      "Params: Parameter containing:\n",
      "tensor([1.3961, 0.4265, 1.9498], requires_grad=True)\n",
      "NLL:  1.694909930229187\n",
      "Params: Parameter containing:\n",
      "tensor([1.3937, 0.4217, 2.1532], requires_grad=True)\n",
      "NLL:  1.6890549659729004\n",
      "Params: Parameter containing:\n",
      "tensor([1.3929, 0.4183, 2.3445], requires_grad=True)\n",
      "NLL:  1.6842516660690308\n",
      "Params: Parameter containing:\n",
      "tensor([1.3930, 0.4157, 2.5264], requires_grad=True)\n",
      "NLL:  1.680208683013916\n",
      "Params: Parameter containing:\n",
      "tensor([1.3936, 0.4136, 2.7010], requires_grad=True)\n",
      "NLL:  1.6767363548278809\n",
      "Params: Parameter containing:\n",
      "tensor([1.3947, 0.4120, 2.8696], requires_grad=True)\n",
      "NLL:  1.673706293106079\n",
      "Params: Parameter containing:\n",
      "tensor([1.3961, 0.4106, 3.0335], requires_grad=True)\n",
      "NLL:  1.6710267066955566\n",
      "Params: Parameter containing:\n",
      "tensor([1.3976, 0.4095, 3.1934], requires_grad=True)\n",
      "NLL:  1.6686302423477173\n",
      "Params: Parameter containing:\n",
      "tensor([1.3992, 0.4085, 3.3500], requires_grad=True)\n",
      "NLL:  1.6664671897888184\n",
      "Params: Parameter containing:\n",
      "tensor([1.4009, 0.4077, 3.5040], requires_grad=True)\n",
      "NLL:  1.6644988059997559\n",
      "Params: Parameter containing:\n",
      "tensor([1.4027, 0.4070, 3.6559], requires_grad=True)\n",
      "NLL:  1.6626948118209839\n",
      "Params: Parameter containing:\n",
      "tensor([1.4044, 0.4063, 3.8060], requires_grad=True)\n",
      "NLL:  1.6610312461853027\n",
      "Params: Parameter containing:\n",
      "tensor([1.4062, 0.4058, 3.9546], requires_grad=True)\n",
      "NLL:  1.6594886779785156\n",
      "Params: Parameter containing:\n",
      "tensor([1.4080, 0.4053, 4.1022], requires_grad=True)\n",
      "NLL:  1.6580513715744019\n",
      "Params: Parameter containing:\n",
      "tensor([1.4097, 0.4048, 4.2490], requires_grad=True)\n",
      "NLL:  1.6567060947418213\n",
      "Params: Parameter containing:\n",
      "tensor([1.4115, 0.4044, 4.3952], requires_grad=True)\n",
      "NLL:  1.655442476272583\n",
      "Params: Parameter containing:\n",
      "tensor([1.4132, 0.4040, 4.5410], requires_grad=True)\n",
      "NLL:  1.654250979423523\n",
      "Params: Parameter containing:\n",
      "tensor([1.4149, 0.4037, 4.6867], requires_grad=True)\n",
      "NLL:  1.6531238555908203\n",
      "Params: Parameter containing:\n",
      "tensor([1.4165, 0.4034, 4.8324], requires_grad=True)\n",
      "NLL:  1.652054786682129\n",
      "Params: Parameter containing:\n",
      "tensor([1.4182, 0.4031, 4.9783], requires_grad=True)\n",
      "NLL:  1.6510379314422607\n",
      "Params: Parameter containing:\n",
      "tensor([1.4198, 0.4029, 5.1246], requires_grad=True)\n",
      "NLL:  1.6500680446624756\n",
      "Params: Parameter containing:\n",
      "tensor([1.4213, 0.4026, 5.2713], requires_grad=True)\n",
      "NLL:  1.6491410732269287\n",
      "Params: Parameter containing:\n",
      "tensor([1.4229, 0.4024, 5.4187], requires_grad=True)\n",
      "NLL:  1.6482539176940918\n",
      "Params: Parameter containing:\n",
      "tensor([1.4244, 0.4022, 5.5668], requires_grad=True)\n",
      "NLL:  1.6474024057388306\n",
      "Params: Parameter containing:\n",
      "tensor([1.4258, 0.4020, 5.7157], requires_grad=True)\n",
      "NLL:  1.6465837955474854\n",
      "Params: Parameter containing:\n",
      "tensor([1.4273, 0.4019, 5.8657], requires_grad=True)\n",
      "NLL:  1.6457959413528442\n",
      "Params: Parameter containing:\n",
      "tensor([1.4287, 0.4017, 6.0167], requires_grad=True)\n",
      "NLL:  1.6450364589691162\n",
      "Params: Parameter containing:\n",
      "tensor([1.4301, 0.4016, 6.1690], requires_grad=True)\n",
      "NLL:  1.6443029642105103\n",
      "Params: Parameter containing:\n",
      "tensor([1.4314, 0.4014, 6.3225], requires_grad=True)\n",
      "NLL:  1.6435937881469727\n",
      "Params: Parameter containing:\n",
      "tensor([1.4327, 0.4013, 6.4774], requires_grad=True)\n",
      "NLL:  1.6429076194763184\n",
      "Params: Parameter containing:\n",
      "tensor([1.4340, 0.4012, 6.6338], requires_grad=True)\n",
      "NLL:  1.642242670059204\n",
      "Params: Parameter containing:\n",
      "tensor([1.4353, 0.4011, 6.7917], requires_grad=True)\n",
      "NLL:  1.6415975093841553\n",
      "Params: Parameter containing:\n",
      "tensor([1.4365, 0.4009, 6.9513], requires_grad=True)\n",
      "NLL:  1.6409764289855957\n",
      "Params: Parameter containing:\n",
      "tensor([1.4377, 0.4004, 7.1121], requires_grad=True)\n",
      "NLL:  1.640364408493042\n",
      "Params: Parameter containing:\n",
      "tensor([1.4389, 0.4008, 7.2752], requires_grad=True)\n",
      "NLL:  1.6397756338119507\n",
      "Params: Parameter containing:\n",
      "tensor([1.4400, 0.4009, 7.4398], requires_grad=True)\n",
      "NLL:  1.639197826385498\n",
      "Params: Parameter containing:\n",
      "tensor([1.4411, 0.4006, 7.6068], requires_grad=True)\n",
      "NLL:  1.6386387348175049\n",
      "Params: Parameter containing:\n",
      "tensor([1.4422, 0.4006, 7.7754], requires_grad=True)\n",
      "NLL:  1.6384459733963013\n",
      "Params: Parameter containing:\n",
      "tensor([1.4433, 0.3976, 7.9463], requires_grad=True)\n",
      "NLL:  1.637559175491333\n",
      "Params: Parameter containing:\n",
      "tensor([1.4443, 0.4004, 8.1194], requires_grad=True)\n",
      "NLL:  1.6370407342910767\n",
      "Params: Parameter containing:\n",
      "tensor([1.4454, 0.4004, 8.2945], requires_grad=True)\n",
      "NLL:  1.6365331411361694\n",
      "Params: Parameter containing:\n",
      "tensor([1.4464, 0.4005, 8.4725], requires_grad=True)\n",
      "NLL:  1.6360362768173218\n",
      "Params: Parameter containing:\n",
      "tensor([1.4473, 0.4002, 8.6523], requires_grad=True)\n",
      "NLL:  1.6355650424957275\n",
      "Params: Parameter containing:\n",
      "tensor([1.4483, 0.3998, 8.8347], requires_grad=True)\n",
      "NLL:  1.6350781917572021\n",
      "Params: Parameter containing:\n",
      "tensor([1.4492, 0.4001, 9.0200], requires_grad=True)\n",
      "NLL:  1.6346155405044556\n",
      "Params: Parameter containing:\n",
      "tensor([1.4501, 0.4000, 9.2074], requires_grad=True)\n",
      "NLL:  1.634338140487671\n",
      "Params: Parameter containing:\n",
      "tensor([1.4510, 0.4009, 9.3978], requires_grad=True)\n",
      "NLL:  1.6337189674377441\n",
      "Params: Parameter containing:\n",
      "tensor([1.4519, 0.3999, 9.5909], requires_grad=True)\n",
      "NLL:  1.6332848072052002\n",
      "Params: Parameter containing:\n",
      "tensor([1.4528, 0.3999, 9.7866], requires_grad=True)\n",
      "NLL:  1.6328625679016113\n",
      "Params: Parameter containing:\n",
      "tensor([1.4536, 0.4001, 9.9852], requires_grad=True)\n",
      "NLL:  1.6324487924575806\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4544,  0.4002, 10.1867], requires_grad=True)\n",
      "NLL:  1.632047414779663\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4552,  0.4003, 10.3912], requires_grad=True)\n",
      "NLL:  1.6316434144973755\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4560,  0.4000, 10.5987], requires_grad=True)\n",
      "NLL:  1.631258249282837\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4567,  0.4002, 10.8093], requires_grad=True)\n",
      "NLL:  1.6308619976043701\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4575,  0.3998, 11.0231], requires_grad=True)\n",
      "NLL:  1.6304914951324463\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4582,  0.3995, 11.2400], requires_grad=True)\n",
      "NLL:  1.6301254034042358\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4589,  0.4001, 11.4601], requires_grad=True)\n",
      "NLL:  1.629759430885315\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4596,  0.3998, 11.6837], requires_grad=True)\n",
      "NLL:  1.629402995109558\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4603,  0.3998, 11.9106], requires_grad=True)\n",
      "NLL:  1.6290702819824219\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4610,  0.3993, 12.1410], requires_grad=True)\n",
      "NLL:  1.6287212371826172\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4616,  0.3993, 12.3751], requires_grad=True)\n",
      "NLL:  1.628396987915039\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4623,  0.3991, 12.6125], requires_grad=True)\n",
      "NLL:  1.6285841464996338\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4629,  0.4019, 12.8534], requires_grad=True)\n",
      "NLL:  1.6277480125427246\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4635,  0.4002, 13.0977], requires_grad=True)\n",
      "NLL:  1.6274352073669434\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4641,  0.4000, 13.3462], requires_grad=True)\n",
      "NLL:  1.6271153688430786\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4647,  0.3995, 13.5982], requires_grad=True)\n",
      "NLL:  1.6268645524978638\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4652,  0.3987, 13.8542], requires_grad=True)\n",
      "NLL:  1.6265249252319336\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4658,  0.4001, 14.1135], requires_grad=True)\n",
      "NLL:  1.6262190341949463\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4663,  0.3996, 14.3774], requires_grad=True)\n",
      "NLL:  1.6259397268295288\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4669,  0.3989, 14.6451], requires_grad=True)\n",
      "NLL:  1.6256685256958008\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4674,  0.3991, 14.9169], requires_grad=True)\n",
      "NLL:  1.6253993511199951\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4679,  0.4001, 15.1927], requires_grad=True)\n",
      "NLL:  1.625116229057312\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4684,  0.3993, 15.4726], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL:  1.6248466968536377\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4688,  0.3997, 15.7567], requires_grad=True)\n",
      "NLL:  1.624754548072815\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4694,  0.4009, 16.0454], requires_grad=True)\n",
      "NLL:  1.6244415044784546\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4697,  0.4003, 16.3375], requires_grad=True)\n",
      "NLL:  1.6240867376327515\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4703,  0.3993, 16.6350], requires_grad=True)\n",
      "NLL:  1.6238558292388916\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4709,  0.3997, 16.9365], requires_grad=True)\n",
      "NLL:  1.6236454248428345\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4713,  0.4002, 17.2427], requires_grad=True)\n",
      "NLL:  1.6234933137893677\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4717,  0.4006, 17.5534], requires_grad=True)\n",
      "NLL:  1.6232755184173584\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4721,  0.4007, 17.8689], requires_grad=True)\n",
      "NLL:  1.622954249382019\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4725,  0.4001, 18.1886], requires_grad=True)\n",
      "NLL:  1.6227880716323853\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4729,  0.4004, 18.5137], requires_grad=True)\n",
      "NLL:  1.6225066184997559\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4733,  0.4001, 18.8436], requires_grad=True)\n",
      "NLL:  1.6222584247589111\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4737,  0.3994, 19.1778], requires_grad=True)\n",
      "NLL:  1.6220803260803223\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4741,  0.3989, 19.5180], requires_grad=True)\n",
      "NLL:  1.621842861175537\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4749,  0.3993, 19.8628], requires_grad=True)\n",
      "NLL:  1.6216669082641602\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4748,  0.3990, 20.2131], requires_grad=True)\n",
      "NLL:  1.6215393543243408\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4697,  0.3990, 20.5680], requires_grad=True)\n",
      "NLL:  1.6212918758392334\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4756,  0.4000, 20.9289], requires_grad=True)\n",
      "NLL:  1.6210980415344238\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4759,  0.3989, 21.2954], requires_grad=True)\n",
      "NLL:  1.6209275722503662\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4763,  0.4001, 21.6669], requires_grad=True)\n",
      "NLL:  1.6209971904754639\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4766,  0.3981, 22.0450], requires_grad=True)\n",
      "NLL:  1.6205511093139648\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4737,  0.3994, 22.4275], requires_grad=True)\n",
      "NLL:  1.6204590797424316\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4772,  0.3986, 22.8171], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    NLL = -bpas.NLL(inp)\n",
    "    optim.zero_grad()\n",
    "    NLL.backward()\n",
    "    if torch.any(torch.isnan(bpas.params.grad)):\n",
    "        print(\"the gradient is NAN\")\n",
    "        print(\"NLL: \", float(NLL))\n",
    "        print(f\"Params: {bpas.params}\")\n",
    "        break\n",
    "#     bpas.params.grad[2] = 0\n",
    "    optim.step()\n",
    "    if i%100 == 0:\n",
    "        print(\"NLL: \", float(NLL))\n",
    "        print(f\"Params: {bpas.params}\")\n",
    "\n",
    "\n",
    "# NLL = -bpas.NLL(inp)\n",
    "# optim.zero_grad()\n",
    "# NLL.backward()\n",
    "# optim.step()\n",
    "# print(\"NLL: \", float(NLL))\n",
    "# print(f\"Params: {bpas.params}\")\n",
    "\n",
    "# bpas.params.grad[2] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL:  1.6202032566070557\n",
      "Params: Parameter containing:\n",
      "tensor([ 1.4773,  0.3992, 23.2126], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "NLL = -bpas.NLL(inp)\n",
    "optim.zero_grad()\n",
    "NLL.backward()\n",
    "optim.step()\n",
    "print(\"NLL: \", float(NLL))\n",
    "print(f\"Params: {bpas.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0013,  0.1614, -0.0004])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpas.params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout = bpas(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(inp.data.numpy(), yout.data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1966, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020,\n",
       "        0.2020, 0.1803, 0.2020, 0.2020, 0.1549, 0.2020, 0.2020, 0.2020, 0.2020,\n",
       "        0.2017, 0.2020, 0.2020, 0.2020, 0.2020, 0.2010, 0.2020, 0.1933, 0.2020,\n",
       "        0.2020, 0.2020, 0.2020, 0.1774, 0.2020, 0.2020, 0.2020, 0.1326, 0.2020,\n",
       "        0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020,\n",
       "        0.1446, 0.1958, 0.2020, 0.2020, 0.2020, 0.2020, 0.1972, 0.2020, 0.2020,\n",
       "        0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020,\n",
       "        0.1715, 0.2020, 0.2017, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020,\n",
       "        0.2020, 0.2020, 0.2019, 0.2020, 0.2015, 0.2020, 0.1972, 0.2020, 0.2020,\n",
       "        0.2020, 0.2020, 0.1821, 0.2020, 0.2020, 0.2018, 0.2020, 0.2013, 0.0933,\n",
       "        0.1968, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2014, 0.2020, 0.2020,\n",
       "        0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.1899, 0.2020, 0.2020,\n",
       "        0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020,\n",
       "        0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.0908, 0.2020, 0.2020, 0.2020,\n",
       "        0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.1141,\n",
       "        0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2019, 0.2020, 0.2020,\n",
       "        0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020,\n",
       "        0.2020, 0.2020, 0.2020, 0.1919, 0.2020, 0.2020, 0.1971, 0.2020, 0.2020,\n",
       "        0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020,\n",
       "        0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020,\n",
       "        0.2001, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020, 0.2020,\n",
       "        0.2007, 0.2016, 0.2020, 0.2010, 0.2020, 0.2019, 0.2020, 0.1816, 0.2020,\n",
       "        0.2020, 0.2020], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(39.7305, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(yout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appriximate the area under the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini, maxi = inp.min(), inp.max()\n",
    "diff = maxi-mini\n",
    "\n",
    "xs = torch.linspace(mini-diff, maxi+diff, steps=100000, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### for gaussian\n",
    "ys = gaus(xs).data\n",
    "width = xs[1:]-xs[:-1]\n",
    "height = (ys[:-1]+ys[1:])/2\n",
    "# height = ys[:-1]\n",
    "\n",
    "areas = width*height\n",
    "area = areas.sum()\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### for bandpass\n",
    "ys = bpas(xs).data\n",
    "width = xs[1:]-xs[:-1]\n",
    "height = (ys[:-1]+ys[1:])/2\n",
    "\n",
    "areas = width*height\n",
    "area = areas.sum()\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
