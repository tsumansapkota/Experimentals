{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e79740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2b919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dtnnlib as dtnn\n",
    "# import resnet_cifar\n",
    "\n",
    "from torchvision import datasets, transforms as T\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53af51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1602c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.5,],\n",
    "        std=[0.5,],\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/\", train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/\", train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "491fefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.data = train_dataset.data.view(-1, 28*28)\n",
    "# test_dataset.data = test_dataset.data.view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6807321",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f12e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd705fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0879c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47582925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuman/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103909e2",
   "metadata": {},
   "source": [
    "## Any function as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9551d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionDT(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, func, inv_temp=0.):\n",
    "        '''\n",
    "        func [input_dim -> 1]\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.func = func\n",
    "        \n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.centers = torch.randn(num_centers, input_dim)/3.\n",
    "        self.centers = nn.Parameter(self.centers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = x.unsqueeze(1) - self.centers.unsqueeze(0)\n",
    "        dists = self.func(z).squeeze(-1)\n",
    "        dists = -dists*torch.exp(self.inv_temp)\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e1d6fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuman/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from classes import DistanceRegressor, ConvexNN\n",
    "from nflib.flows import SequentialFlow, ActNorm\n",
    "import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4fc66",
   "metadata": {},
   "source": [
    "## Merge all models into single and benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffba015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(h = 5, device='cpu'):\n",
    "    I = 784\n",
    "    layer1 = {\n",
    "        \"l_0.5\":dtnn.DistanceTransform(I, h, p=0.5, bias=False),\n",
    "        \"l_1\":dtnn.DistanceTransform(I, h, p=1, bias=False),\n",
    "        \"l_2\":dtnn.DistanceTransform(I, h, bias=False),\n",
    "        \"l_inf\":dtnn.DistanceTransform(I, h, p=20, bias=False),\n",
    "        \"stereo\":dtnn.StereographicTransform(I, h, bias=False),\n",
    "        \"linear\":nn.Linear(I, h, bias=False)\n",
    "    }\n",
    "    net_dict = {}\n",
    "    for key in layer1:\n",
    "        net = nn.Sequential(\n",
    "            layer1[key],\n",
    "            nn.BatchNorm1d(h),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(h, 10),\n",
    "            )\n",
    "        net_dict[key] = net.to(device)\n",
    "    return net_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14541096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_func(h = 500, func_h=500, device='cpu'):\n",
    "    layer1 = {\n",
    "        \"convex\":ConvexNN([784, func_h, 1]),\n",
    "        \"invex\":nn.Sequential(\n",
    "                    ActNorm(784),\n",
    "                    irf.ResidualFlow(784, [func_h], activation=irf.LeakyReLU),\n",
    "                    ActNorm(784),\n",
    "                    DistanceRegressor(784),\n",
    "                    ),\n",
    "        \"ordinary\":nn.Sequential(\n",
    "                    ActNorm(784),\n",
    "                    irf.ResidualFlow(784, [func_h], activation=irf.LeakyReLU),\n",
    "                    ActNorm(784),\n",
    "                    DistanceRegressor(784),\n",
    "                    ),\n",
    "    }\n",
    "    irf.remove_spectral_norm_model(layer1[\"ordinary\"])\n",
    "\n",
    "    net_dict = {}\n",
    "    for key in layer1:\n",
    "        net = nn.Sequential(\n",
    "            FunctionDT(784, h, layer1[key]),\n",
    "            nn.BatchNorm1d(h),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(h, 10),\n",
    "            )\n",
    "        net_dict[key] = net.to(device)\n",
    "    return net_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eaa0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7bd80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch, model, model_name):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e46396d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90b58342",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04636518",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"./outputs/00.2_exp_acc_dict.json\"\n",
    "\n",
    "with open(data_file, 'r') as f:\n",
    "    exp_acc_vals = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6dd5522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5': {'l_0.5': 67.05,\n",
       "  'l_1': 70.7,\n",
       "  'l_2': 78.15,\n",
       "  'l_inf': 79.52,\n",
       "  'stereo': 82.19,\n",
       "  'linear': 82.74,\n",
       "  'convex': 79.49,\n",
       "  'invex': 88.26,\n",
       "  'ordinary': 83.55},\n",
       " '10': {'l_0.5': 72.08,\n",
       "  'l_1': 77.91,\n",
       "  'l_2': 82.35,\n",
       "  'l_inf': 83.98,\n",
       "  'stereo': 84.73,\n",
       "  'linear': 84.89,\n",
       "  'convex': 78.99,\n",
       "  'invex': 88.41,\n",
       "  'ordinary': 81.69},\n",
       " '20': {'l_0.5': 75.54,\n",
       "  'l_1': 80.08,\n",
       "  'l_2': 83.82,\n",
       "  'l_inf': 85.17,\n",
       "  'stereo': 85.86,\n",
       "  'linear': 86.27,\n",
       "  'convex': 81.03}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0feb854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['l_0.5', 'l_1', 'l_2', 'l_inf', 'stereo', 'linear', 'convex', 'invex', 'ordinary'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = [5, 10, 20, 100, 500]\n",
    "net_keys = {**get_models(1), **get_models_func(1)}.keys()\n",
    "net_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "444c21dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 []\n",
      "10 []\n",
      "20 ['invex', 'ordinary']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20, 100, 500]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H_ = [h for h in H if str(h) not in exp_acc_vals.keys()]\n",
    "H_ = []\n",
    "for h in H:\n",
    "    if str(h) in exp_acc_vals.keys():\n",
    "        NET_KEYS = [k for k in net_keys if k not in list(exp_acc_vals[str(h)].keys())]\n",
    "        print(h, NET_KEYS)\n",
    "        if len(NET_KEYS) > 0:\n",
    "            H_.append(h)\n",
    "    else:\n",
    "        H_.append(h)\n",
    "\n",
    "H_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb04c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h = 20\n",
    "# NET_KEYS = list(net_keys)\n",
    "# if str(h) in exp_acc_vals.keys():\n",
    "#     NET_KEYS = [k for k in net_keys if k not in list(exp_acc_vals[str(h)].keys())[:-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dac9b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NET_KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9fb39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str(h) in exp_acc_vals.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea674cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Linear(in_features=784, out_features=500, bias=True)\n",
      "Success\n",
      "Yes Linear(in_features=500, out_features=784, bias=True)\n",
      "Success\n",
      "_________________________\n",
      "Experimenting for invex ; h:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:23<00:00, 52.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 0 Loss: 1.770 | Acc: 40.348 24209/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 135.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.345 | Acc: 58.690 5869/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 1 Loss: 1.086 | Acc: 69.578 41747/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 139.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 1 Loss: 0.885 | Acc: 74.460 7446/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 2 Loss: 0.797 | Acc: 75.828 45497/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 133.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 2 Loss: 0.720 | Acc: 77.360 7736/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 3 Loss: 0.666 | Acc: 78.945 47367/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 137.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 3 Loss: 0.827 | Acc: 71.600 7160/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:22<00:00, 53.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 4 Loss: 0.594 | Acc: 80.893 48536/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 135.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 4 Loss: 0.731 | Acc: 75.570 7557/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████▎                        | 607/1200 [00:11<00:11, 53.58it/s]"
     ]
    }
   ],
   "source": [
    "for h in H_:\n",
    "    net_dict = {**get_models(h), **get_models_func(h)}\n",
    "    acc_dict = {}\n",
    "    NET_KEYS = list(net_keys)\n",
    "    \n",
    "    if str(h) in exp_acc_vals.keys():\n",
    "        acc_dict = exp_acc_vals[str(h)]\n",
    "        NET_KEYS = [k for k in net_keys if k not in list(exp_acc_vals[str(h)].keys())]\n",
    "        pass\n",
    "                    \n",
    "    for key in NET_KEYS:\n",
    "        print(\"_________________________\")\n",
    "        print(f\"Experimenting for {key} ; h:{h}\")\n",
    "        net = net_dict[key].to(device)\n",
    "        \n",
    "        model_name = f\"00.2_fmnist_{key}_h{h}\"\n",
    "        \n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "        best_acc = -1\n",
    "        for epoch in range(EPOCHS):\n",
    "            train(epoch, net, optimizer)\n",
    "            test(epoch, net, model_name)\n",
    "            scheduler.step()\n",
    "        acc_dict[key] = float(best_acc)\n",
    "        exp_acc_vals[str(h)] = acc_dict\n",
    "        \n",
    "        ## Save it in the file.\n",
    "        with open(data_file, \"w\") as f:\n",
    "            json.dump(exp_acc_vals, f, indent=3)\n",
    "        \n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d3d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db5ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12e500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net[0].centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals = \\\n",
    "{'5': {'l_0.5': 67.05,\n",
    "  'l_1': 70.7,\n",
    "  'l_2': 78.15,\n",
    "  'l_inf': 79.52,\n",
    "  'stereo': 82.19,\n",
    "  'linear': 82.74,\n",
    "  'convex': 79.49,\n",
    "  'invex': 88.26,\n",
    "  'ordinary': 83.55},\n",
    " '10': {'l_0.5': 72.08,\n",
    "  'l_1': 77.91,\n",
    "  'l_2': 82.35,\n",
    "  'l_inf': 83.98,\n",
    "  'stereo': 84.73,\n",
    "  'linear': 84.89,\n",
    "  'convex': 78.99,\n",
    "  'invex': 88.41,\n",
    "  'ordinary': 81.69}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf1535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee48e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"./outputs/00.2_exp_acc_dict.json\"\n",
    "with open(data_file, \"w\") as f:\n",
    "    json.dump(exp_acc_vals, f, indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf858b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open(data_file, 'r') as f:\n",
    "    exp_acc_vals = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd77393",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae651c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
