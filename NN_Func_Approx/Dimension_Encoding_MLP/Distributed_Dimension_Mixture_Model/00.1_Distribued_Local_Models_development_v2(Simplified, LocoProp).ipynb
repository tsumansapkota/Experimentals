{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os, sys, pathlib, random, time, pickle, copy, json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 147\n",
    "# SEED = 258\n",
    "# SEED = 369\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=2000, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 1, 28, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## demo of train loader\n",
    "xx, yy = iter(train_loader).next()\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpBLock(nn.Module):\n",
    "    \n",
    "    def __init__(self, dims, actf=nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.dims = dims\n",
    "        #### convert hidden layers ratio to list if integer is inputted\n",
    "            \n",
    "        self.mlp = []\n",
    "        ### for 1 hidden layer, we iterate 2 times\n",
    "        for h in range(len(self.dims)-1):\n",
    "            i, o = int(self.dims[h]),\\\n",
    "                    int(self.dims[h+1])\n",
    "            self.mlp.append(nn.Linear(i, o))\n",
    "#             self.mlp.append(nn.BatchNorm1d(o))\n",
    "            self.mlp.append(\n",
    "                nn.Sequential(\n",
    "#                               nn.BatchNorm1d(o),\n",
    "                              nn.Dropout(p=0.1),\n",
    "                              nn.LayerNorm(o),\n",
    "                              actf(),\n",
    "                             )\n",
    "                            )\n",
    "        self.mlp = self.mlp[:-1]\n",
    "        \n",
    "        self.mlp = nn.Sequential(*self.mlp)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpBLock(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=3, bias=True)\n",
       "    (1): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2): Linear(in_features=3, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MlpBLock([2, 3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_edge(0, 1)\n",
    "G.add_edge(0, 2)\n",
    "G.add_edge(0, 3)\n",
    "G.add_edge(1, 4)\n",
    "G.add_edge(1, 5)\n",
    "G.add_edge(2, 5)\n",
    "G.add_edge(2, 6)\n",
    "G.add_edge(3, 6)\n",
    "G.add_edge(4, 7)\n",
    "G.add_edge(5, 7)\n",
    "G.add_edge(6, 7)\n",
    "G.add_edge(7, 8)\n",
    "G.add_edge(7, 9)\n",
    "G.add_edge(6, 9)\n",
    "G.add_edge(8, 10)\n",
    "G.add_edge(9, 10)\n",
    "G.add_edge(10, 11)\n",
    "\n",
    "\n",
    "# explicitly set positions\n",
    "pos = {0: (0, 1), \n",
    "       1: (1, 0), \n",
    "       2: (1, 1), \n",
    "       3: (1, 2), \n",
    "       4: (2, 0),\n",
    "       5: (2, 1),\n",
    "       6: (2.25, 2),\n",
    "       7: (3, 0.5),\n",
    "       8: (4, 0.5),\n",
    "       9: (4, 1.5),\n",
    "       10: (5, 1),\n",
    "       11: (6, 1),\n",
    "      }\n",
    "\n",
    "options = {\n",
    "    \"font_size\": 10,\n",
    "    \"node_size\": 300,\n",
    "    \"node_color\": \"white\",\n",
    "    \"edgecolors\": \"black\",\n",
    "    \"linewidths\": 2,\n",
    "    \"width\": 2,\n",
    "}\n",
    "nx.draw_networkx(G, pos, **options)\n",
    "\n",
    "# Set margins for the axes so that nodes aren't clipped\n",
    "ax = plt.gca()\n",
    "ax.margins(0.20)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeView([(0, 1), (0, 2), (0, 3), (1, 4), (1, 5), (2, 5), (2, 6), (3, 6), (4, 7), (5, 7), (6, 7), (6, 9), (7, 8), (7, 9), (8, 10), (9, 10), (10, 11)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(InDegreeView({0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 2, 6: 2, 7: 3, 8: 1, 9: 2, 10: 2, 11: 1}),\n",
       " OutDegreeView({0: 3, 1: 2, 2: 2, 3: 1, 4: 1, 5: 1, 6: 2, 7: 2, 8: 1, 9: 1, 10: 1, 11: 0}))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.in_degree(), G.out_degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeView([(0, 1), (0, 2), (0, 3), (1, 4), (1, 5), (2, 5), (2, 6), (3, 6), (4, 7), (5, 7), (6, 7), (6, 9), (7, 8), (7, 9), (8, 10), (9, 10), (10, 11)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.out_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InEdgeView([(0, 1), (0, 2), (0, 3), (1, 4), (1, 5), (2, 5), (2, 6), (3, 6), (4, 7), (5, 7), (6, 7), (7, 8), (7, 9), (6, 9), (8, 10), (9, 10), (10, 11)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.in_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Dimension-Mixer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `Local Models` are the basis for local training of models.\n",
    "2. `Local Models` have their own optimizer and communicate via low bandwidth connection.\n",
    "3. This experiment verifies if training local models reduces the number of forward and backward pass for reaching the solution.\n",
    "4. The main idea is to update local model multiple times and backproping the final gradient, rather than doing it one iteration (similar to higher order optimization ?? like 1.5-nd optimization)\n",
    "5. The optimal spectrum lies in between (Its like dynamic optimization, while doing inference with more communication between local models, far away models communicate less). There has been similar ideas otherwhere as well but not exactly. Its based on my own experiment using optimizer for find better gradient for global optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### temp herer\n",
    "xx = torch.randn(5, 3)\n",
    "dys = [torch.randn(5, 2), torch.randn(5,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedNode(abc.ABC):\n",
    "#     @abc.abstractmethod\n",
    "    def set_input_nodes(self, nodes):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "    def set_output_nodes(self, nodes):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "    def forward_local(self):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "    def backward_local(self):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "    def update_local(self):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "#     def train_loop(self, ):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalModel(DistributedNode):\n",
    "    \n",
    "    def __init__(self, model, lr=0.001, local_lr=0.1, local_updates=100):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.optimizer = None\n",
    "#         self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.local_lr = local_lr\n",
    "        self.local_updates = local_updates\n",
    "        \n",
    "        self.output_dim = model.dims[-1]\n",
    "        self.split_indices = None\n",
    "        \n",
    "        ### temporary state variables\n",
    "        self.input_received = []\n",
    "        self.input_shapes = []\n",
    "        self.output_shape = None\n",
    "        self.grad_received = None\n",
    "        ######## testing target\n",
    "        self.target = None\n",
    "        \n",
    "        #### For storing local variables\n",
    "        \n",
    "    def set_split_mixing_indices(self, split_sizes=None):\n",
    "        if split_sizes is None:\n",
    "            split_sizes = [self.output_dim, ]\n",
    "        ## split sizes added must be >= to input size\n",
    "        assert self.output_dim <= np.sum(split_sizes), \"split sizes are less than input dimension\"\n",
    "        for ss in split_sizes:\n",
    "            assert self.output_dim >= ss, \"split sizes are greater than input dimension\"\n",
    "            \n",
    "        \n",
    "        ## also do not use split sizes greater than input dimension\n",
    "        \n",
    "        indices = np.arange(0, self.output_dim, 1, dtype=int)\n",
    "        indices = np.random.permutation(indices)\n",
    "        \n",
    "        ## first divide input dimension into all splits\n",
    "        split_loc = split_sizes/np.sum(split_sizes)*self.output_dim\n",
    "        split_loc = split_loc.astype(int)\n",
    "        split_loc[0] += self.output_dim-split_loc.sum()\n",
    "        \n",
    "        index = np.split(indices, np.cumsum(split_loc[:-1]))\n",
    "        ## for extra input dimensions, sample randomly from remaining node indices.\n",
    "        for i in range(len(index)):\n",
    "            idx = index[i]\n",
    "            mask = np.ones(self.output_dim, dtype=bool)\n",
    "            mask[idx] = False\n",
    "            remaining = np.arange(0, self.output_dim, 1, dtype=int)[mask]\n",
    "            num_remain = split_sizes[i] - len(idx)\n",
    "            new_idx = remaining[np.random.permutation(len(remaining))[:num_remain]]\n",
    "            new_idx = np.array(new_idx)\n",
    "            \n",
    "            all_inx = np.concatenate((idx, new_idx))\n",
    "            index[i] = torch.LongTensor(all_inx)\n",
    "            pass\n",
    "        \n",
    "        self.split_indices = index\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def forward_local(self, xs):\n",
    "        ### concat received inputs\n",
    "        self.input_shapes = [xi.shape for xi in xs]\n",
    "        xs = torch.cat(xs, dim=1)\n",
    "        \n",
    "        self.input_received = xs.data\n",
    "\n",
    "        xs = self.model(xs)\n",
    "        self.output_shape = xs.shape\n",
    "        \n",
    "        ys = []\n",
    "        for si in self.split_indices:\n",
    "            ys.append(xs[:, si])\n",
    "\n",
    "#         .split([100, 100], dim=1)\n",
    "        return ys\n",
    "    \n",
    "    def backward_local(self, dys):\n",
    "        ### concat received gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            grads = torch.zeros(self.output_shape).to(dys[0].device)\n",
    "            for i, si in enumerate(self.split_indices):\n",
    "                grads[:,si] += dys[i]\n",
    "\n",
    "            self.grad_received = grads\n",
    "\n",
    "        ### Set input gradients and target\n",
    "        Xs = nn.Parameter(self.input_received, requires_grad=True)\n",
    "        ys = self.model(Xs)\n",
    "        Xgrad = torch.autograd.grad(ys, Xs, self.grad_received, only_inputs=True)[0]\n",
    "        \n",
    "        split_sz = [t[-1] for t in self.input_shapes]\n",
    "        input_grads = Xgrad.split(split_sz, dim=1)\n",
    "        \n",
    "        self.target = ys.data - grads.data*10.0\n",
    "\n",
    "        ####### Train the local network\n",
    "        \n",
    "#         criterion = nn.MSELoss()\n",
    "        def criterion(y, t):\n",
    "            return (0.5*(y-t)**2).sum()\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001, betas=(0.9, 0.99))\n",
    "            \n",
    "        ### get model gradients different way\n",
    "        for epoch in range(100): ### Extra steps for optimizing using the same target\n",
    "            ys = self.model(self.input_received)\n",
    "            loss = criterion(ys, self.target)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return input_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LocalModel(MlpBLock([3, 5, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpBLock(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=5, bias=True)\n",
       "    (1): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2): Linear(in_features=5, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.optimizer = torch.optim.SGD(lm.model.parameters(), lr=lm.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6218,  0.1391, -0.1038],\n",
       "        [ 0.6322,  0.0490, -0.0192],\n",
       "        [ 0.9815, -0.3491, -0.5624],\n",
       "        [ 0.4869,  0.3159,  0.0832],\n",
       "        [ 0.9514, -0.2961, -0.5664]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xx = torch.randn(1, 3)\n",
    "lm.forward(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.set_split_mixing_indices([2, 2])\n",
    "# lm.set_split_mixing_indices(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 0]), tensor([2, 0])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.split_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.001\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.7736,  0.0546],\n",
       "         [-0.0384,  0.7111],\n",
       "         [-0.3281,  0.9417],\n",
       "         [ 0.1736,  0.5918],\n",
       "         [-0.2961,  0.9514]]), tensor([[ 0.7708,  0.0546],\n",
       "         [-0.0343,  0.7111],\n",
       "         [-0.4501,  0.9417],\n",
       "         [ 0.1132,  0.5918],\n",
       "         [-0.5664,  0.9514]])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.forward_local([xx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0412,  0.0151, -0.1132],\n",
       "         [-0.0146,  0.0821, -0.1678],\n",
       "         [-0.2792, -0.0083, -0.5008],\n",
       "         [-0.2179,  0.1060, -0.3430],\n",
       "         [-0.1894,  0.4763, -0.3792]]),)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dys = [torch.randn(2, 2), torch.randn(2,2)]\n",
    "# dys = [torch.randn(2, 3),]\n",
    "\n",
    "lm.backward_local(dys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4365,  0.9052, -1.1178],\n",
       "        [-0.6385, -0.6886, -1.2619],\n",
       "        [-1.8118, -1.1341,  0.5572],\n",
       "        [ 0.5301, -0.8454, -0.5601],\n",
       "        [-0.0254, -1.5666,  0.1754]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.grad_received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-23.3312,  25.9624,   5.9204],\n",
      "        [  1.9648,  -8.2210,   4.8717],\n",
      "        [  1.1793,   1.2276,  -5.7612],\n",
      "        [ 22.9163, -31.2994,  -2.0972],\n",
      "        [ -5.8766,   5.6108,  -1.9636]])\n",
      "tensor([-23.5637,   3.3544,   2.8590,  24.8063,  -4.6940])\n",
      "tensor([-21.2026,   0.2697,  -3.5235,  -2.4529,   0.0000])\n",
      "tensor([-19.2972,   1.9264,  -5.5063,   6.5356,   0.0000])\n",
      "tensor([[  8.8809,   0.2320,  -4.9734, -31.6442,   0.0000],\n",
      "        [-19.3861,  -0.3670,  -4.9184, -35.0321,   0.0000],\n",
      "        [-32.5608,  -0.2354,  -9.1424,  -3.1139,   0.0000]])\n",
      "tensor([-16.1850, -29.8577, -18.6896])\n"
     ]
    }
   ],
   "source": [
    "for p in lm.model.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.4337, 0.4827, 0.1345], requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.5614, -0.3028,  0.0709],\n",
       "         [ 0.1420,  0.4275,  0.2995],\n",
       "         [ 0.0889, -0.2332, -0.4129],\n",
       "         [ 0.2047, -0.1809, -0.4406],\n",
       "         [ 0.3281,  0.6147, -0.2883]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1269,  0.2555, -0.3956,  0.0448, -0.5894], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.1080, 0.9351, 1.0587, 0.9351, 0.9841], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1007, -0.0831,  0.0936, -0.0870, -0.0206], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.2902,  0.1959,  0.1175,  0.4369,  0.0396],\n",
       "         [ 0.3997, -0.2160, -0.1230, -0.2876, -0.1232],\n",
       "         [ 0.4647,  0.1328,  0.4673, -0.2659,  0.4008]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4337, 0.4827, 0.1345], requires_grad=True)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.param_groups[0]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {Parameter containing:\n",
       "             tensor([ 0.1007, -0.0831,  0.0936, -0.0870, -0.0206], requires_grad=True): {'exp_avg': tensor([-17.3473,   1.6802,  -7.6070,   7.0065,  -0.5298]),\n",
       "              'exp_avg_sq': tensor([195.9168,   2.7994,  29.5039,  69.6470,   1.6966]),\n",
       "              'step': 100},\n",
       "             Parameter containing:\n",
       "             tensor([-0.1269,  0.2555, -0.3956,  0.0448, -0.5894], requires_grad=True): {'exp_avg': tensor([-17.6780,   2.5028,   0.8006,  22.2754,  -3.5491]),\n",
       "              'exp_avg_sq': tensor([435.2649,  12.5848,  43.2766, 296.5711,  42.4553]),\n",
       "              'step': 100},\n",
       "             Parameter containing:\n",
       "             tensor([0.4337, 0.4827, 0.1345], requires_grad=True): {'exp_avg': tensor([-15.9701, -30.3408, -18.9168]),\n",
       "              'exp_avg_sq': tensor([156.8055, 621.4954, 251.0778]),\n",
       "              'step': 100},\n",
       "             Parameter containing:\n",
       "             tensor([1.1080, 0.9351, 1.0587, 0.9351, 0.9841], requires_grad=True): {'exp_avg': tensor([-18.1355,   0.3741,  -2.8339,   0.1221,  -0.2454]),\n",
       "              'exp_avg_sq': tensor([166.0176,   0.6460,   4.3168,  47.8390,   0.4131]),\n",
       "              'step': 100},\n",
       "             Parameter containing:\n",
       "             tensor([[ 0.5614, -0.3028,  0.0709],\n",
       "                     [ 0.1420,  0.4275,  0.2995],\n",
       "                     [ 0.0889, -0.2332, -0.4129],\n",
       "                     [ 0.2047, -0.1809, -0.4406],\n",
       "                     [ 0.3281,  0.6147, -0.2883]], requires_grad=True): {'exp_avg': tensor([[-14.1364,  22.6669,   0.6917],\n",
       "                      [  1.7972,  -8.9835,   5.5012],\n",
       "                      [  1.5773,  14.6298,  -8.7264],\n",
       "                      [ 18.0172, -34.0114,   2.1514],\n",
       "                      [ -3.6406,   2.0303,  -0.0872]]),\n",
       "              'exp_avg_sq': tensor([[365.2848, 454.5190,  89.4058],\n",
       "                      [ 19.8012,  58.9771,  15.4527],\n",
       "                      [ 42.1936, 186.9454, 118.7319],\n",
       "                      [258.0197, 709.1414,  14.0665],\n",
       "                      [ 25.1696,   8.1143,  57.7773]]),\n",
       "              'step': 100},\n",
       "             Parameter containing:\n",
       "             tensor([[-0.2902,  0.1959,  0.1175,  0.4369,  0.0396],\n",
       "                     [ 0.3997, -0.2160, -0.1230, -0.2876, -0.1232],\n",
       "                     [ 0.4647,  0.1328,  0.4673, -0.2659,  0.4008]], requires_grad=True): {'exp_avg': tensor([[  7.8524,   0.3744,  -5.9337, -29.2129,  -0.4286],\n",
       "                      [-14.7253,  -1.5143,  -5.6125, -36.9464,  -0.4094],\n",
       "                      [-29.8243,  -1.4343,  -8.0489,  -4.0932,  -0.6654]]),\n",
       "              'exp_avg_sq': tensor([[  38.2806,    2.0027,  120.6987,  524.3146,    5.6225],\n",
       "                      [ 154.1244,    7.1828,   49.2807, 1033.4796,    2.1706],\n",
       "                      [ 457.3016,    6.2121,   31.2600,   91.6887,    1.8150]]),\n",
       "              'step': 100}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.randn(5, 3)\n",
    "dys = [torch.randn(5, 2), torch.randn(5,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None\n",
    "# tensor([[-0.0216, -0.0131, -0.0257],\n",
    "#         [-0.0267, -0.0162, -0.0317],\n",
    "#         [ 2.6498,  1.6019,  3.1403],\n",
    "#         [-0.1429, -0.0864, -0.1694],\n",
    "#         [ 0.9580,  0.5792,  1.1354]])\n",
    "# None\n",
    "# tensor([ 0.0157,  0.0194, -1.9184,  0.1035, -0.6936])\n",
    "# None\n",
    "# tensor([[ 0.0912, -0.0091,  1.3586, -0.3357, -0.0134],\n",
    "#         [-0.2009,  0.0201, -2.9941,  0.7397,  0.0295],\n",
    "#         [-0.0647,  0.0065, -0.9643,  0.2382,  0.0095]])\n",
    "# None\n",
    "# tensor([ 2.4200, -5.3331, -1.7176])\n",
    "# ----------\n",
    "# tensor([[-0.0216, -0.0131, -0.0257],\n",
    "#         [-0.0267, -0.0162, -0.0317],\n",
    "#         [ 2.6498,  1.6019,  3.1403],\n",
    "#         [-0.1429, -0.0864, -0.1694],\n",
    "#         [ 0.9580,  0.5792,  1.1354]])\n",
    "# tensor([ 0.0157,  0.0194, -1.9184,  0.1035, -0.6936])\n",
    "# tensor([[ 0.0912, -0.0091,  1.3586, -0.3357, -0.0134],\n",
    "#         [-0.2009,  0.0201, -2.9941,  0.7397,  0.0295],\n",
    "#         [-0.0647,  0.0065, -0.9643,  0.2382,  0.0095]])\n",
    "# tensor([ 2.4200, -5.3331, -1.7176])\n",
    "# (tensor([[-0.6782,  0.9934,  0.2818]]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFeeder(DistributedNode):\n",
    "    \n",
    "    def __init__(self, input_dim, split_sizes = []):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.split_sizes = np.array(split_sizes, dtype=int)\n",
    "        self.split_indices = None\n",
    "\n",
    "        self.inputs = None\n",
    "        self.output_nodes = None\n",
    "        \n",
    "        ## preprocessing steps\n",
    "        self._set_split_mixing_indices_()\n",
    "        \n",
    "    def _set_split_mixing_indices_(self):\n",
    "        ## split sizes added must be >= to input size\n",
    "        assert self.input_dim <= np.sum(self.split_sizes), \"split sizes are less than input dimension\"\n",
    "        for ss in self.split_sizes:\n",
    "            assert self.input_dim >= ss, \"split sizes are greater than input dimension\"\n",
    "            \n",
    "        \n",
    "        ## also do not use split sizes greater than input dimension\n",
    "        \n",
    "        indices = np.arange(0, self.input_dim, 1, dtype=int)\n",
    "        indices = np.random.permutation(indices)\n",
    "        \n",
    "#         print(indices)\n",
    "        ## first divide input dimension into all splits\n",
    "        split_indices = self.split_sizes/np.sum(self.split_sizes)*self.input_dim\n",
    "        split_indices = split_indices.astype(int)\n",
    "        split_indices[0] += self.input_dim-split_indices.sum()\n",
    "        print(split_indices, split_indices.sum())\n",
    "        \n",
    "        index = np.split(indices, np.cumsum(split_indices[:-1]))\n",
    "#         for idx in index:\n",
    "#             print(len(idx))\n",
    "            \n",
    "        ## for extra input dimensions, sample randomly from remaining node indices.\n",
    "        for i in range(len(index)):\n",
    "            idx = index[i]\n",
    "            mask = np.ones(self.input_dim, dtype=bool)\n",
    "            mask[idx] = False\n",
    "            remaining = np.arange(0, self.input_dim, 1, dtype=int)[mask]\n",
    "            num_remain = self.split_sizes[i] - len(idx)\n",
    "            new_idx = remaining[np.random.permutation(len(remaining))[:num_remain]]\n",
    "            new_idx = np.array(new_idx)\n",
    "            \n",
    "            all_inx = np.concatenate((idx, new_idx))\n",
    "            index[i] = torch.LongTensor(all_inx)\n",
    "            \n",
    "        for idx in index:\n",
    "            print(len(idx))\n",
    "            \n",
    "        self.split_indices = index\n",
    "        pass\n",
    "\n",
    "    def set_input(self, x):\n",
    "        '''\n",
    "        x is assumed to be 2D; --> BatchSize, Dimension\n",
    "        '''\n",
    "        sz = x.shape\n",
    "        x = x.reshape(sz[0], -1)\n",
    "        self.inputs = [None for _ in range(len(self.split_indices))]\n",
    "        for i, si in enumerate(self.split_indices):\n",
    "            self.inputs[i] = x[:, si.to(x.device)]\n",
    "        return self.inputs\n",
    "    \n",
    "    def forward_local(self, x):\n",
    "        return self.set_input(x)\n",
    "    \n",
    "    def backward_local(self, ):\n",
    "        pass\n",
    "    \n",
    "    def update_local(self, ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262 261 261] 784\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "df = DataFeeder(784, [300, 300, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDimMixerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ## defining model hardcoded\n",
    "        self.m0 = DataFeeder(784, split_sizes=[300, 300, 300])\n",
    "        \n",
    "        self.m1 = MlpBLock([300, 600, 300])\n",
    "        self.m2 = MlpBLock([300, 500, 250])\n",
    "        self.m3 = MlpBLock([300, 500, 200])\n",
    "        \n",
    "        self.m4 = MlpBLock([150, 300, 100])\n",
    "        self.m5 = MlpBLock([250, 400, 100])\n",
    "        self.m6 = MlpBLock([350, 500, 200])\n",
    "        self.m7 = MlpBLock([300, 500, 200])\n",
    "        self.m8 = MlpBLock([100, 150, 50])\n",
    "        self.m9 = MlpBLock([200, 300, 100])\n",
    "        self.m10 = MlpBLock([150, 200, 10])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1, x2, x3 = self.m0.forward_local(x)\n",
    "        x1 = self.m1(x1).split([150, 150], dim=1)\n",
    "        x2 = self.m2(x2).split([100, 150], dim=1)\n",
    "        x3 = self.m3(x3)\n",
    "        \n",
    "        x4 = x1[0]\n",
    "        x5 = torch.cat([x1[1], x2[0]], dim=1)\n",
    "        x6 = torch.cat([x2[1], x3], dim=1)\n",
    "        x4 = self.m4(x4)\n",
    "        x5 = self.m5(x5)\n",
    "        x6 = self.m6(x6).split([100, 100], dim=1)\n",
    "        \n",
    "        x7 = torch.cat([x4, x5, x6[0]], dim=1)\n",
    "        x7 = self.m7(x7).split([100, 100], dim=1)\n",
    "#         print(x7[0].shape, x7[1].shape)\n",
    "        x8 = x7[0]\n",
    "        x8 = self.m8(x8)\n",
    "        x9 = torch.cat([x6[1], x7[1]], dim=1)\n",
    "        x9 = self.m9(x9)\n",
    "        \n",
    "        x10 = torch.cat([x9, x8], dim=1)\n",
    "        x10 = self.m10(x10)\n",
    "        return x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GraphDimMixerModel().to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dist_GraphDimMixerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ## defining model hardcoded\n",
    "        self.m0 = DataFeeder(784, split_sizes=[300, 300, 300])\n",
    "        \n",
    "        self.m1 = LocalModel(MlpBLock([300, 600, 300]))\n",
    "        self.m1.set_split_mixing_indices([150, 150])\n",
    "        self.m2 = LocalModel(MlpBLock([300, 500, 250]))\n",
    "        self.m2.set_split_mixing_indices([100, 150])\n",
    "        self.m3 = LocalModel(MlpBLock([300, 500, 200]))\n",
    "        self.m3.set_split_mixing_indices(None)\n",
    "        \n",
    "        self.m4 = LocalModel(MlpBLock([150, 300, 100]))\n",
    "        self.m4.set_split_mixing_indices(None)\n",
    "        self.m5 = LocalModel(MlpBLock([250, 400, 100]))\n",
    "        self.m5.set_split_mixing_indices(None)\n",
    "        self.m6 = LocalModel(MlpBLock([350, 500, 200]))\n",
    "        self.m6.set_split_mixing_indices([100, 100])\n",
    "        self.m7 = LocalModel(MlpBLock([300, 500, 200]))\n",
    "        self.m7.set_split_mixing_indices([100, 100])\n",
    "        self.m8 = LocalModel(MlpBLock([100, 150, 50]))\n",
    "        self.m8.set_split_mixing_indices(None)\n",
    "        self.m9 = LocalModel(MlpBLock([200, 300, 100]))\n",
    "        self.m9.set_split_mixing_indices(None)\n",
    "        self.m10 = LocalModel(MlpBLock([150, 200, 10]))\n",
    "        self.m10.set_split_mixing_indices(None)\n",
    "        \n",
    "        self.model_list = [self.m1, self.m2, self.m3, self.m4, self.m5, \n",
    "                           self.m6, self.m7, self.m8, self.m9, self.m10]\n",
    "        self.module_list = nn.ModuleList([m.model for m in self.model_list])\n",
    "        \n",
    "    def set_optimizer_with_device(self, device):\n",
    "        for m in self.model_list:\n",
    "            m.model.to(device)\n",
    "            m.optimizer = torch.optim.Adam(m.model.parameters(), lr=0.0001)\n",
    "#             m.optimizer = torch.optim.SGD(m.model.parameters(), lr=0.01)\n",
    "        pass\n",
    "        \n",
    "    def forward_local(self, x):\n",
    "        x1, x2, x3 = self.m0.forward_local(x)\n",
    "        x1 = self.m1.forward_local([x1])\n",
    "        x2 = self.m2.forward_local([x2])\n",
    "        x3 = self.m3.forward_local([x3])\n",
    "        \n",
    "        x4 = self.m4.forward_local([x1[0]])\n",
    "        x5 = self.m5.forward_local([x1[1], x2[0]])\n",
    "        \n",
    "        x6 = self.m6.forward_local([x2[1], x3[0]])\n",
    "        \n",
    "        x7 = self.m7.forward_local([x4[0], x5[0], x6[0]])\n",
    "        x8 = self.m8.forward_local([x7[0]])\n",
    "        x9 = self.m9.forward_local([x6[1], x7[1]])\n",
    "        \n",
    "        x10 = self.m10.forward_local([x8[0], x9[0]])\n",
    "        return x10[0]\n",
    "    \n",
    "    def backward_local(self, dy):\n",
    "        d10 = self.m10.backward_local([dy])\n",
    "        d9 = self.m9.backward_local([d10[1]])\n",
    "        d8 = self.m8.backward_local([d10[0]])\n",
    "        d7 = self.m7.backward_local([d8[0], d9[1]])\n",
    "        d6 = self.m6.backward_local([d7[2], d9[0]])\n",
    "        d5 = self.m5.backward_local([d7[1]])\n",
    "        d4 = self.m4.backward_local([d7[0]])\n",
    "        d3 = self.m3.backward_local([d6[1]])\n",
    "        d2 = self.m2.backward_local([d5[1], d6[0]])\n",
    "        d1 = self.m1.backward_local([d4[0], d5[0]])\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262 261 261] 784\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "d_dimixer = Dist_GraphDimMixerModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dist_GraphDimMixerModel(\n",
       "  (module_list): ModuleList(\n",
       "    (0): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=600, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=600, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=500, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=500, out_features=250, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=500, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=500, out_features=200, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=150, out_features=300, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=300, out_features=100, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=400, out_features=100, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (5): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=350, out_features=500, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=500, out_features=200, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (6): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=500, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=500, out_features=200, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (7): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=150, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((150,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=150, out_features=50, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (8): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=200, out_features=300, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=300, out_features=100, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (9): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=150, out_features=200, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=200, out_features=10, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dimixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dimixer.set_optimizer_with_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6655,  0.2478,  0.4260,  0.0805, -0.7247, -0.5776, -0.0017, -0.4806,\n",
       "          0.9088, -0.8325],\n",
       "        [-0.4574, -0.1568,  0.0350,  0.1428, -0.3408, -0.0166,  0.6528, -0.1370,\n",
       "          0.9818, -0.3700],\n",
       "        [-0.1164,  0.1584, -0.6405, -0.4857,  0.0346, -0.0892,  0.0524,  0.0131,\n",
       "          0.5807,  0.5327]], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dimixer.forward_local(torch.randn(3, 784).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dimixer.backward_local(torch.randn(3, 10).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdfsdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed local model training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262 261 261] 784\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "model = Dist_GraphDimMixerModel()\n",
    "model.set_optimizer_with_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'distrib_dim_mixer_fmist_s{SEED}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT ={'train_stat':[], 'test_stat':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward_local(inputs)\n",
    "        out = torch.autograd.Variable(outputs, requires_grad=True)\n",
    "        loss = criterion(out, targets)\n",
    "        loss.backward()\n",
    "            \n",
    "        model.backward_local(out.grad)\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    STAT['train_stat'].append((epoch, train_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model.forward_local(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    STAT['test_stat'].append((epoch, test_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "#         state = {\n",
    "#             'model': model.state_dict(),\n",
    "#             'acc': acc,\n",
    "#             'epoch': epoch\n",
    "#         }\n",
    "#         if not os.path.isdir('models'):\n",
    "#             os.mkdir('models')\n",
    "#         torch.save(state, f'./models/{model_name}.pth')\n",
    "#         best_acc = acc\n",
    "        \n",
    "    with open(f\"./output/{model_name}_data.json\", 'w') as f:\n",
    "        json.dump(STAT, f, indent=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('./models'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    \n",
    "    STAT = checkpoint['stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [07:21<02:14, 19.19s/it]"
     ]
    }
   ],
   "source": [
    "### Train the whole damn thing\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+EPOCHS): ## for 200 epochs\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Look more into 2nd Order Optimization\n",
    "Use 2nd Order optimizaton for local blocks (in block)\n",
    "Use 1st Order for in-between blocks (out blocks)\n",
    "\n",
    "TODO: Need more understanding before experimentation\n",
    "(Why updating multiple times for same batch reduce capacity)\n",
    "(Maybe use N-Batch Size and update multiple times using (N/20) bs for 20 epochs ?? )\n",
    "\n",
    "- Why does Dropout destroy the training !! ??? \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdasdadasd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphDimMixerModel().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'dim_mixer_fmist_s{SEED}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT ={'train_stat':[], 'test_stat':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    STAT['train_stat'].append((epoch, train_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    STAT['test_stat'].append((epoch, test_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc\n",
    "        \n",
    "    with open(f\"./output/{model_name}_data.json\", 'w') as f:\n",
    "        json.dump(STAT, f, indent=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('./models'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    \n",
    "    STAT = checkpoint['stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the whole damn thing\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+EPOCHS): ## for 200 epochs\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "best_acc = checkpoint['acc']\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "best_acc, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stat = np.array(STAT['train_stat'])\n",
    "test_stat = np.array(STAT['test_stat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_stat[:,1], label='train')\n",
    "plt.plot(test_stat[:,1], label='test')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"./output/plots/{model_name}_loss.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_stat[:,2], label='train')\n",
    "plt.plot(test_stat[:,2], label='test')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"./output/plots/{model_name}_accs.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
