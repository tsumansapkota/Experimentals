{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-b22782e32495>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\heythere\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE parameters\n",
    "num_label = 10\n",
    "label_hid1 = 5\n",
    "label_hid2 = 3\n",
    "label_hid3 = 2\n",
    "label_hid4 = 1\n",
    "\n",
    "num_image = 784 # 28*28\n",
    "image_hid1 = 392\n",
    "image_hid2 = 196\n",
    "image_hid3 = 98\n",
    "image_hid4 = 49\n",
    "image_hid5 = 25\n",
    "image_hid6 = 12\n",
    "image_hid7 = 6\n",
    "image_hid8 = 3\n",
    "image_hid9 = 2\n",
    "image_hid10 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tie_weight = tf.transpose\n",
    "act_func = lambda X:X\n",
    "initializer = tf.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLACEHOLDER DEFINATION\n",
    "X = tf.placeholder(tf.float32, shape=[None, num_image])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, num_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Encoded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMAGE COMPRESSION\n",
    "wi1 = tf.Variable(np.load('../save/weights/w1.npy'))\n",
    "wi2 = tf.Variable(np.load('../save/weights/w2.npy'))\n",
    "wi3 = tf.Variable(np.load('../save/weights/w3.npy'))\n",
    "wi4 = tf.Variable(np.load('../save/weights/w4.npy'))\n",
    "wi5 = tf.Variable(np.load('../save/weights/w5.npy'))\n",
    "wi6 = tf.Variable(np.load('../save/weights/w6.npy'))\n",
    "wi7 = tf.Variable(np.load('../save/weights/w7.npy'))\n",
    "wi8 = tf.Variable(np.load('../save/weights/w8.npy'))\n",
    "wi9 = tf.Variable(np.load('../save/weights/w9.npy'))\n",
    "wi10 = tf.Variable(np.load('../save/weights/w10.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_layer1 = act_func(tf.matmul(X, wi1))\n",
    "img_layer2 = act_func(tf.matmul(img_layer1, wi2))\n",
    "img_layer3 = act_func(tf.matmul(img_layer2, wi3))\n",
    "img_layer4 = act_func(tf.matmul(img_layer3, wi4))\n",
    "img_layer5 = act_func(tf.matmul(img_layer4, wi5))\n",
    "img_layer6 = act_func(tf.matmul(img_layer5, wi6))\n",
    "img_layer7 = act_func(tf.matmul(img_layer6, wi7))\n",
    "img_layer8 = act_func(tf.matmul(img_layer7, wi8))\n",
    "img_layer9 = act_func(tf.matmul(img_layer8, wi9))\n",
    "img_layer10 = act_func(tf.matmul(img_layer9, wi10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LABEL DECOMPRESSION\n",
    "wl1 = tf.Variable(np.load('../save/weights/lw1.npy'))\n",
    "wl2 = tf.Variable(np.load('../save/weights/lw2.npy'))\n",
    "wl3 = tf.Variable(np.load('../save/weights/lw3.npy'))\n",
    "wl4 = tf.Variable(np.load('../save/weights/lw4.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_layer1 = act_func(tf.matmul(Y, wl1))\n",
    "lbl_layer2 = act_func(tf.matmul(lbl_layer1, wl2))\n",
    "lbl_layer3 = act_func(tf.matmul(lbl_layer2, wl3))\n",
    "lbl_layer4 = act_func(tf.matmul(lbl_layer3, wl4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Parameters for activation learning\n",
    "initializer = tf.random_uniform_initializer()\n",
    "\n",
    "# input_no = image_hid8\n",
    "# output_no = label_hid3\n",
    "\n",
    "inpt = img_layer8\n",
    "yval = lbl_layer3\n",
    "\n",
    "i=2\n",
    "j=2\n",
    "\n",
    "pW1 = tf.Variable(np.load('../save/weights/slearn_parms0_{}-{}.npy'.format(i, j)))\n",
    "W1 = tf.Variable(tf.matmul(wi9,pW1))\n",
    "W2 = tf.Variable(np.load('../save/weights/slearn_parms1_{}-{}.npy'.format(i, j)))\n",
    "W3 = tf.Variable(np.load('../save/weights/slearn_parms2_{}-{}.npy'.format(i, j)))\n",
    "# W3 = tf.Variable(tf.matmul(pW3, tf.transpose(wl4)))\n",
    "\n",
    "b1 = tf.Variable(np.load('../save/weights/slearn_parms3_{}-{}.npy'.format(i, j)))\n",
    "b2 = tf.Variable(np.load('../save/weights/slearn_parms4_{}-{}.npy'.format(i, j)))\n",
    "b3 = tf.Variable(np.load('../save/weights/slearn_parms5_{}-{}.npy'.format(i, j)))\n",
    "# b3 = tf.Variable(tf.matmul(pb3,tf.transpose(wl4)))\n",
    "\n",
    "a1 = tf.nn.relu(tf.matmul(inpt, W1) + b1)\n",
    "a2 = tf.nn.relu(tf.matmul(a1, W2) + b2)\n",
    "a3 = tf.matmul(a2, W3) + b3\n",
    "\n",
    "output = a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_36:0' shape=(3, 155) dtype=float32_ref>\n",
      "Tensor(\"add_11:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(W1)\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Encode-Decode Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_layer1 = tf.matmul(output,tf.transpose(wl4))\n",
    "out_layer2 = tf.matmul(output,tf.transpose(wl3))\n",
    "out_layer3 = tf.matmul(out_layer2,tf.transpose(wl2))\n",
    "out_layer4 = tf.matmul(out_layer3,tf.transpose(wl1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS FUNCTIONS\n",
    "loss = tf.reduce_mean(tf.square(output - yval))\n",
    "# loss = tf.reduce_mean(tf.abs(output_layer - X))\n",
    "# cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=yout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "learning_rate = 0.0001\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss, var_list=[W1, W2, W3, b1, b2, b3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATION\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Complete. Training Loss: 20.433597564697266\n",
      "TEST ACCURACY: \n",
      "0.2359\n",
      "TRAIN ACCURACY: \n",
      "0.23676364\n",
      "\n",
      "Epoch 1 Complete. Training Loss: 20.59037971496582\n",
      "TEST ACCURACY: \n",
      "0.245\n",
      "\n",
      "Epoch 2 Complete. Training Loss: 19.066301345825195\n",
      "TEST ACCURACY: \n",
      "0.2488\n",
      "\n",
      "Epoch 3 Complete. Training Loss: 17.05315589904785\n",
      "TEST ACCURACY: \n",
      "0.2516\n",
      "\n",
      "Epoch 4 Complete. Training Loss: 17.87362289428711\n",
      "TEST ACCURACY: \n",
      "0.2616\n",
      "\n",
      "Epoch 5 Complete. Training Loss: 19.35821533203125\n",
      "TEST ACCURACY: \n",
      "0.2692\n",
      "TRAIN ACCURACY: \n",
      "0.2656\n",
      "\n",
      "Epoch 6 Complete. Training Loss: 18.394580841064453\n",
      "TEST ACCURACY: \n",
      "0.2734\n",
      "\n",
      "Epoch 7 Complete. Training Loss: 18.259571075439453\n",
      "TEST ACCURACY: \n",
      "0.2779\n",
      "\n",
      "Epoch 8 Complete. Training Loss: 22.145641326904297\n",
      "TEST ACCURACY: \n",
      "0.2823\n",
      "\n",
      "Epoch 9 Complete. Training Loss: 18.779987335205078\n",
      "TEST ACCURACY: \n",
      "0.2875\n",
      "\n",
      "Epoch 10 Complete. Training Loss: 17.96345329284668\n",
      "TEST ACCURACY: \n",
      "0.2884\n",
      "TRAIN ACCURACY: \n",
      "0.28678182\n",
      "\n",
      "Epoch 11 Complete. Training Loss: 19.61204719543457\n",
      "TEST ACCURACY: \n",
      "0.2879\n",
      "\n",
      "Epoch 12 Complete. Training Loss: 19.544950485229492\n",
      "TEST ACCURACY: \n",
      "0.2916\n",
      "\n",
      "Epoch 13 Complete. Training Loss: 20.399503707885742\n",
      "TEST ACCURACY: \n",
      "0.295\n",
      "\n",
      "Epoch 14 Complete. Training Loss: 19.4708251953125\n",
      "TEST ACCURACY: \n",
      "0.2936\n",
      "\n",
      "Epoch 15 Complete. Training Loss: 20.343046188354492\n",
      "TEST ACCURACY: \n",
      "0.2925\n",
      "TRAIN ACCURACY: \n",
      "0.28767273\n",
      "\n",
      "Epoch 16 Complete. Training Loss: 17.893661499023438\n",
      "TEST ACCURACY: \n",
      "0.2951\n",
      "\n",
      "Epoch 17 Complete. Training Loss: 19.33905601501465\n",
      "TEST ACCURACY: \n",
      "0.2978\n",
      "\n",
      "Epoch 18 Complete. Training Loss: 18.25695037841797\n",
      "TEST ACCURACY: \n",
      "0.2993\n",
      "\n",
      "Epoch 19 Complete. Training Loss: 18.227497100830078\n",
      "TEST ACCURACY: \n",
      "0.3\n",
      "\n",
      "Epoch 20 Complete. Training Loss: 17.10481071472168\n",
      "TEST ACCURACY: \n",
      "0.3039\n",
      "TRAIN ACCURACY: \n",
      "0.3003091\n",
      "\n",
      "Epoch 21 Complete. Training Loss: 22.124784469604492\n",
      "TEST ACCURACY: \n",
      "0.3177\n",
      "\n",
      "Epoch 22 Complete. Training Loss: 18.57254409790039\n",
      "TEST ACCURACY: \n",
      "0.3196\n",
      "\n",
      "Epoch 23 Complete. Training Loss: 20.318117141723633\n",
      "TEST ACCURACY: \n",
      "0.318\n",
      "\n",
      "Epoch 24 Complete. Training Loss: 19.2360897064209\n",
      "TEST ACCURACY: \n",
      "0.3205\n",
      "\n",
      "Epoch 25 Complete. Training Loss: 16.309268951416016\n",
      "TEST ACCURACY: \n",
      "0.3199\n",
      "TRAIN ACCURACY: \n",
      "0.31763637\n",
      "\n",
      "Epoch 26 Complete. Training Loss: 19.674240112304688\n",
      "TEST ACCURACY: \n",
      "0.3198\n",
      "\n",
      "Epoch 27 Complete. Training Loss: 18.813467025756836\n",
      "TEST ACCURACY: \n",
      "0.3224\n",
      "\n",
      "Epoch 28 Complete. Training Loss: 19.99409294128418\n",
      "TEST ACCURACY: \n",
      "0.321\n",
      "\n",
      "Epoch 29 Complete. Training Loss: 18.357877731323242\n",
      "TEST ACCURACY: \n",
      "0.3216\n",
      "\n",
      "Epoch 30 Complete. Training Loss: 18.825515747070312\n",
      "TEST ACCURACY: \n",
      "0.3201\n",
      "TRAIN ACCURACY: \n",
      "0.31787273\n",
      "\n",
      "Epoch 31 Complete. Training Loss: 18.18103790283203\n",
      "TEST ACCURACY: \n",
      "0.3231\n",
      "\n",
      "Epoch 32 Complete. Training Loss: 18.337379455566406\n",
      "TEST ACCURACY: \n",
      "0.3218\n",
      "\n",
      "Epoch 33 Complete. Training Loss: 17.986202239990234\n",
      "TEST ACCURACY: \n",
      "0.3238\n",
      "\n",
      "Epoch 34 Complete. Training Loss: 18.889141082763672\n",
      "TEST ACCURACY: \n",
      "0.3257\n",
      "\n",
      "Epoch 35 Complete. Training Loss: 19.194049835205078\n",
      "TEST ACCURACY: \n",
      "0.3224\n",
      "TRAIN ACCURACY: \n",
      "0.31876364\n",
      "\n",
      "Epoch 36 Complete. Training Loss: 17.621501922607422\n",
      "TEST ACCURACY: \n",
      "0.3246\n",
      "\n",
      "Epoch 37 Complete. Training Loss: 18.20471954345703\n",
      "TEST ACCURACY: \n",
      "0.3261\n",
      "\n",
      "Epoch 38 Complete. Training Loss: 17.28325080871582\n",
      "TEST ACCURACY: \n",
      "0.3251\n",
      "\n",
      "Epoch 39 Complete. Training Loss: 18.798078536987305\n",
      "TEST ACCURACY: \n",
      "0.3242\n",
      "\n",
      "Epoch 40 Complete. Training Loss: 18.24191665649414\n",
      "TEST ACCURACY: \n",
      "0.3277\n",
      "TRAIN ACCURACY: \n",
      "0.31912726\n",
      "\n",
      "Epoch 41 Complete. Training Loss: 15.903794288635254\n",
      "TEST ACCURACY: \n",
      "0.3266\n",
      "\n",
      "Epoch 42 Complete. Training Loss: 17.885835647583008\n",
      "TEST ACCURACY: \n",
      "0.3272\n",
      "\n",
      "Epoch 43 Complete. Training Loss: 19.5159854888916\n",
      "TEST ACCURACY: \n",
      "0.3267\n",
      "\n",
      "Epoch 44 Complete. Training Loss: 18.87813377380371\n",
      "TEST ACCURACY: \n",
      "0.3261\n",
      "\n",
      "Epoch 45 Complete. Training Loss: 19.6829776763916\n",
      "TEST ACCURACY: \n",
      "0.3265\n",
      "TRAIN ACCURACY: \n",
      "0.31934544\n",
      "\n",
      "Epoch 46 Complete. Training Loss: 16.30359649658203\n",
      "TEST ACCURACY: \n",
      "0.3258\n",
      "\n",
      "Epoch 47 Complete. Training Loss: 19.01897621154785\n",
      "TEST ACCURACY: \n",
      "0.3253\n",
      "\n",
      "Epoch 48 Complete. Training Loss: 15.652013778686523\n",
      "TEST ACCURACY: \n",
      "0.3251\n",
      "\n",
      "Epoch 49 Complete. Training Loss: 19.058589935302734\n",
      "TEST ACCURACY: \n",
      "0.3248\n",
      "\n",
      "Epoch 50 Complete. Training Loss: 17.244678497314453\n",
      "TEST ACCURACY: \n",
      "0.3252\n",
      "TRAIN ACCURACY: \n",
      "0.31983638\n",
      "\n",
      "Epoch 51 Complete. Training Loss: 17.275623321533203\n",
      "TEST ACCURACY: \n",
      "0.3229\n",
      "\n",
      "Epoch 52 Complete. Training Loss: 19.79100799560547\n",
      "TEST ACCURACY: \n",
      "0.3245\n",
      "\n",
      "Epoch 53 Complete. Training Loss: 19.831031799316406\n",
      "TEST ACCURACY: \n",
      "0.3223\n",
      "\n",
      "Epoch 54 Complete. Training Loss: 18.301054000854492\n",
      "TEST ACCURACY: \n",
      "0.3249\n",
      "\n",
      "Epoch 55 Complete. Training Loss: 17.46414566040039\n",
      "TEST ACCURACY: \n",
      "0.3228\n",
      "TRAIN ACCURACY: \n",
      "0.31774545\n",
      "\n",
      "Epoch 56 Complete. Training Loss: 19.090181350708008\n",
      "TEST ACCURACY: \n",
      "0.3209\n",
      "\n",
      "Epoch 57 Complete. Training Loss: 16.802644729614258\n",
      "TEST ACCURACY: \n",
      "0.3248\n",
      "\n",
      "Epoch 58 Complete. Training Loss: 17.632272720336914\n",
      "TEST ACCURACY: \n",
      "0.324\n",
      "\n",
      "Epoch 59 Complete. Training Loss: 16.29527473449707\n",
      "TEST ACCURACY: \n",
      "0.3236\n",
      "\n",
      "Keyboard Interrupted\n",
      "Finished Training the Model\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "try:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # Epoch == Entire Training Set\n",
    "        for epoch in range(num_epochs):\n",
    "            num_batches = mnist.train.num_examples // batch_size\n",
    "\n",
    "            # 150 batch size\n",
    "            for iteration in range(num_batches):\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size+3*epoch)\n",
    "                sess.run(train, feed_dict={X: X_batch, Y: y_batch})\n",
    "\n",
    "            training_loss = loss.eval(feed_dict={X: X_batch, Y: y_batch})   \n",
    "            print(\"Epoch {} Complete. Training Loss: {}\".format(epoch,training_loss))\n",
    "            saver.save(sess, \"../save/slearn_3-2.ckpt\")\n",
    "            \n",
    "            matches = tf.equal(tf.argmax(out_layer4, 1), tf.argmax(Y,1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "\n",
    "            print('TEST ACCURACY: ')\n",
    "            print (sess.run(acc, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n",
    "            if epoch % 5 == 0:\n",
    "                print('TRAIN ACCURACY: ')\n",
    "                print (sess.run(acc, feed_dict={X:mnist.train.images, Y:mnist.train.labels}))\n",
    "            print()\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print('Keyboard Interrupted')\n",
    "finally:\n",
    "    print('Finished Training the Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../save/slearn_3-2.ckpt\n",
      "TRAIN ACCURACY: \n",
      "0.319\n",
      "TEST ACCURACY: \n",
      "0.3236\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_test_labels = 10\n",
    "start_point = 15\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "#     sess.run(init)\n",
    "    saver.restore(sess,\"../save/slearn_3-2.ckpt\")\n",
    "    \n",
    "    params = sess.run([W1, W2, W3, b1, b2, b3])\n",
    "    \n",
    "    matches = tf.equal(tf.argmax(out_layer4, 1), tf.argmax(Y,1))\n",
    "    acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "    \n",
    "    print('TRAIN ACCURACY: ')\n",
    "    print (sess.run(acc, feed_dict={X:mnist.train.images, Y:mnist.train.labels}))\n",
    "\n",
    "    print('TEST ACCURACY: ')\n",
    "    print (sess.run(acc, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-7.07783103e-02, -7.86676630e-02, -3.79772820e-02,\n",
       "          9.42157954e-02, -6.64612204e-02, -3.02982569e-01,\n",
       "         -5.41017391e-02, -7.82911759e-03, -5.56725776e-04,\n",
       "          1.01869024e-01, -2.27870122e-01, -5.30288890e-02,\n",
       "         -1.53675862e-02, -7.80520961e-02, -2.68430859e-02,\n",
       "         -4.40767407e-02, -3.17083485e-02, -1.71202235e-02,\n",
       "         -1.84360981e-01, -2.07138080e-02, -5.95378056e-02,\n",
       "         -4.66670394e-02, -5.93132898e-02, -8.67591053e-02,\n",
       "         -5.37716150e-02, -4.73896042e-02, -1.47447333e-01,\n",
       "         -1.21590324e-01, -1.33291289e-01, -6.46863692e-03,\n",
       "         -6.93688691e-02, -8.36706087e-02, -3.99699137e-02,\n",
       "         -5.03426865e-02, -3.56070511e-02, -4.05929703e-03,\n",
       "         -2.65870914e-02, -2.19562754e-01, -8.31920430e-02,\n",
       "         -3.51440042e-01, -1.56014040e-02, -5.09398356e-02,\n",
       "         -2.63770024e-04, -2.54512914e-02, -2.67969482e-02,\n",
       "         -8.10445324e-02, -1.18046887e-02, -2.80873068e-02,\n",
       "         -4.98527810e-02, -7.11458623e-02, -4.34676781e-02,\n",
       "         -7.72115961e-02, -1.77671403e-01, -2.77522117e-01,\n",
       "         -3.43034342e-02, -1.76680740e-02, -4.24240530e-02,\n",
       "         -4.67506945e-02, -7.56450146e-02, -2.08871573e-01,\n",
       "         -5.76410443e-02, -4.43090141e-01, -4.97431457e-02,\n",
       "         -5.88464737e-02, -5.92282414e-02, -6.93979785e-02,\n",
       "         -8.41250420e-02, -1.60641631e-03, -7.82692283e-02,\n",
       "         -7.69220293e-02, -2.44136736e-01, -8.62905383e-02,\n",
       "         -5.95969483e-02, -4.66222316e-02, -2.26723216e-02,\n",
       "         -4.53892397e-03, -4.70520034e-02,  4.33613621e-02,\n",
       "         -1.67760506e-01,  3.51975411e-02, -4.81576845e-02,\n",
       "         -3.31141688e-02, -1.01556234e-01, -4.74252999e-02,\n",
       "         -6.38317615e-02, -8.10266957e-02, -5.98547608e-02,\n",
       "         -4.15854193e-02, -4.69031185e-02, -6.17454126e-02,\n",
       "         -4.56264615e-03, -7.98818544e-02, -6.32797405e-02,\n",
       "         -2.73740552e-02, -1.62835345e-01, -4.32430059e-02,\n",
       "         -4.30922373e-04, -3.63945141e-02, -7.91479200e-02,\n",
       "         -4.26582932e-01, -2.61914551e-01, -2.87754163e-02,\n",
       "         -2.65657395e-01, -5.05057685e-02, -4.23402637e-02,\n",
       "         -2.69166201e-01, -4.11506027e-01, -6.51795119e-02,\n",
       "         -2.58028470e-02, -1.51825827e-02, -1.67714164e-01,\n",
       "         -3.19965668e-02, -4.25863788e-02, -3.37530002e-02,\n",
       "         -3.30139071e-01, -1.91802174e-01, -1.91197634e-01,\n",
       "         -3.55453312e-01,  7.09207579e-02, -4.65703756e-02,\n",
       "         -6.47140369e-02, -5.43040112e-02, -3.28360319e-01,\n",
       "         -2.17465416e-01, -4.37242165e-02, -9.80388094e-03,\n",
       "         -1.98660523e-01, -2.72489823e-02, -5.26658520e-02,\n",
       "         -2.04546317e-01, -3.85692529e-02, -3.45199183e-02,\n",
       "         -1.59309834e-01, -2.06753202e-02, -1.19917467e-02,\n",
       "         -3.17781121e-01, -4.21599224e-02, -3.21543626e-02,\n",
       "         -2.17857659e-01, -7.61258081e-02, -5.01764044e-02,\n",
       "         -5.00531197e-02, -4.56352159e-02, -1.77510560e-01,\n",
       "         -3.77580561e-02, -7.70436674e-02, -5.53505570e-02,\n",
       "         -5.47569469e-02, -8.40012878e-02, -7.88012967e-02,\n",
       "         -2.13327110e-02, -8.44508410e-03,  1.90127045e-01,\n",
       "         -2.48026997e-02, -8.06044489e-02],\n",
       "        [ 3.50001276e-01,  3.89014393e-01,  1.87799022e-01,\n",
       "          3.09725702e-01,  3.28653097e-01,  5.03987947e-04,\n",
       "          4.85500604e-01,  3.87152657e-02,  2.75302911e-03,\n",
       "          2.25866824e-01,  6.79118872e-01,  2.62229770e-01,\n",
       "          7.59932771e-02,  3.85970384e-01,  1.32740036e-01,\n",
       "          2.85622537e-01,  1.56798899e-01,  8.46601129e-02,\n",
       "          8.55527997e-01,  1.02430530e-01,  2.94416606e-01,\n",
       "          2.30770200e-01,  2.93306410e-01,  4.29026872e-01,\n",
       "          2.65902579e-01,  2.34343275e-01,  5.72291553e-01,\n",
       "          8.16057503e-01,  5.80594778e-01,  3.19876485e-02,\n",
       "          4.24122125e-01,  4.13754195e-01,  1.97652668e-01,\n",
       "          2.48946369e-01,  1.76078156e-01,  2.00733729e-02,\n",
       "          1.31474137e-01,  9.05827761e-01,  4.11387593e-01,\n",
       "          1.82764694e-01,  7.71495253e-02,  2.51899362e-01,\n",
       "          1.30435231e-03,  1.25857547e-01,  1.32511899e-01,\n",
       "          4.00768101e-01,  5.83746135e-02,  1.38892770e-01,\n",
       "          2.46523812e-01,  3.51818830e-01,  2.14949235e-01,\n",
       "          3.81814182e-01,  6.88813210e-01, -2.43647173e-01,\n",
       "          1.69631720e-01,  8.73692706e-02,  2.09788471e-01,\n",
       "          2.31183887e-01,  3.74067307e-01,  8.89830351e-01,\n",
       "          2.85037100e-01,  8.50877941e-01,  2.45981678e-01,\n",
       "          2.90997922e-01,  2.92885751e-01,  3.43175530e-01,\n",
       "          4.16001379e-01,  4.09130335e-01,  3.87044191e-01,\n",
       "          3.80382180e-01,  7.23943949e-01,  4.26709831e-01,\n",
       "          2.94709027e-01,  2.30548590e-01,  1.12115443e-01,\n",
       "          2.24451441e-02,  2.32673839e-01,  3.91735107e-01,\n",
       "          5.92104495e-01,  3.31905633e-01,  2.38141507e-01,\n",
       "          1.63750768e-01,  7.08372593e-01,  2.34519750e-01,\n",
       "          3.15650374e-01,  4.00679976e-01,  2.95983940e-01,\n",
       "          2.05641374e-01,  2.31937617e-01,  3.05333287e-01,\n",
       "          2.25624498e-02,  3.95018697e-01,  3.12920600e-01,\n",
       "          1.35365680e-01,  8.43824863e-01,  2.13838249e-01,\n",
       "          2.13092659e-03,  1.79972157e-01,  3.91389340e-01,\n",
       "          8.18588853e-01,  6.94877148e-01,  1.42295465e-01,\n",
       "          7.24483490e-01,  6.81339979e-01,  2.09374145e-01,\n",
       "          8.63057613e-01,  7.87086368e-01,  3.22315037e-01,\n",
       "          1.27595991e-01,  7.50784129e-02,  7.05808938e-01,\n",
       "          1.58224225e-01,  2.10591197e-01,  1.66909829e-01,\n",
       "          9.03997242e-01,  5.69952607e-01,  5.27965307e-01,\n",
       "          7.94790924e-01,  7.95260906e-01,  2.30292186e-01,\n",
       "          3.20013255e-01,  2.68535256e-01,  6.90699577e-01,\n",
       "          8.78873527e-01,  2.16217831e-01,  4.84805405e-02,\n",
       "          8.50959837e-01,  1.34747207e-01,  2.60434568e-01,\n",
       "          8.43560755e-01,  1.90726385e-01,  1.70702264e-01,\n",
       "          6.49288535e-01,  1.02240197e-01,  5.92996180e-02,\n",
       "          7.85986900e-01,  2.08482355e-01,  1.59004480e-01,\n",
       "          8.40656102e-01,  3.76444876e-01,  2.48124152e-01,\n",
       "          2.47514486e-01,  2.25667804e-01,  6.42898917e-01,\n",
       "          1.86714977e-01,  3.80983770e-01,  2.73710489e-01,\n",
       "          2.70775139e-01,  6.72781885e-01,  3.89675260e-01,\n",
       "          1.05491020e-01,  4.17612493e-02,  6.57716453e-01,\n",
       "          1.22650243e-01,  3.98591906e-01],\n",
       "        [-7.82795921e-02, -8.70050788e-02, -4.20022160e-02,\n",
       "          3.73728663e-01, -7.35049620e-02,  2.14821637e-01,\n",
       "          1.11435838e-02, -8.65886733e-03, -6.15729135e-04,\n",
       "          2.52049845e-02, -1.82000160e-01, -5.86490370e-02,\n",
       "         -1.69962868e-02, -8.63242745e-02, -2.96879876e-02,\n",
       "          1.74829751e-01, -3.50688808e-02, -1.89346690e-02,\n",
       "         -1.75300553e-01, -2.29091123e-02, -6.58477843e-02,\n",
       "         -5.16129434e-02, -6.55994862e-02, -9.59540755e-02,\n",
       "         -5.94704747e-02, -5.24120815e-02,  7.52194673e-02,\n",
       "         -1.26515120e-01, -1.05810076e-01, -7.15420162e-03,\n",
       "          4.50544097e-02, -9.25382450e-02, -4.42060344e-02,\n",
       "         -5.56781366e-02, -3.93807851e-02, -4.48951311e-03,\n",
       "         -2.94048656e-02, -2.19416603e-01, -9.20089632e-02,\n",
       "          1.63846493e-01, -1.72548853e-02, -5.63385859e-02,\n",
       "         -2.91725097e-04, -2.81486865e-02, -2.96369661e-02,\n",
       "         -8.96338448e-02, -1.30557837e-02, -3.10640801e-02,\n",
       "         -5.51363155e-02, -7.86860883e-02, -4.80745062e-02,\n",
       "         -8.53947029e-02, -8.56675431e-02,  4.24986258e-02,\n",
       "         -3.79390083e-02, -1.95405856e-02, -4.69202660e-02,\n",
       "         -5.17054610e-02, -8.36620778e-02, -1.47152275e-01,\n",
       "         -6.37500063e-02,  2.22090222e-02, -5.50150648e-02,\n",
       "         -6.50831759e-02, -6.55054078e-02, -7.67529607e-02,\n",
       "         -9.30408388e-02, -8.33852738e-02, -8.65644217e-02,\n",
       "         -8.50744322e-02, -2.21491620e-01, -9.54358503e-02,\n",
       "         -6.59131855e-02, -5.15633821e-02, -2.50751935e-02,\n",
       "         -5.01997210e-03, -5.20386994e-02,  1.41301855e-01,\n",
       "         -7.82092810e-02,  2.67409962e-02, -5.32615706e-02,\n",
       "         -3.66237015e-02, -9.65613648e-02, -5.24515547e-02,\n",
       "         -7.05968291e-02, -8.96141231e-02, -6.61983341e-02,\n",
       "         -4.59927507e-02, -5.18740416e-02, -6.82893544e-02,\n",
       "         -5.04620839e-03, -8.83479714e-02, -6.99862987e-02,\n",
       "         -3.02752331e-02, -1.21176407e-01, -4.78260219e-02,\n",
       "         -4.76592744e-04, -4.02516946e-02, -8.75362307e-02,\n",
       "          1.10440195e-01, -6.36948347e-02, -3.18251178e-02,\n",
       "         -4.52503115e-02, -7.82180130e-02, -4.68276069e-02,\n",
       "          4.75188997e-03, -3.25029716e-02, -7.20874146e-02,\n",
       "         -2.85374988e-02, -1.67916715e-02, -9.99568403e-02,\n",
       "         -3.53876576e-02, -4.70998064e-02, -3.73302400e-02,\n",
       "         -2.77028263e-01,  7.02063506e-03, -5.25874831e-02,\n",
       "          6.31047040e-02, -2.80859560e-01, -5.15060350e-02,\n",
       "         -7.15726018e-02, -6.00592978e-02,  3.05464473e-02,\n",
       "         -1.57890782e-01, -4.83582281e-02, -1.08429231e-02,\n",
       "         -1.18917264e-01, -3.01369019e-02, -5.82475252e-02,\n",
       "         -1.48066059e-01, -4.26569358e-02, -3.81784365e-02,\n",
       "         -1.82445571e-01, -2.28665471e-02, -1.32626649e-02,\n",
       "         -5.18547557e-02, -4.66281474e-02, -3.55621725e-02,\n",
       "         -1.38943300e-01, -8.41938257e-02, -5.54942414e-02,\n",
       "         -5.53578883e-02, -5.04717603e-02, -1.06425256e-01,\n",
       "         -4.17597592e-02, -8.52089673e-02, -6.12167530e-02,\n",
       "         -6.05602488e-02, -1.71593368e-01, -8.71528685e-02,\n",
       "         -2.35936083e-02, -9.34011769e-03, -8.65792781e-02,\n",
       "         -2.74313577e-02, -8.91471207e-02]], dtype=float32),\n",
       " array([[ 0.12928236,  0.00709345,  0.2270143 , ..., -0.11943059,\n",
       "          0.70338863,  0.65438473],\n",
       "        [ 0.5483187 ,  0.02092948,  0.75045013, ...,  0.6519301 ,\n",
       "          0.2481015 , -0.07473479],\n",
       "        [ 0.6927793 ,  0.39143902,  0.849975  , ..., -0.02917881,\n",
       "          0.7804612 ,  0.8315323 ],\n",
       "        ...,\n",
       "        [ 0.87635386, -0.02215197, -0.00783195, ...,  0.6377076 ,\n",
       "          0.05747489, -0.07916766],\n",
       "        [ 0.40146548,  0.82552207,  0.22120453, ...,  0.37094074,\n",
       "          0.6960912 ,  0.29183385],\n",
       "        [ 0.7315277 ,  0.3760425 ,  0.20362827, ...,  0.39146245,\n",
       "          0.6885634 ,  0.46912655]], dtype=float32),\n",
       " array([[ 0.6863232 , -0.15331934],\n",
       "        [-0.1346482 ,  0.9562666 ],\n",
       "        [ 0.67038196,  0.1751069 ],\n",
       "        [ 0.4680428 ,  0.27903527],\n",
       "        [-0.62222624,  0.9912873 ],\n",
       "        [-1.9586315 , -0.91880345],\n",
       "        [-1.125045  , -0.7164499 ],\n",
       "        [-1.817268  , -1.4153247 ],\n",
       "        [-0.14546566,  0.43282455],\n",
       "        [-0.05263123,  1.3557997 ],\n",
       "        [ 0.6870449 ,  0.52301294],\n",
       "        [ 0.8193781 ,  0.08076601],\n",
       "        [ 0.8614487 ,  0.0697166 ],\n",
       "        [ 0.83453995,  0.01914682],\n",
       "        [ 0.9942077 ,  0.4426133 ],\n",
       "        [-0.10531774,  0.76641434],\n",
       "        [ 0.5152412 ,  0.8558208 ],\n",
       "        [ 0.65242535, -0.18386522],\n",
       "        [ 0.69384706,  0.5340736 ],\n",
       "        [ 0.40103546,  1.1966436 ],\n",
       "        [-1.4748812 , -0.94238144],\n",
       "        [ 0.30144018,  1.0257895 ],\n",
       "        [-1.5474102 , -0.8473881 ],\n",
       "        [-1.1221648 , -0.8756473 ],\n",
       "        [ 0.7400202 , -0.2073289 ],\n",
       "        [ 0.7280379 , -0.1527448 ],\n",
       "        [-0.85351145,  0.59385556],\n",
       "        [ 0.5564144 ,  0.5216752 ],\n",
       "        [ 0.6133937 ,  0.8842093 ],\n",
       "        [-0.12615316,  1.2168283 ],\n",
       "        [ 0.53263384,  0.35883057]], dtype=float32),\n",
       " array([-0.28383029, -0.31458557, -0.15186486,  0.30425993, -0.26639026,\n",
       "         0.01712598,  0.60012305, -0.03149702, -0.00305842, -0.06769948,\n",
       "         0.20669276, -0.21263544, -0.06160916, -0.31217527, -0.10744675,\n",
       "         0.13076761, -0.12664579, -0.06842119,  0.06991691, -0.08283355,\n",
       "        -0.23805155, -0.1870908 , -0.23751526, -0.3471313 , -0.21489719,\n",
       "        -0.18942702,  0.06763341,  0.30711752,  0.21774091, -0.02596493,\n",
       "         0.3584098 , -0.33435127, -0.15995553, -0.20170794, -0.14258547,\n",
       "        -0.01627403, -0.10622326,  0.00116518, -0.3327444 ,  0.31751755,\n",
       "        -0.06249094, -0.20345554, -0.00187809, -0.10168617, -0.10713416,\n",
       "        -0.32413107, -0.04729197, -0.11250894, -0.19976912, -0.28495467,\n",
       "        -0.17469911, -0.30920935,  0.29778016,  0.7953085 , -0.13741975,\n",
       "        -0.07063854, -0.16984136, -0.18727449, -0.30248228,  0.06655616,\n",
       "        -0.23112178,  0.02831766, -0.19898465, -0.23572895, -0.23653843,\n",
       "        -0.27749056, -0.33645573,  0.02051436, -0.31371927, -0.30730048,\n",
       "         0.05587978, -0.34579587, -0.23848681, -0.1865959 , -0.09067887,\n",
       "        -0.01844228, -0.18869911,  0.24750903,  0.28016075,  0.72311   ,\n",
       "        -0.19297187, -0.13239871,  0.36893755, -0.19007044, -0.25604025,\n",
       "        -0.32444695, -0.2393859 , -0.16607864, -0.18790606, -0.24759218,\n",
       "        -0.01826485, -0.31940347, -0.25278816, -0.10948997,  0.14103927,\n",
       "        -0.17285003, -0.00264572, -0.14541171, -0.31624797,  0.00504265,\n",
       "         0.09820411, -0.11497195,  0.03021408,  0.37450218, -0.17002307,\n",
       "        -0.29789093,  0.07308634, -0.26094735, -0.10315148, -0.06065961,\n",
       "         0.22185592, -0.12804289, -0.17049542, -0.13507186, -0.13124591,\n",
       "         0.24352506,  0.24584235, -0.15039709, -0.18415068, -0.18614395,\n",
       "        -0.25848284, -0.21713065,  0.31059852,  0.16940911, -0.17476822,\n",
       "        -0.0395139 ,  0.14646763, -0.1089573 , -0.21143371, -0.17031789,\n",
       "        -0.15427087, -0.13839707,  0.20174702, -0.08271152, -0.04803753,\n",
       "         0.04995073, -0.16844337, -0.12841488,  0.20105141, -0.30410913,\n",
       "        -0.20056294, -0.20006253, -0.18251912,  0.19742718, -0.15121455,\n",
       "        -0.30812535, -0.22134608, -0.21894099,  0.17910449, -0.31525296,\n",
       "        -0.08532681, -0.03395198,  0.24880375, -0.09930573, -0.32260868],\n",
       "       dtype=float32),\n",
       " array([-3.7341675e-04,  7.4855548e-01, -2.8829291e-04, -5.7105254e-04,\n",
       "         8.9687848e-01, -1.2120290e+00,  1.8325676e+00, -1.6328639e+00,\n",
       "        -5.1739424e-01, -6.2699550e-01, -3.2798140e-04, -2.8589868e-04,\n",
       "        -3.0917148e-04, -3.0327064e-04, -2.9883065e-04,  7.1240842e-01,\n",
       "        -1.4255142e-01, -3.8467109e-04, -3.2612358e-04,  2.7126986e-01,\n",
       "        -1.1201730e+00,  2.4729504e-01, -1.0346737e+00,  1.7210363e+00,\n",
       "        -3.6663568e-04, -3.5726582e-04, -8.5691392e-01, -3.2474732e-04,\n",
       "        -1.7081540e-02, -6.7784923e-01, -3.1370623e-04], dtype=float32),\n",
       " array([[-1.6809989 , -0.41714406]], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(params)):\n",
    "    np.save('../save/weights/slearn_parms{}_3-2.npy'.format(i),params[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
