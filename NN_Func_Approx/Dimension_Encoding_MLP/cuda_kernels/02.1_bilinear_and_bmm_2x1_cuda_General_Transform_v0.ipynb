{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets\n",
    "import random, sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cuda:1\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom CUDA-Pytorch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bmm2x2_cuda\n",
    "import bilinear2x2_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuda -bmm2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMM2x2Function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "#     @torch.jit.ignore\n",
    "    def forward(ctx, inputs, weights):\n",
    "        outputs = bmm2x2_cuda.forward(inputs, weights)\n",
    "        ctx.save_for_backward(inputs, weights)\n",
    "        return outputs[0]\n",
    "    \n",
    "    @staticmethod\n",
    "#     @torch.jit.ignore\n",
    "    def backward(ctx, grad_output):\n",
    "        inputs, weights = ctx.saved_tensors\n",
    "        del_input, del_weights = bmm2x2_cuda.backward(\n",
    "            inputs, \n",
    "            weights, \n",
    "            grad_output)\n",
    "    \n",
    "        return del_input, del_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairLinear(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        assert input_dim%2 == 0, \"Input dim must be even number\"\n",
    "        self.weight = torch.eye(2).unsqueeze(0).repeat_interleave(input_dim//2, dim=0)\n",
    "        self.weight = nn.Parameter(self.weight)\n",
    "        self.bmmfunc = BMM2x2Function()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, dim = x.shape[0], x.shape[1]\n",
    "        x = x.view(bs, -1, 2)\n",
    "        x = BMM2x2Function.apply(x, self.weight)\n",
    "        x = x.view(bs, -1)\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        t = self.weight.shape[0]*2\n",
    "        S = f'PairLinear: [{t} -> {t}]'\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(5, 8).to(device)\n",
    "model = PairLinear(8).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairLinear: [8 -> 8]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0482,  0.0458, -0.1138,  0.4797,  0.7061,  0.9942,  0.4593, -0.9618],\n",
       "        [ 0.5966, -1.1693, -0.8379, -1.0604, -0.4124,  1.8205,  0.2100, -0.6360],\n",
       "        [-0.3879,  0.7118,  1.0327, -0.8704,  0.4211,  0.3607,  1.1000, -1.3011],\n",
       "        [ 0.5919, -0.0903, -0.7032,  0.5343, -0.6516, -0.3320,  0.7255,  0.1594],\n",
       "        [ 0.7397, -0.5280, -0.4998,  2.4217, -1.1096,  0.7731,  0.7770, -0.2846]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(A)\n",
    "y.mean().backward()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0373,  0.0373],\n",
       "         [-0.0258, -0.0258]],\n",
       "\n",
       "        [[-0.0280, -0.0280],\n",
       "         [ 0.0376,  0.0376]],\n",
       "\n",
       "        [[-0.0262, -0.0262],\n",
       "         [ 0.0904,  0.0904]],\n",
       "\n",
       "        [[ 0.0818,  0.0818],\n",
       "         [-0.0756, -0.0756]]], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMM 2x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMM2x1Function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, weights):\n",
    "        outputs = bmm2x2_cuda.forward_2x1(inputs, weights)\n",
    "        ctx.save_for_backward(inputs, weights)\n",
    "        return outputs[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        inputs, weights = ctx.saved_tensors\n",
    "        del_input, del_weights = bmm2x2_cuda.backward_2x1(\n",
    "            inputs, \n",
    "            weights, \n",
    "            grad_output)\n",
    "    \n",
    "        return del_input, del_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairLinearHalve(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        assert input_dim%2 == 0, \"Input dim must be even number\"\n",
    "        self.weight = torch.Tensor([0.5, 0.5]).unsqueeze(0).repeat_interleave(input_dim//2, dim=0)\n",
    "        self.weight = nn.Parameter(self.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, dim = x.shape[0], x.shape[1]\n",
    "        x = x.view(bs, -1, 2)\n",
    "        x = BMM2x1Function.apply(x, self.weight)\n",
    "        x = x.view(bs, -1)\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        t = self.weight.shape[0]\n",
    "        S = f'PairLinearHalve: [{t*2} -> {t}]'\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(5, 8).to(device)\n",
    "model = PairLinearHalve(8).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairLinearHalve: [8 -> 4]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3508, -0.7172,  0.6843, -0.1334],\n",
       "        [ 0.0626,  0.1347,  0.2325,  0.3437],\n",
       "        [-0.1255,  0.0414,  0.4830, -0.4375],\n",
       "        [-0.0651,  0.0680,  0.3810, -1.0676],\n",
       "        [ 0.5592,  1.1002,  0.5184, -0.4876]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(A)\n",
    "y.mean().backward()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0161,  0.0943],\n",
       "        [ 0.0667, -0.0040],\n",
       "        [ 0.0653,  0.1646],\n",
       "        [-0.1167, -0.0615]], device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuda - Bilinear2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLinear2x2Function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, weights):\n",
    "        outputs = bilinear2x2_cuda.forward(inputs, weights)\n",
    "        ctx.save_for_backward(inputs, weights)\n",
    "        return outputs[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        inputs, weights = ctx.saved_tensors\n",
    "        del_input, del_weights = bilinear2x2_cuda.backward(\n",
    "            inputs, \n",
    "            weights, \n",
    "            grad_output)\n",
    "    \n",
    "        return del_input, del_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairBilinear(nn.Module):\n",
    "    def __init__(self, dim, grid_width):\n",
    "        super().__init__()\n",
    "        num_pairs = dim // 2\n",
    "        along_row = torch.linspace(0, 1, grid_width).reshape(1, -1).t()\n",
    "        along_col = torch.linspace(0, 1, grid_width).reshape(-1, 1).t()\n",
    "        \n",
    "        self.Y = torch.stack([along_row+along_col*0, along_row*0+along_col])\n",
    "        self.Y = torch.repeat_interleave(self.Y.unsqueeze(0), num_pairs, dim=0)\n",
    "        self.Y = nn.Parameter(self.Y)\n",
    "        \n",
    "        self.pairW = torch.eye(2).unsqueeze(0).repeat_interleave(num_pairs, dim=0)\n",
    "        self.pairW = nn.Parameter(self.pairW)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        x = x.view(bs, -1, 2)\n",
    "        x = BMM2x2Function.apply(x, self.pairW)\n",
    "        ####################################################\n",
    "        x = BiLinear2x2Function.apply(x, self.Y)\n",
    "        x = x.view(bs, -1)\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        t = self.pairW.shape[0]*2\n",
    "        u = self.Y.shape[2]\n",
    "        S = f'PairLinear: [{t} -> {t}] (grid: {u})'\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(5, 8).to(device)\n",
    "model = PairBilinear(8, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairLinear: [8 -> 8] (grid: 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6277,  0.6846, -0.2970,  0.5104,  1.5108,  0.8831, -0.1273, -0.1880],\n",
       "        [-0.2823,  0.2822, -0.3119,  1.1664,  0.8766,  0.5316,  1.3626,  0.1817],\n",
       "        [-0.8798, -0.6815, -0.9414, -0.3515, -0.5076, -0.6730, -0.5839,  1.1094],\n",
       "        [ 0.6834,  0.4560, -1.7385,  2.0084,  0.5141,  1.3177,  1.6020, -0.0783],\n",
       "        [-0.3808,  0.2510, -0.7354, -0.3153,  0.1359, -0.2706, -0.8862,  0.6448]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(A)\n",
    "y.mean().backward()\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2020, -0.0499,  0.0000],\n",
       "          [-0.1182,  0.0686,  0.0069],\n",
       "          [ 0.0008,  0.0124,  0.0024]],\n",
       "\n",
       "         [[ 0.2020, -0.0499,  0.0000],\n",
       "          [-0.1182,  0.0686,  0.0069],\n",
       "          [ 0.0008,  0.0124,  0.0024]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2235, -0.2898,  0.3926],\n",
       "          [-0.1401,  0.2222, -0.2833],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.2235, -0.2898,  0.3926],\n",
       "          [-0.1401,  0.2222, -0.2833],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1462, -0.0777,  0.0000],\n",
       "          [-0.0491,  0.0148,  0.0206],\n",
       "          [ 0.0000,  0.0290,  0.0411]],\n",
       "\n",
       "         [[ 0.1462, -0.0777,  0.0000],\n",
       "          [-0.0491,  0.0148,  0.0206],\n",
       "          [ 0.0000,  0.0290,  0.0411]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0432,  0.0256,  0.0861],\n",
       "          [-0.0551, -0.0246, -0.0484],\n",
       "          [ 0.0912,  0.0070,  0.0000]],\n",
       "\n",
       "         [[ 0.0432,  0.0256,  0.0861],\n",
       "          [-0.0551, -0.0246, -0.0484],\n",
       "          [ 0.0912,  0.0070,  0.0000]]]], device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda - Bilinear2x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLinear2x1Function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, weights):\n",
    "        outputs = bilinear2x2_cuda.forward_2x1(inputs, weights)\n",
    "        ctx.save_for_backward(inputs, weights)\n",
    "        return outputs[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        inputs, weights = ctx.saved_tensors\n",
    "        del_input, del_weights = bilinear2x2_cuda.backward_2x1(\n",
    "            inputs, \n",
    "            weights, \n",
    "            grad_output)\n",
    "    \n",
    "        return del_input, del_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairBilinearHalve(nn.Module):\n",
    "    def __init__(self, dim, grid_width):\n",
    "        super().__init__()\n",
    "        num_pairs = dim // 2\n",
    "        \n",
    "        self.pairW = torch.eye(2).unsqueeze(0).repeat_interleave(num_pairs, dim=0)\n",
    "        self.pairW = nn.Parameter(self.pairW)\n",
    "\n",
    "        along_row = torch.linspace(0, 1, grid_width).reshape(1, -1).t()\n",
    "        along_col = torch.linspace(0, 1, grid_width).reshape(-1, 1).t()\n",
    "        \n",
    "        self.Y = torch.stack([along_row+along_col*0, along_row*0+along_col]).mean(dim=0)\n",
    "        self.Y = torch.repeat_interleave(self.Y.unsqueeze(0), num_pairs, dim=0)\n",
    "        self.Y = nn.Parameter(self.Y)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        x = x.view(bs, -1, 2)\n",
    "        x = BMM2x2Function.apply(x, self.pairW)\n",
    "        ####################################################\n",
    "        x = BiLinear2x1Function.apply(x, self.Y)\n",
    "        x = x.view(bs, -1)\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        t = self.pairW.shape[0]\n",
    "        u = self.Y.shape[2]\n",
    "        S = f'PairLinear: [{t*2} -> {t}] (grid: {u})'\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(5, 8).to(device)\n",
    "model = PairBilinearHalve(8, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairLinear: [8 -> 4] (grid: 3)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8319, -0.6487, -1.2232, -0.6380],\n",
       "        [-1.5712,  0.5226,  0.5464, -0.4149],\n",
       "        [-0.9055, -0.0855, -0.1336,  0.4387],\n",
       "        [-0.2508,  0.1046, -0.4098,  0.1326],\n",
       "        [-1.5982,  0.6126,  0.8330,  0.1647]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(A)\n",
    "y.mean().backward()\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.3839e+00, -1.7646e+00,  0.0000e+00],\n",
       "         [-1.4716e+00,  1.1023e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 6.2555e-02,  1.3307e-02,  0.0000e+00],\n",
       "         [-2.5036e-01,  1.8656e-01,  1.7736e-03],\n",
       "         [ 7.4990e-01, -5.1488e-01,  1.1444e-03]],\n",
       "\n",
       "        [[ 2.2106e-01, -2.5346e-01,  4.6508e-01],\n",
       "         [ 1.1670e-01, -4.5822e-02, -2.8898e-01],\n",
       "         [ 1.8530e-02,  1.6905e-02,  0.0000e+00]],\n",
       "\n",
       "        [[ 3.4840e-01, -3.9973e-02,  2.3891e-03],\n",
       "         [-3.6170e-01,  1.8842e-01,  4.0110e-03],\n",
       "         [ 3.8070e-01, -2.7224e-01,  0.0000e+00]]], device='cuda:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules and Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasLayer(nn.Module):\n",
    "    def __init__(self, dim, init_val=0):\n",
    "        super().__init__()\n",
    "        self.bias = nn.Parameter(torch.ones(dim)*init_val)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x+self.bias\n",
    "    \n",
    "    def __repr__(self):\n",
    "        S = f'BiasLayer: [{self.bias.shape[0]}]'\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimensionSelector(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        assert output_dim > input_dim, \"Slection does not select all inputs\"\n",
    "        remain = output_dim-input_dim\n",
    "        \n",
    "        scale = int(np.ceil(output_dim/input_dim)-1)\n",
    "#         self.indices = torch.randperm(input_dim*scale)[:remain]%input_dim\n",
    "\n",
    "        self.indices = torch.LongTensor([])\n",
    "        for i in range(scale):\n",
    "            c = min(input_dim, remain-len(self.indices))\n",
    "            t = torch.randperm(input_dim)[:c]\n",
    "            self.indices = torch.cat([self.indices, t])\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## x.shape = [batch_size, input_dim]\n",
    "        return torch.cat([x, x[:, self.indices]], dim=1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        S = f'DimensionSelector: [+={self.indices.shape[0]}]'\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DimensionSelector(8, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7]), tensor([3, 3, 3, 3, 3, 3, 3, 3]))"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.indices.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 4, 2, 7, 6, 5, 0, 0, 3, 6, 5, 4, 1, 7, 2, 5, 4, 7, 6, 0, 2, 3, 1])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairBilinear_MixerBlock(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    Handle any input - output size;\n",
    "    \n",
    "    Operations -> Select, NxN mix, Halve\n",
    "    \n",
    "    -Edge cases:\n",
    "    1) 8-8 -> NxN mixing for log(N) times\n",
    "    2) 8-10 -> Select(16) + 16x16 + Select(20) + Halve\n",
    "    3) 8-6 -> 8x8 + Select(12) + Halve\n",
    "    4) 8-32 -> Select(32) + 32x32\n",
    "    5) 8-3 -> 8x8 + Halve + 4-Select(6) + Halve\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, grid_width, bias=True):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.grid_width = grid_width\n",
    "        \n",
    "        self.selector = None\n",
    "        self.pairwise_mixing = []\n",
    "        self.reducer = []\n",
    "        \n",
    "        mix_dim = 2**int(np.ceil(np.log2(max(input_dim, output_dim))))\n",
    "        \n",
    "        #########################################################\n",
    "        ### Find out if first selection is required or Not !\n",
    "        if self.input_dim != mix_dim:\n",
    "            ## Input dimension is not power of 2; requires selector to project to mixing dimension\n",
    "            L = DimensionSelector(input_dim, mix_dim)\n",
    "            self.selector = L\n",
    "            if bias:\n",
    "                self.selector = nn.Sequential(L, BiasLayer(mix_dim, 0.5))\n",
    "        else:\n",
    "            self.selector = nn.Identity()\n",
    "            if bias:\n",
    "                self.selector = BiasLayer(mix_dim, 0.5)\n",
    "        \n",
    "        ### Now perform NxN mixing \n",
    "        num_layers = int(np.ceil(np.log2(mix_dim)))\n",
    "        for i in range(num_layers):\n",
    "            net = PairBilinear(mix_dim, grid_width)\n",
    "            self.pairwise_mixing.append(net)\n",
    "        self.pairwise_mixing = nn.ModuleList(self.pairwise_mixing)\n",
    "        \n",
    "        ### Now for reducer if any\n",
    "        num_halve = int(np.ceil(np.log2(mix_dim/output_dim)))\n",
    "        final_expand = output_dim*(2**num_halve)\n",
    "        if final_expand != mix_dim:\n",
    "            L = DimensionSelector(mix_dim, final_expand)\n",
    "            self.reducer.append(L)\n",
    "        for i in range(num_halve):\n",
    "            L = PairBilinearHalve(final_expand//(2**i), grid_width)\n",
    "            self.reducer.append(L)\n",
    "            \n",
    "        if len(self.reducer) == 0:\n",
    "            self.reducer = nn.Identity()\n",
    "        else:\n",
    "            self.reducer = nn.Sequential(*self.reducer)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: shape-> [batch_size, input_dim]\n",
    "        '''\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        x = self.selector(x)\n",
    "        \n",
    "        y = x\n",
    "        for i, fn in enumerate(self.pairwise_mixing):\n",
    "            y = y.view(-1,2,2**i).permute(0, 2,1).contiguous().view(bs, -1)\n",
    "            y = fn(y) \n",
    "            y = y.view(-1,2**i,2).permute(0, 2,1).contiguous()\n",
    "\n",
    "#         y = x + y ## this is residual addition... remove if only want feed forward\n",
    "        y = y.view(bs, -1)\n",
    "        \n",
    "        y = self.reducer(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "pblm = PairBilinear_MixerBlock(16, 12, grid_width=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairBilinear_MixerBlock(\n",
       "  (selector): BiasLayer: [16]\n",
       "  (pairwise_mixing): ModuleList(\n",
       "    (0): PairLinear: [16 -> 16] (grid: 3)\n",
       "    (1): PairLinear: [16 -> 16] (grid: 3)\n",
       "    (2): PairLinear: [16 -> 16] (grid: 3)\n",
       "    (3): PairLinear: [16 -> 16] (grid: 3)\n",
       "  )\n",
       "  (reducer): Sequential(\n",
       "    (0): DimensionSelector: [+=8]\n",
       "    (1): PairLinear: [24 -> 12] (grid: 3)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pblm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6882,  1.5015,  0.3411, -0.3667,  0.3505,  0.8888,  0.6034,  0.2338,\n",
       "          0.8310,  0.9054, -0.2032,  0.1390],\n",
       "        [ 0.9000,  0.8936,  1.3301,  1.4538,  1.5044,  1.3687,  0.0884, -0.1863,\n",
       "          1.2508,  0.5169,  1.1569,  1.8822],\n",
       "        [-0.0505, -0.1814, -0.5177,  2.0929,  0.0982,  1.7282,  0.9924, -0.1975,\n",
       "          0.7790,  0.9535, -0.9159,  2.0932]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pblm(torch.randn(3, 16).to(device))\n",
    "y.mean().backward()\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.la1 = PairBilinear_MixerBlock(784, 512, grid_width=5)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "#         self.la2 = PairBilinear_MixerBlock(200, 10, grid_width=5)\n",
    "        self.la2 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.la1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.la2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinaryNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.la1 = nn.Linear(784, 200, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(200)\n",
    "        self.la2 = nn.Linear(200, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.la1(x))\n",
    "        x = torch.relu(x)\n",
    "        x = self.la2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126474"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FactorNet()\n",
    "param_count = sum([torch.numel(p) for p in model.parameters()])\n",
    "param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159210, 1.2588358081502917)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OrdinaryNet()\n",
    "param_count1 = sum([torch.numel(p) for p in model.parameters()])\n",
    "param_count1, param_count1/param_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0003\n",
    "BS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BS, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BS, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 1, 28, 28])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## demo of train loader\n",
    "xx, yy = iter(train_loader).next()\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorNet(\n",
       "  (la1): PairBilinear_MixerBlock(\n",
       "    (selector): Sequential(\n",
       "      (0): DimensionSelector: [+=240]\n",
       "      (1): BiasLayer: [1024]\n",
       "    )\n",
       "    (pairwise_mixing): ModuleList(\n",
       "      (0): PairLinear: [1024 -> 1024] (grid: 3)\n",
       "      (1): PairLinear: [1024 -> 1024] (grid: 3)\n",
       "      (2): PairLinear: [1024 -> 1024] (grid: 3)\n",
       "      (3): PairLinear: [1024 -> 1024] (grid: 3)\n",
       "      (4): PairLinear: [1024 -> 1024] (grid: 3)\n",
       "      (5): PairLinear: [1024 -> 1024] (grid: 3)\n",
       "      (6): PairLinear: [1024 -> 1024] (grid: 3)\n",
       "      (7): PairLinear: [1024 -> 1024] (grid: 3)\n",
       "      (8): PairLinear: [1024 -> 1024] (grid: 3)\n",
       "      (9): PairLinear: [1024 -> 1024] (grid: 3)\n",
       "    )\n",
       "    (reducer): Sequential(\n",
       "      (0): PairLinear: [1024 -> 512] (grid: 3)\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (la2): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = FactorNet().to(device)\n",
    "# model = OrdinaryNet().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:20<00:00, 15.00it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0,  Loss:0.4560028910636902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 41.48it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:77.67%, Test Acc:83.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:20<00:00, 14.87it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1,  Loss:0.3467607796192169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 36.75it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:86.10%, Test Acc:85.95%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:20<00:00, 14.98it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2,  Loss:0.32844313979148865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 50.16it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:87.79%, Test Acc:86.91%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:19<00:00, 15.09it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3,  Loss:0.264177531003952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 56.48it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:88.78%, Test Acc:87.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:20<00:00, 14.87it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4,  Loss:0.29283979535102844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 39.50it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:89.50%, Test Acc:87.63%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:20<00:00, 14.64it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5,  Loss:0.21122464537620544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 53.54it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:90.19%, Test Acc:87.86%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:20<00:00, 14.95it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6,  Loss:0.18957166373729706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 47.00it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:90.56%, Test Acc:88.16%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:20<00:00, 14.92it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7,  Loss:0.22201703488826752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 55.51it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:91.09%, Test Acc:88.62%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:20<00:00, 14.95it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8,  Loss:0.3216005563735962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 56.47it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:91.55%, Test Acc:88.27%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:19<00:00, 15.07it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9,  Loss:0.15288347005844116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 57.05it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:91.81%, Test Acc:88.36%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:20<00:00, 14.99it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10,  Loss:0.22441822290420532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 45.51it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.16%, Test Acc:88.95%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 238/300 [00:16<00:04, 14.79it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-411-8838b3837d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "    i = -1\n",
    "    for xx, yy in tqdm(train_loader):\n",
    "        i += 1 \n",
    "        xx = xx.view(xx.shape[0], -1)\n",
    "        xx, yy = xx.to(device), yy.to(device)\n",
    "\n",
    "        yout = model(xx)\n",
    "        loss = criterion(yout, yy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(float(loss))\n",
    "\n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        train_acc += correct\n",
    "        train_count += len(outputs)\n",
    "        \n",
    "\n",
    "    train_accs.append(float(train_acc)/train_count*100)\n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "\n",
    "    print(f'Epoch: {epoch},  Loss:{float(loss)}')\n",
    "    test_count = 0\n",
    "    test_acc = 0\n",
    "    for xx, yy in tqdm(test_loader):\n",
    "        xx = xx.view(xx.shape[0], -1)\n",
    "        xx, yy = xx.to(device), yy.to(device)\n",
    "        with torch.no_grad():\n",
    "            yout = model(xx)\n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        test_acc += correct\n",
    "        test_count += len(xx)\n",
    "    test_accs.append(float(test_acc)/test_count*100)\n",
    "    print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "    print()\n",
    "\n",
    "### after each class index is finished training\n",
    "print(f'\\t-> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
