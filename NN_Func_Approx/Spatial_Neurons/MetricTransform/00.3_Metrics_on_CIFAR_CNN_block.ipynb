{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43fb4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f942dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dtnnlib as dtnn\n",
    "import resnet_cifar\n",
    "\n",
    "from torchvision import datasets, transforms as T\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67efd8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys, random, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a09b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f431fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_train = T.Compose([\n",
    "    T.RandomCrop(size=32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "        std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "    ),\n",
    "])\n",
    "\n",
    "cifar_test = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "        std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=True, download=True, transform=cifar_train)\n",
    "test_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=False, download=True, transform=cifar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30672ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.data = train_dataset.data.view(-1, 28*28)\n",
    "# test_dataset.data = test_dataset.data.view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e2cbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c31a5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68635f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5383efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89c95e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = resnet_cifar.cifar_resnet20(num_classes=10, distance=0.5)\n",
    "# net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b919491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdasd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521fc827",
   "metadata": {},
   "source": [
    "## Any function as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2fab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FunctionDT(nn.Module):\n",
    "    \n",
    "#     def __init__(self, input_dim, num_centers, func, inv_temp=0.):\n",
    "#         '''\n",
    "#         func [input_dim -> 1]\n",
    "#         '''\n",
    "#         super().__init__()\n",
    "#         self.input_dim = input_dim\n",
    "#         self.num_centers = num_centers\n",
    "#         self.func = func\n",
    "        \n",
    "#         self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "#         self.centers = torch.randn(num_centers, input_dim)/3.\n",
    "#         self.centers = nn.Parameter(self.centers)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         z = x.unsqueeze(1) - self.centers.unsqueeze(0)\n",
    "#         dists = self.func(z).squeeze(-1)\n",
    "#         dists = -dists*torch.exp(self.inv_temp)\n",
    "#         return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cc69857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from classes import DistanceRegressor, ConvexNN\n",
    "# from nflib.flows import SequentialFlow, ActNorm\n",
    "# import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd428ec7",
   "metadata": {},
   "source": [
    "## Try Different metrics for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c6f1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "#     for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "#     print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "595490f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch, model, model_name):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "#     print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "#         print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "#         if not os.path.isdir('models'):\n",
    "#             os.mkdir('models')\n",
    "#         torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "470c07e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd51a96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘outputs’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14f49ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59cc699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for 2; seed 852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                             | 0/200 [00:00<?, ?it/s][2023-12-31 10:34:05,797] torch._inductor.utils: [WARNING] make_fallback(aten._euclidean_dist.default): a decomposition exists, we should switch to it\n",
      "100%|█████████████████████████████████████████████████| 200/200 [1:01:34<00:00, 18.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for stereographic; seed 852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 200/200 [42:07<00:00, 12.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for linear; seed 852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 200/200 [44:10<00:00, 13.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for 2; seed 963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 200/200 [1:07:28<00:00, 20.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for stereographic; seed 963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 200/200 [1:02:59<00:00, 18.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for linear; seed 963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 200/200 [46:20<00:00, 13.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for 2; seed 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 200/200 [1:06:05<00:00, 19.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for stereographic; seed 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 200/200 [1:02:42<00:00, 18.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for linear; seed 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 200/200 [46:49<00:00, 14.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for 2; seed 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 200/200 [1:07:40<00:00, 20.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for stereographic; seed 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 200/200 [1:02:40<00:00, 18.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Experimenting for linear; seed 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 200/200 [48:13<00:00, 14.47s/it]\n"
     ]
    }
   ],
   "source": [
    "accs_bench = {}\n",
    "SEEDS = [852, 963, 159, 147]\n",
    "for seed in SEEDS:\n",
    "    acc_dict = {}\n",
    "    for key in [2, \"stereographic\", \"linear\"]:\n",
    "        \n",
    "        print(\"_________________________\")\n",
    "        print(f\"Experimenting for {key}; seed {seed}\")\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        net = resnet_cifar.cifar_resnet20(num_classes=10, distance=key).to(device)\n",
    "        net = torch.compile(net)\n",
    "    #     net = torch.compile(net, mode=\"reduce-overhead\")\n",
    "    #     net = torch.compile(net, mode=\"max-autotune\")\n",
    "\n",
    "        model_name = f\"00.3_c10_{str(key)}_s{seed}\"\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=0.1,\n",
    "                              momentum=0.9, weight_decay=5e-4)\n",
    "#         optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "        best_acc = -1\n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "            train(epoch, net, optimizer)\n",
    "            test(epoch, net, model_name)\n",
    "            scheduler.step()\n",
    "        acc_dict[key] = float(best_acc)\n",
    "        accs_bench[seed] = acc_dict\n",
    "        ## Save it in the file.\n",
    "        with open(f\"./outputs/00.3_bench_metrics_c10_res20_c1_run2.json\", \"w\") as f:\n",
    "            json.dump(accs_bench, f, indent=3)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3899c091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{852: {2: 92.76, 'stereographic': 92.55, 'linear': 92.79},\n",
       " 963: {2: 93.06, 'stereographic': 92.58, 'linear': 92.75},\n",
       " 159: {2: 92.82, 'stereographic': 92.71, 'linear': 92.8},\n",
       " 147: {2: 92.7, 'stereographic': 92.49, 'linear': 92.7}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ad9d1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"Results from prev exps\"\\n{\\'stereographic\\': 90.51}\\n{\\'linear\\': 92.77}\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\"Results from prev exps\"\n",
    "{'stereographic': 90.51}\n",
    "{'linear': 92.77}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45c0261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4ec51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
