{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets\n",
    "import random, sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cuda:1\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom CUDA-Pytorch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bmm2x2_cuda\n",
    "import bilinear2x2_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuda -bmm2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMM2x2Function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "#     @torch.jit.ignore\n",
    "    def forward(ctx, inputs, weights):\n",
    "        outputs = bmm2x2_cuda.forward(inputs, weights)\n",
    "        ctx.save_for_backward(inputs, weights)\n",
    "        return outputs[0]\n",
    "    \n",
    "    @staticmethod\n",
    "#     @torch.jit.ignore\n",
    "    def backward(ctx, grad_output):\n",
    "        inputs, weights = ctx.saved_tensors\n",
    "        del_input, del_weights = bmm2x2_cuda.backward(\n",
    "            inputs, \n",
    "            weights, \n",
    "            grad_output)\n",
    "    \n",
    "        return del_input, del_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairLinear(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        assert input_dim%2 == 0, \"Input dim must be even number\"\n",
    "        self.weight = torch.eye(2).unsqueeze(0).repeat_interleave(input_dim//2, dim=0)\n",
    "        self.weight = nn.Parameter(self.weight)\n",
    "        self.bmmfunc = BMM2x2Function()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, dim = x.shape[0], x.shape[1]\n",
    "        x = x.view(bs, -1, 2)\n",
    "        x = BMM2x2Function.apply(x, self.weight)\n",
    "        x = x.view(bs, -1)\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        t = self.weight.shape[0]*2\n",
    "        S = f'PairLinear: [{t} -> {t}]'\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(5, 8).to(device)\n",
    "model = PairLinear(8).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairLinear: [8 -> 8]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8143e-01, -1.7013e+00,  2.7567e-01,  1.2769e+00,  1.1258e-01,\n",
       "          1.5338e+00,  1.2184e+00,  9.1244e-02],\n",
       "        [ 8.8820e-02,  1.4520e-03,  6.8265e-01, -7.1067e-01, -1.7152e-01,\n",
       "          9.6847e-01, -1.6379e+00, -1.1885e+00],\n",
       "        [-3.6610e-01,  2.6684e-01,  8.7538e-01, -6.9132e-01, -8.3439e-01,\n",
       "         -3.5767e-01, -3.8731e-01,  3.3278e+00],\n",
       "        [ 5.8075e-01,  2.8850e-01,  6.6579e-01, -9.0714e-01,  3.4323e-01,\n",
       "         -1.0848e+00, -4.5794e-01,  6.7424e-01],\n",
       "        [ 8.4624e-01, -1.9748e+00,  5.4001e-01,  1.3055e+00,  6.7613e-01,\n",
       "          3.4019e-01, -5.6331e-01, -1.4729e+00]], device='cuda:1',\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(A)\n",
    "y.mean().backward()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0217,  0.0217],\n",
       "         [-0.0780, -0.0780]],\n",
       "\n",
       "        [[ 0.0760,  0.0760],\n",
       "         [ 0.0068,  0.0068]],\n",
       "\n",
       "        [[ 0.0032,  0.0032],\n",
       "         [ 0.0350,  0.0350]],\n",
       "\n",
       "        [[-0.0457, -0.0457],\n",
       "         [ 0.0358,  0.0358]]], device='cuda:1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMM 2x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BMM2x1Function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, weights):\n",
    "        outputs = bmm2x2_cuda.forward_2x1(inputs, weights)\n",
    "        ctx.save_for_backward(inputs, weights)\n",
    "        return outputs[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        inputs, weights = ctx.saved_tensors\n",
    "        del_input, del_weights = bmm2x2_cuda.backward_2x1(\n",
    "            inputs, \n",
    "            weights, \n",
    "            grad_output)\n",
    "    \n",
    "        return del_input, del_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairLinearHalve(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        assert input_dim%2 == 0, \"Input dim must be even number\"\n",
    "        self.weight = torch.Tensor([0.5, 0.5]).unsqueeze(0).repeat_interleave(input_dim//2, dim=0)\n",
    "        self.weight = nn.Parameter(self.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, dim = x.shape[0], x.shape[1]\n",
    "        x = x.view(bs, -1, 2)\n",
    "        x = BMM2x1Function.apply(x, self.weight)\n",
    "        x = x.view(bs, -1)\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        t = self.weight.shape[0]\n",
    "        S = f'PairLinearHalve: [{t*2} -> {t}]'\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(5, 8).to(device)\n",
    "model = PairLinearHalve(8).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairLinearHalve: [8 -> 4]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0042,  0.3912, -0.4051,  0.8895],\n",
       "        [ 0.3113,  0.6497, -0.5928,  0.5920],\n",
       "        [ 0.5781,  0.0147, -0.5225, -1.0799],\n",
       "        [-1.1975, -0.6876,  0.1668,  0.2346],\n",
       "        [-0.3488,  1.3876, -1.4109,  0.1269]], device='cuda:1',\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(A)\n",
    "y.mean().backward()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0894, -0.1547],\n",
       "        [ 0.1048,  0.0708],\n",
       "        [-0.2432, -0.0332],\n",
       "        [ 0.0159,  0.0604]], device='cuda:1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuda - Bilinear2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLinear2x2Function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, weights):\n",
    "        outputs = bilinear2x2_cuda.forward(inputs, weights)\n",
    "        ctx.save_for_backward(inputs, weights)\n",
    "        return outputs[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        inputs, weights = ctx.saved_tensors\n",
    "        del_input, del_weights = bilinear2x2_cuda.backward(\n",
    "            inputs, \n",
    "            weights, \n",
    "            grad_output)\n",
    "    \n",
    "        return del_input, del_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairBilinear(nn.Module):\n",
    "    def __init__(self, dim, grid_width):\n",
    "        super().__init__()\n",
    "        num_pairs = dim // 2\n",
    "        along_row = torch.linspace(0, 1, grid_width).reshape(1, -1).t()\n",
    "        along_col = torch.linspace(0, 1, grid_width).reshape(-1, 1).t()\n",
    "        \n",
    "        self.pairW = torch.eye(2).unsqueeze(0).repeat_interleave(num_pairs, dim=0)\n",
    "        self.pairW = nn.Parameter(self.pairW)\n",
    "    \n",
    "        self.Y = torch.stack([along_row+along_col*0, along_row*0+along_col])\n",
    "        self.Y = torch.repeat_interleave(self.Y.unsqueeze(0), num_pairs, dim=0)\n",
    "        self.Y = nn.Parameter(self.Y)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        x = x.view(bs, -1, 2)\n",
    "#         x = BMM2x2Function.apply(x, self.pairW)\n",
    "        ####################################################\n",
    "        x = BiLinear2x2Function.apply(x, self.Y)\n",
    "        x = x.view(bs, -1)\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        t = self.pairW.shape[0]*2\n",
    "        u = self.Y.shape[2]\n",
    "        S = f'PairLinear: [{t} -> {t}] (grid: {u})'\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(5, 8).to(device)\n",
    "model = PairBilinear(8, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairLinear: [8 -> 8] (grid: 3)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.6319, -0.9008,  2.0708, -0.5420,  1.2779, -1.0038, -1.0385, -0.6684],\n",
       "        [ 0.7059, -0.2526, -0.5484, -0.9034,  0.3111, -0.6670,  0.5793, -0.8889],\n",
       "        [-0.2838,  0.3112, -0.0567, -1.2892,  1.4162,  0.8061,  1.0327,  0.3577],\n",
       "        [-1.8556, -1.5621, -0.2080,  0.2869,  0.2638, -0.6998, -0.6630, -0.6716],\n",
       "        [-2.0038, -0.5239, -0.0471,  2.1041, -0.3635, -0.3394, -1.5490, -0.2572]],\n",
       "       device='cuda:1', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(A)\n",
    "y.mean().backward()\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.7569, -0.4747,  0.0000],\n",
       "          [-0.7996,  0.5256,  0.0000],\n",
       "          [ 0.3141, -0.1972,  0.0000]],\n",
       "\n",
       "         [[ 0.7569, -0.4747,  0.0000],\n",
       "          [-0.7996,  0.5256,  0.0000],\n",
       "          [ 0.3141, -0.1972,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2618, -0.2066,  0.0878],\n",
       "          [-0.2031,  0.1141, -0.0075],\n",
       "          [ 0.1637, -0.0851,  0.0000]],\n",
       "\n",
       "         [[ 0.2618, -0.2066,  0.0878],\n",
       "          [-0.2031,  0.1141, -0.0075],\n",
       "          [ 0.1637, -0.0851,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1229, -0.0584,  0.0000],\n",
       "          [-0.0044, -0.0070, -0.0127],\n",
       "          [ 0.1170, -0.0603,  0.0280]],\n",
       "\n",
       "         [[ 0.1229, -0.0584,  0.0000],\n",
       "          [-0.0044, -0.0070, -0.0127],\n",
       "          [ 0.1170, -0.0603,  0.0280]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4712, -0.2336,  0.0000],\n",
       "          [-0.2583,  0.1152,  0.0000],\n",
       "          [ 0.0186,  0.0120,  0.0000]],\n",
       "\n",
       "         [[ 0.4712, -0.2336,  0.0000],\n",
       "          [-0.2583,  0.1152,  0.0000],\n",
       "          [ 0.0186,  0.0120,  0.0000]]]], device='cuda:1')"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda - Bilinear2x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLinear2x1Function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, weights):\n",
    "        outputs = bilinear2x2_cuda.forward_2x1(inputs, weights)\n",
    "        ctx.save_for_backward(inputs, weights)\n",
    "        return outputs[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        inputs, weights = ctx.saved_tensors\n",
    "        del_input, del_weights = bilinear2x2_cuda.backward_2x1(\n",
    "            inputs, \n",
    "            weights, \n",
    "            grad_output)\n",
    "    \n",
    "        return del_input, del_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairBilinearHalve(nn.Module):\n",
    "    def __init__(self, dim, grid_width):\n",
    "        super().__init__()\n",
    "        num_pairs = dim // 2\n",
    "        \n",
    "        self.pairW = torch.eye(2).unsqueeze(0).repeat_interleave(num_pairs, dim=0)\n",
    "        self.pairW = nn.Parameter(self.pairW)\n",
    "\n",
    "        along_row = torch.linspace(0, 1, grid_width).reshape(1, -1).t()\n",
    "        along_col = torch.linspace(0, 1, grid_width).reshape(-1, 1).t()\n",
    "        \n",
    "        self.Y = torch.stack([along_row+along_col*0, along_row*0+along_col]).mean(dim=0)\n",
    "        self.Y = torch.repeat_interleave(self.Y.unsqueeze(0), num_pairs, dim=0)\n",
    "        self.Y = nn.Parameter(self.Y)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        x = x.view(bs, -1, 2)\n",
    "#         x = BMM2x2Function.apply(x, self.pairW)\n",
    "        ####################################################\n",
    "        x = BiLinear2x1Function.apply(x, self.Y)\n",
    "        x = x.view(bs, -1)\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        t = self.pairW.shape[0]\n",
    "        u = self.Y.shape[2]\n",
    "        S = f'PairLinear: [{t*2} -> {t}] (grid: {u})'\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(5, 8).to(device)\n",
    "model = PairBilinearHalve(8, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairLinear: [8 -> 4] (grid: 3)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5034,  0.5507,  0.2926, -0.2328],\n",
       "        [-0.1249, -0.7540, -0.0688, -0.3511],\n",
       "        [-0.7080, -0.8221, -0.8722, -0.8480],\n",
       "        [ 0.0894, -0.0411, -0.7886,  0.7815],\n",
       "        [-0.7506, -0.8115, -0.1640, -0.9617]], device='cuda:1',\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(A)\n",
    "y.mean().backward()\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8354, -0.4413,  0.0000],\n",
       "         [-0.3300,  0.1859,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.7969, -0.4051,  0.0000],\n",
       "         [-1.0159,  0.6316,  0.0000],\n",
       "         [ 0.9452, -0.7027,  0.0000]],\n",
       "\n",
       "        [[ 0.5055,  0.0808,  0.0000],\n",
       "         [-0.2938, -0.0803,  0.0000],\n",
       "         [ 0.0602, -0.0223,  0.0000]],\n",
       "\n",
       "        [[ 0.6779, -0.4217,  0.0000],\n",
       "         [-0.0930,  0.0293,  0.0080],\n",
       "         [ 0.0542, -0.0201,  0.0154]]], device='cuda:1')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules and Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasLayer(nn.Module):\n",
    "    def __init__(self, dim, init_val=0):\n",
    "        super().__init__()\n",
    "        self.bias = nn.Parameter(torch.ones(dim)*init_val)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x+self.bias\n",
    "    \n",
    "    def __repr__(self):\n",
    "        S = f'BiasLayer: [{self.bias.shape[0]}]'\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimensionSelector(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        assert output_dim > input_dim, \"Slection does not select all inputs\"\n",
    "        remain = output_dim-input_dim\n",
    "        \n",
    "        scale = int(np.ceil(output_dim/input_dim)-1)\n",
    "#         self.indices = torch.randperm(input_dim*scale)[:remain]%input_dim\n",
    "\n",
    "        self.indices = torch.LongTensor([])\n",
    "        for i in range(scale):\n",
    "            c = min(input_dim, remain-len(self.indices))\n",
    "            t = torch.randperm(input_dim)[:c]\n",
    "            self.indices = torch.cat([self.indices, t])\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## x.shape = [batch_size, input_dim]\n",
    "        return torch.cat([x, x[:, self.indices]], dim=1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        S = f'DimensionSelector: [+={self.indices.shape[0]}]'\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DimensionSelector(8, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7]), tensor([3, 3, 3, 3, 3, 3, 3, 3]))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.indices.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 3, 5, 1, 6, 7, 2, 3, 2, 4, 0, 5, 1, 7, 6, 4, 1, 6, 5, 7, 3, 0, 2])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairBilinear_MixerBlock(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    Handle any input - output size;\n",
    "    \n",
    "    Operations -> Select, NxN mix, Halve\n",
    "    \n",
    "    -Edge cases:\n",
    "    1) 8-8 -> NxN mixing for log(N) times\n",
    "    2) 8-10 -> Select(16) + 16x16 + Select(20) + Halve\n",
    "    3) 8-6 -> 8x8 + Select(12) + Halve\n",
    "    4) 8-32 -> Select(32) + 32x32\n",
    "    5) 8-3 -> 8x8 + Halve + 4-Select(6) + Halve\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, grid_width, bias=True):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.grid_width = grid_width\n",
    "        \n",
    "        self.selector = None\n",
    "        self.pairwise_mixing = []\n",
    "        self.reducer = []\n",
    "        \n",
    "        mix_dim = 2**int(np.ceil(np.log2(max(input_dim, output_dim))))\n",
    "        \n",
    "        #########################################################\n",
    "        ### Find out if first selection is required or Not !\n",
    "        if self.input_dim != mix_dim:\n",
    "            ## Input dimension is not power of 2; requires selector to project to mixing dimension\n",
    "            L = DimensionSelector(input_dim, mix_dim)\n",
    "            self.selector = L\n",
    "            if bias:\n",
    "                self.selector = nn.Sequential(L, BiasLayer(mix_dim, 0.5))\n",
    "        else:\n",
    "            self.selector = nn.Identity()\n",
    "            if bias:\n",
    "                self.selector = BiasLayer(mix_dim, 0.5)\n",
    "        \n",
    "        ### Now perform NxN mixing \n",
    "        num_layers = int(np.ceil(np.log2(mix_dim)))\n",
    "        for i in range(num_layers):\n",
    "            net = PairBilinear(mix_dim, grid_width)\n",
    "            self.pairwise_mixing.append(net)\n",
    "        self.pairwise_mixing = nn.ModuleList(self.pairwise_mixing)\n",
    "        \n",
    "        ### Now for reducer if any\n",
    "        num_halve = int(np.ceil(np.log2(mix_dim/output_dim)))\n",
    "        final_expand = output_dim*(2**num_halve)\n",
    "        if final_expand != mix_dim:\n",
    "            L = DimensionSelector(mix_dim, final_expand)\n",
    "            self.reducer.append(L)\n",
    "        for i in range(num_halve):\n",
    "#             L = PairBilinearHalve(final_expand//(2**i), grid_width)\n",
    "            L = PairLinearHalve(final_expand//(2**i))\n",
    "            self.reducer.append(L)\n",
    "            \n",
    "        if len(self.reducer) == 0:\n",
    "            self.reducer = nn.Identity()\n",
    "        else:\n",
    "            self.reducer = nn.Sequential(*self.reducer)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: shape-> [batch_size, input_dim]\n",
    "        '''\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        x = self.selector(x)\n",
    "        \n",
    "        y = x\n",
    "        for i, fn in enumerate(self.pairwise_mixing):\n",
    "            y = y.view(-1,2,2**i).permute(0, 2,1).contiguous().view(bs, -1)\n",
    "            y = fn(y)\n",
    "            y = y.view(-1,2**i,2).permute(0, 2,1).contiguous()\n",
    "\n",
    "        y = y.view(bs, -1)\n",
    "        y = x + y ## this is residual addition... remove if only want feed forward\n",
    "        y = self.reducer(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "pblm = PairBilinear_MixerBlock(16, 12, grid_width=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairBilinear_MixerBlock(\n",
       "  (selector): BiasLayer: [16]\n",
       "  (pairwise_mixing): ModuleList(\n",
       "    (0): PairLinear: [16 -> 16] (grid: 3)\n",
       "    (1): PairLinear: [16 -> 16] (grid: 3)\n",
       "    (2): PairLinear: [16 -> 16] (grid: 3)\n",
       "    (3): PairLinear: [16 -> 16] (grid: 3)\n",
       "  )\n",
       "  (reducer): Sequential(\n",
       "    (0): DimensionSelector: [+=8]\n",
       "    (1): PairLinearHalve: [24 -> 12]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pblm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7938,  3.2138,  2.3757,  0.8527,  1.9313,  1.9148, -0.2545,  1.1918,\n",
       "          1.6951,  1.9313,  4.1814,  1.5474],\n",
       "        [ 0.3515,  0.4075,  0.0384,  3.4861,  0.1212,  3.7080,  1.4738,  0.4823,\n",
       "          2.6307,  0.1212,  1.0725, -0.1545],\n",
       "        [-1.2820,  4.1760, -0.3801,  0.4690,  2.0405,  1.9404, -0.3773, -0.6107,\n",
       "          2.2265,  2.0405,  2.0836,  0.0365]], device='cuda:1',\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pblm(torch.randn(3, 16).to(device))\n",
    "y.mean().backward()\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.la0 = PairBilinear(784, 50)\n",
    "        self.la1 = PairBilinear_MixerBlock(784, 512, grid_width=10)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "#         self.bn1 = nn.LayerNorm(512)\n",
    "#         self.la2 = PairBilinear_MixerBlock(512, 10, grid_width=50)\n",
    "        self.la2 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.la0(x)\n",
    "        x = self.la1(x)\n",
    "        x = self.bn1(x)\n",
    "#         x = torch.relu(x)\n",
    "        x = self.la2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinaryNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.la1 = nn.Linear(784, 200, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(200)\n",
    "        self.la2 = nn.Linear(200, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.la1(x))\n",
    "        x = torch.relu(x)\n",
    "        x = self.la2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3014250"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FactorNet()\n",
    "param_count = sum([torch.numel(p) for p in model.parameters()])\n",
    "param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159210, 0.05281910923115203)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OrdinaryNet()\n",
    "param_count1 = sum([torch.numel(p) for p in model.parameters()])\n",
    "param_count1, param_count1/param_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "BS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BS, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BS, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 28, 28])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## demo of train loader\n",
    "xx, yy = iter(train_loader).next()\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorNet(\n",
       "  (la0): PairLinear: [784 -> 784] (grid: 50)\n",
       "  (la1): PairBilinear_MixerBlock(\n",
       "    (selector): Sequential(\n",
       "      (0): DimensionSelector: [+=240]\n",
       "      (1): BiasLayer: [1024]\n",
       "    )\n",
       "    (pairwise_mixing): ModuleList(\n",
       "      (0): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (1): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (2): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (3): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (4): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (5): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (6): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (7): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (8): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (9): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "    )\n",
       "    (reducer): Sequential(\n",
       "      (0): PairLinearHalve: [1024 -> 512]\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (la2): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = FactorNet().to(device)\n",
    "# model = OrdinaryNet().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 92.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0,  Loss:0.43971577286720276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 354.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:80.55%, Test Acc:84.55%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 93.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1,  Loss:0.31764519214630127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 331.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:86.80%, Test Acc:85.78%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 93.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2,  Loss:0.348450243473053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 380.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:88.95%, Test Acc:86.62%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 92.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3,  Loss:0.15511386096477509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 339.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:90.67%, Test Acc:87.30%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 92.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4,  Loss:0.37110352516174316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 371.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.05%, Test Acc:87.15%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 93.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5,  Loss:0.13232402503490448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 349.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.28%, Test Acc:87.16%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:13<00:00, 92.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6,  Loss:0.24082571268081665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 371.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.41%, Test Acc:86.97%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 93.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7,  Loss:0.1541043221950531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 341.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.03%, Test Acc:87.34%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 92.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8,  Loss:0.16107267141342163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 362.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.89%, Test Acc:87.21%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 93.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9,  Loss:0.07172103971242905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 366.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:96.58%, Test Acc:87.28%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 92.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10,  Loss:0.09318865835666656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 354.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:97.03%, Test Acc:86.68%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 93.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11,  Loss:0.15648604929447174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 376.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:97.17%, Test Acc:86.91%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 93.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12,  Loss:0.017733529210090637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 346.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:97.30%, Test Acc:86.68%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 92.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13,  Loss:0.13603618741035461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 356.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:96.89%, Test Acc:86.49%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 92.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14,  Loss:0.1014559343457222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 353.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:97.72%, Test Acc:86.94%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 92.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15,  Loss:0.0994148924946785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 375.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:98.08%, Test Acc:86.56%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 92.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16,  Loss:0.29445207118988037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 347.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:98.18%, Test Acc:86.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 92.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17,  Loss:0.11577855050563812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 374.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:98.18%, Test Acc:86.69%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 92.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18,  Loss:0.050337500870227814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 343.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:98.62%, Test Acc:86.65%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:12<00:00, 93.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19,  Loss:0.016569487750530243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 375.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:98.68%, Test Acc:86.65%\n",
      "\n",
      "\t-> Train Acc 98.68166666666667 ; Test Acc 87.33999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "    i = -1\n",
    "    for xx, yy in tqdm(train_loader):\n",
    "        i += 1 \n",
    "        xx = xx.view(xx.shape[0], -1)\n",
    "        xx, yy = xx.to(device), yy.to(device)\n",
    "\n",
    "        yout = model(xx)\n",
    "        loss = criterion(yout, yy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(float(loss))\n",
    "\n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        train_acc += correct\n",
    "        train_count += len(outputs)\n",
    "        \n",
    "        if torch.any(torch.isnan(yout.data)):\n",
    "            print(f\"NAN values found\")\n",
    "        \n",
    "\n",
    "    train_accs.append(float(train_acc)/train_count*100)\n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "\n",
    "    print(f'Epoch: {epoch},  Loss:{float(loss)}')\n",
    "    test_count = 0\n",
    "    test_acc = 0\n",
    "    for xx, yy in tqdm(test_loader):\n",
    "        xx = xx.view(xx.shape[0], -1)\n",
    "        xx, yy = xx.to(device), yy.to(device)\n",
    "        with torch.no_grad():\n",
    "            yout = model(xx)\n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        test_acc += correct\n",
    "        test_count += len(xx)\n",
    "    test_accs.append(float(test_acc)/test_count*100)\n",
    "    print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "    print()\n",
    "\n",
    "### after each class index is finished training\n",
    "print(f'\\t-> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:1',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
