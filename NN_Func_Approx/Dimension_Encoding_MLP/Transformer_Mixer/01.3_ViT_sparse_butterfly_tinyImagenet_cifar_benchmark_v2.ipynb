{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6287145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os, sys, pathlib, random, time, pickle, copy, json\n",
    "# from tqdm.autonotebook import tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075be09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb5227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0173cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcaa3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_lib import TransformerBlock, \\\n",
    "        Mixer_TransformerBlock_Encoder, \\\n",
    "        PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ae2ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyImageNet_Preload(data.Dataset):\n",
    "#     https://gist.github.com/z-a-f/b862013c0dc2b540cf96a123a6766e54\n",
    "    \n",
    "    def __init__(self, root, mode='train', transform=None, preload=False):\n",
    "        super().__init__()\n",
    "        self.preload = preload\n",
    "        dataset = datasets.ImageFolder(\n",
    "            root=os.path.join(root, mode),\n",
    "            transform=None\n",
    "        )\n",
    "        self.transform = transform\n",
    "        self.images, self.labels = [], []\n",
    "        print(\"Dataset Size:\",len(dataset))\n",
    "        \n",
    "        if preload:\n",
    "            for i in tqdm(range(len(dataset))):\n",
    "                x, y = dataset[i]\n",
    "                self.images.append(x)\n",
    "                self.labels.append(y)\n",
    "                \n",
    "#         del dataset\n",
    "        self.dataset = dataset\n",
    "            \n",
    "    def _add_channels(img, total_channels=3):\n",
    "        while len(img.shape) < 3:  # third axis is the channels\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "        while(img.shape[-1]) < 3:\n",
    "            img = np.concatenate([img, img[:, :, -1:]], axis=-1)\n",
    "        return img\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.preload:\n",
    "            img, lbl = self.images[idx], self.labels[idx]\n",
    "        else:\n",
    "            img, lbl = self.dataset[idx]\n",
    "        return self.transform(img), lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2e11b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b45f6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixer_ViT_Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_dim:tuple, patch_size:tuple, hidden_channel:int, num_blocks:int, num_classes:int, block_seq_size:int, block_mlp_size:int, forward_expansion:float=2.0, pos_emb=True, dropout:float=0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_dim = image_dim ### must contain (C, H, W) or (H, W)\n",
    "        \n",
    "        ### find patch dim\n",
    "        d0 = int(image_dim[-2]/patch_size[0])\n",
    "        d1 = int(image_dim[-1]/patch_size[1])\n",
    "        assert d0*patch_size[0]==image_dim[-2], \"Image must be divisible into patch size\"\n",
    "        assert d1*patch_size[1]==image_dim[-1], \"Image must be divisible into patch size\"\n",
    "        \n",
    "#         self.d0, self.d1 = d0, d1 ### number of patches in each axis\n",
    "        __patch_size = patch_size[0]*patch_size[1]*image_dim[0] ## number of channels in each patch\n",
    "    \n",
    "        ### find channel dim\n",
    "        channel_size = d0*d1 ## number of patches\n",
    "        \n",
    "        ### after the number of channels are changed\n",
    "        init_dim = __patch_size\n",
    "        final_dim = hidden_channel\n",
    "        self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "        #### rescale the patches (patch wise image non preserving transform, unlike bilinear interpolation)\n",
    "        self.channel_change = nn.Linear(init_dim, final_dim)\n",
    "        print(f\"ViT Mixer : Channels per patch -> Initial:{init_dim} Final:{final_dim}\")\n",
    "        \n",
    "        \n",
    "        self.channel_dim = final_dim\n",
    "        self.patch_dim = channel_size\n",
    "        \n",
    "        self.transformer_blocks = []\n",
    "        \n",
    "        f = self.get_factors(self.channel_dim)\n",
    "        print(f)\n",
    "        fi = np.abs(np.array(f) - np.sqrt(self.channel_dim)).argmin()\n",
    "        \n",
    "        _n_heads = f[fi]\n",
    "        \n",
    "        ## number of dims per channel -> channel_dim\n",
    "#         print('Num patches:', self.patch_dim)\n",
    "        print(f'Sequence len: {self.patch_dim} ; Block size: {block_seq_size}')\n",
    "        print('Channel dim:', self.channel_dim, 'num heads:',_n_heads)\n",
    "        \n",
    "        if block_seq_size is None or block_seq_size<2:\n",
    "            ### Find the block size for sequence:\n",
    "            block_seq_size = int(2**np.ceil(np.log2(np.sqrt(self.patch_dim))))\n",
    "            \n",
    "        print(f'MLP dim: {self.channel_dim} ; Block size: {block_mlp_size}')\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            L = Mixer_TransformerBlock_Encoder(self.patch_dim, block_seq_size, self.channel_dim, _n_heads, dropout, forward_expansion, nn.GELU, block_mlp_size)\n",
    "            self.transformer_blocks.append(L)\n",
    "        self.transformer_blocks = nn.Sequential(*self.transformer_blocks)\n",
    "        \n",
    "        self.linear = nn.Linear(self.patch_dim*self.channel_dim, num_classes)\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(self.channel_dim, dropout=0)\n",
    "        if not pos_emb:\n",
    "            self.positional_encoding = nn.Identity()\n",
    "        \n",
    "        \n",
    "    def get_factors(self, n):\n",
    "        facts = []\n",
    "        for i in range(2, n+1):\n",
    "            if n%i == 0:\n",
    "                facts.append(i)\n",
    "        return facts\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = self.unfold(x).swapaxes(-1, -2)\n",
    "        x = self.channel_change(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.linear(x.view(bs, -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d3e403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_skip(model_name, ep):\n",
    "    \n",
    "    filename = f\"./output/benchmark/{model_name}_data.json\"\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename) as f:\n",
    "            data = json.load(f)\n",
    "        ## data consists of lists and dicts.\n",
    "        epochs = data['train_stat'][-1][0]\n",
    "        if epochs == ep-1:\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b05ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(dataset:str, patch_size:int, num_layers:int, SEED:int, sparse_att:bool=False, sparse_mlp:bool=False, pos_emb:bool=False, cuda:int=0):\n",
    "    device = torch.device(f\"cuda:{cuda}\")\n",
    "    \n",
    "    if sparse_att:\n",
    "        assert num_layers%2 == 0, 'number of blocks on sparse transformer is (x2)/2 hence it must be even'\n",
    "        num_layers_ = num_layers//2\n",
    "    else:\n",
    "        num_layers_ = num_layers\n",
    "    \n",
    "    BS = 256\n",
    "    NC = -1\n",
    "    EPOCHS = 300\n",
    "    imsize = (3, 32, 32)\n",
    "    expansion_dict = {16:1024, 8:256, 4:128, 2:64, 1:64}\n",
    "    expansion = expansion_dict[patch_size]\n",
    "\n",
    "    \n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    ##### Data Transforms\n",
    "    if dataset == 'tiny':\n",
    "        NC = 200\n",
    "        EPOCHS = 400\n",
    "        imsize = (3, 64, 64)\n",
    "        tiny_train = transforms.Compose([\n",
    "        transforms.RandAugment(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.5]*3,\n",
    "            std=[0.2]*3,\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "        tiny_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.5]*3,\n",
    "                std=[0.2]*3,\n",
    "            ),\n",
    "        ])\n",
    "        \n",
    "        train_dataset = TinyImageNet_Preload(root=\"../../../../../_Datasets/tiny-imagenet-200\",\n",
    "                                     mode='train', transform=tiny_train)\n",
    "        test_dataset = TinyImageNet_Preload(root=\"../../../../../_Datasets/tiny-imagenet-200\",\n",
    "                                     mode='val', transform=tiny_test)\n",
    "        \n",
    "    elif dataset == 'cifar10':\n",
    "        NC = 10\n",
    "        BS = 128\n",
    "        cifar_train = transforms.Compose([\n",
    "            transforms.RandomCrop(size=32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "                std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "        cifar_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "                std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "        train_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=True, download=True, transform=cifar_train)\n",
    "        test_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=False, download=True, transform=cifar_test)\n",
    "\n",
    "    elif dataset == 'cifar100':\n",
    "        NC = 100\n",
    "        BS = 128\n",
    "        cifar_train = transforms.Compose([\n",
    "            transforms.RandomCrop(size=32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.5071, 0.4865, 0.4409],\n",
    "                std=[0.2009, 0.1984, 0.2023],\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "        cifar_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.5071, 0.4865, 0.4409],\n",
    "                std=[0.2009, 0.1984, 0.2023],\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "        train_dataset = datasets.CIFAR100(root=\"../../../../../_Datasets/cifar100/\", train=True, download=True, transform=cifar_train)\n",
    "        test_dataset = datasets.CIFAR100(root=\"../../../../../_Datasets/cifar100/\", train=False, download=True, transform=cifar_test)\n",
    "        \n",
    "    ##### Now create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BS, shuffle=True, num_workers=4)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BS, shuffle=False, num_workers=4)\n",
    "    \n",
    "    ### Now create models\n",
    "    \n",
    "    seq_len = (imsize[-1]*imsize[-2])//(patch_size*patch_size)\n",
    "    mlp_dim = expansion\n",
    "    print(seq_len, mlp_dim)\n",
    "    \n",
    "    if sparse_att:\n",
    "        seq_len = int(2**np.ceil(np.log2(np.sqrt(seq_len))))\n",
    "    if sparse_mlp:\n",
    "        mlp_dim = int(2**np.ceil(np.log2(np.sqrt(expansion))))\n",
    "    \n",
    "    \n",
    "    torch.manual_seed(SEED)\n",
    "    model = Mixer_ViT_Classifier(imsize, \n",
    "                                 patch_size=[patch_size]*2, \n",
    "                                 hidden_channel=expansion, \n",
    "                                 num_blocks=num_layers_, \n",
    "                                 num_classes=NC, \n",
    "                                 block_seq_size=seq_len, \n",
    "                                 block_mlp_size=mlp_dim,\n",
    "                                 pos_emb=pos_emb).to(device)\n",
    "    \n",
    "#     _x = torch.randn(BS, *imsize).to(device)\n",
    "#     print(\"Output: \",vit_mixer(_x).shape)\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"number of params: \", num_params)\n",
    "    \n",
    "    _a, _b, _c = 'att', 'mlp', 'nPE'\n",
    "    if sparse_att: _a = 'sAtt'\n",
    "    if sparse_mlp: _b = 'sMlp'\n",
    "    if pos_emb: _c = 'PE'\n",
    "    model_name = f'01.3_ViT_{_c}_{dataset}_patch{patch_size}_l{num_layers}_{_a}_{_b}_s{SEED}'\n",
    "    print(f\"Model Name: {model_name}\")\n",
    "    \n",
    "    if experiment_skip(model_name, EPOCHS):\n",
    "        print(f'EXPERIMENT DONE... SKIPPING : {model_name}')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    STAT ={'train_stat':[], 'test_stat':[], 'params':num_params, }\n",
    "\n",
    "    ## Following is copied from \n",
    "    ### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "    # Training\n",
    "    def train(epoch):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "#             break\n",
    "\n",
    "        STAT['train_stat'].append((epoch, train_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "        print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "        return\n",
    "\n",
    "    global best_acc\n",
    "    best_acc = -1\n",
    "    def test(epoch):\n",
    "        global best_acc\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        time_taken = []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                start = time.time()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                start = time.time()-start\n",
    "                time_taken.append(start)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        STAT['test_stat'].append((epoch, test_loss/(batch_idx+1), 100.*correct/total, np.mean(time_taken))) ### (Epochs, Loss, Acc, time)\n",
    "        print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "\n",
    "        # Save checkpoint.\n",
    "        acc = 100.*correct/total\n",
    "        if acc > best_acc:\n",
    "            print('Saving..')\n",
    "            state = {\n",
    "                'model': model.state_dict(),\n",
    "                'acc': acc,\n",
    "                'epoch': epoch\n",
    "            }\n",
    "            if not os.path.isdir('models'):\n",
    "                os.mkdir('models')\n",
    "            torch.save(state, f'./models/benchmark/{model_name}.pth')\n",
    "            best_acc = acc\n",
    "\n",
    "        with open(f\"./output/benchmark/{model_name}_data.json\", 'w') as f:\n",
    "            json.dump(STAT, f, indent=0)\n",
    "\n",
    "    ### Train the whole damn thing\n",
    "#     EPOCHS = 1\n",
    "    for epoch in range(0, EPOCHS):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "        scheduler.step()\n",
    "        \n",
    "    \n",
    "    train_stat = np.array(STAT['train_stat'])\n",
    "    test_stat = np.array(STAT['test_stat'])\n",
    "\n",
    "    plt.plot(train_stat[:,1], label='train')\n",
    "    plt.plot(test_stat[:,1], label='test')\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"./output/benchmark/plots/{model_name}_loss.svg\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(train_stat[:,2], label='train')\n",
    "    plt.plot(test_stat[:,2], label='test')\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"./output/benchmark/plots/{model_name}_accs.svg\")\n",
    "    plt.show()\n",
    "    \n",
    "    del model, optimizer\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88a2ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark(dataset='tiny', \n",
    "#           patch_size=4, num_layers=10, SEED=123, sparse_att=True, sparse_mlp=True, cuda=0\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "176808bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Automate the benchmark\n",
    "# ###### for tiny\n",
    "# cuda_idx = 0\n",
    "# # for seed in [147, 258, 369]:\n",
    "# for seed in [147]:\n",
    "#     for patch_size in [16, 8, 4]:\n",
    "#         for sparse_attention in [False, True]:\n",
    "#             for sparse_mlp in [False, True]:\n",
    "# #                 for nlayers in [6, 10, 14]:\n",
    "#                 for nlayers in [6]:\n",
    "#                     print(f'''\n",
    "#                         Experimenting on Tiny Dataset \n",
    "#                         patch:{patch_size},\n",
    "#                         sparse_att: {sparse_attention},\n",
    "#                         sparse_mlp: {sparse_mlp},\n",
    "#                         num_layers : {nlayers},\n",
    "#                         seed: {seed}\n",
    "#                     ''')\n",
    "            \n",
    "#                     benchmark(dataset='tiny', \n",
    "#                               patch_size=patch_size, \n",
    "#                               num_layers=nlayers, \n",
    "#                               SEED=seed, \n",
    "#                               sparse_att=sparse_attention, sparse_mlp=sparse_mlp, \n",
    "#                               cuda=cuda_idx\n",
    "#                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5773c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Automate the benchmark\n",
    "# ###### for tiny\n",
    "\n",
    "# not_working = [\n",
    "#     (4, False, True, 6),\n",
    "#     (4, False, False, 10),\n",
    "#     (4, False, False, 14),\n",
    "#     (4, False, True, 10),\n",
    "#     (4, False, True, 14),\n",
    "#     (4, True, True, 14),\n",
    "# ]\n",
    "\n",
    "# cuda_idx = 0\n",
    "# # for seed in [147, 258, 369]:\n",
    "# for seed in [147]:\n",
    "#     for patch_size in [16, 8, 4]:\n",
    "#         for sparse_attention in [False, True]:\n",
    "#             for sparse_mlp in [False, True]:\n",
    "#                 for nlayers in [6, 10, 14]:\n",
    "\n",
    "#                     print(f'''\n",
    "#                         Experimenting on Tiny Dataset \n",
    "#                         patch:{patch_size},\n",
    "#                         sparse_att: {sparse_attention},\n",
    "#                         sparse_mlp: {sparse_mlp},\n",
    "#                         num_layers : {nlayers},\n",
    "#                         seed: {seed}\n",
    "#                     ''')\n",
    "            \n",
    "#                 ### check if config is in not_working case\n",
    "#                     exit = False\n",
    "#                     for nw in not_working:\n",
    "#                         if patch_size==nw[0] and \\\n",
    "#                             sparse_attention==nw[1] and \\\n",
    "#                             sparse_mlp==nw[2] and\\\n",
    "#                             nlayers==nw[3]:\n",
    "                            \n",
    "#                             exit=True\n",
    "#                             break\n",
    "#                     if exit:\n",
    "#                         print(f'Exiting as the config is in NOT WORKING')\n",
    "#                         continue\n",
    "\n",
    "\n",
    "#                     benchmark(dataset='tiny', \n",
    "#                               patch_size=patch_size, \n",
    "#                               num_layers=nlayers, \n",
    "#                               SEED=seed, \n",
    "#                               sparse_att=sparse_attention, sparse_mlp=sparse_mlp, \n",
    "#                               cuda=cuda_idx\n",
    "#                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8645f1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                Experimenting on cifar100 Dataset \n",
      "                                patch:4,\n",
      "                                sparse_att: False,\n",
      "                                sparse_mlp: False,\n",
      "                                num_layers: 4,\n",
      "                                pos_embed: False,\n",
      "                                seed: 147\n",
      "                            \n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "64 128\n",
      "ViT Mixer : Channels per patch -> Initial:48 Final:128\n",
      "[2, 4, 8, 16, 32, 64, 128]\n",
      "Sequence len: 64 ; Block size: 64\n",
      "Channel dim: 128 num heads: 8\n",
      "MLP dim: 128 ; Block size: 128\n",
      "number of params:  1355492\n",
      "Model Name: 01.3_ViT_nPE_cifar100_patch4_l4_att_mlp_s147\n",
      "EXPERIMENT DONE... SKIPPING : 01.3_ViT_nPE_cifar100_patch4_l4_att_mlp_s147\n",
      "\n",
      "                                Experimenting on cifar100 Dataset \n",
      "                                patch:4,\n",
      "                                sparse_att: True,\n",
      "                                sparse_mlp: False,\n",
      "                                num_layers: 4,\n",
      "                                pos_embed: False,\n",
      "                                seed: 147\n",
      "                            \n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "64 128\n",
      "ViT Mixer : Channels per patch -> Initial:48 Final:128\n",
      "[2, 4, 8, 16, 32, 64, 128]\n",
      "Sequence len: 64 ; Block size: 8\n",
      "Channel dim: 128 num heads: 8\n",
      "MLP dim: 128 ; Block size: 128\n",
      "number of params:  1355492\n",
      "Model Name: 01.3_ViT_nPE_cifar100_patch4_l4_sAtt_mlp_s147\n",
      "EXPERIMENT DONE... SKIPPING : 01.3_ViT_nPE_cifar100_patch4_l4_sAtt_mlp_s147\n",
      "\n",
      "                                Experimenting on cifar100 Dataset \n",
      "                                patch:2,\n",
      "                                sparse_att: False,\n",
      "                                sparse_mlp: False,\n",
      "                                num_layers: 4,\n",
      "                                pos_embed: False,\n",
      "                                seed: 147\n",
      "                            \n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "256 64\n",
      "ViT Mixer : Channels per patch -> Initial:12 Final:64\n",
      "[2, 4, 8, 16, 32, 64]\n",
      "Sequence len: 256 ; Block size: 256\n",
      "Channel dim: 64 num heads: 8\n",
      "MLP dim: 64 ; Block size: 64\n",
      "number of params:  1773220\n",
      "Model Name: 01.3_ViT_nPE_cifar100_patch2_l4_att_mlp_s147\n",
      "EXPERIMENT DONE... SKIPPING : 01.3_ViT_nPE_cifar100_patch2_l4_att_mlp_s147\n",
      "\n",
      "                                Experimenting on cifar100 Dataset \n",
      "                                patch:2,\n",
      "                                sparse_att: True,\n",
      "                                sparse_mlp: False,\n",
      "                                num_layers: 4,\n",
      "                                pos_embed: False,\n",
      "                                seed: 147\n",
      "                            \n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "256 64\n",
      "ViT Mixer : Channels per patch -> Initial:12 Final:64\n",
      "[2, 4, 8, 16, 32, 64]\n",
      "Sequence len: 256 ; Block size: 16\n",
      "Channel dim: 64 num heads: 8\n",
      "MLP dim: 64 ; Block size: 64\n",
      "number of params:  1773220\n",
      "Model Name: 01.3_ViT_nPE_cifar100_patch2_l4_sAtt_mlp_s147\n",
      "EXPERIMENT DONE... SKIPPING : 01.3_ViT_nPE_cifar100_patch2_l4_sAtt_mlp_s147\n",
      "\n",
      "                                Experimenting on cifar100 Dataset \n",
      "                                patch:4,\n",
      "                                sparse_att: False,\n",
      "                                sparse_mlp: False,\n",
      "                                num_layers: 8,\n",
      "                                pos_embed: False,\n",
      "                                seed: 147\n",
      "                            \n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "64 128\n",
      "ViT Mixer : Channels per patch -> Initial:48 Final:128\n",
      "[2, 4, 8, 16, 32, 64, 128]\n",
      "Sequence len: 64 ; Block size: 64\n",
      "Channel dim: 128 num heads: 8\n",
      "MLP dim: 128 ; Block size: 128\n",
      "number of params:  1885412\n",
      "Model Name: 01.3_ViT_nPE_cifar100_patch4_l8_att_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:31<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 0 Loss: 3.842 | Acc: 12.122 6061/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 37.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 3.445 | Acc: 19.410 1941/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:31<00:00, 12.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 1 Loss: 3.317 | Acc: 20.836 10418/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 36.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 1 Loss: 3.082 | Acc: 25.640 2564/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 391/391 [00:31<00:00, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 2 Loss: 3.055 | Acc: 25.410 12705/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 79/79 [00:02<00:00, 37.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 2 Loss: 2.900 | Acc: 29.180 2918/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████████████▉ | 383/391 [00:48<00:00, 11.96it/s]"
     ]
    }
   ],
   "source": [
    "### Automate the benchmark\n",
    "###### for c10 / c100\n",
    "\n",
    "not_working = [\n",
    "    (1, False, False, 4),\n",
    "    (1, False, False, 8),\n",
    "    (1, False, False, 12),\n",
    "    (1, False, True, 4),\n",
    "    (1, False, True, 8),\n",
    "    (1, False, True, 12),\n",
    "\n",
    "    (1, True, False, 12),\n",
    "    (1, True, True, 12),\n",
    "]\n",
    "\n",
    "cuda_idx = 1\n",
    "for dataset in ['cifar100']:\n",
    "    for seed in [147, 258, 369]:\n",
    "        for nlayers in [4, 8, 12]:\n",
    "            for patch_size in [4, 2]:\n",
    "#             for patch_size in [8, 4, 2, 1]:\n",
    "                for sparse_attention in [False, True]:\n",
    "                    for sparse_mlp in [False]:\n",
    "                        for PE in [False]:\n",
    "\n",
    "                            print(f'''\n",
    "                                Experimenting on {dataset} Dataset \n",
    "                                patch:{patch_size},\n",
    "                                sparse_att: {sparse_attention},\n",
    "                                sparse_mlp: {sparse_mlp},\n",
    "                                num_layers: {nlayers},\n",
    "                                pos_embed: {PE},\n",
    "                                seed: {seed}\n",
    "                            ''')\n",
    "\n",
    "                        ### check if config is in not_working case\n",
    "                            exit = False\n",
    "                            for nw in not_working:\n",
    "                                if patch_size==nw[0] and \\\n",
    "                                    sparse_attention==nw[1] and \\\n",
    "                                    sparse_mlp==nw[2] and\\\n",
    "                                    nlayers==nw[3]:\n",
    "\n",
    "                                    exit=True\n",
    "                                    break\n",
    "                            if exit:\n",
    "                                print(f'Exiting as the config is in NOT WORKING')\n",
    "                                continue\n",
    "\n",
    "\n",
    "                            benchmark(dataset=dataset, \n",
    "                                      patch_size=patch_size, \n",
    "                                      num_layers=nlayers, \n",
    "                                      SEED=seed, \n",
    "                                      sparse_att=sparse_attention, sparse_mlp=sparse_mlp, \n",
    "                                      pos_emb=PE,\n",
    "                                      cuda=cuda_idx\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdasdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use mixing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d174ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Experiments\n",
    "'''\n",
    "1. Sparse Attention\n",
    "2. Sparse MLP\n",
    "3. Sparse Att + MLP\n",
    "\n",
    "Datasets:\n",
    "A. Cifar-10/100 -> 4x4 vs 2x2 vs 1x1 patch\n",
    "B. Tiny-Imagenet -> 16x16 vs 4x4 vs 2x2 patch\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ca1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## Cifar 10/100\n",
    "\n",
    "vit_mixer = Mixer_ViT_Classifier((3, 32, 32), patch_size=[8, 8], hidden_channel=256, num_blocks=6, num_classes=200, block_seq_size=4, block_mlp_size=16)\n",
    "\n",
    "vit_mixer = Mixer_ViT_Classifier((3, 32, 32), patch_size=[4, 4], hidden_channel=128, num_blocks=3, num_classes=10, block_seq_size=8, block_mlp_size=128)\n",
    "\n",
    "vit_mixer = Mixer_ViT_Classifier((3, 32, 32), patch_size=[2, 2], hidden_channel=64, num_blocks=3, num_classes=10, block_seq_size=16, block_mlp_size=8)\n",
    "\n",
    "vit_mixer = Mixer_ViT_Classifier((3, 32, 32), patch_size=[1, 1], hidden_channel=64, num_blocks=3, num_classes=10, block_seq_size=32, block_mlp_size=8)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1eee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "vit_mixer = Mixer_ViT_Classifier((3, 64, 64), patch_size=[4, 4], hidden_channel=128, num_blocks=9, num_classes=200, block_seq_size=16, block_mlp_size=16)\n",
    "Sequence len: 256 ; Block size: 16\n",
    "Channel dim: 128 num heads: 8\n",
    "MLP dim: 128 ; Block size: 16\n",
    "\n",
    "\n",
    "vit_mixer = Mixer_ViT_Classifier((3, 64, 64), patch_size=[8, 8], hidden_channel=256, num_blocks=9, num_classes=200, block_seq_size=8, block_mlp_size=16)\n",
    "Sequence len: 64 ; Block size: 16\n",
    "Channel dim: 256 num heads: 16\n",
    "MLP dim: 256 ; Block size: 16\n",
    "\n",
    "vit_mixer = Mixer_ViT_Classifier((3, 64, 64), patch_size=[16, 16], hidden_channel=1024, num_blocks=9, num_classes=200, block_seq_size=4, block_mlp_size=32)\n",
    "Sequence len: 16 ; Block size: 4\n",
    "Channel dim: 1024 num heads: 32\n",
    "MLP dim: 1024 ; Block size: 32\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57171612",
   "metadata": {},
   "source": [
    "### Automate the model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b409b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 64\n",
    "patch_size = [16, 8, 4, 2, 1]\n",
    "expansion = [1024, 256, 128, 64, 64]\n",
    "\n",
    "for i in range(len(patch_size)):\n",
    "    ps, exp = patch_size[i], expansion[i]\n",
    "    print(i, ps, exp)\n",
    "    seq_len = (img//ps)**2\n",
    "    print('seq:', seq_len)\n",
    "    \n",
    "    fact_seq = int(2**np.ceil(np.log2(np.sqrt(seq_len))))\n",
    "    print(f'fact_seq: {fact_seq}')\n",
    "    \n",
    "    \n",
    "    fact_mlp = int(2**np.ceil(np.log2(np.sqrt(exp))))\n",
    "    print(f'fact_mlp: {fact_mlp}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
