{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mylibrary.nnlib as tnn\n",
    "import mylibrary.splinelib as tsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0,1,300)\n",
    "noise = np.random.normal(0,0.02, x.shape)\n",
    "x = x + noise\n",
    "x = np.sort(x)\n",
    "\n",
    "y= (2 * np.sin(10*x) + np.cos(20 * x - 3) + 3 * np.log(10*x + 0.5) - 4)/6.\n",
    "noise = np.random.normal(0,0.1, x.shape)\n",
    "y = y + noise\n",
    "\n",
    "x = x*2\n",
    "x = x - x.mean() # good practice to zero-center x in linear mapping\n",
    "# xx = x.reshape(-1,1)\n",
    "# yy = y.reshape(-1,1)\n",
    "xx = np.c_[x,y]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.scatter(x, y, marker='.', color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing NonLinear Autoencoder (3 Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tnn.Adam()\n",
    "\n",
    "n_hidden1 = 5\n",
    "n_hidden2 = 5\n",
    "net = tnn.AutoForm(new_layers=True)\n",
    "e1 = tnn.NonLinearLayer(2, n_hidden1, activation=tnn.LeakyRelu(), optimizer=optimizer)\n",
    "e2 = tnn.NonLinearLayer(n_hidden1, n_hidden2, activation=tnn.LeakyRelu(), optimizer=optimizer)\n",
    "e3 = tnn.LinearLayer(n_hidden2, 1, optimizer=optimizer)\n",
    "\n",
    "d3 = tnn.NonLinearLayer(1, n_hidden2, activation=tnn.LeakyRelu(), optimizer=optimizer)\n",
    "d2 = tnn.NonLinearLayer(n_hidden2, n_hidden1, activation=tnn.LeakyRelu(), optimizer=optimizer)\n",
    "d1 = tnn.LinearLayer(n_hidden1, 2, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________\n",
      "epoch 0\n",
      "Loss 0.2634363509329489\n",
      "\n",
      "_______________________\n",
      "epoch 10\n",
      "Loss 0.17962362002448373\n",
      "\n",
      "_______________________\n",
      "epoch 20\n",
      "Loss 0.09636788553415672\n",
      "\n",
      "_______________________\n",
      "epoch 30\n",
      "Loss 0.064855534222487\n",
      "\n",
      "_______________________\n",
      "epoch 40\n",
      "Loss 0.040755562360296975\n",
      "\n",
      "_______________________\n",
      "epoch 50\n",
      "Loss 0.034569732475092915\n",
      "\n",
      "_______________________\n",
      "epoch 60\n",
      "Loss 0.02950267828036397\n",
      "\n",
      "_______________________\n",
      "epoch 70\n",
      "Loss 0.02819858518854226\n",
      "\n",
      "_______________________\n",
      "epoch 80\n",
      "Loss 0.027167545579416686\n",
      "\n",
      "_______________________\n",
      "epoch 90\n",
      "Loss 0.026070633802760174\n",
      "\n",
      "_______________________\n",
      "epoch 100\n",
      "Loss 0.024939616973897436\n",
      "\n",
      "_______________________\n",
      "epoch 110\n",
      "Loss 0.023852752870795288\n",
      "\n",
      "_______________________\n",
      "epoch 120\n",
      "Loss 0.022911385455653036\n",
      "\n",
      "_______________________\n",
      "epoch 130\n",
      "Loss 0.022039305164157627\n",
      "\n",
      "_______________________\n",
      "epoch 140\n",
      "Loss 0.021273151559379967\n",
      "\n",
      "_______________________\n",
      "epoch 150\n",
      "Loss 0.02060987563774455\n",
      "\n",
      "_______________________\n",
      "epoch 160\n",
      "Loss 0.02001475126749522\n",
      "\n",
      "_______________________\n",
      "epoch 170\n",
      "Loss 0.019494643998376485\n",
      "\n",
      "_______________________\n",
      "epoch 180\n",
      "Loss 0.01903780108517884\n",
      "\n",
      "_______________________\n",
      "epoch 190\n",
      "Loss 0.018646236019144058\n",
      "\n",
      "_______________________\n",
      "epoch 200\n",
      "Loss 0.018286390578292597\n",
      "\n",
      "_______________________\n",
      "epoch 210\n",
      "Loss 0.01807236195332098\n",
      "\n",
      "_______________________\n",
      "epoch 220\n",
      "Loss 0.01779224954054369\n",
      "\n",
      "_______________________\n",
      "epoch 230\n",
      "Loss 0.017543853376915795\n",
      "\n",
      "_______________________\n",
      "epoch 240\n",
      "Loss 0.01736607938119562\n",
      "\n",
      "_______________________\n",
      "epoch 250\n",
      "Loss 0.01722356023510679\n",
      "\n",
      "_______________________\n",
      "epoch 260\n",
      "Loss 0.01703864942399502\n",
      "\n",
      "_______________________\n",
      "epoch 270\n",
      "Loss 0.01690040279469013\n",
      "\n",
      "_______________________\n",
      "epoch 280\n",
      "Loss 0.016782660859875207\n",
      "\n",
      "_______________________\n",
      "epoch 290\n",
      "Loss 0.016698812537857367\n",
      "\n",
      "_______________________\n",
      "epoch 300\n",
      "Loss 0.016659427835970318\n",
      "\n",
      "_______________________\n",
      "epoch 310\n",
      "Loss 0.016708848083575752\n",
      "\n",
      "_______________________\n",
      "epoch 320\n",
      "Loss 0.01658767632197669\n",
      "\n",
      "_______________________\n",
      "epoch 330\n",
      "Loss 0.016485797316226132\n",
      "\n",
      "_______________________\n",
      "epoch 340\n",
      "Loss 0.016426777182276357\n",
      "\n",
      "_______________________\n",
      "epoch 350\n",
      "Loss 0.016366739750836412\n",
      "\n",
      "_______________________\n",
      "epoch 360\n",
      "Loss 0.016317437884336573\n",
      "\n",
      "_______________________\n",
      "epoch 370\n",
      "Loss 0.016294822217449392\n",
      "\n",
      "_______________________\n",
      "epoch 380\n",
      "Loss 0.016198527274686927\n",
      "\n",
      "_______________________\n",
      "epoch 390\n",
      "Loss 0.016078595890857198\n",
      "\n",
      "_______________________\n",
      "epoch 400\n",
      "Loss 0.016004862479034227\n",
      "\n",
      "_______________________\n",
      "epoch 410\n",
      "Loss 0.01592853023951375\n",
      "\n",
      "_______________________\n",
      "epoch 420\n",
      "Loss 0.01583499941731394\n",
      "\n",
      "_______________________\n",
      "epoch 430\n",
      "Loss 0.015773088308897797\n",
      "\n",
      "_______________________\n",
      "epoch 440\n",
      "Loss 0.015716461811782784\n",
      "\n",
      "_______________________\n",
      "epoch 450\n",
      "Loss 0.015646448125825843\n",
      "\n",
      "_______________________\n",
      "epoch 460\n",
      "Loss 0.015580346446063273\n",
      "\n",
      "_______________________\n",
      "epoch 470\n",
      "Loss 0.015543271032376437\n",
      "\n",
      "_______________________\n",
      "epoch 480\n",
      "Loss 0.015438664159965351\n",
      "\n",
      "_______________________\n",
      "epoch 490\n",
      "Loss 0.015349123173887745\n",
      "\n",
      "_______________________\n",
      "epoch 500\n",
      "Loss 0.015255028226443323\n",
      "\n",
      "_______________________\n",
      "epoch 510\n",
      "Loss 0.015121118441081239\n",
      "\n",
      "_______________________\n",
      "epoch 520\n",
      "Loss 0.01493142640220731\n",
      "\n",
      "_______________________\n",
      "epoch 530\n",
      "Loss 0.014662189591186493\n",
      "\n",
      "_______________________\n",
      "epoch 540\n",
      "Loss 0.014252020923068891\n",
      "\n",
      "_______________________\n",
      "epoch 550\n",
      "Loss 0.013613753856464532\n",
      "\n",
      "_______________________\n",
      "epoch 560\n",
      "Loss 0.01304949359026297\n",
      "\n",
      "_______________________\n",
      "epoch 570\n",
      "Loss 0.01255748409177026\n",
      "\n",
      "_______________________\n",
      "epoch 580\n",
      "Loss 0.0121204965828526\n",
      "\n",
      "_______________________\n",
      "epoch 590\n",
      "Loss 0.01180063275892378\n",
      "\n",
      "_______________________\n",
      "epoch 600\n",
      "Loss 0.01155970255524229\n",
      "\n",
      "_______________________\n",
      "epoch 610\n",
      "Loss 0.011410884137442696\n",
      "\n",
      "_______________________\n",
      "epoch 620\n",
      "Loss 0.01134216537488651\n",
      "\n",
      "_______________________\n",
      "epoch 630\n",
      "Loss 0.011280520151108931\n",
      "\n",
      "_______________________\n",
      "epoch 640\n",
      "Loss 0.01124880169197124\n",
      "\n",
      "_______________________\n",
      "epoch 650\n",
      "Loss 0.011168363037894431\n",
      "\n",
      "_______________________\n",
      "epoch 660\n",
      "Loss 0.01115702213991106\n",
      "\n",
      "_______________________\n",
      "epoch 670\n",
      "Loss 0.011099662942513093\n",
      "\n",
      "_______________________\n",
      "epoch 680\n",
      "Loss 0.011144653338342905\n",
      "\n",
      "_______________________\n",
      "epoch 690\n",
      "Loss 0.010983558260614317\n",
      "\n",
      "_______________________\n",
      "epoch 700\n",
      "Loss 0.01088074356195996\n",
      "\n",
      "_______________________\n",
      "epoch 710\n",
      "Loss 0.010843278815541927\n",
      "\n",
      "_______________________\n",
      "epoch 720\n",
      "Loss 0.01092254938433306\n",
      "\n",
      "_______________________\n",
      "epoch 730\n",
      "Loss 0.010732120620229635\n",
      "\n",
      "_______________________\n",
      "epoch 740\n",
      "Loss 0.010795945810678609\n",
      "\n",
      "_______________________\n",
      "epoch 750\n",
      "Loss 0.01065820542626704\n",
      "\n",
      "_______________________\n",
      "epoch 760\n",
      "Loss 0.010848140118361898\n",
      "\n",
      "_______________________\n",
      "epoch 770\n",
      "Loss 0.011069743318858051\n",
      "\n",
      "_______________________\n",
      "epoch 780\n",
      "Loss 0.010658862393944256\n",
      "\n",
      "_______________________\n",
      "epoch 790\n",
      "Loss 0.010610399018157883\n",
      "\n",
      "_______________________\n",
      "epoch 800\n",
      "Loss 0.010989351127841334\n",
      "\n",
      "_______________________\n",
      "epoch 810\n",
      "Loss 0.010174656864017887\n",
      "\n",
      "_______________________\n",
      "epoch 820\n",
      "Loss 0.010470118081204977\n",
      "\n",
      "_______________________\n",
      "epoch 830\n",
      "Loss 0.010048872524873437\n",
      "\n",
      "_______________________\n",
      "epoch 840\n",
      "Loss 0.010437140602878326\n",
      "\n",
      "_______________________\n",
      "epoch 850\n",
      "Loss 0.010117461823030664\n",
      "\n",
      "_______________________\n",
      "epoch 860\n",
      "Loss 0.010165617790184598\n",
      "\n",
      "_______________________\n",
      "epoch 870\n",
      "Loss 0.010205730149888818\n",
      "\n",
      "_______________________\n",
      "epoch 880\n",
      "Loss 0.010158337659026594\n",
      "\n",
      "_______________________\n",
      "epoch 890\n",
      "Loss 0.010015129581817024\n",
      "\n",
      "_______________________\n",
      "epoch 900\n",
      "Loss 0.009897780305594432\n",
      "\n",
      "_______________________\n",
      "epoch 910\n",
      "Loss 0.00994772055901242\n",
      "\n",
      "_______________________\n",
      "epoch 920\n",
      "Loss 0.010048255414842822\n",
      "\n",
      "_______________________\n",
      "epoch 930\n",
      "Loss 0.010025249074375273\n",
      "\n",
      "_______________________\n",
      "epoch 940\n",
      "Loss 0.009807017865088157\n",
      "\n",
      "_______________________\n",
      "epoch 950\n",
      "Loss 0.009805740070221041\n",
      "\n",
      "_______________________\n",
      "epoch 960\n",
      "Loss 0.010267051066702934\n",
      "\n",
      "_______________________\n",
      "epoch 970\n",
      "Loss 0.009699286287372476\n",
      "\n",
      "_______________________\n",
      "epoch 980\n",
      "Loss 0.009665528535588084\n",
      "\n",
      "_______________________\n",
      "epoch 990\n",
      "Loss 0.0098615238716964\n",
      "\n",
      "_______________________\n",
      "epoch 1000\n",
      "Loss 0.009775131810912384\n",
      "\n",
      "_______________________\n",
      "epoch 1010\n",
      "Loss 0.009661616202257285\n",
      "\n",
      "_______________________\n",
      "epoch 1020\n",
      "Loss 0.009976995047756232\n",
      "\n",
      "_______________________\n",
      "epoch 1030\n",
      "Loss 0.009639119835214392\n",
      "\n",
      "_______________________\n",
      "epoch 1040\n",
      "Loss 0.009788981495071916\n",
      "\n",
      "_______________________\n",
      "epoch 1050\n",
      "Loss 0.009620653577573406\n",
      "\n",
      "_______________________\n",
      "epoch 1060\n",
      "Loss 0.009680940091101568\n",
      "\n",
      "_______________________\n",
      "epoch 1070\n",
      "Loss 0.00970542531627395\n",
      "\n",
      "_______________________\n",
      "epoch 1080\n",
      "Loss 0.009568004814197137\n",
      "\n",
      "_______________________\n",
      "epoch 1090\n",
      "Loss 0.010279836413994315\n",
      "\n",
      "_______________________\n",
      "epoch 1100\n",
      "Loss 0.00973167687905528\n",
      "\n",
      "_______________________\n",
      "epoch 1110\n",
      "Loss 0.009676062159315487\n",
      "\n",
      "_______________________\n",
      "epoch 1120\n",
      "Loss 0.009532027389394508\n",
      "\n",
      "_______________________\n",
      "epoch 1130\n",
      "Loss 0.00992411690388206\n",
      "\n",
      "_______________________\n",
      "epoch 1140\n",
      "Loss 0.009529180886575388\n",
      "\n",
      "_______________________\n",
      "epoch 1150\n",
      "Loss 0.00964497578236821\n",
      "\n",
      "_______________________\n",
      "epoch 1160\n",
      "Loss 0.010004036449201307\n",
      "\n",
      "_______________________\n",
      "epoch 1170\n",
      "Loss 0.00988595349979789\n",
      "\n",
      "_______________________\n",
      "epoch 1180\n",
      "Loss 0.009500768723862348\n",
      "\n",
      "_______________________\n",
      "epoch 1190\n",
      "Loss 0.009515636872068734\n",
      "\n",
      "_______________________\n",
      "epoch 1200\n",
      "Loss 0.009574901161523387\n",
      "\n",
      "_______________________\n",
      "epoch 1210\n",
      "Loss 0.009488324362804992\n",
      "\n",
      "_______________________\n",
      "epoch 1220\n",
      "Loss 0.009657849774988427\n",
      "\n",
      "_______________________\n",
      "epoch 1230\n",
      "Loss 0.009720822329437783\n",
      "\n",
      "_______________________\n",
      "epoch 1240\n",
      "Loss 0.009595680035940312\n",
      "\n",
      "_______________________\n",
      "epoch 1250\n",
      "Loss 0.009625331875380928\n",
      "\n",
      "_______________________\n",
      "epoch 1260\n",
      "Loss 0.0095090182568091\n",
      "\n",
      "_______________________\n",
      "epoch 1270\n",
      "Loss 0.009959547087101837\n",
      "\n",
      "_______________________\n",
      "epoch 1280\n",
      "Loss 0.009554176158960476\n",
      "\n",
      "_______________________\n",
      "epoch 1290\n",
      "Loss 0.009467503852131005\n",
      "\n",
      "_______________________\n",
      "epoch 1300\n",
      "Loss 0.010191659118213237\n",
      "\n",
      "_______________________\n",
      "epoch 1310\n",
      "Loss 0.009468109306051742\n",
      "\n",
      "_______________________\n",
      "epoch 1320\n",
      "Loss 0.00944059531562249\n",
      "\n",
      "_______________________\n",
      "epoch 1330\n",
      "Loss 0.009457584929607936\n",
      "\n",
      "_______________________\n",
      "epoch 1340\n",
      "Loss 0.009409759990284018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_______________________\n",
      "epoch 1350\n",
      "Loss 0.009395295015779986\n",
      "\n",
      "_______________________\n",
      "epoch 1360\n",
      "Loss 0.009427198963568601\n",
      "\n",
      "_______________________\n",
      "epoch 1370\n",
      "Loss 0.009385294826784645\n",
      "\n",
      "_______________________\n",
      "epoch 1380\n",
      "Loss 0.009633696271587978\n",
      "\n",
      "_______________________\n",
      "epoch 1390\n",
      "Loss 0.009394751693735152\n",
      "\n",
      "_______________________\n",
      "epoch 1400\n",
      "Loss 0.009462426995853312\n",
      "\n",
      "_______________________\n",
      "epoch 1410\n",
      "Loss 0.009869386290621512\n",
      "\n",
      "_______________________\n",
      "epoch 1420\n",
      "Loss 0.009542398442776075\n",
      "\n",
      "_______________________\n",
      "epoch 1430\n",
      "Loss 0.009725966831384108\n",
      "\n",
      "_______________________\n",
      "epoch 1440\n",
      "Loss 0.010196929272528774\n",
      "\n",
      "_______________________\n",
      "epoch 1450\n",
      "Loss 0.009391716345242442\n",
      "\n",
      "_______________________\n",
      "epoch 1460\n",
      "Loss 0.009404174511482987\n",
      "\n",
      "_______________________\n",
      "epoch 1470\n",
      "Loss 0.00946579948112068\n",
      "\n",
      "_______________________\n",
      "epoch 1480\n",
      "Loss 0.009389816607314675\n",
      "\n",
      "_______________________\n",
      "epoch 1490\n",
      "Loss 0.00935277751035205\n",
      "\n",
      "_______________________\n",
      "epoch 1500\n",
      "Loss 0.009360820500531053\n",
      "\n",
      "_______________________\n",
      "epoch 1510\n",
      "Loss 0.0093646501524575\n",
      "\n",
      "_______________________\n",
      "epoch 1520\n",
      "Loss 0.009350688876913251\n",
      "\n",
      "_______________________\n",
      "epoch 1530\n",
      "Loss 0.010262754392519767\n",
      "\n",
      "_______________________\n",
      "epoch 1540\n",
      "Loss 0.010166171040340965\n",
      "\n",
      "_______________________\n",
      "epoch 1550\n",
      "Loss 0.010217517820233753\n",
      "\n",
      "_______________________\n",
      "epoch 1560\n",
      "Loss 0.01025329496669149\n",
      "\n",
      "_______________________\n",
      "epoch 1570\n",
      "Loss 0.00965778704087402\n",
      "\n",
      "_______________________\n",
      "epoch 1580\n",
      "Loss 0.009583865210118605\n",
      "\n",
      "_______________________\n",
      "epoch 1590\n",
      "Loss 0.009511819946171002\n",
      "\n",
      "_______________________\n",
      "epoch 1600\n",
      "Loss 0.009449242818812738\n",
      "\n",
      "_______________________\n",
      "epoch 1610\n",
      "Loss 0.009465387773382461\n",
      "\n",
      "_______________________\n",
      "epoch 1620\n",
      "Loss 0.00933224447803607\n",
      "\n",
      "_______________________\n",
      "epoch 1630\n",
      "Loss 0.009358421868907108\n",
      "\n",
      "_______________________\n",
      "epoch 1640\n",
      "Loss 0.009322453467544548\n",
      "\n",
      "_______________________\n",
      "epoch 1650\n",
      "Loss 0.009331238632509429\n",
      "\n",
      "_______________________\n",
      "epoch 1660\n",
      "Loss 0.009306674817691112\n",
      "\n",
      "_______________________\n",
      "epoch 1670\n",
      "Loss 0.009301107909047411\n",
      "\n",
      "_______________________\n",
      "epoch 1680\n",
      "Loss 0.00928939977512229\n",
      "\n",
      "_______________________\n",
      "epoch 1690\n",
      "Loss 0.009285080292379363\n",
      "\n",
      "_______________________\n",
      "epoch 1700\n",
      "Loss 0.009279493892230262\n",
      "\n",
      "_______________________\n",
      "epoch 1710\n",
      "Loss 0.009274074118310367\n",
      "\n",
      "_______________________\n",
      "epoch 1720\n",
      "Loss 0.009956502174559841\n",
      "\n",
      "_______________________\n",
      "epoch 1730\n",
      "Loss 0.00995337156333331\n",
      "\n",
      "_______________________\n",
      "epoch 1740\n",
      "Loss 0.009594502980198458\n",
      "\n",
      "_______________________\n",
      "epoch 1750\n",
      "Loss 0.02390216248992887\n",
      "\n",
      "_______________________\n",
      "epoch 1760\n",
      "Loss 0.012868158188238126\n",
      "\n",
      "_______________________\n",
      "epoch 1770\n",
      "Loss 0.011029596637416594\n",
      "\n",
      "_______________________\n",
      "epoch 1780\n",
      "Loss 0.010458182613309726\n",
      "\n",
      "_______________________\n",
      "epoch 1790\n",
      "Loss 0.009807804884269276\n",
      "\n",
      "_______________________\n",
      "epoch 1800\n",
      "Loss 0.009686074678977\n",
      "\n",
      "_______________________\n",
      "epoch 1810\n",
      "Loss 0.009530847388070335\n",
      "\n",
      "_______________________\n",
      "epoch 1820\n",
      "Loss 0.009410296445943326\n",
      "\n",
      "_______________________\n",
      "epoch 1830\n",
      "Loss 0.009387765057329892\n",
      "\n",
      "_______________________\n",
      "epoch 1840\n",
      "Loss 0.009364240822594771\n",
      "\n",
      "_______________________\n",
      "epoch 1850\n",
      "Loss 0.009352781965024582\n",
      "\n",
      "_______________________\n",
      "epoch 1860\n",
      "Loss 0.00934323628928543\n",
      "\n",
      "_______________________\n",
      "epoch 1870\n",
      "Loss 0.009335604830609651\n",
      "\n",
      "_______________________\n",
      "epoch 1880\n",
      "Loss 0.009328808027505686\n",
      "\n",
      "_______________________\n",
      "epoch 1890\n",
      "Loss 0.009321857727992522\n",
      "\n",
      "_______________________\n",
      "epoch 1900\n",
      "Loss 0.009315157188259794\n",
      "\n",
      "_______________________\n",
      "epoch 1910\n",
      "Loss 0.009308636763744731\n",
      "\n",
      "_______________________\n",
      "epoch 1920\n",
      "Loss 0.009302806023304714\n",
      "\n",
      "_______________________\n",
      "epoch 1930\n",
      "Loss 0.009296610324081531\n",
      "\n",
      "_______________________\n",
      "epoch 1940\n",
      "Loss 0.00929008730931443\n",
      "\n",
      "_______________________\n",
      "epoch 1950\n",
      "Loss 0.009284974753897548\n",
      "\n",
      "_______________________\n",
      "epoch 1960\n",
      "Loss 0.009278556331959533\n",
      "\n",
      "_______________________\n",
      "epoch 1970\n",
      "Loss 0.009273072497863055\n",
      "\n",
      "_______________________\n",
      "epoch 1980\n",
      "Loss 0.00926747919785743\n",
      "\n",
      "_______________________\n",
      "epoch 1990\n",
      "Loss 0.009262221868735432\n",
      "\n",
      "_______________________\n",
      "epoch 2000\n",
      "Loss 0.00925665440878833\n",
      "\n",
      "_______________________\n",
      "epoch 2010\n",
      "Loss 0.009251782061027454\n",
      "\n",
      "_______________________\n",
      "epoch 2020\n",
      "Loss 0.009246327451226267\n",
      "\n",
      "_______________________\n",
      "epoch 2030\n",
      "Loss 0.00924115029847739\n",
      "\n",
      "_______________________\n",
      "epoch 2040\n",
      "Loss 0.009236429617843472\n",
      "\n",
      "_______________________\n",
      "epoch 2050\n",
      "Loss 0.009230391392763142\n",
      "\n",
      "_______________________\n",
      "epoch 2060\n",
      "Loss 0.009225348572880009\n",
      "\n",
      "_______________________\n",
      "epoch 2070\n",
      "Loss 0.009220738142022913\n",
      "\n",
      "_______________________\n",
      "epoch 2080\n",
      "Loss 0.009215452832095525\n",
      "\n",
      "_______________________\n",
      "epoch 2090\n",
      "Loss 0.00921053527941595\n",
      "\n",
      "_______________________\n",
      "epoch 2100\n",
      "Loss 0.009205708835335677\n",
      "\n",
      "_______________________\n",
      "epoch 2110\n",
      "Loss 0.009201276701164737\n",
      "\n",
      "_______________________\n",
      "epoch 2120\n",
      "Loss 0.009196548438749631\n",
      "\n",
      "_______________________\n",
      "epoch 2130\n",
      "Loss 0.009192023939529052\n",
      "\n",
      "_______________________\n",
      "epoch 2140\n",
      "Loss 0.00918724563017418\n",
      "\n",
      "_______________________\n",
      "epoch 2150\n",
      "Loss 0.009208829574433851\n",
      "\n",
      "_______________________\n",
      "epoch 2160\n",
      "Loss 0.00970459635086461\n",
      "\n",
      "_______________________\n",
      "epoch 2170\n",
      "Loss 0.011367957622200478\n",
      "\n",
      "_______________________\n",
      "epoch 2180\n",
      "Loss 0.013109168430610193\n",
      "\n",
      "_______________________\n",
      "epoch 2190\n",
      "Loss 0.01054023026468343\n",
      "\n",
      "_______________________\n",
      "epoch 2200\n",
      "Loss 0.009908848660931472\n",
      "\n",
      "_______________________\n",
      "epoch 2210\n",
      "Loss 0.009806206798503683\n",
      "\n",
      "_______________________\n",
      "epoch 2220\n",
      "Loss 0.00962518216977185\n",
      "\n",
      "_______________________\n",
      "epoch 2230\n",
      "Loss 0.009575130503011212\n",
      "\n",
      "_______________________\n",
      "epoch 2240\n",
      "Loss 0.00955113934220364\n",
      "\n",
      "_______________________\n",
      "epoch 2250\n",
      "Loss 0.009540238211272202\n",
      "\n",
      "_______________________\n",
      "epoch 2260\n",
      "Loss 0.009533518164407314\n",
      "\n",
      "_______________________\n",
      "epoch 2270\n",
      "Loss 0.009524291310690727\n",
      "\n",
      "_______________________\n",
      "epoch 2280\n",
      "Loss 0.009518814608576355\n",
      "\n",
      "_______________________\n",
      "epoch 2290\n",
      "Loss 0.009512462332289251\n",
      "\n",
      "_______________________\n",
      "epoch 2300\n",
      "Loss 0.009507287121676965\n",
      "\n",
      "_______________________\n",
      "epoch 2310\n",
      "Loss 0.00950225002811627\n",
      "\n",
      "_______________________\n",
      "epoch 2320\n",
      "Loss 0.009497308177329506\n",
      "\n",
      "_______________________\n",
      "epoch 2330\n",
      "Loss 0.009492725623238074\n",
      "\n",
      "_______________________\n",
      "epoch 2340\n",
      "Loss 0.009487974979322206\n",
      "\n",
      "_______________________\n",
      "epoch 2350\n",
      "Loss 0.00948356340976676\n",
      "\n",
      "_______________________\n",
      "epoch 2360\n",
      "Loss 0.009479303149317723\n",
      "\n",
      "_______________________\n",
      "epoch 2370\n",
      "Loss 0.00947501265990222\n",
      "\n",
      "_______________________\n",
      "epoch 2380\n",
      "Loss 0.009470972837224438\n",
      "\n",
      "_______________________\n",
      "epoch 2390\n",
      "Loss 0.0094668869507527\n",
      "\n",
      "_______________________\n",
      "epoch 2400\n",
      "Loss 0.009462904419268711\n",
      "\n",
      "_______________________\n",
      "epoch 2410\n",
      "Loss 0.009459129282454496\n",
      "\n",
      "_______________________\n",
      "epoch 2420\n",
      "Loss 0.009455561177618471\n",
      "\n",
      "_______________________\n",
      "epoch 2430\n",
      "Loss 0.00945216177071762\n",
      "\n",
      "_______________________\n",
      "epoch 2440\n",
      "Loss 0.00944828378174064\n",
      "\n",
      "_______________________\n",
      "epoch 2450\n",
      "Loss 0.009444989610605263\n",
      "\n",
      "_______________________\n",
      "epoch 2460\n",
      "Loss 0.009441426339205847\n",
      "\n",
      "_______________________\n",
      "epoch 2470\n",
      "Loss 0.009437971221728694\n",
      "\n",
      "_______________________\n",
      "epoch 2480\n",
      "Loss 0.009434860721407248\n",
      "\n",
      "_______________________\n",
      "epoch 2490\n",
      "Loss 0.009431321117598491\n",
      "\n",
      "_______________________\n",
      "epoch 2500\n",
      "Loss 0.009428140980172433\n",
      "\n",
      "_______________________\n",
      "epoch 2510\n",
      "Loss 0.009424910679618129\n",
      "\n",
      "_______________________\n",
      "epoch 2520\n",
      "Loss 0.009421614370720992\n",
      "\n",
      "_______________________\n",
      "epoch 2530\n",
      "Loss 0.009420066466453417\n",
      "\n",
      "_______________________\n",
      "epoch 2540\n",
      "Loss 0.009415459968136737\n",
      "\n",
      "_______________________\n",
      "epoch 2550\n",
      "Loss 0.009414339502770394\n",
      "\n",
      "_______________________\n",
      "epoch 2560\n",
      "Loss 0.009409689726961448\n",
      "\n",
      "_______________________\n",
      "epoch 2570\n",
      "Loss 0.009408126942313001\n",
      "\n",
      "_______________________\n",
      "epoch 2580\n",
      "Loss 0.009405053460066\n",
      "\n",
      "_______________________\n",
      "epoch 2590\n",
      "Loss 0.009400736683712685\n",
      "\n",
      "_______________________\n",
      "epoch 2600\n",
      "Loss 0.00939886851429102\n",
      "\n",
      "_______________________\n",
      "epoch 2610\n",
      "Loss 0.00939742509075481\n",
      "\n",
      "_______________________\n",
      "epoch 2620\n",
      "Loss 0.009395524676825001\n",
      "\n",
      "_______________________\n",
      "epoch 2630\n",
      "Loss 0.00939433737850287\n",
      "\n",
      "_______________________\n",
      "epoch 2640\n",
      "Loss 0.009393689049323847\n",
      "\n",
      "_______________________\n",
      "epoch 2650\n",
      "Loss 0.009392845733854098\n",
      "\n",
      "_______________________\n",
      "epoch 2660\n",
      "Loss 0.009396270424044503\n",
      "\n",
      "_______________________\n",
      "epoch 2670\n",
      "Loss 0.00941715934703432\n",
      "\n",
      "_______________________\n",
      "epoch 2680\n",
      "Loss 0.009463171125963022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_______________________\n",
      "epoch 2690\n",
      "Loss 0.01030844577997426\n",
      "\n",
      "_______________________\n",
      "epoch 2700\n",
      "Loss 0.009469729590479483\n",
      "\n",
      "_______________________\n",
      "epoch 2710\n",
      "Loss 0.009418375506307853\n",
      "\n",
      "_______________________\n",
      "epoch 2720\n",
      "Loss 0.009390961618248444\n",
      "\n",
      "_______________________\n",
      "epoch 2730\n",
      "Loss 0.009394435697187955\n",
      "\n",
      "_______________________\n",
      "epoch 2740\n",
      "Loss 0.009381344600507904\n",
      "\n",
      "_______________________\n",
      "epoch 2750\n",
      "Loss 0.009381077858920367\n",
      "\n",
      "_______________________\n",
      "epoch 2760\n",
      "Loss 0.009413497833154417\n",
      "\n",
      "_______________________\n",
      "epoch 2770\n",
      "Loss 0.009402302817458668\n",
      "\n",
      "_______________________\n",
      "epoch 2780\n",
      "Loss 0.00946063752696934\n",
      "\n",
      "_______________________\n",
      "epoch 2790\n",
      "Loss 0.009710858756489398\n",
      "\n",
      "_______________________\n",
      "epoch 2800\n",
      "Loss 0.009822617122085419\n",
      "\n",
      "_______________________\n",
      "epoch 2810\n",
      "Loss 0.009400385928555606\n",
      "\n",
      "_______________________\n",
      "epoch 2820\n",
      "Loss 0.009678905043533626\n",
      "\n",
      "_______________________\n",
      "epoch 2830\n",
      "Loss 0.009528683587638618\n",
      "\n",
      "_______________________\n",
      "epoch 2840\n",
      "Loss 0.009420250950304559\n",
      "\n",
      "_______________________\n",
      "epoch 2850\n",
      "Loss 0.009487365036543191\n",
      "\n",
      "_______________________\n",
      "epoch 2860\n",
      "Loss 0.009397538414907538\n",
      "\n",
      "_______________________\n",
      "epoch 2870\n",
      "Loss 0.009378863216383012\n",
      "\n",
      "_______________________\n",
      "epoch 2880\n",
      "Loss 0.010046902852645883\n",
      "\n",
      "_______________________\n",
      "epoch 2890\n",
      "Loss 0.009480462796733301\n",
      "\n",
      "_______________________\n",
      "epoch 2900\n",
      "Loss 0.009892459519708569\n",
      "\n",
      "_______________________\n",
      "epoch 2910\n",
      "Loss 0.00946455229069382\n",
      "\n",
      "_______________________\n",
      "epoch 2920\n",
      "Loss 0.009919906349575135\n",
      "\n",
      "_______________________\n",
      "epoch 2930\n",
      "Loss 0.009664830103573777\n",
      "\n",
      "_______________________\n",
      "epoch 2940\n",
      "Loss 0.015540142069274338\n",
      "\n",
      "_______________________\n",
      "epoch 2950\n",
      "Loss 0.010880751349627033\n",
      "\n",
      "_______________________\n",
      "epoch 2960\n",
      "Loss 0.010364941110139905\n",
      "\n",
      "_______________________\n",
      "epoch 2970\n",
      "Loss 0.009543404564932781\n",
      "\n",
      "_______________________\n",
      "epoch 2980\n",
      "Loss 0.009559044772079032\n",
      "\n",
      "_______________________\n",
      "epoch 2990\n",
      "Loss 0.009471517093178249\n",
      "\n",
      "_______________________\n",
      "epoch 3000\n",
      "Loss 0.009443496410358783\n",
      "\n",
      "_______________________\n",
      "epoch 3010\n",
      "Loss 0.009432837579746781\n",
      "\n",
      "_______________________\n",
      "epoch 3020\n",
      "Loss 0.009424906825901807\n",
      "\n",
      "_______________________\n",
      "epoch 3030\n",
      "Loss 0.009420023090774929\n",
      "\n",
      "_______________________\n",
      "epoch 3040\n",
      "Loss 0.009414490921831093\n",
      "\n",
      "_______________________\n",
      "epoch 3050\n",
      "Loss 0.009412971747676083\n",
      "\n",
      "_______________________\n",
      "epoch 3060\n",
      "Loss 0.009410462746634958\n",
      "\n",
      "_______________________\n",
      "epoch 3070\n",
      "Loss 0.00940320568310811\n",
      "\n",
      "_______________________\n",
      "epoch 3080\n",
      "Loss 0.009405010170863894\n",
      "\n",
      "_______________________\n",
      "epoch 3090\n",
      "Loss 0.00940344754883587\n",
      "\n",
      "_______________________\n",
      "epoch 3100\n",
      "Loss 0.009393783006061897\n",
      "\n",
      "_______________________\n",
      "epoch 3110\n",
      "Loss 0.00939101190796903\n",
      "\n",
      "_______________________\n",
      "epoch 3120\n",
      "Loss 0.009387420919873912\n",
      "\n",
      "_______________________\n",
      "epoch 3130\n",
      "Loss 0.009385799463219296\n",
      "\n",
      "_______________________\n",
      "epoch 3140\n",
      "Loss 0.009382170291128743\n",
      "\n",
      "_______________________\n",
      "epoch 3150\n",
      "Loss 0.009379844850690692\n",
      "\n",
      "_______________________\n",
      "epoch 3160\n",
      "Loss 0.009375933990642056\n",
      "\n",
      "_______________________\n",
      "epoch 3170\n",
      "Loss 0.009374548698015687\n",
      "\n",
      "_______________________\n",
      "epoch 3180\n",
      "Loss 0.009371637427681469\n",
      "\n",
      "_______________________\n",
      "epoch 3190\n",
      "Loss 0.009369076703602416\n",
      "\n",
      "_______________________\n",
      "epoch 3200\n",
      "Loss 0.009367106682701184\n",
      "\n",
      "_______________________\n",
      "epoch 3210\n",
      "Loss 0.009365119851430998\n",
      "\n",
      "_______________________\n",
      "epoch 3220\n",
      "Loss 0.009363274126407714\n",
      "\n",
      "_______________________\n",
      "epoch 3230\n",
      "Loss 0.009362467930538987\n",
      "\n",
      "_______________________\n",
      "epoch 3240\n",
      "Loss 0.00936278177688422\n",
      "\n",
      "_______________________\n",
      "epoch 3250\n",
      "Loss 0.009357597401611904\n",
      "\n",
      "_______________________\n",
      "epoch 3260\n",
      "Loss 0.009382715874882283\n",
      "\n",
      "_______________________\n",
      "epoch 3270\n",
      "Loss 0.009440967074496513\n",
      "\n",
      "_______________________\n",
      "epoch 3280\n",
      "Loss 0.009364571213590047\n",
      "\n",
      "_______________________\n",
      "epoch 3290\n",
      "Loss 0.009399759144365505\n",
      "\n",
      "_______________________\n",
      "epoch 3300\n",
      "Loss 0.0102095560421835\n",
      "\n",
      "_______________________\n",
      "epoch 3310\n",
      "Loss 0.009504872924141736\n",
      "\n",
      "_______________________\n",
      "epoch 3320\n",
      "Loss 0.009578919274965824\n",
      "\n",
      "_______________________\n",
      "epoch 3330\n",
      "Loss 0.009615069935232933\n",
      "\n",
      "_______________________\n",
      "epoch 3340\n",
      "Loss 0.009423726480557561\n",
      "\n",
      "_______________________\n",
      "epoch 3350\n",
      "Loss 0.00936997775403356\n",
      "\n",
      "_______________________\n",
      "epoch 3360\n",
      "Loss 0.009356466060647751\n",
      "\n",
      "_______________________\n",
      "epoch 3370\n",
      "Loss 0.009353684341512953\n",
      "\n",
      "_______________________\n",
      "epoch 3380\n",
      "Loss 0.00935428936795858\n",
      "\n",
      "_______________________\n",
      "epoch 3390\n",
      "Loss 0.009353745143903787\n",
      "\n",
      "_______________________\n",
      "epoch 3400\n",
      "Loss 0.009372665795700959\n",
      "\n",
      "_______________________\n",
      "epoch 3410\n",
      "Loss 0.009679855528658842\n",
      "\n",
      "_______________________\n",
      "epoch 3420\n",
      "Loss 0.00950614828532373\n",
      "\n",
      "_______________________\n",
      "epoch 3430\n",
      "Loss 0.010057391492642261\n",
      "\n",
      "_______________________\n",
      "epoch 3440\n",
      "Loss 0.013113272994765248\n",
      "\n",
      "_______________________\n",
      "epoch 3450\n",
      "Loss 0.00978368333835788\n",
      "\n",
      "_______________________\n",
      "epoch 3460\n",
      "Loss 0.00981136705558453\n",
      "\n",
      "_______________________\n",
      "epoch 3470\n",
      "Loss 0.009790398025751398\n",
      "\n",
      "_______________________\n",
      "epoch 3480\n",
      "Loss 0.009547663150545326\n",
      "\n",
      "_______________________\n",
      "epoch 3490\n",
      "Loss 0.00941557397357421\n",
      "\n",
      "_______________________\n",
      "epoch 3500\n",
      "Loss 0.009364411648021525\n",
      "\n",
      "_______________________\n",
      "epoch 3510\n",
      "Loss 0.009366246069220544\n",
      "\n",
      "_______________________\n",
      "epoch 3520\n",
      "Loss 0.00935860613711729\n",
      "\n",
      "_______________________\n",
      "epoch 3530\n",
      "Loss 0.009346041975031522\n",
      "\n",
      "_______________________\n",
      "epoch 3540\n",
      "Loss 0.009345317552693537\n",
      "\n",
      "_______________________\n",
      "epoch 3550\n",
      "Loss 0.00934328003944917\n",
      "\n",
      "_______________________\n",
      "epoch 3560\n",
      "Loss 0.009358950714802462\n",
      "\n",
      "_______________________\n",
      "epoch 3570\n",
      "Loss 0.009352952301827174\n",
      "\n",
      "_______________________\n",
      "epoch 3580\n",
      "Loss 0.009592899640099538\n",
      "\n",
      "_______________________\n",
      "epoch 3590\n",
      "Loss 0.00948009806973848\n",
      "\n",
      "_______________________\n",
      "epoch 3600\n",
      "Loss 0.009794851292284412\n",
      "\n",
      "_______________________\n",
      "epoch 3610\n",
      "Loss 0.009348615559004665\n",
      "\n",
      "_______________________\n",
      "epoch 3620\n",
      "Loss 0.009352823264611303\n",
      "\n",
      "_______________________\n",
      "epoch 3630\n",
      "Loss 0.009360678313329344\n",
      "\n",
      "_______________________\n",
      "epoch 3640\n",
      "Loss 0.009661471209256327\n",
      "\n",
      "_______________________\n",
      "epoch 3650\n",
      "Loss 0.009628166025844289\n",
      "\n",
      "_______________________\n",
      "epoch 3660\n",
      "Loss 0.00963072006164106\n",
      "\n",
      "_______________________\n",
      "epoch 3670\n",
      "Loss 0.009690128809359108\n",
      "\n",
      "_______________________\n",
      "epoch 3680\n",
      "Loss 0.009775358323559144\n",
      "\n",
      "_______________________\n",
      "epoch 3690\n",
      "Loss 0.00965848443551565\n",
      "\n",
      "_______________________\n",
      "epoch 3700\n",
      "Loss 0.00938960861138394\n",
      "\n",
      "_______________________\n",
      "epoch 3710\n",
      "Loss 0.009500474186660253\n",
      "\n",
      "_______________________\n",
      "epoch 3720\n",
      "Loss 0.009347898237275434\n",
      "\n",
      "_______________________\n",
      "epoch 3730\n",
      "Loss 0.009377009807934992\n",
      "\n",
      "_______________________\n",
      "epoch 3740\n",
      "Loss 0.009346678947927083\n",
      "\n",
      "_______________________\n",
      "epoch 3750\n",
      "Loss 0.009335544712855137\n",
      "\n",
      "_______________________\n",
      "epoch 3760\n",
      "Loss 0.009334272680708284\n",
      "\n",
      "_______________________\n",
      "epoch 3770\n",
      "Loss 0.009335302685967134\n",
      "\n",
      "_______________________\n",
      "epoch 3780\n",
      "Loss 0.009370281186842468\n",
      "\n",
      "_______________________\n",
      "epoch 3790\n",
      "Loss 0.009438420230074617\n",
      "\n",
      "_______________________\n",
      "epoch 3800\n",
      "Loss 0.010341313477217368\n",
      "\n",
      "_______________________\n",
      "epoch 3810\n",
      "Loss 0.009839113118307357\n",
      "\n",
      "_______________________\n",
      "epoch 3820\n",
      "Loss 0.009900626999888574\n",
      "\n",
      "_______________________\n",
      "epoch 3830\n",
      "Loss 0.009435187083766556\n",
      "\n",
      "_______________________\n",
      "epoch 3840\n",
      "Loss 0.009379515355521482\n",
      "\n",
      "_______________________\n",
      "epoch 3850\n",
      "Loss 0.00958267613933993\n",
      "\n",
      "_______________________\n",
      "epoch 3860\n",
      "Loss 0.009397155311245808\n",
      "\n",
      "_______________________\n",
      "epoch 3870\n",
      "Loss 0.009485931123220631\n",
      "\n",
      "_______________________\n",
      "epoch 3880\n",
      "Loss 0.009342628613339963\n",
      "\n",
      "_______________________\n",
      "epoch 3890\n",
      "Loss 0.009436276013343327\n",
      "\n",
      "_______________________\n",
      "epoch 3900\n",
      "Loss 0.00932924531273971\n",
      "\n",
      "_______________________\n",
      "epoch 3910\n",
      "Loss 0.010048471459491358\n",
      "\n",
      "_______________________\n",
      "epoch 3920\n",
      "Loss 0.009714307274205022\n",
      "\n",
      "_______________________\n",
      "epoch 3930\n",
      "Loss 0.009592729490548402\n",
      "\n",
      "_______________________\n",
      "epoch 3940\n",
      "Loss 0.009964129096157657\n",
      "\n",
      "_______________________\n",
      "epoch 3950\n",
      "Loss 0.009386618170045396\n",
      "\n",
      "_______________________\n",
      "epoch 3960\n",
      "Loss 0.00974573040641427\n",
      "\n",
      "_______________________\n",
      "epoch 3970\n",
      "Loss 0.009665055491093916\n",
      "\n",
      "_______________________\n",
      "epoch 3980\n",
      "Loss 0.009409362272986336\n",
      "\n",
      "_______________________\n",
      "epoch 3990\n",
      "Loss 0.00933648762425181\n",
      "\n",
      "_______________________\n",
      "epoch 4000\n",
      "Loss 0.009326403775808508\n",
      "\n",
      "_______________________\n",
      "epoch 4010\n",
      "Loss 0.009328790204384802\n",
      "\n",
      "_______________________\n",
      "epoch 4020\n",
      "Loss 0.009329965384644923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_______________________\n",
      "epoch 4030\n",
      "Loss 0.009346473615816843\n",
      "\n",
      "_______________________\n",
      "epoch 4040\n",
      "Loss 0.00948271176526936\n",
      "\n",
      "_______________________\n",
      "epoch 4050\n",
      "Loss 0.009425219020695319\n",
      "\n",
      "_______________________\n",
      "epoch 4060\n",
      "Loss 0.009391974315964375\n",
      "\n",
      "_______________________\n",
      "epoch 4070\n",
      "Loss 0.011553002669664187\n",
      "\n",
      "_______________________\n",
      "epoch 4080\n",
      "Loss 0.010409854251324365\n",
      "\n",
      "_______________________\n",
      "epoch 4090\n",
      "Loss 0.02140794512463239\n",
      "\n",
      "_______________________\n",
      "epoch 4100\n",
      "Loss 0.02255271164810375\n",
      "\n",
      "_______________________\n",
      "epoch 4110\n",
      "Loss 0.017428908379976182\n",
      "\n",
      "_______________________\n",
      "epoch 4120\n",
      "Loss 0.016538669428723476\n",
      "\n",
      "_______________________\n",
      "epoch 4130\n",
      "Loss 0.015714237375758656\n",
      "\n",
      "_______________________\n",
      "epoch 4140\n",
      "Loss 0.015159162628393974\n",
      "\n",
      "_______________________\n",
      "epoch 4150\n",
      "Loss 0.011758967855629732\n",
      "\n",
      "_______________________\n",
      "epoch 4160\n",
      "Loss 0.010744342248128824\n",
      "\n",
      "_______________________\n",
      "epoch 4170\n",
      "Loss 0.010372502577351384\n",
      "\n",
      "_______________________\n",
      "epoch 4180\n",
      "Loss 0.010337469197121137\n",
      "\n",
      "_______________________\n",
      "epoch 4190\n",
      "Loss 0.010208937639295328\n",
      "\n",
      "_______________________\n",
      "epoch 4200\n",
      "Loss 0.010342437069907827\n",
      "\n",
      "_______________________\n",
      "epoch 4210\n",
      "Loss 0.010110540327982108\n",
      "\n",
      "_______________________\n",
      "epoch 4220\n",
      "Loss 0.009985616810427096\n",
      "\n",
      "_______________________\n",
      "epoch 4230\n",
      "Loss 0.00997091594373941\n",
      "\n",
      "_______________________\n",
      "epoch 4240\n",
      "Loss 0.009952579794654595\n",
      "\n",
      "_______________________\n",
      "epoch 4250\n",
      "Loss 0.009939463334999838\n",
      "\n",
      "_______________________\n",
      "epoch 4260\n",
      "Loss 0.009930669929002312\n",
      "\n",
      "_______________________\n",
      "epoch 4270\n",
      "Loss 0.009919978058670731\n",
      "\n",
      "_______________________\n",
      "epoch 4280\n",
      "Loss 0.009913359421898532\n",
      "\n",
      "_______________________\n",
      "epoch 4290\n",
      "Loss 0.009907582944743138\n",
      "\n",
      "_______________________\n",
      "epoch 4300\n",
      "Loss 0.009902429259761607\n",
      "\n",
      "_______________________\n",
      "epoch 4310\n",
      "Loss 0.009897709184768134\n",
      "\n",
      "_______________________\n",
      "epoch 4320\n",
      "Loss 0.00989327009232196\n",
      "\n",
      "_______________________\n",
      "epoch 4330\n",
      "Loss 0.009889139877537409\n",
      "\n",
      "_______________________\n",
      "epoch 4340\n",
      "Loss 0.009885443399031408\n",
      "\n",
      "_______________________\n",
      "epoch 4350\n",
      "Loss 0.009881779410339592\n",
      "\n",
      "_______________________\n",
      "epoch 4360\n",
      "Loss 0.009878498243347812\n",
      "\n",
      "_______________________\n",
      "epoch 4370\n",
      "Loss 0.009875135989381122\n",
      "\n",
      "_______________________\n",
      "epoch 4380\n",
      "Loss 0.009872028473632034\n",
      "\n",
      "_______________________\n",
      "epoch 4390\n",
      "Loss 0.009868968956941216\n",
      "\n",
      "_______________________\n",
      "epoch 4400\n",
      "Loss 0.009866088923062444\n",
      "\n",
      "_______________________\n",
      "epoch 4410\n",
      "Loss 0.00986329982432128\n",
      "\n",
      "_______________________\n",
      "epoch 4420\n",
      "Loss 0.009860681678700805\n",
      "\n",
      "_______________________\n",
      "epoch 4430\n",
      "Loss 0.009858095207264128\n",
      "\n",
      "_______________________\n",
      "epoch 4440\n",
      "Loss 0.009855605060821778\n",
      "\n",
      "_______________________\n",
      "epoch 4450\n",
      "Loss 0.009853291796022953\n",
      "\n",
      "_______________________\n",
      "epoch 4460\n",
      "Loss 0.009851005083073539\n",
      "\n",
      "_______________________\n",
      "epoch 4470\n",
      "Loss 0.009848614344299858\n",
      "\n",
      "_______________________\n",
      "epoch 4480\n",
      "Loss 0.009846464059878792\n",
      "\n",
      "_______________________\n",
      "epoch 4490\n",
      "Loss 0.009844447829572696\n",
      "\n",
      "_______________________\n",
      "epoch 4500\n",
      "Loss 0.009842172115793817\n",
      "\n",
      "_______________________\n",
      "epoch 4510\n",
      "Loss 0.009840270363284784\n",
      "\n",
      "_______________________\n",
      "epoch 4520\n",
      "Loss 0.009838277541020325\n",
      "\n",
      "_______________________\n",
      "epoch 4530\n",
      "Loss 0.009836242456896791\n",
      "\n",
      "_______________________\n",
      "epoch 4540\n",
      "Loss 0.009834432636285868\n",
      "\n",
      "_______________________\n",
      "epoch 4550\n",
      "Loss 0.009832508705061308\n",
      "\n",
      "_______________________\n",
      "epoch 4560\n",
      "Loss 0.00983068259716294\n",
      "\n",
      "_______________________\n",
      "epoch 4570\n",
      "Loss 0.009828925043585473\n",
      "\n",
      "_______________________\n",
      "epoch 4580\n",
      "Loss 0.009827440540598694\n",
      "\n",
      "_______________________\n",
      "epoch 4590\n",
      "Loss 0.009847024335226488\n",
      "\n",
      "_______________________\n",
      "epoch 4600\n",
      "Loss 0.009850282743291992\n",
      "\n",
      "_______________________\n",
      "epoch 4610\n",
      "Loss 0.009944099508351657\n",
      "\n",
      "_______________________\n",
      "epoch 4620\n",
      "Loss 0.009828573309294404\n",
      "\n",
      "_______________________\n",
      "epoch 4630\n",
      "Loss 0.010062919080136935\n",
      "\n",
      "_______________________\n",
      "epoch 4640\n",
      "Loss 0.009892047029212574\n",
      "\n",
      "_______________________\n",
      "epoch 4650\n",
      "Loss 0.009862160116965031\n",
      "\n",
      "_______________________\n",
      "epoch 4660\n",
      "Loss 0.00989776990514143\n"
     ]
    },
    {
     "ename": "TclError",
     "evalue": "invalid command name \"pyimage50\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-98059ae67ff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/miniconda/lib/python3.7/site-packages/matplotlib/backends/backend_tkagg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigureCanvasTkAgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0m_backend_tk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tkphoto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_master\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_idletasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/miniconda/lib/python3.7/site-packages/matplotlib/backends/_backend_tk.py\u001b[0m in \u001b[0;36mblit\u001b[0;34m(photoimage, aggimage, offsets, bbox)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mbboxptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mphotoimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mbboxptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     _tkagg.blit(\n",
      "\u001b[0;32m~/Program_Files/miniconda/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36mblank\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3546\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mblank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3547\u001b[0m         \u001b[0;34m\"\"\"Display a transparent image.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3548\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'blank'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3550\u001b[0m         \u001b[0;34m\"\"\"Return the value of OPTION.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTclError\u001b[0m: invalid command name \"pyimage50\""
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "fig.show()\n",
    "\n",
    "for step in range(100000):\n",
    "    \n",
    "    d3.weights = e3.weights.T\n",
    "    yy = net.forward(xx)\n",
    "    \n",
    "    dy = yy-xx\n",
    "    dx = net.backward(dy)\n",
    "\n",
    "    loss = (dy**2).mean()\n",
    "    net.update()\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "\n",
    "        print('_______________________')\n",
    "        print(\"epoch\", step)\n",
    "        print(\"Loss\", loss)\n",
    "\n",
    "        ax.clear()\n",
    "        plt.scatter(x, y, marker='.', color='g', label='x,y')\n",
    "        \n",
    "        plt.plot(yy[:,0], yy[:,1], c='r', lw=2, label='x,y_out')\n",
    "        plt.legend()\n",
    "        \n",
    "        fig.canvas.draw()\n",
    "        \n",
    "        plt.pause(0.01)\n",
    "        print()\n",
    "        if loss < 0.0025:\n",
    "            print('fitted to our expectation')\n",
    "            plt.pause(50)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.scatter(x, y, marker='.', color='g', label='x,y')\n",
    "plt.plot(yy[:,0], yy[:,1], c='r', lw=2, label='x,y_out')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.40735272],\n",
       "       [ 2.29791333],\n",
       "       [ 2.24634769],\n",
       "       [ 2.25027968],\n",
       "       [ 2.27770412],\n",
       "       [ 2.24618639],\n",
       "       [ 2.24635349],\n",
       "       [ 2.20147473],\n",
       "       [ 2.19129724],\n",
       "       [ 2.16143048],\n",
       "       [ 2.0823388 ],\n",
       "       [ 2.11585317],\n",
       "       [ 2.09448222],\n",
       "       [ 2.08408913],\n",
       "       [ 2.07219707],\n",
       "       [ 2.06918098],\n",
       "       [ 2.01170102],\n",
       "       [ 2.0487408 ],\n",
       "       [ 2.01223401],\n",
       "       [ 2.00062002],\n",
       "       [ 1.9954523 ],\n",
       "       [ 1.97218492],\n",
       "       [ 1.96886595],\n",
       "       [ 1.94283286],\n",
       "       [ 1.92408094],\n",
       "       [ 1.89523652],\n",
       "       [ 1.90773832],\n",
       "       [ 1.87624306],\n",
       "       [ 1.86084408],\n",
       "       [ 1.85988731],\n",
       "       [ 1.83712046],\n",
       "       [ 1.85244785],\n",
       "       [ 1.82614166],\n",
       "       [ 1.79434646],\n",
       "       [ 1.7579114 ],\n",
       "       [ 1.76575923],\n",
       "       [ 1.73354006],\n",
       "       [ 1.74047056],\n",
       "       [ 1.72682408],\n",
       "       [ 1.70190199],\n",
       "       [ 1.71110734],\n",
       "       [ 1.70862118],\n",
       "       [ 1.66803987],\n",
       "       [ 1.69114768],\n",
       "       [ 1.679871  ],\n",
       "       [ 1.65056295],\n",
       "       [ 1.67177186],\n",
       "       [ 1.65034069],\n",
       "       [ 1.63710574],\n",
       "       [ 1.59355803],\n",
       "       [ 1.57661251],\n",
       "       [ 1.57248122],\n",
       "       [ 1.57707976],\n",
       "       [ 1.56972204],\n",
       "       [ 1.55854794],\n",
       "       [ 1.57001808],\n",
       "       [ 1.53174211],\n",
       "       [ 1.51546835],\n",
       "       [ 1.52292313],\n",
       "       [ 1.53370915],\n",
       "       [ 1.52392242],\n",
       "       [ 1.487527  ],\n",
       "       [ 1.44296942],\n",
       "       [ 1.47850095],\n",
       "       [ 1.46103937],\n",
       "       [ 1.42154471],\n",
       "       [ 1.39848688],\n",
       "       [ 1.40867549],\n",
       "       [ 1.37326209],\n",
       "       [ 1.37300379],\n",
       "       [ 1.37598761],\n",
       "       [ 1.37875986],\n",
       "       [ 1.38220012],\n",
       "       [ 1.35154208],\n",
       "       [ 1.34619217],\n",
       "       [ 1.35628236],\n",
       "       [ 1.31729346],\n",
       "       [ 1.32836261],\n",
       "       [ 1.31216299],\n",
       "       [ 1.33954585],\n",
       "       [ 1.28563069],\n",
       "       [ 1.30461682],\n",
       "       [ 1.2902751 ],\n",
       "       [ 1.2656644 ],\n",
       "       [ 1.26995901],\n",
       "       [ 1.23078636],\n",
       "       [ 1.23259649],\n",
       "       [ 1.25318412],\n",
       "       [ 1.2192835 ],\n",
       "       [ 1.24230883],\n",
       "       [ 1.21788603],\n",
       "       [ 1.18939503],\n",
       "       [ 1.2053469 ],\n",
       "       [ 1.17516435],\n",
       "       [ 1.23074292],\n",
       "       [ 1.16406385],\n",
       "       [ 1.10625336],\n",
       "       [ 1.11503273],\n",
       "       [ 1.11902647],\n",
       "       [ 1.122178  ],\n",
       "       [ 1.13238431],\n",
       "       [ 1.10877323],\n",
       "       [ 1.11099659],\n",
       "       [ 1.11701899],\n",
       "       [ 1.11328052],\n",
       "       [ 1.09734979],\n",
       "       [ 1.09878361],\n",
       "       [ 1.06314813],\n",
       "       [ 1.06856814],\n",
       "       [ 1.06045784],\n",
       "       [ 1.06574521],\n",
       "       [ 1.024152  ],\n",
       "       [ 1.01985609],\n",
       "       [ 0.98207133],\n",
       "       [ 0.93449114],\n",
       "       [ 0.94395436],\n",
       "       [ 0.92722771],\n",
       "       [ 0.87500303],\n",
       "       [ 0.92126451],\n",
       "       [ 0.8814502 ],\n",
       "       [ 0.89146081],\n",
       "       [ 0.88261208],\n",
       "       [ 0.81418987],\n",
       "       [ 0.84062578],\n",
       "       [ 0.84125466],\n",
       "       [ 0.80650799],\n",
       "       [ 0.82203723],\n",
       "       [ 0.82106057],\n",
       "       [ 0.78097065],\n",
       "       [ 0.77850438],\n",
       "       [ 0.78424368],\n",
       "       [ 0.76312184],\n",
       "       [ 0.76637583],\n",
       "       [ 0.7699489 ],\n",
       "       [ 0.75186174],\n",
       "       [ 0.71208459],\n",
       "       [ 0.70784202],\n",
       "       [ 0.71413813],\n",
       "       [ 0.70828563],\n",
       "       [ 0.68313025],\n",
       "       [ 0.68385396],\n",
       "       [ 0.67113732],\n",
       "       [ 0.68992983],\n",
       "       [ 0.68256517],\n",
       "       [ 0.65849394],\n",
       "       [ 0.64634473],\n",
       "       [ 0.62582667],\n",
       "       [ 0.61731532],\n",
       "       [ 0.59070607],\n",
       "       [ 0.55771503],\n",
       "       [ 0.54942906],\n",
       "       [ 0.5489892 ],\n",
       "       [ 0.52426689],\n",
       "       [ 0.47251979],\n",
       "       [ 0.54323422],\n",
       "       [ 0.46995156],\n",
       "       [ 0.44424001],\n",
       "       [ 0.5020691 ],\n",
       "       [ 0.46962842],\n",
       "       [ 0.41074811],\n",
       "       [ 0.38618611],\n",
       "       [ 0.3905826 ],\n",
       "       [ 0.4163451 ],\n",
       "       [ 0.41774007],\n",
       "       [ 0.407033  ],\n",
       "       [ 0.31647748],\n",
       "       [ 0.33397291],\n",
       "       [ 0.34419271],\n",
       "       [ 0.30592533],\n",
       "       [ 0.29917365],\n",
       "       [ 0.28725051],\n",
       "       [ 0.26195063],\n",
       "       [ 0.25669332],\n",
       "       [ 0.2597939 ],\n",
       "       [ 0.26621796],\n",
       "       [ 0.25581602],\n",
       "       [ 0.2430093 ],\n",
       "       [ 0.25715928],\n",
       "       [ 0.24958808],\n",
       "       [ 0.21011557],\n",
       "       [ 0.23065419],\n",
       "       [ 0.2231279 ],\n",
       "       [ 0.21008505],\n",
       "       [ 0.21730295],\n",
       "       [ 0.22222651],\n",
       "       [ 0.20841258],\n",
       "       [ 0.22472066],\n",
       "       [ 0.21110716],\n",
       "       [ 0.20875919],\n",
       "       [ 0.20251063],\n",
       "       [ 0.19329209],\n",
       "       [ 0.19911313],\n",
       "       [ 0.18844453],\n",
       "       [ 0.20084013],\n",
       "       [ 0.179249  ],\n",
       "       [ 0.19887698],\n",
       "       [ 0.19431871],\n",
       "       [ 0.19093189],\n",
       "       [ 0.18910989],\n",
       "       [ 0.179426  ],\n",
       "       [ 0.1815184 ],\n",
       "       [ 0.18028553],\n",
       "       [ 0.18058564],\n",
       "       [ 0.1961326 ],\n",
       "       [ 0.16887133],\n",
       "       [ 0.15515184],\n",
       "       [ 0.16772785],\n",
       "       [ 0.17429239],\n",
       "       [ 0.16695339],\n",
       "       [ 0.16264988],\n",
       "       [ 0.18105479],\n",
       "       [ 0.15481338],\n",
       "       [ 0.16667062],\n",
       "       [ 0.14850484],\n",
       "       [ 0.15178315],\n",
       "       [ 0.16052143],\n",
       "       [ 0.14561123],\n",
       "       [ 0.16250764],\n",
       "       [ 0.13677803],\n",
       "       [ 0.13924714],\n",
       "       [ 0.15165741],\n",
       "       [ 0.13960293],\n",
       "       [ 0.14160607],\n",
       "       [ 0.13817015],\n",
       "       [ 0.13034172],\n",
       "       [ 0.15271257],\n",
       "       [ 0.14124728],\n",
       "       [ 0.13376278],\n",
       "       [ 0.121753  ],\n",
       "       [ 0.13447306],\n",
       "       [ 0.14381942],\n",
       "       [ 0.13080521],\n",
       "       [ 0.13343668],\n",
       "       [ 0.13119103],\n",
       "       [ 0.11327567],\n",
       "       [ 0.10759036],\n",
       "       [ 0.12890849],\n",
       "       [ 0.13424593],\n",
       "       [ 0.11833574],\n",
       "       [ 0.10857939],\n",
       "       [ 0.11499657],\n",
       "       [ 0.08688072],\n",
       "       [ 0.08958499],\n",
       "       [ 0.10656318],\n",
       "       [ 0.0716936 ],\n",
       "       [ 0.07262518],\n",
       "       [ 0.04690589],\n",
       "       [ 0.03970245],\n",
       "       [ 0.03176192],\n",
       "       [ 0.03012583],\n",
       "       [ 0.00567497],\n",
       "       [ 0.01014665],\n",
       "       [ 0.037258  ],\n",
       "       [ 0.01430198],\n",
       "       [ 0.00596808],\n",
       "       [-0.02382077],\n",
       "       [ 0.02422014],\n",
       "       [ 0.00470964],\n",
       "       [-0.02648315],\n",
       "       [-0.05378665],\n",
       "       [-0.05045983],\n",
       "       [-0.08098803],\n",
       "       [-0.09808634],\n",
       "       [-0.11672662],\n",
       "       [-0.11055771],\n",
       "       [-0.10210797],\n",
       "       [-0.1011338 ],\n",
       "       [-0.11607879],\n",
       "       [-0.09974611],\n",
       "       [-0.12651431],\n",
       "       [-0.12071416],\n",
       "       [-0.14170422],\n",
       "       [-0.14197249],\n",
       "       [-0.1625644 ],\n",
       "       [-0.22530801],\n",
       "       [-0.18039484],\n",
       "       [-0.24161906],\n",
       "       [-0.23345165],\n",
       "       [-0.24414842],\n",
       "       [-0.26158452],\n",
       "       [-0.2626295 ],\n",
       "       [-0.26924199],\n",
       "       [-0.27669271],\n",
       "       [-0.27887155],\n",
       "       [-0.27787333],\n",
       "       [-0.27927912],\n",
       "       [-0.28052967],\n",
       "       [-0.28967025],\n",
       "       [-0.29501726],\n",
       "       [-0.29883885],\n",
       "       [-0.30447312],\n",
       "       [-0.31173254],\n",
       "       [-0.31269755],\n",
       "       [-0.31540933],\n",
       "       [-0.31522083],\n",
       "       [-0.31850594],\n",
       "       [-0.31913141],\n",
       "       [-0.32835832],\n",
       "       [-0.33007331],\n",
       "       [-0.34286658]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3.input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing Non-Linear encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tnn.Adam()\n",
    "\n",
    "net1 = tnn.AutoForm(new_layers=True)\n",
    "e1 = tnn.NonLinearLayer(2, 1, activation=tnn.Relu(), optimizer=optimizer)\n",
    "d1 = tnn.LinearLayer(1, 2, optimizer=optimizer)\n",
    "\n",
    "net2 = tnn.AutoForm(new_layers=True)\n",
    "e2 = tnn.NonLinearLayer(2, 1, activation=tnn.Relu(), optimizer=optimizer)\n",
    "d2 = tnn.LinearLayer(1, 2, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________\n",
      "epoch 0\n",
      "Loss 0.8852269151191302\n",
      "\n",
      "_______________________\n",
      "epoch 10\n",
      "Loss 0.47900662713653136\n",
      "\n",
      "_______________________\n",
      "epoch 20\n",
      "Loss 0.2416201081925538\n",
      "\n",
      "_______________________\n",
      "epoch 30\n",
      "Loss 0.11644410284708047\n",
      "\n",
      "_______________________\n",
      "epoch 40\n",
      "Loss 0.04683902111574471\n",
      "\n",
      "_______________________\n",
      "epoch 50\n",
      "Loss 0.02346936172500331\n",
      "\n",
      "_______________________\n",
      "epoch 60\n",
      "Loss 0.013489911300991902\n",
      "\n",
      "_______________________\n",
      "epoch 70\n",
      "Loss 0.007598480000926563\n",
      "\n",
      "_______________________\n",
      "epoch 80\n",
      "Loss 0.0050787108357276105\n",
      "\n",
      "_______________________\n",
      "epoch 90\n",
      "Loss 0.0036877695918903263\n",
      "\n",
      "_______________________\n",
      "epoch 100\n",
      "Loss 0.002445080351380306\n",
      "\n",
      "_______________________\n",
      "epoch 110\n",
      "Loss 0.0019983848743197023\n",
      "\n",
      "_______________________\n",
      "epoch 120\n",
      "Loss 0.0019127871857333855\n",
      "\n",
      "_______________________\n",
      "epoch 130\n",
      "Loss 0.0008159501454038315\n",
      "\n",
      "_______________________\n",
      "epoch 140\n",
      "Loss 0.0007963625259401131\n",
      "\n",
      "_______________________\n",
      "epoch 150\n",
      "Loss 0.0007814634849442193\n",
      "\n",
      "_______________________\n",
      "epoch 160\n",
      "Loss 0.00043547688320753767\n",
      "\n",
      "_______________________\n",
      "epoch 170\n",
      "Loss 0.0004299254882668099\n",
      "\n",
      "_______________________\n",
      "epoch 180\n",
      "Loss 0.0004254882535669063\n",
      "\n",
      "_______________________\n",
      "epoch 190\n",
      "Loss 0.00042140504185634117\n",
      "\n",
      "_______________________\n",
      "epoch 200\n",
      "Loss 0.0004174056457750647\n",
      "\n",
      "_______________________\n",
      "epoch 210\n",
      "Loss 0.0004133959723305669\n",
      "\n",
      "_______________________\n",
      "epoch 220\n",
      "Loss 0.0004093451825776217\n",
      "\n",
      "_______________________\n",
      "epoch 230\n",
      "Loss 0.00040524505732889655\n",
      "\n",
      "_______________________\n",
      "epoch 240\n",
      "Loss 0.0004010953821070761\n",
      "\n",
      "_______________________\n",
      "epoch 250\n",
      "Loss 0.0003968987018925247\n",
      "\n",
      "_______________________\n",
      "epoch 260\n",
      "Loss 0.00039265844551197404\n",
      "\n",
      "_______________________\n",
      "epoch 270\n",
      "Loss 0.0003883782596579077\n",
      "\n",
      "_______________________\n",
      "epoch 280\n",
      "Loss 0.0003840617760952291\n",
      "\n",
      "_______________________\n",
      "epoch 290\n",
      "Loss 0.0003797125334115459\n",
      "\n",
      "_______________________\n",
      "epoch 300\n",
      "Loss 0.00037533395350567675\n",
      "\n",
      "_______________________\n",
      "epoch 310\n",
      "Loss 0.0003709293371601\n",
      "\n",
      "_______________________\n",
      "epoch 320\n",
      "Loss 0.0003665018660169756\n",
      "\n",
      "_______________________\n",
      "epoch 330\n",
      "Loss 0.00036205460648814237\n",
      "\n",
      "_______________________\n",
      "epoch 340\n",
      "Loss 0.0\n",
      "\n",
      "_______________________\n",
      "epoch 350\n",
      "Loss 0.0\n",
      "\n",
      "_______________________\n",
      "epoch 360\n",
      "Loss 0.0\n",
      "\n",
      "_______________________\n",
      "epoch 370\n",
      "Loss 0.0\n",
      "\n",
      "_______________________\n",
      "epoch 380\n",
      "Loss 0.0\n",
      "\n",
      "_______________________\n",
      "epoch 390\n",
      "Loss 0.0\n",
      "\n",
      "_______________________\n",
      "epoch 400\n",
      "Loss 0.0\n",
      "\n",
      "_______________________\n",
      "epoch 410\n",
      "Loss 0.0\n",
      "\n",
      "_______________________\n",
      "epoch 420\n",
      "Loss 0.0\n"
     ]
    },
    {
     "ename": "TclError",
     "evalue": "invalid command name \"pyimage72\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-29d036fef782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/miniconda/lib/python3.7/site-packages/matplotlib/backends/backend_tkagg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigureCanvasTkAgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0m_backend_tk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tkphoto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_master\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_idletasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/miniconda/lib/python3.7/site-packages/matplotlib/backends/_backend_tk.py\u001b[0m in \u001b[0;36mblit\u001b[0;34m(photoimage, aggimage, offsets, bbox)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mbboxptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mphotoimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mbboxptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     _tkagg.blit(\n",
      "\u001b[0;32m~/Program_Files/miniconda/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36mblank\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3546\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mblank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3547\u001b[0m         \u001b[0;34m\"\"\"Display a transparent image.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3548\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'blank'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3550\u001b[0m         \u001b[0;34m\"\"\"Return the value of OPTION.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTclError\u001b[0m: invalid command name \"pyimage72\""
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "fig.show()\n",
    "\n",
    "for step in range(100000):\n",
    "    \n",
    "    yy = net1.forward(xx)\n",
    "    \n",
    "    dy = yy-xx\n",
    "    mask = e1.activation.x>0\n",
    "    dy = dy*mask\n",
    "    dx = net1.backward(dy)\n",
    "\n",
    "    loss = (dy**2).mean()\n",
    "    net1.update()\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "\n",
    "        print('_______________________')\n",
    "        print(\"epoch\", step)\n",
    "        print(\"Loss\", loss)\n",
    "\n",
    "        ax.clear()\n",
    "        plt.scatter(x, y, marker='.', color='g', label='x,y')\n",
    "        \n",
    "        plt.plot(yy[:,0], yy[:,1], c='r', lw=2, label='x,y_out')\n",
    "        plt.legend()\n",
    "        \n",
    "        fig.canvas.draw()\n",
    "        \n",
    "        plt.pause(0.01)\n",
    "        print()\n",
    "#         if loss < 0.0025:\n",
    "#             print('fitted to our expectation')\n",
    "#             plt.pause(50)\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
