{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os, sys, pathlib, random, time, pickle, copy, json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED = 147\n",
    "# SEED = 258\n",
    "SEED = 369\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_train = transforms.Compose([\n",
    "    transforms.RandomCrop(size=32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "        std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "    ),\n",
    "])\n",
    "\n",
    "cifar_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "        std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=True, download=True, transform=cifar_train)\n",
    "test_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=False, download=True, transform=cifar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpBLock(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_layers_ratio=[2], actf=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        #### convert hidden layers ratio to list if integer is inputted\n",
    "        if isinstance(hidden_layers_ratio, int):\n",
    "            hidden_layers_ratio = [hidden_layers_ratio]\n",
    "            \n",
    "        self.hlr = [1]+hidden_layers_ratio+[1]\n",
    "        \n",
    "        self.mlp = []\n",
    "        ### for 1 hidden layer, we iterate 2 times\n",
    "        for h in range(len(self.hlr)-1):\n",
    "            i, o = int(self.hlr[h]*self.input_dim),\\\n",
    "                    int(self.hlr[h+1]*self.input_dim)\n",
    "            self.mlp.append(nn.Linear(i, o))\n",
    "            self.mlp.append(actf())\n",
    "        self.mlp = self.mlp[:-1]\n",
    "        \n",
    "        self.mlp = nn.Sequential(*self.mlp)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpBLock(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=6, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=6, out_features=8, bias=True)\n",
       "    (3): GELU(approximate='none')\n",
       "    (4): Linear(in_features=8, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MlpBLock(2, [3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP-Mixer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, patch_dim, channel_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln0 = nn.LayerNorm(channel_dim)\n",
    "        self.mlp_patch = MlpBLock(patch_dim, [2])\n",
    "        self.ln1 = nn.LayerNorm(channel_dim)\n",
    "        self.mlp_channel = MlpBLock(channel_dim, [2])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## x has shape-> N, nP, nC/hidden_dims; C=Channel, P=Patch\n",
    "        \n",
    "        ######## !!!! Can use same mixer on shape of -> N, C, P;\n",
    "        \n",
    "        #### mix per patch\n",
    "        y = self.ln0(x) ### per channel layer normalization ?? \n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        y = self.mlp_patch(y)\n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        x = x+y\n",
    "        \n",
    "        #### mix per channel \n",
    "        y = self.ln1(x)\n",
    "        y = self.mlp_channel(y)\n",
    "        x = x+y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpMixer(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels:int, hidden_image_dim:tuple, patch_size:tuple, num_blocks:int, num_classes:int, use1x1scale=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_dim = hidden_image_dim ### must contain (C, H, W) or (H, W)\n",
    "        \n",
    "        ### find patch dim\n",
    "        d0 = int(self.img_dim[-2]/patch_size[0])\n",
    "        d1 = int(self.img_dim[-1]/patch_size[1])\n",
    "        assert d0*patch_size[0]==self.img_dim[-2], \"Image must be divisible into patch size\"\n",
    "        assert d1*patch_size[1]==self.img_dim[-1], \"Image must be divisible into patch size\"\n",
    "        \n",
    "        ### find channel dim\n",
    "        channel_size = d0*d1 ## number of patches\n",
    "        \n",
    "        ### after the number of channels are changed\n",
    "        init_dim = patch_size[0]*patch_size[1]*input_channels ## number of channels in each patch\n",
    "        final_dim = patch_size[0]*patch_size[1]*self.img_dim[0]\n",
    "\n",
    "        self.scaler = nn.UpsamplingBilinear2d(size=(self.img_dim[-2], self.img_dim[-1]))\n",
    "        \n",
    "        if use1x1scale:\n",
    "            self.conv1x1 = nn.Conv2d(input_channels, self.img_dim[0], kernel_size=1, stride=1)\n",
    "            if input_channels == self.img_dim[0]:\n",
    "                self.conv1x1 = nn.Identity()\n",
    "        else:\n",
    "            #### rescale the patches (patch wise image non preserving transform, unlike bilinear interpolation)\n",
    "            self.channel_change = nn.Linear(init_dim, final_dim) ## apply after unfold\n",
    "            \n",
    "        self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "        print(f\"MLP Mixer : Channes per patch -> Initial:{init_dim} Final:{final_dim}\")\n",
    "        \n",
    "        ### after the axis are swapped\n",
    "        self.channel_dim = final_dim\n",
    "        self.patch_dim = channel_size\n",
    "        \n",
    "        self.mixer_blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            self.mixer_blocks.append(MixerBlock(self.patch_dim, self.channel_dim))\n",
    "        self.mixer_blocks = nn.Sequential(*self.mixer_blocks)\n",
    "        \n",
    "        self.linear = nn.Linear(self.patch_dim*self.channel_dim, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = self.scaler(x) ## scale to high dimension\n",
    "        x = self.conv1x1(x)\n",
    "        x = self.unfold(x).swapaxes(-1, -2).contiguous() ## convert to patches, bring channels first\n",
    "#         x = self.channel_change(x) ## change the number of channels\n",
    "        x = self.mixer_blocks(x) ## the mixer architecture\n",
    "        x = self.linear(x.view(bs, -1)) ## classify\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Mixer : Channes per patch -> Initial:75 Final:125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MlpMixer(\n",
       "  (scaler): UpsamplingBilinear2d(size=(35, 35), mode=bilinear)\n",
       "  (channel_change): Linear(in_features=75, out_features=125, bias=True)\n",
       "  (unfold): Unfold(kernel_size=(5, 5), dilation=1, padding=0, stride=(5, 5))\n",
       "  (mixer_blocks): Sequential(\n",
       "    (0): MixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=6125, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixer = MlpMixer(3, (5, 35, 35), (5, 5), num_blocks=1, num_classes=10, use1x1scale=False)\n",
    "mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0804, -0.3449, -0.1566, -0.8707, -0.3013, -0.1984, -0.0258, -0.3818,\n",
       "          0.6066, -0.0815]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixer(torch.randn(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMixerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, patch_size, num_channel):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "#         self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "        ps = None\n",
    "        if isinstance(patch_size, int):\n",
    "            ps = patch_size**2\n",
    "        else:\n",
    "            ps = patch_size[0]*patch_size[1]\n",
    "        ps = ps*num_channel\n",
    "        \n",
    "        self.ln0 = nn.LayerNorm(ps)\n",
    "        self.mlp_patch = MlpBLock(ps, [2])\n",
    "        \n",
    "#         self.fold = nn.Fold(kernel_size=patch_size, stride=patch_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## x has shape-> N, C, H, W; C=Channel\n",
    "        \n",
    "        sz = x.shape\n",
    "        \n",
    "        y = nn.functional.unfold(x, \n",
    "                                 kernel_size=self.patch_size, \n",
    "                                 stride=self.patch_size\n",
    "                                )\n",
    "        #### mix per patch\n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        y = self.ln0(y) \n",
    "        y = self.mlp_patch(y)\n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        \n",
    "        y = nn.functional.fold(y, (sz[-2], sz[-1]), \n",
    "                               kernel_size=self.patch_size, \n",
    "                               stride=self.patch_size\n",
    "                              )\n",
    "        x = x+y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchMixerBlock(\n",
       "  (ln0): LayerNorm((245,), eps=1e-05, elementwise_affine=True)\n",
       "  (mlp_patch): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=245, out_features=490, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=490, out_features=245, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmb = PatchMixerBlock(7, 5)\n",
    "pmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 35, 35])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmb(torch.randn(1, 5, 35, 35)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factors(n):\n",
    "    facts = []\n",
    "    for i in range(2, n+1):\n",
    "        if n%i == 0:\n",
    "            facts.append(i)\n",
    "    return facts\n",
    "\n",
    "class PatchMlpMixer(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels:int, hidden_image_dim:tuple, patch_sizes:list, num_blocks:int, num_classes:int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_dim = hidden_image_dim ### must contain (C, H, W)\n",
    "        self.scaler = nn.UpsamplingBilinear2d(size=(self.img_dim[-2], self.img_dim[-1]))\n",
    "        \n",
    "        assert np.prod(patch_sizes) == hidden_image_dim[-1], \"The product of patches must equal image dimension\"\n",
    "        assert np.prod(patch_sizes) == hidden_image_dim[-2], \"The product of patches must equal image dimension\"\n",
    "        \n",
    "        ### find number of channel for input, the channel is \n",
    "        self.conv1x1 = nn.Conv2d(input_channels, self.img_dim[0], kernel_size=1, stride=1)\n",
    "        if input_channels == self.img_dim[0]:\n",
    "            self.conv1x1 = nn.Identity()\n",
    "        \n",
    "        self.mixer_blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            for ps in patch_sizes:\n",
    "                self.mixer_blocks.append(PatchMixerBlock(ps, self.img_dim[0]))\n",
    "                \n",
    "        self.mixer_blocks = nn.Sequential(*self.mixer_blocks)\n",
    "        self.linear = nn.Linear(np.prod(self.img_dim), num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = self.scaler(x)\n",
    "        x = self.conv1x1(x)\n",
    "        x = self.mixer_blocks(x)\n",
    "        x = self.linear(x.view(bs, -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_mixer = PatchMlpMixer(3, (5, 35, 35), patch_sizes=[5, 7], num_blocks=1, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchMlpMixer(\n",
       "  (scaler): UpsamplingBilinear2d(size=(35, 35), mode=bilinear)\n",
       "  (conv1x1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (mixer_blocks): Sequential(\n",
       "    (0): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((245,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=245, out_features=490, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=490, out_features=245, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=6125, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_mixer(torch.randn(1, 3, 32, 32)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Mixer : Channes per patch -> Initial:48 Final:144\n"
     ]
    }
   ],
   "source": [
    "model = MlpMixer(3, (9, 32, 32), patch_size=(4, 4), num_blocks=10, num_classes=10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  1097486\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpMixer(\n",
       "  (scaler): UpsamplingBilinear2d(size=(35, 35), mode=bilinear)\n",
       "  (conv1x1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (unfold): Unfold(kernel_size=(5, 5), dilation=1, padding=0, stride=(5, 5))\n",
       "  (mixer_blocks): Sequential(\n",
       "    (0): MixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): MixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): MixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): MixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): MixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): MixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): MixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): MixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): MixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=6125, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PatchMlpMixer(3, (3, 35, 35), patch_sizes=[5, 7], num_blocks=10, num_classes=10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  1137220\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchMlpMixer(\n",
       "  (scaler): UpsamplingBilinear2d(size=(35, 35), mode=bilinear)\n",
       "  (conv1x1): Identity()\n",
       "  (mixer_blocks): Sequential(\n",
       "    (0): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (17): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (18): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (19): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=3675, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  937160\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters())) \n",
    "## Patch ||  1137220\n",
    "## Mixer ||  1141703"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = f'mlp_mixer_c10_s{SEED}'\n",
    "model_name = f'patch_mixer2_c10_s{SEED}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT ={'train_stat':[], 'test_stat':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    STAT['train_stat'].append((epoch, train_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    STAT['test_stat'].append((epoch, test_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc\n",
    "        \n",
    "    with open(f\"./output/{model_name}_data.json\", 'w') as f:\n",
    "        json.dump(STAT, f, indent=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('./models'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:55<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 0 Loss: 1.798 | Acc: 37.696 18848/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.420 | Acc: 49.310 4931/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 1 Loss: 1.553 | Acc: 45.828 22914/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 1 Loss: 1.375 | Acc: 51.900 5190/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 2 Loss: 1.501 | Acc: 47.896 23948/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 2 Loss: 1.262 | Acc: 54.550 5455/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 3 Loss: 1.448 | Acc: 49.832 24916/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 3 Loss: 1.298 | Acc: 56.530 5653/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 4 Loss: 1.406 | Acc: 51.450 25725/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 4 Loss: 1.269 | Acc: 57.400 5740/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 5 Loss: 1.359 | Acc: 53.032 26516/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 5 Loss: 1.221 | Acc: 58.350 5835/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [02:07<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 6 Loss: 1.326 | Acc: 53.930 26965/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:11<00:00, 28.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 6 Loss: 1.354 | Acc: 55.340 5534/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [02:08<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 7 Loss: 1.296 | Acc: 54.858 27429/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 7 Loss: 1.099 | Acc: 61.740 6174/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 8 Loss: 1.270 | Acc: 56.158 28079/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 8 Loss: 1.087 | Acc: 61.090 6109/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 9 Loss: 1.250 | Acc: 56.664 28332/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 9 Loss: 1.121 | Acc: 61.710 6171/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:55<00:00, 13.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 10 Loss: 1.214 | Acc: 57.946 28973/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 10 Loss: 1.264 | Acc: 57.850 5785/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:56<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 11 Loss: 1.196 | Acc: 58.502 29251/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 11 Loss: 1.062 | Acc: 62.660 6266/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:56<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 12 Loss: 1.195 | Acc: 58.908 29454/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 28.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 12 Loss: 1.024 | Acc: 64.410 6441/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 13 Loss: 1.166 | Acc: 59.860 29930/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 13 Loss: 0.995 | Acc: 65.930 6593/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:58<00:00, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 14 Loss: 1.140 | Acc: 60.188 30094/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 14 Loss: 1.091 | Acc: 64.080 6408/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [02:06<00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 15 Loss: 1.119 | Acc: 61.232 30616/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:12<00:00, 25.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 15 Loss: 0.994 | Acc: 66.060 6606/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [02:14<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 16 Loss: 1.107 | Acc: 61.756 30878/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:12<00:00, 24.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 16 Loss: 0.987 | Acc: 65.820 6582/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [02:13<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 17 Loss: 1.106 | Acc: 61.730 30865/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:11<00:00, 26.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 17 Loss: 0.942 | Acc: 67.240 6724/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [02:02<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 18 Loss: 1.068 | Acc: 62.708 31354/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 18 Loss: 0.996 | Acc: 65.650 6565/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:56<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 19 Loss: 1.059 | Acc: 62.928 31464/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 19 Loss: 0.942 | Acc: 67.340 6734/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 20 Loss: 1.044 | Acc: 63.476 31738/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 20 Loss: 0.889 | Acc: 68.670 6867/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 21 Loss: 1.032 | Acc: 64.228 32114/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 21 Loss: 0.945 | Acc: 69.040 6904/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 22 Loss: 1.027 | Acc: 64.584 32292/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 22 Loss: 0.911 | Acc: 68.710 6871/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 23 Loss: 1.006 | Acc: 64.896 32448/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 23 Loss: 0.897 | Acc: 69.030 6903/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 24 Loss: 0.989 | Acc: 65.526 32763/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 24 Loss: 0.870 | Acc: 69.990 6999/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 25 Loss: 0.981 | Acc: 65.976 32988/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 25 Loss: 0.891 | Acc: 70.480 7048/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 26 Loss: 0.976 | Acc: 66.058 33029/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 26 Loss: 0.902 | Acc: 69.330 6933/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 27 Loss: 0.963 | Acc: 66.434 33217/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 27 Loss: 0.877 | Acc: 70.630 7063/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 28 Loss: 0.955 | Acc: 66.852 33426/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 28 Loss: 0.874 | Acc: 70.430 7043/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 29 Loss: 0.939 | Acc: 67.274 33637/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 29 Loss: 0.879 | Acc: 69.970 6997/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 30 Loss: 0.935 | Acc: 67.606 33803/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 30 Loss: 0.836 | Acc: 71.580 7158/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 31 Loss: 0.918 | Acc: 67.956 33978/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 31 Loss: 0.853 | Acc: 71.700 7170/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 32 Loss: 0.905 | Acc: 68.732 34366/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 32 Loss: 0.961 | Acc: 70.250 7025/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 33 Loss: 0.902 | Acc: 68.828 34414/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 33 Loss: 0.795 | Acc: 72.450 7245/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 34 Loss: 0.901 | Acc: 68.886 34443/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 34 Loss: 0.847 | Acc: 71.460 7146/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 35 Loss: 0.880 | Acc: 69.472 34736/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 35 Loss: 0.823 | Acc: 71.790 7179/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 36 Loss: 0.877 | Acc: 69.776 34888/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 36 Loss: 0.844 | Acc: 71.680 7168/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 37 Loss: 0.864 | Acc: 70.156 35078/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 37 Loss: 0.789 | Acc: 73.120 7312/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:58<00:00, 13.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 38 Loss: 0.858 | Acc: 70.214 35107/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 28.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 38 Loss: 0.893 | Acc: 71.410 7141/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:58<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 39 Loss: 0.855 | Acc: 70.406 35203/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 39 Loss: 0.767 | Acc: 73.910 7391/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:55<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 40 Loss: 0.844 | Acc: 70.790 35395/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 40 Loss: 0.794 | Acc: 72.760 7276/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:55<00:00, 13.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 41 Loss: 0.829 | Acc: 71.294 35647/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 41 Loss: 0.793 | Acc: 74.060 7406/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:55<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 42 Loss: 0.820 | Acc: 71.578 35789/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 42 Loss: 0.767 | Acc: 74.070 7407/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:55<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 43 Loss: 0.817 | Acc: 71.838 35919/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 43 Loss: 0.754 | Acc: 74.330 7433/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 44 Loss: 0.811 | Acc: 72.094 36047/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:11<00:00, 28.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 44 Loss: 0.756 | Acc: 73.430 7343/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [02:09<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 45 Loss: 0.805 | Acc: 72.128 36064/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:11<00:00, 28.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 45 Loss: 0.815 | Acc: 73.000 7300/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [02:09<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 46 Loss: 0.806 | Acc: 72.134 36067/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 46 Loss: 0.781 | Acc: 73.490 7349/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [02:09<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 47 Loss: 0.785 | Acc: 72.938 36469/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:11<00:00, 28.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 47 Loss: 0.827 | Acc: 73.810 7381/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [02:09<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 48 Loss: 0.783 | Acc: 72.828 36414/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 28.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 48 Loss: 0.746 | Acc: 74.680 7468/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [02:09<00:00, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 49 Loss: 0.778 | Acc: 73.232 36616/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:11<00:00, 27.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 49 Loss: 0.827 | Acc: 71.950 7195/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████▌                                    | 424/1563 [00:35<01:29, 12.74it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 67 Loss: 0.683 | Acc: 76.220 38110/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 67 Loss: 0.688 | Acc: 77.300 7730/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 68 Loss: 0.671 | Acc: 76.728 38364/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 68 Loss: 0.672 | Acc: 78.380 7838/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 69 Loss: 0.658 | Acc: 77.314 38657/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 69 Loss: 0.690 | Acc: 77.590 7759/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 70 Loss: 0.665 | Acc: 77.110 38555/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 70 Loss: 0.676 | Acc: 77.780 7778/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████▉                                     | 405/1563 [00:29<01:24, 13.65it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 88 Loss: 0.602 | Acc: 79.850 7985/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 89 Loss: 0.576 | Acc: 80.120 40060/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 89 Loss: 0.622 | Acc: 78.970 7897/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 90 Loss: 0.568 | Acc: 80.354 40177/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 90 Loss: 0.592 | Acc: 80.220 8022/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 91 Loss: 0.564 | Acc: 80.450 40225/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 91 Loss: 0.605 | Acc: 79.910 7991/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████                         | 785/1563 [00:57<00:56, 13.66it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 110 Loss: 0.481 | Acc: 83.244 41622/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 110 Loss: 0.582 | Acc: 81.370 8137/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 111 Loss: 0.485 | Acc: 83.204 41602/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 111 Loss: 0.558 | Acc: 81.620 8162/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 112 Loss: 0.475 | Acc: 83.466 41733/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 112 Loss: 0.581 | Acc: 81.340 8134/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████▋                     | 895/1563 [01:05<00:49, 13.60it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 130 Loss: 0.406 | Acc: 85.800 42900/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 130 Loss: 0.557 | Acc: 82.710 8271/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 131 Loss: 0.402 | Acc: 85.894 42947/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 131 Loss: 0.545 | Acc: 82.600 8260/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 132 Loss: 0.404 | Acc: 85.592 42796/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 132 Loss: 0.555 | Acc: 82.710 8271/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 133 Loss: 0.398 | Acc: 86.056 43028/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 133 Loss: 0.548 | Acc: 82.370 8237/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████                                       | 345/1563 [00:25<01:29, 13.66it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 150 Loss: 0.348 | Acc: 87.806 43903/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 150 Loss: 0.551 | Acc: 82.420 8242/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 151 Loss: 0.346 | Acc: 87.988 43994/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 151 Loss: 0.534 | Acc: 83.290 8329/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 152 Loss: 0.345 | Acc: 87.856 43928/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 152 Loss: 0.523 | Acc: 83.650 8365/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 153 Loss: 0.337 | Acc: 88.142 44071/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 153 Loss: 0.543 | Acc: 83.580 8358/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████▉                                 | 531/1563 [00:38<01:15, 13.64it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 169 Loss: 0.308 | Acc: 89.324 44662/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 169 Loss: 0.543 | Acc: 83.650 8365/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 170 Loss: 0.304 | Acc: 89.286 44643/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 170 Loss: 0.533 | Acc: 83.850 8385/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 171 Loss: 0.301 | Acc: 89.570 44785/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 171 Loss: 0.549 | Acc: 83.860 8386/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 172 Loss: 0.303 | Acc: 89.352 44676/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 172 Loss: 0.537 | Acc: 83.670 8367/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 173 Loss: 0.301 | Acc: 89.404 44702/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 173 Loss: 0.543 | Acc: 83.860 8386/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 174 Loss: 0.302 | Acc: 89.332 44666/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 174 Loss: 0.541 | Acc: 83.910 8391/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 175 Loss: 0.296 | Acc: 89.600 44800/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 175 Loss: 0.538 | Acc: 83.840 8384/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 176 Loss: 0.296 | Acc: 89.540 44770/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 176 Loss: 0.537 | Acc: 83.980 8398/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 177 Loss: 0.294 | Acc: 89.772 44886/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 177 Loss: 0.536 | Acc: 83.730 8373/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 178 Loss: 0.296 | Acc: 89.524 44762/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 178 Loss: 0.541 | Acc: 83.960 8396/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 179 Loss: 0.293 | Acc: 89.794 44897/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 179 Loss: 0.542 | Acc: 83.840 8384/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 180 Loss: 0.290 | Acc: 89.766 44883/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 180 Loss: 0.539 | Acc: 83.930 8393/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 182 Loss: 0.293 | Acc: 89.798 44899/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 182 Loss: 0.542 | Acc: 83.890 8389/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 183 Loss: 0.288 | Acc: 89.804 44902/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 183 Loss: 0.541 | Acc: 83.990 8399/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 184 Loss: 0.290 | Acc: 89.902 44951/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 184 Loss: 0.541 | Acc: 83.980 8398/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1563/1563 [01:54<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 185 Loss: 0.290 | Acc: 89.784 44892/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▉                                               | 30/313 [00:01<00:09, 30.60it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Train the whole damn thing\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+EPOCHS): ## for 200 epochs\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.08"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84.08, 190)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "best_acc = checkpoint['acc']\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "best_acc, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchMlpMixer(\n",
       "  (conv1x1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (mixer_blocks): Sequential(\n",
       "    (0): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((45,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=45, out_features=90, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=90, out_features=45, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=80, out_features=160, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=160, out_features=80, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((45,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=45, out_features=90, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=90, out_features=45, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=80, out_features=160, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=160, out_features=80, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((45,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=45, out_features=90, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=90, out_features=45, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=80, out_features=160, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=160, out_features=80, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((45,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=45, out_features=90, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=90, out_features=45, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=80, out_features=160, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=160, out_features=80, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((45,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=45, out_features=90, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=90, out_features=45, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=80, out_features=160, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=160, out_features=80, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((45,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=45, out_features=90, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=90, out_features=45, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=80, out_features=160, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=160, out_features=80, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (17): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (18): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((45,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=45, out_features=90, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=90, out_features=45, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (19): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=80, out_features=160, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=160, out_features=80, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (20): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (21): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((45,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=45, out_features=90, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=90, out_features=45, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (22): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=80, out_features=160, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=160, out_features=80, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (23): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (24): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((45,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=45, out_features=90, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=90, out_features=45, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (25): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=80, out_features=160, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=160, out_features=80, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (26): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (27): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((45,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=45, out_features=90, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=90, out_features=45, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (28): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=80, out_features=160, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=160, out_features=80, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (29): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((125,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=125, out_features=250, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=250, out_features=125, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=18000, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_stat': [(0, 1.7984710254504448, 37.696),\n",
       "  (1, 1.5529344635214168, 45.828),\n",
       "  (2, 1.5013800998261855, 47.896),\n",
       "  (3, 1.4476978307874708, 49.832),\n",
       "  (4, 1.4061498146597118, 51.45),\n",
       "  (5, 1.359452192019135, 53.032),\n",
       "  (6, 1.3257629438920122, 53.93),\n",
       "  (7, 1.2964890681621897, 54.858),\n",
       "  (8, 1.2703649810469464, 56.158),\n",
       "  (9, 1.249518721933481, 56.664),\n",
       "  (10, 1.2136063165033162, 57.946),\n",
       "  (11, 1.1964740671565421, 58.502),\n",
       "  (12, 1.195441531280791, 58.908),\n",
       "  (13, 1.1658616149112802, 59.86),\n",
       "  (14, 1.140263609716851, 60.188),\n",
       "  (15, 1.1192025954877423, 61.232),\n",
       "  (16, 1.1070720252324127, 61.756),\n",
       "  (17, 1.1062602438342473, 61.73),\n",
       "  (18, 1.068259621555044, 62.708),\n",
       "  (19, 1.0588978678655412, 62.928),\n",
       "  (20, 1.0438884792996002, 63.476),\n",
       "  (21, 1.0318751508657245, 64.228),\n",
       "  (22, 1.0267509796149594, 64.584),\n",
       "  (23, 1.0062313425716345, 64.896),\n",
       "  (24, 0.9887511227387156, 65.526),\n",
       "  (25, 0.981249506494134, 65.976),\n",
       "  (26, 0.9764000438797268, 66.058),\n",
       "  (27, 0.9625826107525169, 66.434),\n",
       "  (28, 0.954623668489743, 66.852),\n",
       "  (29, 0.9392106771202173, 67.274),\n",
       "  (30, 0.9351206357404351, 67.606),\n",
       "  (31, 0.9178405736626072, 67.956),\n",
       "  (32, 0.9053992357150302, 68.732),\n",
       "  (33, 0.9017022183249566, 68.828),\n",
       "  (34, 0.9013852030896866, 68.886),\n",
       "  (35, 0.8803125480696397, 69.472),\n",
       "  (36, 0.8772046035936225, 69.776),\n",
       "  (37, 0.8639046221075345, 70.156),\n",
       "  (38, 0.8581586194701936, 70.214),\n",
       "  (39, 0.8554661711743453, 70.406),\n",
       "  (40, 0.8442688092007823, 70.79),\n",
       "  (41, 0.8286161944222465, 71.294),\n",
       "  (42, 0.8204678469793353, 71.578),\n",
       "  (43, 0.8166783353360281, 71.838),\n",
       "  (44, 0.8110247098686446, 72.094),\n",
       "  (45, 0.8054019083159899, 72.128),\n",
       "  (46, 0.8055660775931157, 72.134),\n",
       "  (47, 0.7852806250254313, 72.938),\n",
       "  (48, 0.7831508955433821, 72.828),\n",
       "  (49, 0.7780067090300208, 73.232),\n",
       "  (50, 0.7807885745131504, 73.168),\n",
       "  (51, 0.7712171575005666, 73.438),\n",
       "  (52, 0.7536637481595184, 73.804),\n",
       "  (53, 0.7586306917480529, 73.856),\n",
       "  (54, 0.7400688631215769, 74.6),\n",
       "  (55, 0.7436266441186574, 74.384),\n",
       "  (56, 0.732747590692472, 74.586),\n",
       "  (57, 0.7262885770829, 74.804),\n",
       "  (58, 0.7205221923932157, 74.902),\n",
       "  (59, 0.7165039568205179, 75.158),\n",
       "  (60, 0.7128159598002278, 75.308),\n",
       "  (61, 0.7077223124198249, 75.594),\n",
       "  (62, 0.7058486622625334, 75.536),\n",
       "  (63, 0.6955287761781281, 75.916),\n",
       "  (64, 0.6888333234414029, 76.072),\n",
       "  (65, 0.6832106026391226, 76.276),\n",
       "  (66, 0.6809904031260076, 76.462),\n",
       "  (67, 0.6829851069800456, 76.22),\n",
       "  (68, 0.6707956287163767, 76.728),\n",
       "  (69, 0.6584825493628904, 77.314),\n",
       "  (70, 0.6647926628284552, 77.11),\n",
       "  (71, 0.6550993359411137, 77.282),\n",
       "  (72, 0.6543939619093313, 77.386),\n",
       "  (73, 0.6379825453192319, 77.882),\n",
       "  (74, 0.6408922137622259, 77.798),\n",
       "  (75, 0.6341995133548232, 77.908),\n",
       "  (76, 0.6310974922858212, 78.406),\n",
       "  (77, 0.6324288253877991, 78.236),\n",
       "  (78, 0.6201450659137312, 78.572),\n",
       "  (79, 0.6195159268756746, 78.574),\n",
       "  (80, 0.6180272338219507, 78.518),\n",
       "  (81, 0.6082679593145505, 78.94),\n",
       "  (82, 0.6028611342627043, 78.986),\n",
       "  (83, 0.5993289907754268, 79.362),\n",
       "  (84, 0.5929699168657921, 79.484),\n",
       "  (85, 0.5905101594639679, 79.174),\n",
       "  (86, 0.5837152339732579, 79.698),\n",
       "  (87, 0.579252998043693, 79.98),\n",
       "  (88, 0.5775483529955168, 79.972),\n",
       "  (89, 0.5759781319373933, 80.12),\n",
       "  (90, 0.5683150501374777, 80.354),\n",
       "  (91, 0.5635960497395853, 80.45),\n",
       "  (92, 0.5594977778707341, 80.648),\n",
       "  (93, 0.5616837914458697, 80.506),\n",
       "  (94, 0.5528095065880035, 80.776),\n",
       "  (95, 0.5496845401046525, 80.966),\n",
       "  (96, 0.5411762426525678, 81.09),\n",
       "  (97, 0.5393941150269139, 81.272),\n",
       "  (98, 0.5328764406653146, 81.476),\n",
       "  (99, 0.5278872194117792, 81.654),\n",
       "  (100, 0.5307562697538183, 81.374),\n",
       "  (101, 0.5215015758498692, 81.782),\n",
       "  (102, 0.516107138720599, 82.144),\n",
       "  (103, 0.5158302130860468, 81.992),\n",
       "  (104, 0.5111000830127654, 82.186),\n",
       "  (105, 0.5069740318186148, 82.21),\n",
       "  (106, 0.4938799059942069, 82.792),\n",
       "  (107, 0.4942496233188946, 82.64),\n",
       "  (108, 0.49161766848919564, 82.918),\n",
       "  (109, 0.484643370632895, 83.066),\n",
       "  (110, 0.4812630560017898, 83.244),\n",
       "  (111, 0.4849976201470815, 83.204),\n",
       "  (112, 0.47478897198415, 83.466),\n",
       "  (113, 0.4762035053478398, 83.586),\n",
       "  (114, 0.4660324653561727, 83.784),\n",
       "  (115, 0.4621252460799687, 83.642),\n",
       "  (116, 0.461657181296376, 83.796),\n",
       "  (117, 0.45376153629671206, 84.216),\n",
       "  (118, 0.455666250903791, 84.026),\n",
       "  (119, 0.4504141825479494, 84.184),\n",
       "  (120, 0.443439243364929, 84.538),\n",
       "  (121, 0.4374494845105987, 84.756),\n",
       "  (122, 0.43972680859758695, 84.47),\n",
       "  (123, 0.43427268350383674, 84.598),\n",
       "  (124, 0.4378273126145471, 84.654),\n",
       "  (125, 0.4294655636162691, 84.902),\n",
       "  (126, 0.42284369799746435, 85.188),\n",
       "  (127, 0.41942521005926114, 85.24),\n",
       "  (128, 0.41492683795338553, 85.574),\n",
       "  (129, 0.4149148953972493, 85.48),\n",
       "  (130, 0.4056558229257987, 85.8),\n",
       "  (131, 0.4018371855018998, 85.894),\n",
       "  (132, 0.4037903063356762, 85.592),\n",
       "  (133, 0.3979702283338103, 86.056),\n",
       "  (134, 0.39529186360399765, 86.244),\n",
       "  (135, 0.3911124829701026, 86.3),\n",
       "  (136, 0.39642838898733956, 86.194),\n",
       "  (137, 0.38231498944696446, 86.45),\n",
       "  (138, 0.3827489431964154, 86.552),\n",
       "  (139, 0.38116943654118635, 86.644),\n",
       "  (140, 0.37476229937943756, 86.952),\n",
       "  (141, 0.3777823015041673, 86.746),\n",
       "  (142, 0.3708737718629021, 86.88),\n",
       "  (143, 0.3662159945231863, 87.148),\n",
       "  (144, 0.3715101027776626, 87.082),\n",
       "  (145, 0.3628622103775646, 87.294),\n",
       "  (146, 0.35908539448069293, 87.37),\n",
       "  (147, 0.35524617072125697, 87.398),\n",
       "  (148, 0.3558597123263474, 87.6),\n",
       "  (149, 0.3498156414446507, 87.734),\n",
       "  (150, 0.3480250509199582, 87.806),\n",
       "  (151, 0.34611708681818315, 87.988),\n",
       "  (152, 0.34481215988710684, 87.856),\n",
       "  (153, 0.33658746679528584, 88.142),\n",
       "  (154, 0.33784353677052303, 88.24),\n",
       "  (155, 0.3369840680122833, 88.22),\n",
       "  (156, 0.32712613631299653, 88.47),\n",
       "  (157, 0.3240290653849556, 88.594),\n",
       "  (158, 0.3260782568912741, 88.55),\n",
       "  (159, 0.3231948434934735, 88.644),\n",
       "  (160, 0.32339801236996646, 88.584),\n",
       "  (161, 0.3208700316092351, 88.818),\n",
       "  (162, 0.3217870951394812, 88.568),\n",
       "  (163, 0.31831681154673097, 88.69),\n",
       "  (164, 0.31565178148996653, 88.986),\n",
       "  (165, 0.3133103052322215, 88.998),\n",
       "  (166, 0.3119375986581572, 89.204),\n",
       "  (167, 0.3112260707542634, 89.048),\n",
       "  (168, 0.3068711952909932, 89.28),\n",
       "  (169, 0.3075432728925959, 89.324),\n",
       "  (170, 0.3041117072095874, 89.286),\n",
       "  (171, 0.3013223003970265, 89.57),\n",
       "  (172, 0.3030778317451858, 89.352),\n",
       "  (173, 0.3012128933615892, 89.404),\n",
       "  (174, 0.301668421210994, 89.332),\n",
       "  (175, 0.29637421635637967, 89.6),\n",
       "  (176, 0.29621059664775945, 89.54),\n",
       "  (177, 0.2943463371548222, 89.772),\n",
       "  (178, 0.2963102668147208, 89.524),\n",
       "  (179, 0.29330364450626434, 89.794),\n",
       "  (180, 0.289971733030816, 89.766),\n",
       "  (181, 0.29474474763305847, 89.77),\n",
       "  (182, 0.2931397347350534, 89.798),\n",
       "  (183, 0.28786005972338197, 89.804),\n",
       "  (184, 0.29046307844053226, 89.902),\n",
       "  (185, 0.2904032332309053, 89.784),\n",
       "  (186, 0.2863249121208795, 89.926),\n",
       "  (187, 0.2837984018642706, 90.05),\n",
       "  (188, 0.28651269018335446, 90.098),\n",
       "  (189, 0.28984192505202383, 89.86),\n",
       "  (190, 0.2834658781358506, 90.036),\n",
       "  (191, 0.2873515824257603, 89.974),\n",
       "  (192, 0.28503027223098265, 89.864),\n",
       "  (193, 0.28883251343315713, 89.876),\n",
       "  (194, 0.281139798367054, 90.224),\n",
       "  (195, 0.28489595930963774, 89.96),\n",
       "  (196, 0.2843083330571308, 90.148),\n",
       "  (197, 0.2843481880718138, 90.048),\n",
       "  (198, 0.2879154310988945, 89.91),\n",
       "  (199, 0.28449281979225916, 89.938)],\n",
       " 'test_stat': [(0, 1.4203009253111891, 49.31),\n",
       "  (1, 1.374701457663466, 51.9),\n",
       "  (2, 1.2617056428814848, 54.55),\n",
       "  (3, 1.2984153597880477, 56.53),\n",
       "  (4, 1.268752632049707, 57.4),\n",
       "  (5, 1.2209298624017368, 58.35),\n",
       "  (6, 1.3541131055774018, 55.34),\n",
       "  (7, 1.0994691884936616, 61.74),\n",
       "  (8, 1.0868206637355085, 61.09),\n",
       "  (9, 1.1209985707133723, 61.71),\n",
       "  (10, 1.2644765439886636, 57.85),\n",
       "  (11, 1.0615358613550472, 62.66),\n",
       "  (12, 1.0240792726365904, 64.41),\n",
       "  (13, 0.995311508734767, 65.93),\n",
       "  (14, 1.0908701680719661, 64.08),\n",
       "  (15, 0.9939892572907213, 66.06),\n",
       "  (16, 0.9868884153259448, 65.82),\n",
       "  (17, 0.9424199799950511, 67.24),\n",
       "  (18, 0.9961304867419952, 65.65),\n",
       "  (19, 0.9415734590242465, 67.34),\n",
       "  (20, 0.8894704141365454, 68.67),\n",
       "  (21, 0.9449241227996997, 69.04),\n",
       "  (22, 0.9111812372748463, 68.71),\n",
       "  (23, 0.8967502541816272, 69.03),\n",
       "  (24, 0.8703834062186293, 69.99),\n",
       "  (25, 0.8910283900487918, 70.48),\n",
       "  (26, 0.901533238137492, 69.33),\n",
       "  (27, 0.8770043537639581, 70.63),\n",
       "  (28, 0.8740730271362268, 70.43),\n",
       "  (29, 0.8787948562504765, 69.97),\n",
       "  (30, 0.8357560892645924, 71.58),\n",
       "  (31, 0.8528145795432143, 71.7),\n",
       "  (32, 0.9612277590047819, 70.25),\n",
       "  (33, 0.7953549060768212, 72.45),\n",
       "  (34, 0.8472034501762816, 71.46),\n",
       "  (35, 0.8230417349848884, 71.79),\n",
       "  (36, 0.8443021415331112, 71.68),\n",
       "  (37, 0.7892177311566692, 73.12),\n",
       "  (38, 0.8925066000927752, 71.41),\n",
       "  (39, 0.7671619775577094, 73.91),\n",
       "  (40, 0.7936942478338369, 72.76),\n",
       "  (41, 0.7925059118400366, 74.06),\n",
       "  (42, 0.7670924029411218, 74.07),\n",
       "  (43, 0.7544800314469079, 74.33),\n",
       "  (44, 0.755716592549516, 73.43),\n",
       "  (45, 0.8150685229621375, 73.0),\n",
       "  (46, 0.780854949459862, 73.49),\n",
       "  (47, 0.8273164574711468, 73.81),\n",
       "  (48, 0.7461540090580718, 74.68),\n",
       "  (49, 0.8267871412796716, 71.95),\n",
       "  (50, 0.8154695922383866, 73.16),\n",
       "  (51, 0.7295975792712678, 75.15),\n",
       "  (52, 0.7677666243082418, 74.3),\n",
       "  (53, 0.7364079646123484, 75.93),\n",
       "  (54, 0.7161056068949044, 76.39),\n",
       "  (55, 0.7468190278869848, 74.78),\n",
       "  (56, 0.6711762429426272, 77.54),\n",
       "  (57, 0.7198031909359149, 76.18),\n",
       "  (58, 0.7261178603473182, 76.36),\n",
       "  (59, 0.7230740492336285, 76.14),\n",
       "  (60, 0.6969589390122471, 76.34),\n",
       "  (61, 0.6964481979513321, 76.37),\n",
       "  (62, 0.6977489857247081, 76.9),\n",
       "  (63, 0.671252891945001, 77.26),\n",
       "  (64, 0.6879215129552939, 77.16),\n",
       "  (65, 0.6659490048123625, 77.47),\n",
       "  (66, 0.6597014207142992, 78.31),\n",
       "  (67, 0.6881797180865139, 77.3),\n",
       "  (68, 0.6716218466004624, 78.38),\n",
       "  (69, 0.6902878861457776, 77.59),\n",
       "  (70, 0.6760586319735256, 77.78),\n",
       "  (71, 0.7268727689314955, 76.0),\n",
       "  (72, 0.6502493924131028, 78.34),\n",
       "  (73, 0.6599585263492962, 78.65),\n",
       "  (74, 0.6855573013853341, 78.12),\n",
       "  (75, 0.8464270778738272, 75.74),\n",
       "  (76, 0.6640302317496687, 78.33),\n",
       "  (77, 0.660813012395423, 78.42),\n",
       "  (78, 0.6816892748633132, 78.07),\n",
       "  (79, 0.6622211440397908, 78.89),\n",
       "  (80, 0.7829423218299025, 74.16),\n",
       "  (81, 0.6474667458107677, 78.47),\n",
       "  (82, 0.7172540636679616, 77.53),\n",
       "  (83, 0.6423403546452141, 78.92),\n",
       "  (84, 0.6208829935461568, 79.33),\n",
       "  (85, 0.6053442058567041, 80.27),\n",
       "  (86, 0.6101052415923188, 79.36),\n",
       "  (87, 0.6325948882026794, 79.5),\n",
       "  (88, 0.6022857139571406, 79.85),\n",
       "  (89, 0.6216002817923268, 78.97),\n",
       "  (90, 0.5916484854758357, 80.22),\n",
       "  (91, 0.6050692943338388, 79.91),\n",
       "  (92, 0.606751971446668, 80.32),\n",
       "  (93, 0.6040236045377323, 80.59),\n",
       "  (94, 0.6173752275899577, 80.12),\n",
       "  (95, 0.6148127323617569, 80.15),\n",
       "  (96, 0.6066374611169004, 80.09),\n",
       "  (97, 0.6533304411953631, 79.36),\n",
       "  (98, 0.5840074528996556, 81.05),\n",
       "  (99, 0.600082865919168, 80.74),\n",
       "  (100, 0.6165821264727047, 80.38),\n",
       "  (101, 0.6350262718269238, 79.94),\n",
       "  (102, 0.6019780393035267, 80.33),\n",
       "  (103, 0.5822640044715839, 80.85),\n",
       "  (104, 0.5939217441664717, 80.24),\n",
       "  (105, 0.6136863750105087, 80.18),\n",
       "  (106, 0.5780922170645132, 81.3),\n",
       "  (107, 0.5900544816027053, 81.19),\n",
       "  (108, 0.5732730082667674, 81.39),\n",
       "  (109, 0.624301166484912, 79.69),\n",
       "  (110, 0.5816165753922904, 81.37),\n",
       "  (111, 0.5581780804422336, 81.62),\n",
       "  (112, 0.58087559870352, 81.34),\n",
       "  (113, 0.5777761558183847, 81.66),\n",
       "  (114, 0.5733793931552016, 81.69),\n",
       "  (115, 0.5752148905310768, 81.76),\n",
       "  (116, 0.55879401172788, 81.61),\n",
       "  (117, 0.5746299422587069, 81.89),\n",
       "  (118, 0.5618475333522683, 82.26),\n",
       "  (119, 0.5669447954375142, 82.05),\n",
       "  (120, 0.5748855747020664, 82.09),\n",
       "  (121, 0.5470216393280334, 82.45),\n",
       "  (122, 0.5736233020028748, 81.96),\n",
       "  (123, 0.5475324839115524, 82.93),\n",
       "  (124, 0.5531532268721265, 82.42),\n",
       "  (125, 0.5398485213518143, 82.59),\n",
       "  (126, 0.5458333992158262, 82.63),\n",
       "  (127, 0.5453802895384093, 82.75),\n",
       "  (128, 0.5584501124466189, 82.53),\n",
       "  (129, 0.5465940033046963, 82.7),\n",
       "  (130, 0.556937901094889, 82.71),\n",
       "  (131, 0.5446354330014497, 82.6),\n",
       "  (132, 0.5551826596831362, 82.71),\n",
       "  (133, 0.5477160094216609, 82.37),\n",
       "  (134, 0.5416403901510345, 82.99),\n",
       "  (135, 0.5472569762232204, 83.22),\n",
       "  (136, 0.540662378548814, 82.91),\n",
       "  (137, 0.567793951842922, 82.66),\n",
       "  (138, 0.5321889989577924, 82.81),\n",
       "  (139, 0.5399638505789418, 83.22),\n",
       "  (140, 0.5328169439356929, 82.66),\n",
       "  (141, 0.5370863489449595, 82.87),\n",
       "  (142, 0.5474088918001127, 82.87),\n",
       "  (143, 0.5377781144536722, 83.23),\n",
       "  (144, 0.5313739373137395, 83.22),\n",
       "  (145, 0.5420497003407143, 83.24),\n",
       "  (146, 0.5566166332021308, 83.22),\n",
       "  (147, 0.5279630513998647, 83.26),\n",
       "  (148, 0.5413054454678925, 83.16),\n",
       "  (149, 0.5305883696142096, 83.68),\n",
       "  (150, 0.5511917341679049, 82.42),\n",
       "  (151, 0.5339427597749348, 83.29),\n",
       "  (152, 0.5225188065403567, 83.65),\n",
       "  (153, 0.5427216707755582, 83.58),\n",
       "  (154, 0.5401008089129536, 83.33),\n",
       "  (155, 0.5345536408761439, 83.55),\n",
       "  (156, 0.5388465615840384, 83.81),\n",
       "  (157, 0.54045651912594, 83.49),\n",
       "  (158, 0.5482953970853132, 83.5),\n",
       "  (159, 0.5473584504173206, 83.68),\n",
       "  (160, 0.5365064095574826, 83.5),\n",
       "  (161, 0.5498540763752148, 83.55),\n",
       "  (162, 0.537015439746098, 83.79),\n",
       "  (163, 0.5381937463062639, 83.73),\n",
       "  (164, 0.5444563775540541, 83.7),\n",
       "  (165, 0.543225533522356, 83.9),\n",
       "  (166, 0.5417793124152449, 83.74),\n",
       "  (167, 0.5368170540172833, 83.98),\n",
       "  (168, 0.5355026615551486, 83.81),\n",
       "  (169, 0.5426810714669121, 83.65),\n",
       "  (170, 0.5325086035619909, 83.85),\n",
       "  (171, 0.5486937862948869, 83.86),\n",
       "  (172, 0.53736425714847, 83.67),\n",
       "  (173, 0.5432261706303103, 83.86),\n",
       "  (174, 0.5405067902641555, 83.91),\n",
       "  (175, 0.5382171053046616, 83.84),\n",
       "  (176, 0.5371769720468277, 83.98),\n",
       "  (177, 0.5356202733616668, 83.73),\n",
       "  (178, 0.5408248225578104, 83.96),\n",
       "  (179, 0.5420193527215205, 83.84),\n",
       "  (180, 0.5394550364095563, 83.93),\n",
       "  (181, 0.5380170266277874, 83.87),\n",
       "  (182, 0.5418561401125341, 83.89),\n",
       "  (183, 0.5413422985627248, 83.99),\n",
       "  (184, 0.5414495346502374, 83.98),\n",
       "  (185, 0.5379262892440104, 83.89),\n",
       "  (186, 0.5411879824944579, 83.96),\n",
       "  (187, 0.5430139543863531, 83.89),\n",
       "  (188, 0.5410171045234409, 84.04),\n",
       "  (189, 0.5413809202063959, 84.07),\n",
       "  (190, 0.5406164385783024, 84.08),\n",
       "  (191, 0.5403290303370443, 83.98),\n",
       "  (192, 0.5402919974047155, 84.0),\n",
       "  (193, 0.5395734170422005, 83.96),\n",
       "  (194, 0.540570170329973, 83.93),\n",
       "  (195, 0.5404385035030377, 83.94),\n",
       "  (196, 0.5403682898741942, 84.0),\n",
       "  (197, 0.5404836657329108, 83.99),\n",
       "  (198, 0.5404865027854617, 84.0),\n",
       "  (199, 0.5404950762137818, 84.0)]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stat = np.array(STAT['train_stat'])\n",
    "test_stat = np.array(STAT['test_stat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_stat[:,1], label='train')\n",
    "plt.plot(test_stat[:,1], label='test')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"./output/plots/{model_name}_loss.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_stat[:,2], label='train')\n",
    "plt.plot(test_stat[:,2], label='test')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"./output/plots/{model_name}_accs.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
