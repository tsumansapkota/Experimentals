{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets\n",
    "\n",
    "from typing import Union, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mylibrary.datasets as datasets\n",
    "import mylibrary.nnlib as tnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.FashionMNIST()\n",
    "# mnist.download_mnist()\n",
    "# mnist.save_mnist()\n",
    "train_data, train_label_, test_data, test_label_ = mnist.load()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "# train_label = tnn.Logits.index_to_logit(train_label_)\n",
    "train_size = len(train_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting data to pytorch format\n",
    "train_data = torch.Tensor(train_data)\n",
    "test_data = torch.Tensor(test_data)\n",
    "train_label = torch.LongTensor(train_label_)\n",
    "test_label = torch.LongTensor(test_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         print(idx)\n",
    "        img, lbl = self.data[idx], self.label[idx]\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST_Dataset(train_data, train_label)\n",
    "test_dataset = MNIST_Dataset(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                    num_workers=4, \n",
    "                                    batch_size=batch_size, \n",
    "                                    shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                    num_workers=1, \n",
    "                                    batch_size=batch_size, \n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftScale(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.scaler = nn.Parameter(torch.ones(1, input_dim))\n",
    "        self.shifter = nn.Parameter(torch.zeros(1, input_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return (x+self.shifter)*self.scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DistanceTransform(nn.Module):\n",
    "    \n",
    "#     def __init__(self, input_dim, num_centers):\n",
    "#         super().__init__()\n",
    "#         self.input_dim = input_dim\n",
    "#         self.num_centers = num_centers\n",
    "        \n",
    "# #         self.centers = torch.randn(num_centers, input_dim)/2.\n",
    "#         self.centers = torch.rand(num_centers, input_dim)\n",
    "#         self.centers = nn.Parameter(self.centers)\n",
    "# #         self.scaler = nn.Parameter(torch.Tensor([1.0]))\n",
    "# #         self.layernorm = nn.LayerNorm(num_centers, elementwise_affine=False)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = x[:, :self.input_dim]\n",
    "#         dists = torch.cdist(x, self.centers)\n",
    "        \n",
    "#         ### normalize similar to UMAP\n",
    "# #         dists = dists-dists.min(dim=1, keepdim=True)[0]\n",
    "#         dists = dists-dists.mean(dim=1, keepdim=True)\n",
    "#         dists = dists/dists.std(dim=1, keepdim=True)\n",
    "\n",
    "# #         dists = self.layernorm(dists)\n",
    "\n",
    "# #         dists = torch.exp(-(dists**2) * self.scaler)\n",
    "# #         dists = torch.softmax(-dists*self.scaler, dim=1)\n",
    "        \n",
    "#         return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### shift normalized dists towards 0 for sparse activation with exponential\n",
    "class DistanceTransform(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, p=2):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.p = p\n",
    "        \n",
    "#         self.centers = torch.randn(num_centers, input_dim)/2.\n",
    "        self.centers = torch.rand(num_centers, input_dim)\n",
    "        self.centers = nn.Parameter(self.centers)\n",
    "        \n",
    "        self.scaler = nn.Parameter(torch.ones(1, num_centers)*2/3)\n",
    "        self.bias = nn.Parameter(torch.ones(1, num_centers)*-0.1)# if bias else None\n",
    "        \n",
    "        self.layernorm = nn.LayerNorm(num_centers, elementwise_affine=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         x = x[:, :self.input_dim]\n",
    "        dists = torch.cdist(x, self.centers)\n",
    "        \n",
    "        ### normalize similar to UMAP\n",
    "#         dists = dists-dists.min(dim=1, keepdim=True)[0]\n",
    "        dists = dists-dists.mean(dim=1, keepdim=True)\n",
    "        dists = dists/dists.std(dim=1, keepdim=True)\n",
    "\n",
    "#         dists = self.layernorm(dists)\n",
    "\n",
    "#         dists = torch.exp(-dists*self.scaler)+self.bias\n",
    "        dists = torch.exp((-dists-3)*self.scaler)+self.bias\n",
    "    \n",
    "#         dists = torch.softmax(-dists*self.scaler, dim=1)\n",
    "\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## bias to basic dist\n",
    "# class DistanceTransform(nn.Module):\n",
    "    \n",
    "#     def __init__(self, input_dim, num_centers, p=2, bias=True):\n",
    "#         super().__init__()\n",
    "#         self.input_dim = input_dim\n",
    "#         self.num_centers = num_centers\n",
    "#         self.p = p\n",
    "#         self.bias = nn.Parameter(torch.zeros(1, num_centers)) if bias else None\n",
    "        \n",
    "# #         self.centers = torch.randn(num_centers, input_dim)/2.\n",
    "#         self.centers = torch.rand(num_centers, input_dim)\n",
    "#         self.centers = nn.Parameter(self.centers)\n",
    "# #         self.scaler = nn.Parameter(torch.Tensor([1.0]))\n",
    "# #         self.layernorm = nn.LayerNorm(num_centers, elementwise_affine=False)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = x[:, :self.input_dim]\n",
    "#         dists = torch.cdist(x, self.centers)\n",
    "        \n",
    "#         ### normalize similar to UMAP\n",
    "# #         dists = dists-dists.min(dim=1, keepdim=True)[0]\n",
    "# #         dists = dists-dists.max(dim=1, keepdim=True)[0]\n",
    "#         dists = dists-dists.mean(dim=1, keepdim=True)\n",
    "# #         dists = dists/dists.std(dim=1, keepdim=True)*(2/3)\n",
    "\n",
    "# #         dists = self.layernorm(dists)\n",
    "\n",
    "# #         dists = torch.exp(-dists*(2/3)-2)\n",
    "# #         dists = torch.softmax(-dists*self.scaler, dim=1)\n",
    "\n",
    "#         if self.bias is not None: dists = dists+self.bias\n",
    "#         return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DistanceTransform(784, 785)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 785])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = dt(torch.randn(2, 784))\n",
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Convolution to distance transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D_DT(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 kernel_size: Union[int, Tuple[int, ...]],\n",
    "                 dilation: Union[int, Tuple[int, ...]] = 1,\n",
    "                 padding: Union[int, Tuple[int, ...]] = 0,\n",
    "                 stride: Union[int, Tuple[int, ...]] = 1,):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation = dilation\n",
    "        self.padding = padding  # format for padding -> l, r, t, b\n",
    "        self.stride = stride\n",
    "        self._preprocess_()\n",
    "        \n",
    "        self.unfold = nn.Unfold(self.kernel_size, self.dilation, self.padding, self.stride)\n",
    "        self.dt = DistanceTransform(self.kernel_size[0]*self.kernel_size[1]*in_channels, out_channels)\n",
    "    \n",
    "    def _preprocess_(self):\n",
    "        if not isinstance(self.kernel_size, (tuple, list)):\n",
    "            self.kernel_size = (self.kernel_size, self.kernel_size)\n",
    "        if not isinstance(self.dilation, (tuple, list)):\n",
    "            self.dilation = (self.dilation, self.dilation)\n",
    "        if not isinstance(self.stride, (tuple, list)):\n",
    "            self.stride = (self.stride, self.stride)\n",
    "#         if not isinstance(self.padding, (tuple, list)):\n",
    "#             self.padding = (self.padding, self.padding, self.padding, self.padding)\n",
    "#         assert len(self.padding) == 4, 'padding must be specified for all sides of image'\n",
    "        if not isinstance(self.padding, (tuple, list)):\n",
    "            self.padding = (self.padding, self.padding)\n",
    "        assert len(self.padding) == 2, 'padding must be specified for TB, LR'\n",
    "        return\n",
    "        \n",
    "    def _get_output_size_(self, inputH, inputW):\n",
    "        ### input change due to padding\n",
    "        inputH, inputW = (inputH+2*self.padding[0], inputW+2*self.padding[1])\n",
    "        \n",
    "        ### kernel change due to dilation\n",
    "        kH = (self.kernel_size[0]-1)*self.dilation[0]+1\n",
    "        kW = (self.kernel_size[1]-1)*self.dilation[1]+1\n",
    "        \n",
    "        oH = (inputH-kH)/self.stride[0]+1\n",
    "        oW = (inputW-kW)/self.stride[1]+1\n",
    "        return (int(oH), int(oW))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        c = x.shape\n",
    "        x = self.unfold(x).transpose(1,2).reshape(-1, self.dt.input_dim)\n",
    "        x = self.dt(x).view(c[0], -1, self.dt.num_centers).transpose(1,2)\\\n",
    "                    .view(c[0], -1, *self._get_output_size_(c[2], c[3]))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "convdt = Conv2D_DT(3, 4, kernel_size=3, padding=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 10, 10)\n",
    "# x = torch.arange(torch.numel(x), dtype=x.dtype).reshape(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 10])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = convdt(x)\n",
    "y.shape ## B, K1*K2*C, N_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.5820e-02, -2.9336e-01, -1.1420e-01, -2.8184e-01, -9.9238e-02,\n",
       "            1.1778e-01, -7.6962e-02, -5.0676e-01, -1.6824e-01, -3.3333e-01],\n",
       "          [ 1.2480e-01, -1.8395e-01, -1.3378e-01, -4.8187e-02, -1.7141e-01,\n",
       "           -4.0958e-01, -9.9412e-02, -1.7116e-01, -2.1677e-02, -1.9155e-01],\n",
       "          [-4.1571e-01, -2.2958e-01, -1.0402e-01, -1.7689e-01, -1.5786e-01,\n",
       "           -6.3832e-02, -1.9401e-01, -1.0064e-01, -5.3067e-01, -2.8397e-01],\n",
       "          [-2.2334e-01, -5.1131e-01, -2.5324e-01, -1.8139e-01, -3.8438e-01,\n",
       "           -2.0437e-01, -1.9531e-01, -2.1935e-01, -1.3157e-01, -3.7372e-01],\n",
       "          [-5.1013e-02,  3.1500e-03, -6.6307e-02, -2.5629e-01,  8.9358e-02,\n",
       "           -1.0644e-01, -1.7593e-01, -2.9563e-01,  5.9885e-02, -4.7546e-02],\n",
       "          [-3.9073e-01, -3.7214e-01, -3.6599e-01, -4.8006e-01, -2.2589e-01,\n",
       "           -4.6470e-01, -3.0997e-01, -2.1423e-01, -2.2089e-01, -3.3721e-01],\n",
       "          [-1.5872e-01,  9.2511e-03,  7.4882e-02,  2.8109e-02,  1.0479e-01,\n",
       "           -1.3393e-01, -3.4241e-01, -1.8637e-01,  1.0054e-01, -3.7046e-01],\n",
       "          [-1.1538e-01, -3.5093e-01, -4.1513e-01, -1.5296e-01, -3.1181e-01,\n",
       "           -1.6868e-01, -5.4877e-01, -1.4382e-01, -3.4528e-01, -4.9856e-01]],\n",
       "\n",
       "         [[-2.3325e-02,  2.0783e-01,  1.2094e-01, -1.4276e-01,  2.1457e-02,\n",
       "           -3.0388e-01,  3.8645e-02,  1.6465e-01, -2.5234e-02,  1.8115e-01],\n",
       "          [ 1.7221e-02,  3.5366e-01,  1.6874e-01,  3.7514e-01,  2.5231e-01,\n",
       "           -1.1968e-01, -8.9835e-02,  1.7777e-01,  2.0157e-01,  8.4492e-02],\n",
       "          [ 1.0371e-01, -2.3465e-01, -1.8216e-01,  1.6012e-02,  8.5118e-02,\n",
       "            8.8813e-02,  2.3200e-01, -6.9575e-03,  3.6821e-01, -3.3178e-01],\n",
       "          [ 4.2508e-01,  3.4094e-01, -6.6779e-02,  1.0535e-01,  9.2986e-02,\n",
       "           -1.3319e-01,  1.2892e-01,  3.5210e-01,  2.6738e-01,  4.6304e-01],\n",
       "          [ 3.8927e-01,  3.6295e-01,  4.1695e-01,  4.5371e-03,  3.3433e-02,\n",
       "            4.4414e-01,  5.1467e-02,  3.1374e-01,  4.6524e-02,  1.7702e-01],\n",
       "          [ 2.8386e-01,  2.8744e-01,  1.1462e-01,  1.6456e-01,  7.2215e-02,\n",
       "            1.3744e-01,  3.4470e-01,  3.9065e-01, -8.6389e-02, -6.0119e-02],\n",
       "          [ 2.6300e-01, -3.6393e-02, -4.6024e-03,  1.1643e-01,  9.7585e-02,\n",
       "            2.4234e-01,  2.9384e-01,  1.0421e-01, -1.0572e-02,  1.1012e-01],\n",
       "          [ 1.0891e-01,  1.2122e-01, -2.7312e-01, -5.2925e-01,  2.6798e-01,\n",
       "           -3.6363e-01,  2.3920e-01, -1.3323e-02,  3.0799e-01,  1.6662e-01]],\n",
       "\n",
       "         [[ 2.5155e-01,  5.6167e-03, -3.8030e-02,  5.8022e-01, -6.0587e-02,\n",
       "           -1.3113e-01, -1.0507e-01,  1.0996e-01,  2.2007e-01, -3.6564e-03],\n",
       "          [-9.3937e-02, -2.5202e-01,  1.9533e-01, -2.0040e-01,  2.6103e-01,\n",
       "            4.5667e-01,  8.6570e-02, -1.6294e-02,  1.2676e-02,  9.3079e-02],\n",
       "          [ 1.9411e-01,  2.0780e-01,  1.1197e-01,  2.5346e-01, -1.3098e-01,\n",
       "           -3.4094e-03,  3.2711e-03,  3.3096e-01, -8.6360e-02,  5.0611e-01],\n",
       "          [ 4.0441e-02,  2.1205e-01,  2.0712e-01,  1.5150e-02,  8.8176e-02,\n",
       "            4.4451e-01, -1.5636e-01, -1.5344e-01,  2.2299e-01,  2.2189e-02],\n",
       "          [-2.2377e-01, -1.6451e-04, -3.9548e-01,  2.9820e-01,  2.1191e-01,\n",
       "           -3.6915e-01,  4.0236e-01,  1.1669e-01, -2.8417e-01,  8.0474e-02],\n",
       "          [ 2.7133e-01,  4.2926e-02,  3.9791e-01,  2.7887e-01,  7.9034e-02,\n",
       "            2.3383e-01,  2.1294e-01,  6.3592e-02,  4.1722e-01,  3.4593e-01],\n",
       "          [-1.7157e-01,  1.4319e-01, -1.9101e-01, -7.8731e-02, -3.1734e-02,\n",
       "           -3.2065e-01,  1.9554e-01,  2.7836e-01, -1.4343e-01,  8.0104e-03],\n",
       "          [-1.0348e-01,  3.2242e-01,  5.1426e-01,  3.2729e-01, -2.1604e-01,\n",
       "            5.1639e-01,  4.4645e-02,  1.7885e-01,  1.7412e-02,  1.9150e-01]],\n",
       "\n",
       "         [[-2.1241e-01,  7.9914e-02,  3.1282e-02, -1.5561e-01,  1.3837e-01,\n",
       "            3.1722e-01,  1.4339e-01,  2.3215e-01, -2.6598e-02,  1.5584e-01],\n",
       "          [-4.8083e-02,  8.2315e-02, -2.3029e-01, -1.2656e-01, -3.4193e-01,\n",
       "            7.2595e-02,  1.0268e-01,  9.6817e-03, -1.9257e-01,  1.3985e-02],\n",
       "          [ 1.1789e-01,  2.5643e-01,  1.7421e-01, -9.2587e-02,  2.0372e-01,\n",
       "           -2.1572e-02, -4.1259e-02, -2.2337e-01,  2.4882e-01,  1.0964e-01],\n",
       "          [-2.4218e-01, -4.1684e-02,  1.1290e-01,  6.0892e-02,  2.0322e-01,\n",
       "           -1.0696e-01,  2.2275e-01,  2.0684e-02, -3.5879e-01, -1.1151e-01],\n",
       "          [-1.1448e-01, -3.6594e-01,  4.4833e-02, -4.6445e-02, -3.3470e-01,\n",
       "            3.1448e-02, -2.7789e-01, -1.3479e-01,  1.7776e-01, -2.0994e-01],\n",
       "          [-1.6446e-01,  4.1770e-02, -1.4653e-01,  3.6631e-02,  7.4636e-02,\n",
       "            9.3432e-02, -2.4767e-01, -2.4001e-01, -1.0995e-01,  5.1401e-02],\n",
       "          [ 6.7284e-02, -1.1605e-01,  1.2073e-01, -6.5805e-02, -1.7064e-01,\n",
       "            2.1224e-01, -1.4698e-01, -1.9620e-01,  5.3465e-02,  2.5232e-01],\n",
       "          [ 1.0995e-01, -9.2721e-02,  1.7399e-01,  3.5492e-01,  2.5987e-01,\n",
       "            1.5920e-02,  2.6492e-01, -2.1702e-02,  1.9882e-02,  1.4044e-01]]]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "                Conv2D_DT(1, 20, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.LeakyReLU(),\n",
    "                Conv2D_DT(20, 50, 5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.LeakyReLU(),\n",
    "                )\n",
    "        self.fc = nn.Sequential(\n",
    "                DistanceTransform(4*4*50, 500),\n",
    "                nn.LeakyReLU(),\n",
    "                DistanceTransform(500, 10),\n",
    "                ShiftScale(10),\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.reshape(-1, 4*4*50)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyModel(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.cnn = nn.Sequential(\n",
    "#                 nn.Conv2d(1, 20, 5),\n",
    "#                 nn.MaxPool2d(2),\n",
    "#                 nn.LeakyReLU(),\n",
    "#                 nn.Conv2d(20, 50, 5),\n",
    "#                 nn.MaxPool2d(2),\n",
    "#                 nn.LeakyReLU(),\n",
    "#                 )\n",
    "#         self.fc = nn.Sequential(\n",
    "#                 nn.Linear(4*4*50, 500),\n",
    "#                 nn.LeakyReLU(),\n",
    "#                 nn.Linear(500, 10),\n",
    "#                 nn.BatchNorm1d(10),\n",
    "#             )\n",
    "#     def forward(self,x):\n",
    "#         x = self.cnn(x)\n",
    "#         x = x.reshape(-1, 4*4*50)\n",
    "#         x = self.fc(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2D_DT(\n",
       "      (unfold): Unfold(kernel_size=(5, 5), dilation=(1, 1), padding=(0, 0), stride=(1, 1))\n",
       "      (dt): DistanceTransform()\n",
       "    )\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2D_DT(\n",
       "      (unfold): Unfold(kernel_size=(5, 5), dilation=(1, 1), padding=(0, 0), stride=(1, 1))\n",
       "      (dt): DistanceTransform()\n",
       "    )\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): DistanceTransform()\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): DistanceTransform()\n",
       "    (3): ShiftScale()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx, yy = iter(train_loader).next()\n",
    "model(xx.reshape(-1, 1, 28, 28).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(list(model.parameters()), \n",
    "                            lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0:0,  Loss:0.4128994047641754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 1/40 [00:08<05:26,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:70.59%, Test Acc:80.02%\n",
      "\n",
      "Epoch: 1:0,  Loss:0.32194313406944275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 2/40 [00:16<05:19,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:83.30%, Test Acc:84.16%\n",
      "\n",
      "Epoch: 2:0,  Loss:0.2974202036857605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 3/40 [00:25<05:11,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:86.00%, Test Acc:85.90%\n",
      "\n",
      "Epoch: 3:0,  Loss:0.3440536558628082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 4/40 [00:33<05:03,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:87.26%, Test Acc:86.17%\n",
      "\n",
      "Epoch: 4:0,  Loss:0.3156658113002777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 5/40 [00:42<04:54,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:88.13%, Test Acc:87.27%\n",
      "\n",
      "Epoch: 5:0,  Loss:0.22195637226104736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 6/40 [00:50<04:45,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:88.74%, Test Acc:88.03%\n",
      "\n",
      "Epoch: 6:0,  Loss:0.29990965127944946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 7/40 [00:58<04:37,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:89.18%, Test Acc:88.49%\n",
      "\n",
      "Epoch: 7:0,  Loss:0.23408469557762146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 8/40 [01:07<04:29,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:89.68%, Test Acc:89.08%\n",
      "\n",
      "Epoch: 8:0,  Loss:0.13937540352344513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▎       | 9/40 [01:15<04:20,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:90.22%, Test Acc:89.48%\n",
      "\n",
      "Epoch: 9:0,  Loss:0.2537733018398285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 10/40 [01:24<04:12,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:90.40%, Test Acc:89.31%\n",
      "\n",
      "Epoch: 10:0,  Loss:0.2230251133441925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 11/40 [01:32<04:03,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:90.70%, Test Acc:89.41%\n",
      "\n",
      "Epoch: 11:0,  Loss:0.43614470958709717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 12/40 [01:40<03:55,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:90.95%, Test Acc:89.52%\n",
      "\n",
      "Epoch: 12:0,  Loss:0.18129204213619232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▎      | 13/40 [01:49<03:46,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:91.23%, Test Acc:89.49%\n",
      "\n",
      "Epoch: 13:0,  Loss:0.14957067370414734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 14/40 [01:57<03:38,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:91.50%, Test Acc:89.21%\n",
      "\n",
      "Epoch: 14:0,  Loss:0.30811789631843567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 15/40 [02:06<03:30,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:91.73%, Test Acc:89.79%\n",
      "\n",
      "Epoch: 15:0,  Loss:0.30762791633605957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 16/40 [02:14<03:21,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:91.95%, Test Acc:90.37%\n",
      "\n",
      "Epoch: 16:0,  Loss:0.3574450612068176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▎     | 17/40 [02:22<03:13,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.11%, Test Acc:89.94%\n",
      "\n",
      "Epoch: 17:0,  Loss:0.20711122453212738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 18/40 [02:31<03:04,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.34%, Test Acc:90.04%\n",
      "\n",
      "Epoch: 18:0,  Loss:0.283222496509552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 19/40 [02:39<02:56,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.52%, Test Acc:90.31%\n",
      "\n",
      "Epoch: 19:0,  Loss:0.2070496678352356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 20/40 [02:48<02:48,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.71%, Test Acc:90.33%\n",
      "\n",
      "Epoch: 20:0,  Loss:0.12107142806053162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▎    | 21/40 [02:56<02:39,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:92.86%, Test Acc:90.61%\n",
      "\n",
      "Epoch: 21:0,  Loss:0.1419389247894287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 22/40 [03:04<02:31,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.01%, Test Acc:90.19%\n",
      "\n",
      "Epoch: 22:0,  Loss:0.11178340017795563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▊    | 23/40 [03:13<02:22,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.17%, Test Acc:90.59%\n",
      "\n",
      "Epoch: 23:0,  Loss:0.1981443464756012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 24/40 [03:21<02:14,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.41%, Test Acc:90.45%\n",
      "\n",
      "Epoch: 24:0,  Loss:0.09476640820503235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 25/40 [03:30<02:06,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.50%, Test Acc:90.16%\n",
      "\n",
      "Epoch: 25:0,  Loss:0.10581621527671814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 26/40 [03:38<01:57,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.67%, Test Acc:90.63%\n",
      "\n",
      "Epoch: 26:0,  Loss:0.16052870452404022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 27/40 [03:46<01:49,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.58%, Test Acc:90.90%\n",
      "\n",
      "Epoch: 27:0,  Loss:0.35116758942604065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 28/40 [03:55<01:40,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:93.85%, Test Acc:90.84%\n",
      "\n",
      "Epoch: 28:0,  Loss:0.25284063816070557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▎  | 29/40 [04:03<01:32,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.03%, Test Acc:90.60%\n",
      "\n",
      "Epoch: 29:0,  Loss:0.11799734830856323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 30/40 [04:12<01:24,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.17%, Test Acc:90.89%\n",
      "\n",
      "Epoch: 30:0,  Loss:0.10534902662038803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 31/40 [04:20<01:15,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.20%, Test Acc:91.04%\n",
      "\n",
      "Epoch: 31:0,  Loss:0.16730950772762299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 32/40 [04:29<01:07,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.36%, Test Acc:90.34%\n",
      "\n",
      "Epoch: 32:0,  Loss:0.1351667046546936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▎ | 33/40 [04:37<00:58,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.50%, Test Acc:91.43%\n",
      "\n",
      "Epoch: 33:0,  Loss:0.2073395848274231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 34/40 [04:45<00:50,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.65%, Test Acc:90.86%\n",
      "\n",
      "Epoch: 34:0,  Loss:0.16478420794010162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 35/40 [04:54<00:42,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.77%, Test Acc:91.06%\n",
      "\n",
      "Epoch: 35:0,  Loss:0.13498421013355255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 36/40 [05:02<00:33,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.79%, Test Acc:91.11%\n",
      "\n",
      "Epoch: 36:0,  Loss:0.19256603717803955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▎| 37/40 [05:11<00:25,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.91%, Test Acc:91.25%\n",
      "\n",
      "Epoch: 37:0,  Loss:0.29411786794662476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 38/40 [05:19<00:16,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:94.96%, Test Acc:91.19%\n",
      "\n",
      "Epoch: 38:0,  Loss:0.19522039592266083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 39/40 [05:27<00:08,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.24%, Test Acc:90.40%\n",
      "\n",
      "Epoch: 39:0,  Loss:0.08623470366001129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [05:36<00:00,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:95.24%, Test Acc:91.29%\n",
      "\n",
      "\t-> MAX Train Acc 95.24333333333334 ; Test Acc 91.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "train_accs, test_accs = [], []\n",
    "for epoch in tqdm(list(range(40))):\n",
    "    model.train()\n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "    for xx, yy in train_loader:\n",
    "        xx, yy = xx.reshape(-1, 1, 28, 28).to(device), yy.to(device)\n",
    "        yout = model(xx)\n",
    "        loss = criterion(yout, yy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        train_acc += correct\n",
    "        train_count += len(outputs)\n",
    "\n",
    "    train_accs.append(float(train_acc)/train_count*100)\n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "    \n",
    "#     if epoch%5 == 0:\n",
    "#         print(f\"Shifting the centroids to the nearest data point\")\n",
    "#         model[0].set_centroid_to_data(train_loader)\n",
    "\n",
    "    print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "    test_count = 0\n",
    "    test_acc = 0\n",
    "    model.eval()\n",
    "    for xx, yy in test_loader:\n",
    "        xx, yy = xx.reshape(-1, 1, 28, 28).to(device), yy.to(device)\n",
    "        with torch.no_grad():\n",
    "            yout = model(xx)\n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        test_acc += correct\n",
    "        test_count += len(xx)\n",
    "    test_accs.append(float(test_acc)/test_count*100)\n",
    "    print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "    print()\n",
    "\n",
    "### after each class index is finished training\n",
    "print(f'\\t-> MAX Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Report\n",
    "# -mean works better than -min\n",
    "# -min and -max work the same\n",
    "# non exp works == exps ?? (need expansion)\n",
    "# layernorm works best for activation functions, not needed if batchnorm used\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2D_DT(\n",
       "  (unfold): Unfold(kernel_size=(5, 5), dilation=(1, 1), padding=(0, 0), stride=(1, 1))\n",
       "  (dt): DistanceTransform(\n",
       "    (layernorm): LayerNorm((20,), eps=1e-05, elementwise_affine=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cnn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 50, 4, 4])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "xx = train_dataset[np.random.randint(0, len(train_dataset), 50)][0].to(device)\n",
    "hh = model.cnn(xx.reshape(-1, 1, 28, 28))\n",
    "hh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3639, 0.4713, 0.4519, 0.5083],\n",
       "         [0.3742, 0.4260, 0.3797, 0.5161],\n",
       "         [0.6105, 0.7115, 0.8506, 0.3109],\n",
       "         [0.4332, 0.3778, 0.4804, 0.4227]],\n",
       "\n",
       "        [[0.4507, 0.4439, 0.4287, 0.3602],\n",
       "         [0.4195, 0.3900, 0.4831, 0.5990],\n",
       "         [0.4930, 0.7527, 0.5622, 0.3342],\n",
       "         [0.5466, 0.4771, 0.4981, 0.4912]],\n",
       "\n",
       "        [[0.5052, 0.3938, 0.3243, 0.3371],\n",
       "         [0.4597, 0.3492, 0.2942, 0.3626],\n",
       "         [0.5308, 0.3488, 0.5289, 0.6275],\n",
       "         [0.7375, 0.6787, 0.5943, 0.5946]],\n",
       "\n",
       "        [[0.3175, 0.3861, 0.3877, 0.3782],\n",
       "         [0.3409, 0.2672, 0.2723, 0.3228],\n",
       "         [0.2752, 0.3433, 0.4133, 0.2556],\n",
       "         [0.6312, 0.4924, 0.6295, 0.6080]],\n",
       "\n",
       "        [[0.7979, 0.8010, 0.7175, 0.6030],\n",
       "         [0.8726, 0.6133, 0.7082, 0.6839],\n",
       "         [0.5143, 0.7394, 0.5239, 0.5849],\n",
       "         [0.7327, 0.6134, 0.5752, 0.6405]],\n",
       "\n",
       "        [[0.4284, 0.3650, 0.5119, 0.4893],\n",
       "         [0.3136, 0.5471, 0.4954, 0.3413],\n",
       "         [0.4130, 0.4061, 0.4837, 0.3165],\n",
       "         [0.3311, 0.3804, 0.3756, 0.3492]],\n",
       "\n",
       "        [[0.3282, 0.3121, 0.3185, 0.2869],\n",
       "         [0.3929, 0.5164, 0.6314, 0.3558],\n",
       "         [0.4047, 0.4167, 0.5105, 0.4710],\n",
       "         [0.4145, 0.5147, 0.5595, 0.3938]],\n",
       "\n",
       "        [[0.3843, 0.4061, 0.4373, 0.3555],\n",
       "         [0.3205, 0.3985, 0.3709, 0.4008],\n",
       "         [0.3032, 0.3325, 0.3813, 0.3402],\n",
       "         [0.4343, 0.4668, 0.4123, 0.4207]],\n",
       "\n",
       "        [[0.6900, 0.3966, 0.4423, 0.4812],\n",
       "         [0.7903, 0.8186, 0.4696, 0.6014],\n",
       "         [1.3071, 1.1385, 0.8988, 1.4678],\n",
       "         [0.3553, 0.4689, 0.3905, 0.4202]],\n",
       "\n",
       "        [[0.4237, 0.4371, 0.4119, 0.3582],\n",
       "         [0.4941, 0.4222, 0.4507, 0.3636],\n",
       "         [0.3852, 0.3423, 0.3136, 0.3710],\n",
       "         [0.3635, 0.3904, 0.3509, 0.3852]],\n",
       "\n",
       "        [[0.3947, 0.4942, 0.3642, 0.4116],\n",
       "         [0.4385, 0.3858, 0.4533, 0.4314],\n",
       "         [0.3432, 0.3485, 0.3332, 0.3848],\n",
       "         [0.3847, 0.3800, 0.3943, 0.3742]],\n",
       "\n",
       "        [[0.2566, 0.2547, 0.2417, 0.2400],\n",
       "         [0.2110, 0.2004, 0.1925, 0.2041],\n",
       "         [0.3208, 0.3259, 0.2648, 0.3422],\n",
       "         [1.4824, 0.8431, 0.5351, 0.9356]],\n",
       "\n",
       "        [[0.2179, 0.2234, 0.2254, 0.2189],\n",
       "         [0.2589, 0.2840, 0.2450, 0.2207],\n",
       "         [0.2913, 0.3150, 0.2476, 0.2356],\n",
       "         [0.2579, 0.2279, 0.2436, 0.2170]],\n",
       "\n",
       "        [[0.3509, 0.3858, 0.4650, 0.4163],\n",
       "         [0.4101, 0.6851, 0.5420, 0.4128],\n",
       "         [0.4457, 0.3215, 0.4668, 0.3596],\n",
       "         [0.4236, 0.3481, 0.4040, 0.4070]],\n",
       "\n",
       "        [[0.2270, 0.2366, 0.2362, 0.2622],\n",
       "         [0.4184, 0.3345, 0.4194, 0.3569],\n",
       "         [1.4829, 1.3737, 1.1515, 0.6637],\n",
       "         [0.6325, 0.5261, 0.6069, 0.5039]],\n",
       "\n",
       "        [[0.5136, 0.5432, 0.7695, 0.5951],\n",
       "         [1.1460, 0.9588, 0.6758, 1.0130],\n",
       "         [0.3441, 0.4653, 0.3525, 0.4836],\n",
       "         [0.2558, 0.2401, 0.2781, 0.2713]],\n",
       "\n",
       "        [[0.4771, 0.3211, 0.3238, 0.3929],\n",
       "         [0.3732, 0.3911, 0.3598, 0.3466],\n",
       "         [0.5521, 0.3371, 0.4332, 0.7015],\n",
       "         [0.2714, 0.2559, 0.2764, 0.2909]],\n",
       "\n",
       "        [[0.3440, 0.3111, 0.3492, 0.3198],\n",
       "         [0.4195, 0.4513, 0.4846, 0.3915],\n",
       "         [0.4516, 0.4402, 0.3645, 0.4004],\n",
       "         [0.4256, 0.4089, 0.3484, 0.4699]],\n",
       "\n",
       "        [[0.3909, 0.4185, 0.3690, 0.3738],\n",
       "         [0.3848, 0.4114, 0.3879, 0.3726],\n",
       "         [0.4310, 0.4496, 0.4493, 0.3939],\n",
       "         [0.3518, 0.3705, 0.3553, 0.3408]],\n",
       "\n",
       "        [[0.5588, 0.5389, 0.5584, 0.7898],\n",
       "         [0.4482, 0.5070, 0.5420, 0.6406],\n",
       "         [0.3806, 0.4097, 0.5841, 0.6401],\n",
       "         [0.3324, 0.3452, 0.4238, 0.2993]],\n",
       "\n",
       "        [[0.3703, 0.5803, 0.6061, 0.3610],\n",
       "         [1.6628, 0.7066, 0.9068, 0.6926],\n",
       "         [1.7494, 0.3079, 0.4460, 0.6933],\n",
       "         [0.2185, 0.2434, 0.2034, 0.2488]],\n",
       "\n",
       "        [[0.6990, 0.6129, 0.8895, 0.5759],\n",
       "         [0.4283, 0.3832, 0.4177, 0.4450],\n",
       "         [0.5343, 0.7876, 0.5818, 0.9693],\n",
       "         [0.5217, 0.8832, 0.6946, 0.4697]],\n",
       "\n",
       "        [[0.3286, 0.3188, 0.2587, 0.2829],\n",
       "         [0.2896, 0.3054, 0.4288, 0.4108],\n",
       "         [0.3127, 0.3414, 0.3075, 0.3423],\n",
       "         [0.3686, 0.3256, 0.3769, 0.3876]],\n",
       "\n",
       "        [[0.3571, 0.3202, 0.2742, 0.3078],\n",
       "         [0.4876, 0.3088, 0.3034, 0.2925],\n",
       "         [0.3977, 0.5367, 0.4185, 0.3595],\n",
       "         [0.4294, 0.4198, 0.4210, 0.5287]],\n",
       "\n",
       "        [[0.2925, 0.2727, 0.2901, 0.2890],\n",
       "         [0.3222, 0.2946, 0.3546, 0.3084],\n",
       "         [0.3437, 0.3134, 0.2760, 0.3001],\n",
       "         [0.2613, 0.2489, 0.2627, 0.2278]],\n",
       "\n",
       "        [[0.3595, 0.3327, 0.4135, 0.3296],\n",
       "         [0.5049, 0.5205, 0.4067, 0.3595],\n",
       "         [0.5344, 0.3655, 0.4277, 0.4993],\n",
       "         [0.3411, 0.2950, 0.2698, 0.3355]],\n",
       "\n",
       "        [[0.8564, 0.7725, 0.7056, 0.8836],\n",
       "         [0.3640, 0.3399, 0.4497, 0.4568],\n",
       "         [0.3385, 0.4744, 0.4392, 0.4186],\n",
       "         [0.8671, 0.7985, 0.8039, 1.0903]],\n",
       "\n",
       "        [[0.4234, 0.3556, 0.6588, 0.6293],\n",
       "         [0.4548, 0.2921, 0.4101, 0.3560],\n",
       "         [0.9234, 0.3487, 0.5006, 0.3275],\n",
       "         [1.0038, 0.7071, 1.6248, 1.0327]],\n",
       "\n",
       "        [[0.4946, 0.6178, 0.6164, 0.6126],\n",
       "         [0.4971, 0.5388, 0.4832, 0.5221],\n",
       "         [0.5221, 0.3936, 0.5038, 0.4443],\n",
       "         [0.4359, 0.4005, 0.4636, 0.5622]],\n",
       "\n",
       "        [[0.4291, 0.4806, 0.3957, 0.3908],\n",
       "         [0.4686, 0.4526, 0.6333, 0.5182],\n",
       "         [0.3954, 0.3812, 0.3562, 0.4298],\n",
       "         [0.4215, 0.5002, 0.4536, 0.4771]],\n",
       "\n",
       "        [[0.5595, 0.5638, 0.4504, 0.3529],\n",
       "         [0.7195, 0.5258, 0.4141, 0.3687],\n",
       "         [0.3791, 0.6006, 0.4672, 0.4018],\n",
       "         [0.4196, 0.3871, 0.4414, 0.4000]],\n",
       "\n",
       "        [[0.4904, 0.4938, 0.4947, 0.4907],\n",
       "         [0.4967, 0.4354, 0.5291, 0.4410],\n",
       "         [0.6493, 0.5416, 0.4853, 0.5846],\n",
       "         [0.6557, 0.5791, 0.5997, 0.6166]],\n",
       "\n",
       "        [[0.4623, 0.4717, 0.4115, 0.3842],\n",
       "         [0.5502, 0.5341, 0.5316, 0.4479],\n",
       "         [0.4441, 0.4301, 0.6090, 0.4102],\n",
       "         [0.4005, 0.3666, 0.3481, 0.3546]],\n",
       "\n",
       "        [[0.4324, 0.4599, 0.5757, 0.5627],\n",
       "         [0.3082, 0.4816, 0.4268, 0.3892],\n",
       "         [0.3586, 0.4824, 0.3749, 0.4235],\n",
       "         [0.4513, 0.4566, 0.5721, 0.4259]],\n",
       "\n",
       "        [[0.4032, 0.4385, 0.3601, 0.3331],\n",
       "         [0.4767, 0.5371, 0.4938, 0.5941],\n",
       "         [0.7471, 0.4609, 0.8224, 0.5510],\n",
       "         [0.3700, 0.3849, 0.3485, 0.3361]],\n",
       "\n",
       "        [[0.4598, 0.4715, 0.4302, 0.3897],\n",
       "         [0.6447, 0.6061, 0.8961, 0.6004],\n",
       "         [0.4364, 0.3560, 0.3550, 0.6181],\n",
       "         [0.3221, 0.2808, 0.2452, 0.2891]],\n",
       "\n",
       "        [[1.2272, 1.6214, 0.5792, 0.6444],\n",
       "         [0.8454, 0.5043, 0.4883, 0.8902],\n",
       "         [0.6071, 0.4850, 0.6184, 0.4040],\n",
       "         [0.3282, 0.4521, 0.4691, 0.3297]],\n",
       "\n",
       "        [[0.4942, 0.4534, 0.4610, 0.5480],\n",
       "         [0.6544, 0.5791, 0.5983, 0.5201],\n",
       "         [0.7025, 0.6112, 0.7033, 0.7500],\n",
       "         [0.5388, 0.4333, 0.4726, 0.4772]],\n",
       "\n",
       "        [[0.4280, 0.6254, 0.4882, 0.6870],\n",
       "         [0.4674, 1.2322, 0.7169, 0.7628],\n",
       "         [0.8022, 0.6164, 1.0255, 0.9172],\n",
       "         [0.3305, 0.3770, 0.4059, 0.3521]],\n",
       "\n",
       "        [[0.5843, 0.5572, 0.6654, 0.3677],\n",
       "         [0.6767, 0.4156, 0.3928, 0.8606],\n",
       "         [0.3957, 0.4068, 0.4731, 0.3510],\n",
       "         [0.5618, 0.4059, 0.3883, 0.4850]],\n",
       "\n",
       "        [[0.5869, 0.5428, 0.5133, 0.5145],\n",
       "         [0.4827, 0.6633, 0.3441, 0.4591],\n",
       "         [0.4681, 0.4173, 0.5216, 0.5386],\n",
       "         [0.5708, 0.5992, 0.5484, 0.6309]],\n",
       "\n",
       "        [[0.4106, 0.3677, 0.4251, 0.3585],\n",
       "         [0.4178, 0.3327, 0.3651, 0.3496],\n",
       "         [0.4168, 0.4417, 0.3237, 0.6298],\n",
       "         [0.5445, 0.7995, 0.5728, 0.5219]],\n",
       "\n",
       "        [[0.3244, 0.3142, 0.3068, 0.2924],\n",
       "         [0.4149, 0.3401, 0.3225, 0.2883],\n",
       "         [0.3767, 0.3542, 0.4131, 0.3913],\n",
       "         [0.4329, 0.4886, 0.3917, 0.4127]],\n",
       "\n",
       "        [[0.7622, 0.3354, 0.5097, 0.5037],\n",
       "         [0.3091, 0.4555, 0.2424, 0.3712],\n",
       "         [0.3230, 0.4101, 0.3190, 0.4601],\n",
       "         [0.3040, 0.3792, 0.4608, 0.3166]],\n",
       "\n",
       "        [[0.3322, 0.3640, 0.4702, 0.3582],\n",
       "         [0.5135, 0.4598, 0.3831, 0.3780],\n",
       "         [0.3935, 0.6076, 0.5565, 0.5022],\n",
       "         [0.4374, 0.4018, 0.4315, 0.4241]],\n",
       "\n",
       "        [[1.3288, 0.5322, 0.6402, 0.6396],\n",
       "         [0.4254, 0.4200, 0.5026, 0.5226],\n",
       "         [0.5183, 0.5103, 0.4448, 0.4407],\n",
       "         [0.4074, 0.4343, 0.4446, 0.4765]],\n",
       "\n",
       "        [[0.3133, 0.3547, 0.3461, 0.3922],\n",
       "         [0.4878, 0.5380, 0.4216, 0.4378],\n",
       "         [0.5089, 0.6528, 0.5245, 0.6045],\n",
       "         [0.4358, 0.3774, 0.5491, 0.4039]],\n",
       "\n",
       "        [[0.3601, 0.9381, 0.5094, 0.6992],\n",
       "         [0.6509, 0.3811, 0.7081, 0.5120],\n",
       "         [0.3549, 0.4211, 0.3533, 0.3549],\n",
       "         [0.3039, 0.3526, 0.3498, 0.3590]],\n",
       "\n",
       "        [[0.2972, 0.2923, 0.2417, 0.2665],\n",
       "         [0.4476, 0.3952, 0.3779, 0.2936],\n",
       "         [0.4463, 0.4332, 0.6389, 0.5830],\n",
       "         [0.3324, 0.3346, 0.3095, 0.3019]],\n",
       "\n",
       "        [[0.3071, 0.3633, 0.5407, 0.3881],\n",
       "         [0.3929, 0.4582, 0.3910, 0.3691],\n",
       "         [1.7880, 0.7627, 0.6644, 0.4141],\n",
       "         [0.3844, 0.5176, 0.6454, 0.3352]]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-> MAX Train Acc 99.41499999999999 ; Test Acc 90.93\n"
     ]
    }
   ],
   "source": [
    "print(f'\\t-> MAX Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./models/temp_03_1_model_dec1_v0.pth\")\n",
    "\n",
    "# model.load_state_dict(torch.load(\"./temp_01_2_model_nov26.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "xx = train_dataset[np.random.randint(0, len(train_dataset), 50)][0].to(device)\n",
    "dists = model[0](xx.reshape(-1, 1, 28, 28))\n",
    "# dists = xx@model[0].weight.data.t()\n",
    "\n",
    "# dists = model[1](dists)\n",
    "model.train()\n",
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx[0], model[0].weight.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists.mean(), dists.std(), dists.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model[0].scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP - from library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = umap.UMAP(n_neighbors=784, n_components=2, min_dist=0.1, spread=1, metric=\"euclidean\")\n",
    "# embed = umap.UMAP(n_neighbors=784, n_components=2, min_dist=0.1, spread=1,\n",
    "# #                   target_metric='euclidean',\n",
    "#                   target_metric='categorical',\n",
    "#                   target_weight=0.1\n",
    "#                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_lbl = model(model[0].centers.data)\n",
    "# center_lbl = model(model[0].weight.data)\n",
    "# output_cent = torch.softmax(center_lbl, dim=1).argmax(dim=1).data.cpu()\n",
    "output_cent = center_lbl.argmax(dim=1).data.cpu()\n",
    "\n",
    "# output_cent = center_lbl.data.cpu().numpy()\n",
    "\n",
    "torch.unique(output_cent, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = model[0].centers.data.cpu().numpy()\n",
    "# centers = model[0].weight.data.cpu().numpy()\n",
    "\n",
    "embedding = embed.fit_transform(centers)\n",
    "# embedding = embed.fit_transform(centers, output_cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activ = dists.data.cpu()[i]\n",
    "# activ = activ - activ.min()\n",
    "# activ = torch.exp(activ)\n",
    "\n",
    "i += 1\n",
    "print(f\"{i}/{len(dists)}\")\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(embedding[:,0], embedding[:, 1], c=output_cent, s=np.maximum(activ*50, 0.5), cmap=\"tab10\")\n",
    "# plt.scatter(embedding[:,0], embedding[:, 1], c=output_cent, s=activ, cmap=\"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = dists.data.cpu()[i]\n",
    "aa.mean(), aa.min(), aa.max(), aa.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(xx.cpu()[j].reshape(28,28))\n",
    "plt.imshow(centers[j].reshape(28,28))\n",
    "j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleShift(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.scaler = nn.Parameter(torch.ones(1, input_dim))\n",
    "        self.shifter = nn.Parameter(torch.zeros(1, input_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x*self.scaler+self.shifter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
