{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6287145e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuman/All-Files/Program_Files/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os, sys, pathlib, random, time, pickle, copy, json\n",
    "# from tqdm.autonotebook import tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0173cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcaa3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_lib import TransformerBlock, \\\n",
    "        Mixer_TransformerBlock_Encoder, \\\n",
    "        PositionalEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2e11b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45f6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "### add randomize patches for clear benefit\n",
    "class Mixer_ViT_Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_dim:tuple, patch_size:tuple, hidden_channel:int, num_blocks:int, num_classes:int, block_seq_size:int, block_mlp_size:int, forward_expansion:float=2.0, pos_emb=True, dropout:float=0.0, randomize_patch:bool=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_dim = image_dim ### must contain (C, H, W) or (H, W)\n",
    "        \n",
    "        ### find patch dim\n",
    "        d0 = int(image_dim[-2]/patch_size[0])\n",
    "        d1 = int(image_dim[-1]/patch_size[1])\n",
    "        assert d0*patch_size[0]==image_dim[-2], \"Image must be divisible into patch size\"\n",
    "        assert d1*patch_size[1]==image_dim[-1], \"Image must be divisible into patch size\"\n",
    "        \n",
    "#         self.d0, self.d1 = d0, d1 ### number of patches in each axis\n",
    "        __patch_size = patch_size[0]*patch_size[1]*image_dim[0] ## number of channels in each patch\n",
    "    \n",
    "        ### find channel dim\n",
    "        channel_size = d0*d1 ## number of patches\n",
    "        \n",
    "        ### after the number of channels are changed\n",
    "        init_dim = __patch_size\n",
    "        final_dim = hidden_channel\n",
    "        self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "        #### rescale the patches (patch wise image non preserving transform, unlike bilinear interpolation)\n",
    "        self.channel_change = nn.Linear(init_dim, final_dim)\n",
    "        print(f\"ViT Mixer : Channels per patch -> Initial:{init_dim} Final:{final_dim}\")\n",
    "        \n",
    "        \n",
    "        self.channel_dim = final_dim\n",
    "        self.patch_dim = channel_size\n",
    "        \n",
    "        self.transformer_blocks = []\n",
    "        \n",
    "        f = self.get_factors(self.channel_dim)\n",
    "        print(f)\n",
    "        fi = np.abs(np.array(f) - np.sqrt(self.channel_dim)).argmin()\n",
    "        \n",
    "        _n_heads = f[fi]\n",
    "        \n",
    "        ## number of dims per channel -> channel_dim\n",
    "#         print('Num patches:', self.patch_dim)\n",
    "        print(f'Sequence len: {self.patch_dim} ; Block size: {block_seq_size}')\n",
    "        print('Channel dim:', self.channel_dim, 'num heads:',_n_heads)\n",
    "            \n",
    "        \n",
    "        if block_seq_size is None or block_seq_size<2:\n",
    "            ### Find the block size for sequence:\n",
    "            block_seq_size = int(2**np.ceil(np.log2(np.sqrt(self.patch_dim))))\n",
    "            \n",
    "        print(f'MLP dim: {self.channel_dim} ; Block size: {block_mlp_size}')\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            L = Mixer_TransformerBlock_Encoder(self.patch_dim, block_seq_size, self.channel_dim, _n_heads, dropout, forward_expansion, nn.GELU, block_mlp_size)\n",
    "            self.transformer_blocks.append(L)\n",
    "        self.transformer_blocks = nn.Sequential(*self.transformer_blocks)\n",
    "        \n",
    "        self.linear = nn.Linear(self.patch_dim*self.channel_dim, num_classes)\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(self.channel_dim, dropout=0)\n",
    "        if not pos_emb:\n",
    "            self.positional_encoding = nn.Identity()\n",
    "            \n",
    "        self.randomize = None\n",
    "        if randomize_patch is not None:\n",
    "            self.randomize = torch.randperm(self.patch_dim)\n",
    "        \n",
    "        \n",
    "    def get_factors(self, n):\n",
    "        facts = []\n",
    "        for i in range(2, n+1):\n",
    "            if n%i == 0:\n",
    "                facts.append(i)\n",
    "        return facts\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = self.unfold(x).swapaxes(-1, -2)\n",
    "        x = self.channel_change(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        ## swap position of patches here\n",
    "        if self.randomize is not None:\n",
    "            x = x[..., self.randomize, :]\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.linear(x.view(bs, -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7094b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b0ac9f5-f1e2-4dba-a8e3-06bb4d5acac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a356db1-2fad-40ba-8186-7ca3c40ddd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3efe0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e27199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Mixer_ViT_Classifier([3, 32, 32], [2, 2], 64, num_blocks=2, num_classes=10, \n",
    "#                             block_seq_size=16, block_mlp_size=None, pos_emb=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f741268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b73c4162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1017ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Mixer_ViT_Classifier([3, 32, 32], [1, 1], 64, num_blocks=2, num_classes=10, \n",
    "#                             block_seq_size=32, block_mlp_size=None, pos_emb=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae575940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(\"number of params: \", sum(p.numel() for p in model.parameters()))\n",
    "# for name, m in model.named_children():\n",
    "# #     print(name)\n",
    "#     print(f\"{name}: {sum(p.numel() for p in m.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d642126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b258ea4-8037-457d-aea6-35e9e02d9be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20622e",
   "metadata": {},
   "source": [
    "## Benchmark Memory and Time CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1faebb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nvidia_smi\n",
    "# ### pip install nvidia-ml-py3\n",
    "\n",
    "\n",
    "# MB = 1024*1024\n",
    "# def get_memory_used(cuda_idx):\n",
    "#     nvidia_smi.nvmlInit()\n",
    "#     handle = nvidia_smi.nvmlDeviceGetHandleByIndex(cuda_idx)\n",
    "#     info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "#     val = info.used/MB\n",
    "#     nvidia_smi.nvmlShutdown()\n",
    "#     return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1812db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_memory_used(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb7fa91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "def get_memory_used(cuda_idx):\n",
    "    if cuda_idx == 0: ## server 1 has pytorch-cuda index and nvidia-smi index flipped\n",
    "        cuda_idx = 1\n",
    "    else:\n",
    "        cuda_idx = 0\n",
    "    command = \"nvidia-smi --query-gpu=memory.used --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values[cuda_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30adc9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_memory_used(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c9ae24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 MiB', '1 MiB']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"nvidia-smi --query-gpu=memory.used --format=csv\"\n",
    "memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "memory_free_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47d9cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdfsadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7429fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "expansion_dict = {16:1024, 8:256, 4:128, 2:64, 1:64}\n",
    "def benchmark_memory(dataset:str, patch_size:int, num_layers:int, SEED:int, sparse_att:bool=False, sparse_mlp:bool=False, pos_emb:bool=False, cuda:int=0):\n",
    "    global expansion_dict, filename, model_name\n",
    "    device = torch.device(f\"cuda:{cuda}\")\n",
    "    \n",
    "    if sparse_att:\n",
    "        assert num_layers%2 == 0, 'number of blocks on sparse transformer is (x2)/2 hence it must be even'\n",
    "        num_layers_ = num_layers//2\n",
    "    else:\n",
    "        num_layers_ = num_layers\n",
    "    \n",
    "    BS = 32\n",
    "    NC = -1\n",
    "    EPOCHS = 1\n",
    "    imsize = (3, 32, 32)\n",
    "    expansion = expansion_dict[patch_size]\n",
    "\n",
    "    \n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    ##### Data Transforms\n",
    "        \n",
    "    if dataset == 'cifar10':\n",
    "        NC = 10\n",
    "    elif dataset == 'cifar100':\n",
    "        NC = 100\n",
    "\n",
    "    ### Now create models\n",
    "    \n",
    "    seq_len = (imsize[-1]*imsize[-2])//(patch_size*patch_size)\n",
    "    mlp_dim = expansion\n",
    "    print(seq_len, mlp_dim)\n",
    "    \n",
    "    if sparse_att:\n",
    "        seq_len = int(2**np.ceil(np.log2(np.sqrt(seq_len))))\n",
    "    if sparse_mlp:\n",
    "        mlp_dim = int(2**np.ceil(np.log2(np.sqrt(expansion))))\n",
    "    \n",
    "    _a, _b, _c = 'att', 'mlp', 'nPE'\n",
    "    if sparse_att: _a = 'sAtt'\n",
    "    if sparse_mlp: _b = 'sMlp'\n",
    "    if pos_emb: _c = 'PE'\n",
    "        \n",
    "    filename = f\"./output/bench_mem_retest_data_3090_v3(1by1)_compile.json\"\n",
    "    \n",
    "    if not os.path.exists(filename):\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump({}, f, indent=0)\n",
    "            \n",
    "        \n",
    "    ### Training\n",
    "    model_name = f'01.3_ViT_train_{dataset}_patch{patch_size}_l{num_layers}_exp{expansion}_{_a}_{_b}_s{SEED}'\n",
    "    ### Inference\n",
    "#     model_name = f'01.3_ViT_eval_{dataset}_patch{patch_size}_l{num_layers}_exp{expansion}_{_a}_{_b}_s{SEED}'\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        file_data = json.load(f)\n",
    "        if model_name in file_data.keys():\n",
    "            print(f\"{model_name} already found.. !!\")\n",
    "            return 0\n",
    "        \n",
    "    mem_begin = get_memory_used(cuda)\n",
    "    \n",
    "    torch.manual_seed(SEED)\n",
    "    model = Mixer_ViT_Classifier(imsize, \n",
    "                                 patch_size=[patch_size]*2, \n",
    "                                 hidden_channel=expansion, \n",
    "                                 num_blocks=num_layers_, \n",
    "                                 num_classes=NC, \n",
    "                                 block_seq_size=seq_len, \n",
    "                                 block_mlp_size=mlp_dim,\n",
    "                                 pos_emb=pos_emb).to(device)\n",
    "    model = torch.compile(model)\n",
    "    \n",
    "    _x = torch.randn(BS, *imsize)#.to(device)\n",
    "    _y = torch.randint(10, (BS,))\n",
    "#     print(\"Output: \",vit_mixer(_x).shape)\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"number of params: \", num_params)\n",
    "    \n",
    "    print(f\"Model Name: {model_name}\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    ### Training\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    ### Inference\n",
    "#     model.eval()\n",
    "\n",
    "    inputs, targets = _x.to(device), _y.to(device)\n",
    "    ### test time taken for multiple iterations\n",
    "    time_taken = []\n",
    "    for i in tqdm(range(50)):\n",
    "\n",
    "        ### Inference\n",
    "#         with torch.no_grad():\n",
    "#             start = time.time()\n",
    "#             outputs = model(inputs)\n",
    "#             start = time.time()-start\n",
    "            \n",
    "        ### Training\n",
    "        start = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        start = time.time()-start\n",
    "        \n",
    "        time_taken.append(start)\n",
    "    train_time = {\"mean\":np.mean(time_taken), \"std\":np.std(time_taken), \n",
    "                  \"min\":np.min(time_taken), \"max\":np.max(time_taken)}\n",
    "        \n",
    "    mem_end = get_memory_used(cuda)\n",
    "    print(f\"mem begin: {mem_begin}  end: {mem_end}\")\n",
    "\n",
    "    model.eval()\n",
    "    time_taken = []\n",
    "    for i in range(50):\n",
    "        with torch.no_grad():\n",
    "            start = time.time()\n",
    "            outputs = model(inputs)\n",
    "            start = time.time()-start\n",
    "            time_taken.append(start)\n",
    "            \n",
    "    test_time = {\"mean\":np.mean(time_taken), \"std\":np.std(time_taken), \n",
    "                  \"min\":np.min(time_taken), \"max\":np.max(time_taken)}\n",
    "    \n",
    "    with open(filename, 'r+') as f:\n",
    "#         with open(filename,'r+') as f:\n",
    "        file_data = json.load(f)\n",
    "        file_data[f\"{model_name}\"] = {'memory':mem_end-mem_begin, \n",
    "                                      'time_train':train_time, \n",
    "                                      'time_test':test_time,\n",
    "                                      'param':num_params}\n",
    "        f.seek(0)\n",
    "        json.dump(file_data, f, indent = 0)\n",
    "\n",
    "    del model, optimizer\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c0e54bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark_memory(dataset='cifar100', \n",
    "#                   patch_size=2, \n",
    "#                   num_layers=4, \n",
    "#                   SEED=147, \n",
    "#                   sparse_att=True, \n",
    "#                   sparse_mlp=False, \n",
    "#                   pos_emb=False,\n",
    "#                   cuda=0\n",
    "#                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "675693c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Automate the benchmark\n",
    "# ###### for c10\n",
    "\n",
    "# cuda_idx = 0\n",
    "# seed = 147\n",
    "# PE = False\n",
    "# nlayers=2\n",
    "# dataset='cifar10'\n",
    "# nlayers = 2\n",
    "# sparse_mlp = False\n",
    "# for patch_size in [4, 2, 1]:\n",
    "#     for _expansion in [64, 256, 1024]:\n",
    "#         for sparse_attention in [False, True]:\n",
    "#             expansion_dict[patch_size] = _expansion\n",
    "#             print(f'''\n",
    "#                 Experimenting on {dataset} Dataset \n",
    "#                 patch:{patch_size},\n",
    "#                 sparse_att: {sparse_attention},\n",
    "#                 sparse_mlp: {sparse_mlp},\n",
    "#                 num_layers: {nlayers},\n",
    "#                 pos_embed: {PE},\n",
    "#                 seed: {seed}\n",
    "#             ''')\n",
    "\n",
    "#             try:\n",
    "#                 benchmark_memory(dataset=dataset, \n",
    "#                           patch_size=patch_size, \n",
    "#                           num_layers=nlayers, \n",
    "#                           SEED=seed, \n",
    "#                           sparse_att=sparse_attention, sparse_mlp=sparse_mlp, \n",
    "#                           pos_emb=PE,\n",
    "#                           cuda=cuda_idx\n",
    "#                          )\n",
    "#             except Exception as e:\n",
    "#                 print(\"Cuda out of memory \\n !!!!!!!!!!!!!!!!!!! \\n\")\n",
    "#                 print(e)\n",
    "\n",
    "#             torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91296f4",
   "metadata": {},
   "source": [
    "## Test 1 by 1\n",
    "\n",
    "- continue next exp if output is found\n",
    "- exit after successful experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e9d9aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:4,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "64 64\n",
      "01.3_ViT_train_cifar10_patch4_l2_exp64_att_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:4,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "64 64\n",
      "01.3_ViT_train_cifar10_patch4_l2_exp64_sAtt_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:4,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "64 256\n",
      "01.3_ViT_train_cifar10_patch4_l2_exp256_att_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:4,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "64 256\n",
      "01.3_ViT_train_cifar10_patch4_l2_exp256_sAtt_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:4,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "64 1024\n",
      "01.3_ViT_train_cifar10_patch4_l2_exp1024_att_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:4,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "64 1024\n",
      "01.3_ViT_train_cifar10_patch4_l2_exp1024_sAtt_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:2,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "256 64\n",
      "01.3_ViT_train_cifar10_patch2_l2_exp64_att_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:2,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "256 64\n",
      "01.3_ViT_train_cifar10_patch2_l2_exp64_sAtt_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:2,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "256 256\n",
      "01.3_ViT_train_cifar10_patch2_l2_exp256_att_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:2,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "256 256\n",
      "01.3_ViT_train_cifar10_patch2_l2_exp256_sAtt_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:2,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "256 1024\n",
      "01.3_ViT_train_cifar10_patch2_l2_exp1024_att_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:2,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "256 1024\n",
      "01.3_ViT_train_cifar10_patch2_l2_exp1024_sAtt_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:1,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "1024 64\n",
      "01.3_ViT_train_cifar10_patch1_l2_exp64_att_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:1,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "1024 64\n",
      "01.3_ViT_train_cifar10_patch1_l2_exp64_sAtt_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:1,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "1024 256\n",
      "01.3_ViT_train_cifar10_patch1_l2_exp256_att_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:1,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "1024 256\n",
      "01.3_ViT_train_cifar10_patch1_l2_exp256_sAtt_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:1,\n",
      "                sparse_att: False,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "1024 1024\n",
      "01.3_ViT_train_cifar10_patch1_l2_exp1024_att_mlp_s147 already found.. !!\n",
      "\n",
      "                Experimenting on cifar10 Dataset \n",
      "                patch:1,\n",
      "                sparse_att: True,\n",
      "                sparse_mlp: False,\n",
      "                num_layers: 2,\n",
      "                pos_embed: False,\n",
      "                seed: 147\n",
      "            \n",
      "1024 1024\n",
      "ViT Mixer : Channels per patch -> Initial:3 Final:1024\n",
      "[2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
      "Sequence len: 1024 ; Block size: 32\n",
      "Channel dim: 1024 num heads: 32\n",
      "MLP dim: 1024 ; Block size: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuman/All-Files/Program_Files/miniconda3/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:366: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled.Consider setting `torch.set_float32_matmul_precision('high')`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  27289610\n",
      "Model Name: 01.3_ViT_train_cifar10_patch1_l2_exp1024_sAtt_mlp_s147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/50 [00:00<?, ?it/s][2022-12-15 19:25:14,232] torch._inductor.ir: [WARNING] Using FallbackKernel: aten.index\n",
      "100%|█████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem begin: 1  end: 5569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-15 19:25:28,471] torch._inductor.ir: [WARNING] Using FallbackKernel: aten.index\n"
     ]
    }
   ],
   "source": [
    "### Automate the benchmark\n",
    "###### for c10\n",
    "\n",
    "cuda_idx = 0\n",
    "seed = 147\n",
    "PE = False\n",
    "nlayers=2\n",
    "dataset='cifar10'\n",
    "nlayers = 2\n",
    "sparse_mlp = False\n",
    "for patch_size in [4, 2, 1]:\n",
    "    for _expansion in [64, 256, 1024]:\n",
    "        for sparse_attention in [False, True]:\n",
    "            expansion_dict[patch_size] = _expansion\n",
    "            print(f'''\n",
    "                Experimenting on {dataset} Dataset \n",
    "                patch:{patch_size},\n",
    "                sparse_att: {sparse_attention},\n",
    "                sparse_mlp: {sparse_mlp},\n",
    "                num_layers: {nlayers},\n",
    "                pos_embed: {PE},\n",
    "                seed: {seed}\n",
    "            ''')\n",
    "            out = 1 ## dont break, if out is 0(already done) then do next exp, till existing one is found\n",
    "            try:\n",
    "                out = benchmark_memory(dataset=dataset, \n",
    "                          patch_size=patch_size, \n",
    "                          num_layers=nlayers, \n",
    "                          SEED=seed, \n",
    "                          sparse_att=sparse_attention, sparse_mlp=sparse_mlp, \n",
    "                          pos_emb=PE,\n",
    "                          cuda=cuda_idx\n",
    "                         )\n",
    "            except Exception as e:\n",
    "                print(\"Cuda out of memory \\n !!!!!!!!!!!!!!!!!!! \\n\")\n",
    "                print(e)\n",
    "                out = 1 ## exit by saving \n",
    "                \n",
    "                with open(filename, 'r+') as f:\n",
    "                    file_data = json.load(f)\n",
    "                    file_data[f\"{model_name}\"] = -1\n",
    "                    f.seek(0)\n",
    "                    json.dump(file_data, f, indent = 0)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            if out == 1: break\n",
    "        if out == 1: break                \n",
    "    if out == 1: break            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
