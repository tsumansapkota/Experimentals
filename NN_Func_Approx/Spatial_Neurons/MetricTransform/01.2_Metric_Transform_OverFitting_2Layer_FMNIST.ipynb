{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms as T\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm\n",
    "# from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtnnlib as dtnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.5,],\n",
    "        std=[0.5,],\n",
    "    ),\n",
    "])\n",
    "\n",
    "# train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/\", train=True, download=True, transform=mnist_transform)\n",
    "# test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/\", train=False, download=True, transform=mnist_transform)\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"../../../../_Datasets/\", train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = datasets.MNIST(root=\"../../../../_Datasets/\", train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 10\n",
    "model = nn.Sequential(\n",
    "            dtnn.DistanceTransform_MinExp(784, h),\n",
    "#             dtnn.DistanceTransform_Exp(784, h),\n",
    "#             nn.BatchNorm1d(10),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(h, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DistanceTransform_MinExp()\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model[0].set_centroid_to_data_maxdist(train_loader)\n",
    "# model[0].set_centroid_to_data(train_loader)\n",
    "# model[0].set_centroid_to_data_randomly(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = model[0].centers.shape[0]\n",
    "new_center = []\n",
    "new_labels = []\n",
    "count = 0\n",
    "for i, (xx, yy) in enumerate(train_loader):\n",
    "    xx = xx.reshape(-1, model[0].input_dim).to(model[0].centers.device)\n",
    "    if count+xx.shape[0] < N:\n",
    "        new_center.append(xx)\n",
    "        new_labels.append(yy)\n",
    "        count += xx.shape[0]\n",
    "    elif count >= N:\n",
    "        break\n",
    "    else:\n",
    "        new_center.append(xx[:N-count])\n",
    "        new_labels.append(yy[:N-count])\n",
    "        count = N\n",
    "        break\n",
    "        \n",
    "new_center = torch.cat(new_center, dim=0)\n",
    "new_labels = torch.cat(new_labels, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = model[0].centers.shape[0]\n",
    "# new_center = torch.empty_like(model[0].centers)\n",
    "# new_labels = torch.empty(model[0].num_centers, dtype=torch.long)\n",
    "\n",
    "# min_dists = torch.empty(N)\n",
    "# count = 0\n",
    "# steps = int(epoch*len(train_loader))\n",
    "# for i, (xx, yy) in enumerate(tqdm(train_loader)):\n",
    "#     if i > steps: break\n",
    "\n",
    "#     xx = xx.reshape(-1, model[0].input_dim).to(model[0].centers.device)\n",
    "#     if count < N:\n",
    "#         if N-count < train_loader.batch_size:\n",
    "#             #### final fillup\n",
    "#             new_center[count:count+N-count] = xx[:N-count]\n",
    "#             xx = xx[N-count:]\n",
    "#             yy = yy[N-count:]\n",
    "#             dists = torch.cdist(new_center, new_center)+torch.eye(N).to(model[0].centers.device)*1e5\n",
    "#             min_dists = dists.min(dim=0)[0]\n",
    "#             count = N\n",
    "\n",
    "#         else:#### fill the center\n",
    "#             new_center[count:count+len(xx)] = xx\n",
    "#             new_labels[count:count+len(xx)] = yy\n",
    "#             count += len(xx)\n",
    "#             continue\n",
    "\n",
    "#     ammd = min_dists.argmin()\n",
    "#     for i, x in enumerate(xx):\n",
    "#         dists = torch.norm(new_center-x, dim=1)\n",
    "#         md = dists.min()\n",
    "#         if md > min_dists[ammd]:\n",
    "#             min_dists[ammd] = md\n",
    "#             new_center[ammd] = x\n",
    "#             new_labels[ammd] = yy[i]\n",
    "#             ammd = min_dists.argmin()\n",
    "            \n",
    "# # self.centers.data = new_center.to(self.centers.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 784]), torch.Size([10]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_center.shape, new_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.zeros(len(new_labels), 10)\n",
    "for i in range(len(new_labels)):\n",
    "    weights[i, new_labels[i]] = 1.\n",
    "# weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].centers.data = new_center.to(model[0].centers.device)\n",
    "model[-1].weight.data = weights.t().to(model[-1].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch, model):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    acc = 100.*correct/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DistanceTransform_MinExp()\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 2.126 | Acc: 33.160 3316/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33.16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = test(0, model)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FMNIST={\n",
    "#     10:37.08,\n",
    "#     50:58.11,\n",
    "#     200:67.64,\n",
    "#     1000:73.16,\n",
    "#     5000:73.98,\n",
    "# }\n",
    "\n",
    "# MNIST={\n",
    "#     10:38.92,\n",
    "#     50:60.02,\n",
    "#     200:75.01,\n",
    "#     1000:84.47,\n",
    "#     5000:88.82,\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark with stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4951, 5657, 2743, 6049, 5852, 6659, 9076,  470,  357, 5088, 7605,\n",
       "       9549, 8231, 8408, 5763, 7226, 9244, 2257, 4295, 8433])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HIDDEN_UNITS = [10, 50, 200, 1000, 5000, 20000]\n",
    "\n",
    "seed = 2023\n",
    "np.random.seed(seed)\n",
    "SEEDS = np.random.randint(0, high=9999, size=20)\n",
    "SEEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: [], 50: [], 200: [], 1000: [], 5000: [], 20000: []}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = {h:[] for h in HIDDEN_UNITS}\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers_and_labels(data_loader, N):\n",
    "    new_center = []\n",
    "    new_labels = []\n",
    "    count = 0\n",
    "    for i, (xx, yy) in enumerate(data_loader):\n",
    "        xx = xx.reshape(-1, model[0].input_dim).to(model[0].centers.device)\n",
    "        if count+xx.shape[0] < N:\n",
    "            new_center.append(xx)\n",
    "            new_labels.append(yy)\n",
    "            count += xx.shape[0]\n",
    "        elif count >= N:\n",
    "            break\n",
    "        else:\n",
    "            new_center.append(xx[:N-count])\n",
    "            new_labels.append(yy[:N-count])\n",
    "            count = N\n",
    "            break\n",
    "\n",
    "    new_center = torch.cat(new_center, dim=0)\n",
    "    new_labels = torch.cat(new_labels, dim=0)\n",
    "    return new_center, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "for h in HIDDEN_UNITS:\n",
    "    print(f\"Experiment for Hidden units: {h}\")\n",
    "    for seed in tqdm(SEEDS):\n",
    "        seed = int(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        \n",
    "        train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        model = nn.Sequential(\n",
    "                    dtnn.DistanceTransform_MinExp(784, h),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(h, 10)).to(device)\n",
    "        \n",
    "        new_center, new_labels = get_centers_and_labels(train_loader, h)\n",
    "        weights = torch.zeros(len(new_labels), 10)\n",
    "        for i in range(len(new_labels)):\n",
    "            weights[i, new_labels[i]] = 1.\n",
    "            \n",
    "        model[0].centers.data = new_center.to(model[0].centers.device)\n",
    "        model[-1].weight.data = weights.t().to(model[-1].weight.data)\n",
    "        model.eval()\n",
    "        \n",
    "        test_acc = test(0, model)\n",
    "        test_accuracy[h].append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"H \\tMean \\t\\tSTD \\tMAX\")\n",
    "for k, v in test_accuracy.items():\n",
    "#     print(k, v)\n",
    "    print(f\"{k} \\t{np.mean(v):.4f} \\t{np.std(v):.4f} \\t{np.max(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=\"\"\"\n",
    "MNIST:\n",
    "H \tMean \t\tSTD \tMAX\n",
    "10 \t36.4770 \t3.2851 \t42.69\n",
    "50 \t60.7590 \t3.4937 \t67.86\n",
    "200 \t76.4045 \t2.2082 \t81.0\n",
    "1000 \t85.6070 \t0.8276 \t87.03\n",
    "5000 \t88.5605 \t0.3878 \t89.57\n",
    "20000 \t89.4285 \t0.2048 \t89.79\n",
    "\n",
    "FMNIST:\n",
    "H \tMean \t\tSTD \tMAX\n",
    "10 \t32.7495 \t6.6256 \t50.23\n",
    "50 \t58.0805 \t3.4686 \t62.1\n",
    "200 \t67.7500 \t1.8382 \t70.5\n",
    "1000 \t72.5960 \t1.4290 \t75.08\n",
    "5000 \t73.9515 \t0.4545 \t74.74\n",
    "20000 \t74.4270 \t0.2121 \t74.94\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MNIST:\n",
      "H \tMean \t\tSTD \tMAX\n",
      "10 \t36.4770 \t3.2851 \t42.69\n",
      "50 \t60.7590 \t3.4937 \t67.86\n",
      "200 \t76.4045 \t2.2082 \t81.0\n",
      "1000 \t85.6070 \t0.8276 \t87.03\n",
      "5000 \t88.5605 \t0.3878 \t89.57\n",
      "20000 \t89.4285 \t0.2048 \t89.79\n",
      "\n",
      "FMNIST:\n",
      "H \tMean \t\tSTD \tMAX\n",
      "10 \t32.7495 \t6.6256 \t50.23\n",
      "50 \t58.0805 \t3.4686 \t62.1\n",
      "200 \t67.7500 \t1.8382 \t70.5\n",
      "1000 \t72.5960 \t1.4290 \t75.08\n",
      "5000 \t73.9515 \t0.4545 \t74.74\n",
      "20000 \t74.4270 \t0.2121 \t74.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
