{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuman/All_Files/Program_Files/miniconda3/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os, sys, pathlib, random, time, pickle, copy, json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED = 147\n",
    "# SEED = 258\n",
    "SEED = 369\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(size=32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(\n",
    "#         mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "#         std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "#     ),\n",
    "# ])\n",
    "\n",
    "# cifar_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(\n",
    "#         mean=[0.4914, 0.4822, 0.4465], # mean=[0.5071, 0.4865, 0.4409] for cifar100\n",
    "#         std=[0.2023, 0.1994, 0.2010], # std=[0.2009, 0.1984, 0.2023] for cifar100\n",
    "#     ),\n",
    "# ])\n",
    "\n",
    "# train_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=True, download=True, transform=cifar_train)\n",
    "# test_dataset = datasets.CIFAR10(root=\"../../../../../_Datasets/cifar10/\", train=False, download=True, transform=cifar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_train = transforms.Compose([\n",
    "    transforms.RandomCrop(size=32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5071, 0.4865, 0.4409],\n",
    "        std=[0.2009, 0.1984, 0.2023],\n",
    "    ),\n",
    "])\n",
    "\n",
    "cifar_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5071, 0.4865, 0.4409],\n",
    "        std=[0.2009, 0.1984, 0.2023],\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root=\"../../../../../_Datasets/cifar100/\", train=True, download=True, transform=cifar_train)\n",
    "test_dataset = datasets.CIFAR100(root=\"../../../../../_Datasets/cifar100/\", train=False, download=True, transform=cifar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpBLock(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_layers_ratio=[2], actf=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        #### convert hidden layers ratio to list if integer is inputted\n",
    "        if isinstance(hidden_layers_ratio, int):\n",
    "            hidden_layers_ratio = [hidden_layers_ratio]\n",
    "            \n",
    "        self.hlr = [1]+hidden_layers_ratio+[1]\n",
    "        \n",
    "        self.mlp = []\n",
    "        ### for 1 hidden layer, we iterate 2 times\n",
    "        for h in range(len(self.hlr)-1):\n",
    "            i, o = int(self.hlr[h]*self.input_dim),\\\n",
    "                    int(self.hlr[h+1]*self.input_dim)\n",
    "            self.mlp.append(nn.Linear(i, o))\n",
    "            self.mlp.append(actf())\n",
    "        self.mlp = self.mlp[:-1]\n",
    "        \n",
    "        self.mlp = nn.Sequential(*self.mlp)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpBLock(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=6, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=6, out_features=8, bias=True)\n",
       "    (3): GELU(approximate='none')\n",
       "    (4): Linear(in_features=8, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MlpBLock(2, [3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP-Mixer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, patch_dim, channel_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln0 = nn.LayerNorm(channel_dim)\n",
    "        self.mlp_patch = MlpBLock(patch_dim, [2])\n",
    "        self.ln1 = nn.LayerNorm(channel_dim)\n",
    "        self.mlp_channel = MlpBLock(channel_dim, [2])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## x has shape-> N, nP, nC/hidden_dims; C=Channel, P=Patch\n",
    "        \n",
    "        ######## !!!! Can use same mixer on shape of -> N, C, P;\n",
    "        \n",
    "        #### mix per patch\n",
    "        y = self.ln0(x) ### per channel layer normalization ?? \n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        y = self.mlp_patch(y)\n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        x = x+y\n",
    "        \n",
    "        #### mix per channel \n",
    "        y = self.ln1(x)\n",
    "        y = self.mlp_channel(y)\n",
    "        x = x+y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpMixer(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_dim:tuple, patch_size:tuple, hidden_expansion:float, num_blocks:int, num_classes:int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_dim = image_dim ### must contain (C, H, W) or (H, W)\n",
    "        self.scaler = nn.UpsamplingBilinear2d(size=(self.img_dim[-2], self.img_dim[-1]))\n",
    "        \n",
    "        ### find patch dim\n",
    "        d0 = int(image_dim[-2]/patch_size[0])\n",
    "        d1 = int(image_dim[-1]/patch_size[1])\n",
    "        assert d0*patch_size[0]==image_dim[-2], \"Image must be divisible into patch size\"\n",
    "        assert d1*patch_size[1]==image_dim[-1], \"Image must be divisible into patch size\"\n",
    "#         self.d0, self.d1 = d0, d1 ### number of patches in each axis\n",
    "        __patch_size = patch_size[0]*patch_size[1]*image_dim[0] ## number of channels in each patch\n",
    "    \n",
    "        ### find channel dim\n",
    "        channel_size = d0*d1 ## number of patches\n",
    "        \n",
    "        ### after the number of channels are changed\n",
    "        init_dim = __patch_size\n",
    "#         final_dim = int(patch_size[0]*patch_size[1]*hidden_expansion)\n",
    "        final_dim = int(init_dim*hidden_expansion)\n",
    "\n",
    "        self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "        #### rescale the patches (patch wise image non preserving transform, unlike bilinear interpolation)\n",
    "        self.channel_change = nn.Linear(init_dim, final_dim)\n",
    "        print(f\"MLP Mixer : Channes per patch -> Initial:{init_dim} Final:{final_dim}\")\n",
    "        \n",
    "        \n",
    "        self.channel_dim = final_dim\n",
    "        self.patch_dim = channel_size\n",
    "        \n",
    "        self.mixer_blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            self.mixer_blocks.append(MixerBlock(self.patch_dim, self.channel_dim))\n",
    "        self.mixer_blocks = nn.Sequential(*self.mixer_blocks)\n",
    "        \n",
    "        self.linear = nn.Linear(self.patch_dim*self.channel_dim, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = self.scaler(x)\n",
    "        x = self.unfold(x).swapaxes(-1, -2)\n",
    "        x = self.channel_change(x)\n",
    "        x = self.mixer_blocks(x)\n",
    "        x = self.linear(x.view(bs, -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MlpMixer(nn.Module):\n",
    "    \n",
    "#     def __init__(self, input_channels:int, hidden_image_dim:tuple, patch_size:tuple, num_blocks:int, num_classes:int, use1x1scale=True):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.img_dim = hidden_image_dim ### must contain (C, H, W) or (H, W)\n",
    "        \n",
    "#         ### find patch dim\n",
    "#         d0 = int(self.img_dim[-2]/patch_size[0])\n",
    "#         d1 = int(self.img_dim[-1]/patch_size[1])\n",
    "#         assert d0*patch_size[0]==self.img_dim[-2], \"Image must be divisible into patch size\"\n",
    "#         assert d1*patch_size[1]==self.img_dim[-1], \"Image must be divisible into patch size\"\n",
    "        \n",
    "#         ### find channel dim\n",
    "#         channel_size = d0*d1 ## number of patches\n",
    "        \n",
    "#         ### after the number of channels are changed\n",
    "#         init_dim = patch_size[0]*patch_size[1]*input_channels ## number of channels in each patch\n",
    "#         final_dim = patch_size[0]*patch_size[1]*self.img_dim[0]\n",
    "\n",
    "#         self.scaler = nn.UpsamplingBilinear2d(size=(self.img_dim[-2], self.img_dim[-1]))\n",
    "        \n",
    "#         if use1x1scale:\n",
    "#             self.conv1x1 = nn.Conv2d(input_channels, self.img_dim[0], kernel_size=1, stride=1)\n",
    "#             if input_channels == self.img_dim[0]:\n",
    "#                 self.conv1x1 = nn.Identity()\n",
    "#         else:\n",
    "#             #### rescale the patches (patch wise image non preserving transform, unlike bilinear interpolation)\n",
    "#             self.channel_change = nn.Linear(init_dim, final_dim) ## apply after unfold\n",
    "            \n",
    "#         self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "#         print(f\"MLP Mixer : Channes per patch -> Initial:{init_dim} Final:{final_dim}\")\n",
    "        \n",
    "#         ### after the axis are swapped\n",
    "#         self.channel_dim = final_dim\n",
    "#         self.patch_dim = channel_size\n",
    "        \n",
    "#         self.mixer_blocks = []\n",
    "#         for i in range(num_blocks):\n",
    "#             self.mixer_blocks.append(MixerBlock(self.patch_dim, self.channel_dim))\n",
    "#         self.mixer_blocks = nn.Sequential(*self.mixer_blocks)\n",
    "        \n",
    "#         self.linear = nn.Linear(self.patch_dim*self.channel_dim, num_classes)\n",
    "        \n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         bs = x.shape[0]\n",
    "#         x = self.scaler(x) ## scale to high dimension\n",
    "#         x = self.conv1x1(x)\n",
    "#         x = self.unfold(x).swapaxes(-1, -2).contiguous() ## convert to patches, bring channels first\n",
    "# #         x = self.channel_change(x) ## change the number of channels\n",
    "#         x = self.mixer_blocks(x) ## the mixer architecture\n",
    "#         x = self.linear(x.view(bs, -1)) ## classify\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Mixer : Channes per patch -> Initial:48 Final:120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MlpMixer(\n",
       "  (scaler): UpsamplingBilinear2d(size=(32, 32), mode=bilinear)\n",
       "  (unfold): Unfold(kernel_size=(4, 4), dilation=1, padding=0, stride=(4, 4))\n",
       "  (channel_change): Linear(in_features=48, out_features=120, bias=True)\n",
       "  (mixer_blocks): Sequential(\n",
       "    (0): MixerBlock(\n",
       "      (ln0): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=120, out_features=240, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=240, out_features=120, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=7680, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixer = MlpMixer((3, 32, 32), (4, 4), hidden_expansion=2.5, num_blocks=1, num_classes=10)\n",
    "mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  157706\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in mixer.parameters())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1648, -0.0510, -0.0486, -0.1505, -0.3137, -0.5226,  0.0023,  0.5233,\n",
       "         -0.2587, -0.5398]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixer(torch.randn(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMixerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, patch_size, num_channel):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "#         self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "        ps = None\n",
    "        if isinstance(patch_size, int):\n",
    "            ps = patch_size**2\n",
    "        else:\n",
    "            ps = patch_size[0]*patch_size[1]\n",
    "        ps = ps*num_channel\n",
    "        \n",
    "        self.ln0 = nn.LayerNorm(ps)\n",
    "        self.mlp_patch = MlpBLock(ps, [2])\n",
    "        \n",
    "#         self.fold = nn.Fold(kernel_size=patch_size, stride=patch_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## x has shape-> N, C, H, W; C=Channel\n",
    "        \n",
    "        sz = x.shape\n",
    "        \n",
    "        y = nn.functional.unfold(x, \n",
    "                                 kernel_size=self.patch_size, \n",
    "                                 stride=self.patch_size\n",
    "                                )\n",
    "        #### mix per patch\n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        y = self.ln0(y) \n",
    "        y = self.mlp_patch(y)\n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        \n",
    "        y = nn.functional.fold(y, (sz[-2], sz[-1]), \n",
    "                               kernel_size=self.patch_size, \n",
    "                               stride=self.patch_size\n",
    "                              )\n",
    "        x = x+y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchMixerBlock(\n",
       "  (ln0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "  (mlp_patch): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=192, out_features=384, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=384, out_features=192, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmb = PatchMixerBlock(8, 3)\n",
    "pmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pmb(torch.randn(1, 3, 35, 35)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factors(n):\n",
    "    facts = []\n",
    "    for i in range(2, n+1):\n",
    "        if n%i == 0:\n",
    "            facts.append(i)\n",
    "    return facts\n",
    "\n",
    "class PatchMlpMixer(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_dim:tuple, patch_sizes:tuple, hidden_channels:int, num_blocks:int, num_classes:int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_dim = image_dim ### must contain (C, H, W)\n",
    "        self.target_dim = np.prod(patch_sizes)\n",
    "        \n",
    "        ### find number of channel for input, the channel is \n",
    "        num_channel = image_dim[0]\n",
    "        \n",
    "        self.conv1x1 = nn.Conv2d(num_channel, hidden_channels, kernel_size=1, stride=1)\n",
    "        if num_channel == hidden_channels:\n",
    "            self.conv1x1 = nn.Identity()\n",
    "        \n",
    "        self.mixer_blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            for ps in patch_sizes:\n",
    "                self.mixer_blocks.append(PatchMixerBlock(ps, hidden_channels))\n",
    "                \n",
    "        self.mixer_blocks = nn.Sequential(*self.mixer_blocks)\n",
    "        self.linear = nn.Linear(self.target_dim*self.target_dim*hidden_channels, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        x = nn.functional.interpolate(x, size=self.target_dim, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        x = self.conv1x1(x) \n",
    "        x = self.mixer_blocks(x)\n",
    "        x = self.linear(x.view(bs, -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*3*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_mixer = PatchMlpMixer((3, 35, 35), patch_sizes=[5, 7], hidden_channels=3, num_blocks=1, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchMlpMixer(\n",
       "  (conv1x1): Identity()\n",
       "  (mixer_blocks): Sequential(\n",
       "    (0): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=3675, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  146806\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in patch_mixer.parameters())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_mixer(torch.randn(1, 3, 32, 32)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Mixer : Channes per patch -> Initial:48 Final:144\n"
     ]
    }
   ],
   "source": [
    "### Model 1 : balanced with (1) of PatchOnly ; higher image scaling, low channel scaling for similar params\n",
    "#### it has large dimension of final hidden unit.\n",
    "## 81, 150\n",
    "# model = MlpMixer((3, 5*9, 5*9), (5, 5), hidden_expansion=2, num_blocks=10, num_classes=10)\n",
    "### balanced model with 4*9 expansion as well\n",
    "## 81, 144\n",
    "model = MlpMixer((3, 4*9, 4*9), (4, 4), hidden_expansion=3.0, num_blocks=10, num_classes=10)\n",
    "\n",
    "### Model 2 : use simple method of expanding only hidden dimension/channel\n",
    "## 64, 135\n",
    "# model = MlpMixer((3, 32, 32), (4, 4), hidden_expansion=3.2, num_blocks=10, num_classes=10)\n",
    "\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpMixer(\n",
       "  (scaler): UpsamplingBilinear2d(size=(36, 36), mode=bilinear)\n",
       "  (unfold): Unfold(kernel_size=(4, 4), dilation=1, padding=0, stride=(4, 4))\n",
       "  (channel_change): Linear(in_features=48, out_features=144, bias=True)\n",
       "  (mixer_blocks): Sequential(\n",
       "    (0): MixerBlock(\n",
       "      (ln0): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=81, out_features=162, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=162, out_features=81, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=288, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=288, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MixerBlock(\n",
       "      (ln0): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=81, out_features=162, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=162, out_features=81, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=288, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=288, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): MixerBlock(\n",
       "      (ln0): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=81, out_features=162, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=162, out_features=81, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=288, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=288, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): MixerBlock(\n",
       "      (ln0): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=81, out_features=162, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=162, out_features=81, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=288, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=288, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): MixerBlock(\n",
       "      (ln0): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=81, out_features=162, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=162, out_features=81, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=288, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=288, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): MixerBlock(\n",
       "      (ln0): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=81, out_features=162, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=162, out_features=81, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=288, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=288, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): MixerBlock(\n",
       "      (ln0): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=81, out_features=162, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=162, out_features=81, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=288, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=288, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): MixerBlock(\n",
       "      (ln0): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=81, out_features=162, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=162, out_features=81, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=288, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=288, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): MixerBlock(\n",
       "      (ln0): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=81, out_features=162, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=162, out_features=81, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=288, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=288, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): MixerBlock(\n",
       "      (ln0): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=81, out_features=162, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=162, out_features=81, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_channel): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=288, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=288, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=11664, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  1104390\n"
     ]
    }
   ],
   "source": [
    "# print(\"number of params: \", sum(p.numel() for p in model.parameters())) \n",
    "print(\"number of params: \", sum(p.numel() for p in model.mixer_blocks.parameters())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1, 3, 32, 32).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 1 : balanced using best settings for default patch mixer without scaling hidden channels.\n",
    "model = PatchMlpMixer((3, 35, 35), patch_sizes=[5,7], hidden_channels=3, num_blocks=10, num_classes=10)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchMlpMixer(\n",
       "  (conv1x1): Identity()\n",
       "  (mixer_blocks): Sequential(\n",
       "    (0): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (17): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (18): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((75,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=75, out_features=150, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=150, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (19): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((147,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=147, out_features=294, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=294, out_features=147, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=3675, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  1100460\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.mixer_blocks.parameters())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1, 3, 32, 32).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  1137220\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters())) \n",
    "## Patch ||  1137220\n",
    "## Mixer ||  1141703"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = f'mlp_mixer_c10_s{SEED}'\n",
    "# model_name = f'temp_c10_s{SEED}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 200\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAT ={'train_stat':[], 'test_stat':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    STAT['train_stat'].append((epoch, train_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    time_taken = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            start = time.time()-start\n",
    "            time_taken.append(start)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    STAT['test_stat'].append((epoch, test_loss/(batch_idx+1), 100.*correct/total, np.mean(time_taken))) ### (Epochs, Loss, Acc, time)\n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc\n",
    "        \n",
    "    with open(f\"./output/{model_name}_data.json\", 'w') as f:\n",
    "        json.dump(STAT, f, indent=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "# resume = False\n",
    "\n",
    "# if resume:\n",
    "#     # Load checkpoint.\n",
    "#     print('==> Resuming from checkpoint..')\n",
    "#     assert os.path.isdir('./models'), 'Error: no checkpoint directory found!'\n",
    "#     checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "#     model.load_state_dict(checkpoint['model'])\n",
    "#     best_acc = checkpoint['acc']\n",
    "#     start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Train the whole damn thing\n",
    "\n",
    "# for epoch in range(start_epoch, start_epoch+EPOCHS): ## for 200 epochs\n",
    "#     train(epoch)\n",
    "#     test(epoch)\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "# best_acc = checkpoint['acc']\n",
    "# start_epoch = checkpoint['epoch']\n",
    "\n",
    "# best_acc, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_stat = np.array(STAT['train_stat'])\n",
    "# test_stat = np.array(STAT['test_stat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_stat[:,1], label='train')\n",
    "# plt.plot(test_stat[:,1], label='test')\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "# plt.savefig(f\"./output/plots/{model_name}_loss.svg\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_stat[:,2], label='train')\n",
    "# plt.plot(test_stat[:,2], label='test')\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.savefig(f\"./output/plots/{model_name}_accs.svg\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(seed, ds):\n",
    "    BS = 64\n",
    "    if ds == 'c100': BS = 128\n",
    "    torch.manual_seed(seed)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BS, shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BS, shuffle=False, num_workers=2)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark():\n",
    "    global model, optimizer, train_loader, test_loader, model_name, criterion, STAT, best_acc\n",
    "    EPOCHS = 200\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    lr = 0.001\n",
    "    DS = 'c100'\n",
    "#     DS = 'c10'\n",
    "    for SEED in [369]:\n",
    "        for num_layers in [10]:\n",
    "\n",
    "            for i in range(3): ## 3 models training\n",
    "                print(\"Experiment index:\", i)\n",
    "                train_loader, test_loader = get_data_loaders(SEED, DS)\n",
    "                num_cls = 10\n",
    "                if DS=='c100': num_cls = 100\n",
    "                ### FOR ORIGINAL MIXER V0\n",
    "                if i==0:\n",
    "                    ## hard core ignore\n",
    "#                     if SEED==258 and num_layers==7: continue\n",
    "                    model = MlpMixer((3, 4*9, 4*9), (4, 4), hidden_expansion=3.0, num_blocks=num_layers, num_classes=num_cls)\n",
    "                    model_name = f'original_mixer0_l{num_layers}_{DS}_s{SEED}'\n",
    "                elif i == 1:\n",
    "                    ### FOR ORIGINAL MIXER V1\n",
    "#                     if SEED==258 and num_layers==7: continue\n",
    "                    model = MlpMixer((3, 32, 32), (4, 4), hidden_expansion=3.2, num_blocks=num_layers, num_classes=num_cls)\n",
    "                    model_name = f'original_mixer1_l{num_layers}_{DS}_s{SEED}'\n",
    "                elif i == 2:\n",
    "                    model = PatchMlpMixer((3, 35, 35), patch_sizes=[5,7], hidden_channels=3, num_blocks=num_layers, num_classes=num_cls)\n",
    "                    model_name = f'patchonly_mixer0_l{num_layers}_{DS}_s{SEED}'\n",
    "                else:\n",
    "                    print(\"JPT........!!!!\")\n",
    "                model = model.to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "                num_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "                model_name = \"03.0_\" + model_name\n",
    "                print(f\"EXPERIMENTING FOR : {model_name} | params: {num_params}  .......\\n.......\")\n",
    "                \n",
    "#                 continue\n",
    "                STAT ={'train_stat':[], 'test_stat':[], 'num_params':num_params}\n",
    "                best_acc = -1\n",
    "                for epoch in range(0, EPOCHS): ## for 200 epochs\n",
    "                    train(epoch)\n",
    "                    test(epoch)\n",
    "                    scheduler.step()\n",
    "                print(f\"Training finished\\n\")\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    return 0           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment index: 0\n",
      "MLP Mixer : Channes per patch -> Initial:48 Final:144\n",
      "EXPERIMENTING FOR : 03.0_original_mixer0_l10_c100_s369 | params: 2277946  .......\n",
      ".......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:13<00:00, 29.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 0 Loss: 3.723 | Acc: 15.414 7707/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 53.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 3.171 | Acc: 24.090 2409/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 25.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 1 Loss: 3.098 | Acc: 25.172 12586/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 54.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 1 Loss: 2.862 | Acc: 30.060 3006/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 2 Loss: 2.823 | Acc: 30.350 15175/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 2 Loss: 2.615 | Acc: 34.840 3484/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 3 Loss: 2.613 | Acc: 34.572 17286/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 53.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 3 Loss: 2.514 | Acc: 37.100 3710/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 4 Loss: 2.441 | Acc: 38.094 19047/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 62.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 4 Loss: 2.445 | Acc: 38.760 3876/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 5 Loss: 2.288 | Acc: 41.498 20749/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 53.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 5 Loss: 2.285 | Acc: 42.750 4275/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 6 Loss: 2.150 | Acc: 44.430 22215/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 51.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 6 Loss: 2.214 | Acc: 44.620 4462/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 7 Loss: 2.029 | Acc: 46.924 23462/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 61.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 7 Loss: 2.136 | Acc: 45.980 4598/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 8 Loss: 1.918 | Acc: 49.632 24816/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 8 Loss: 2.150 | Acc: 46.940 4694/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 9 Loss: 1.814 | Acc: 52.066 26033/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 9 Loss: 2.146 | Acc: 47.650 4765/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 10 Loss: 1.705 | Acc: 54.364 27182/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 53.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 10 Loss: 2.132 | Acc: 48.690 4869/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 11 Loss: 1.616 | Acc: 56.414 28207/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 11 Loss: 2.137 | Acc: 48.730 4873/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 12 Loss: 1.510 | Acc: 58.868 29434/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 53.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 12 Loss: 2.158 | Acc: 49.920 4992/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 13 Loss: 1.398 | Acc: 61.522 30761/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 13 Loss: 2.177 | Acc: 50.170 5017/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 14 Loss: 1.306 | Acc: 63.718 31859/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 51.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 14 Loss: 2.258 | Acc: 50.450 5045/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 15 Loss: 1.189 | Acc: 66.702 33351/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 53.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 15 Loss: 2.305 | Acc: 50.580 5058/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 16 Loss: 1.108 | Acc: 68.524 34262/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 16 Loss: 2.388 | Acc: 50.720 5072/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 17 Loss: 1.012 | Acc: 71.278 35639/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 58.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 17 Loss: 2.484 | Acc: 50.030 5003/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 18 Loss: 0.940 | Acc: 73.008 36504/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 18 Loss: 2.584 | Acc: 50.100 5010/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 19 Loss: 0.864 | Acc: 75.256 37628/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 19 Loss: 2.688 | Acc: 51.080 5108/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 20 Loss: 0.788 | Acc: 77.208 38604/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 60.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 20 Loss: 2.803 | Acc: 51.080 5108/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 21 Loss: 0.737 | Acc: 78.702 39351/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 21 Loss: 2.826 | Acc: 51.920 5192/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 22 Loss: 0.679 | Acc: 80.342 40171/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 22 Loss: 3.011 | Acc: 50.310 5031/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 23 Loss: 0.630 | Acc: 81.800 40900/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 55.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 23 Loss: 3.167 | Acc: 51.280 5128/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 24 Loss: 0.614 | Acc: 82.440 41220/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 24 Loss: 3.239 | Acc: 51.350 5135/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 25 Loss: 0.562 | Acc: 83.664 41832/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 25 Loss: 3.423 | Acc: 51.460 5146/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 26 Loss: 0.543 | Acc: 84.500 42250/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 51.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 26 Loss: 3.479 | Acc: 51.040 5104/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 25.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 27 Loss: 0.511 | Acc: 85.408 42704/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 54.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 27 Loss: 3.667 | Acc: 51.060 5106/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 28 Loss: 0.486 | Acc: 86.220 43110/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 51.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 28 Loss: 3.637 | Acc: 51.470 5147/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 29 Loss: 0.458 | Acc: 87.042 43521/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 29 Loss: 3.754 | Acc: 51.470 5147/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 30 Loss: 0.446 | Acc: 87.518 43759/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 62.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 30 Loss: 3.895 | Acc: 51.980 5198/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 31 Loss: 0.453 | Acc: 87.506 43753/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 31 Loss: 3.970 | Acc: 51.420 5142/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 32 Loss: 0.423 | Acc: 88.496 44248/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 32 Loss: 4.215 | Acc: 51.340 5134/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 33 Loss: 0.403 | Acc: 89.172 44586/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 55.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 33 Loss: 4.253 | Acc: 50.880 5088/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 34 Loss: 0.381 | Acc: 89.804 44902/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 34 Loss: 4.270 | Acc: 51.340 5134/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 35 Loss: 0.370 | Acc: 89.944 44972/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 53.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 35 Loss: 4.528 | Acc: 51.350 5135/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 36 Loss: 0.367 | Acc: 90.364 45182/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 36 Loss: 4.527 | Acc: 50.910 5091/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 37 Loss: 0.376 | Acc: 90.098 45049/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 55.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 37 Loss: 4.576 | Acc: 51.360 5136/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 38 Loss: 0.340 | Acc: 90.960 45480/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 38 Loss: 4.733 | Acc: 50.650 5065/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 39 Loss: 0.340 | Acc: 91.128 45564/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 51.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 39 Loss: 4.750 | Acc: 51.540 5154/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 40 Loss: 0.339 | Acc: 91.450 45725/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 61.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 40 Loss: 4.923 | Acc: 51.070 5107/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 41 Loss: 0.340 | Acc: 91.274 45637/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 41 Loss: 5.097 | Acc: 51.210 5121/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 42 Loss: 0.321 | Acc: 91.890 45945/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 53.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 42 Loss: 5.022 | Acc: 51.550 5155/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:16<00:00, 24.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 43 Loss: 0.311 | Acc: 92.132 46066/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 55.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 43 Loss: 5.083 | Acc: 51.860 5186/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 44 Loss: 0.296 | Acc: 92.648 46324/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 44 Loss: 5.167 | Acc: 51.390 5139/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:16<00:00, 24.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 45 Loss: 0.272 | Acc: 93.152 46576/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 45 Loss: 5.426 | Acc: 51.410 5141/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 46 Loss: 0.293 | Acc: 92.710 46355/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 46 Loss: 5.496 | Acc: 51.660 5166/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 25.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 47 Loss: 0.280 | Acc: 93.030 46515/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 47 Loss: 5.515 | Acc: 51.040 5104/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 48 Loss: 0.294 | Acc: 92.920 46460/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 48 Loss: 5.828 | Acc: 50.670 5067/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 49 Loss: 0.277 | Acc: 93.394 46697/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 53.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 49 Loss: 5.612 | Acc: 52.450 5245/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 50 Loss: 0.266 | Acc: 93.712 46856/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 58.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 50 Loss: 5.855 | Acc: 51.180 5118/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:16<00:00, 24.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 51 Loss: 0.258 | Acc: 93.870 46935/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 51 Loss: 5.906 | Acc: 51.900 5190/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 52 Loss: 0.259 | Acc: 93.892 46946/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 51.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 52 Loss: 6.043 | Acc: 51.040 5104/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 53 Loss: 0.258 | Acc: 93.948 46974/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 59.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 53 Loss: 6.015 | Acc: 51.630 5163/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 54 Loss: 0.238 | Acc: 94.372 47186/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 54 Loss: 5.978 | Acc: 51.670 5167/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 55 Loss: 0.232 | Acc: 94.710 47355/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 55 Loss: 6.175 | Acc: 51.050 5105/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 56 Loss: 0.242 | Acc: 94.416 47208/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 56 Loss: 6.257 | Acc: 50.730 5073/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 25.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 57 Loss: 0.215 | Acc: 95.160 47580/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 51.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 57 Loss: 6.384 | Acc: 51.250 5125/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 58 Loss: 0.232 | Acc: 94.770 47385/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 58 Loss: 6.421 | Acc: 51.120 5112/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 59 Loss: 0.218 | Acc: 95.044 47522/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 59 Loss: 6.648 | Acc: 51.540 5154/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 60 Loss: 0.205 | Acc: 95.294 47647/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 59.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 60 Loss: 6.496 | Acc: 52.340 5234/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 61 Loss: 0.207 | Acc: 95.354 47677/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 51.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 61 Loss: 6.761 | Acc: 51.530 5153/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 62 Loss: 0.205 | Acc: 95.402 47701/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 51.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 62 Loss: 6.571 | Acc: 52.050 5205/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 63 Loss: 0.185 | Acc: 95.816 47908/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 58.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 63 Loss: 6.759 | Acc: 52.020 5202/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 64 Loss: 0.197 | Acc: 95.650 47825/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 64 Loss: 6.890 | Acc: 51.700 5170/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:16<00:00, 24.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 65 Loss: 0.208 | Acc: 95.436 47718/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 51.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 65 Loss: 6.994 | Acc: 51.530 5153/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 66 Loss: 0.197 | Acc: 95.748 47874/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 66 Loss: 6.944 | Acc: 52.320 5232/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 67 Loss: 0.184 | Acc: 95.960 47980/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 51.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 67 Loss: 7.042 | Acc: 52.250 5225/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 68 Loss: 0.181 | Acc: 96.076 48038/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 53.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 68 Loss: 7.237 | Acc: 51.610 5161/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 69 Loss: 0.177 | Acc: 96.124 48062/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 52.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 69 Loss: 7.173 | Acc: 52.200 5220/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 70 Loss: 0.183 | Acc: 96.252 48126/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 58.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 70 Loss: 7.320 | Acc: 51.950 5195/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [00:15<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 71 Loss: 0.166 | Acc: 96.424 48212/50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 79/79 [00:01<00:00, 51.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 71 Loss: 7.163 | Acc: 53.030 5303/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|                               | 154/391 [00:06<00:09, 24.17it/s]"
     ]
    }
   ],
   "source": [
    "benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdfasdfwdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models -- New Test \n",
    "1. Scaling is different for original mlp mixer so not useful for benchmarking\n",
    "2. MLP mixer uses channel wise mixing, here channels are number of patches; it changes differntly from patch size when scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpBLock(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_layers_ratio=[2], actf=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        #### convert hidden layers ratio to list if integer is inputted\n",
    "        if isinstance(hidden_layers_ratio, int):\n",
    "            hidden_layers_ratio = [hidden_layers_ratio]\n",
    "            \n",
    "        self.hlr = [1]+hidden_layers_ratio+[1]\n",
    "        \n",
    "        self.mlp = []\n",
    "        ### for 1 hidden layer, we iterate 2 times\n",
    "        for h in range(len(self.hlr)-1):\n",
    "            i, o = int(self.hlr[h]*self.input_dim),\\\n",
    "                    int(self.hlr[h+1]*self.input_dim)\n",
    "            self.mlp.append(nn.Linear(i, o))\n",
    "            self.mlp.append(actf())\n",
    "        self.mlp = self.mlp[:-1]\n",
    "        \n",
    "        self.mlp = nn.Sequential(*self.mlp)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MlpBLock(2, [3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP-Mixer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, patch_dim, channel_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln0 = nn.LayerNorm(channel_dim)\n",
    "        self.mlp_patch = MlpBLock(patch_dim, [2])\n",
    "        self.ln1 = nn.LayerNorm(channel_dim)\n",
    "        self.mlp_channel = MlpBLock(channel_dim, [2])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## x has shape-> N, nP, nC/hidden_dims; C=Channel, P=Patch\n",
    "        \n",
    "        ######## !!!! Can use same mixer on shape of -> N, C, P;\n",
    "        \n",
    "        #### mix per patch\n",
    "        y = self.ln0(x) ### per channel layer normalization ?? \n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        y = self.mlp_patch(y)\n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        x = x+y\n",
    "        \n",
    "        #### mix per channel \n",
    "        y = self.ln1(x)\n",
    "        y = self.mlp_channel(y)\n",
    "        x = x+y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpMixer(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels:int, hidden_image_dim:tuple, patch_size:tuple, num_blocks:int, num_classes:int, use1x1scale=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_dim = hidden_image_dim ### must contain (C, H, W) or (H, W)\n",
    "        \n",
    "        ### find patch dim\n",
    "        d0 = int(self.img_dim[-2]/patch_size[0])\n",
    "        d1 = int(self.img_dim[-1]/patch_size[1])\n",
    "        assert d0*patch_size[0]==self.img_dim[-2], \"Image must be divisible into patch size\"\n",
    "        assert d1*patch_size[1]==self.img_dim[-1], \"Image must be divisible into patch size\"\n",
    "        \n",
    "        ### find channel dim\n",
    "        channel_size = d0*d1 ## number of patches\n",
    "        \n",
    "        ### after the number of channels are changed\n",
    "        init_dim = patch_size[0]*patch_size[1]*input_channels ## number of channels in each patch\n",
    "        final_dim = patch_size[0]*patch_size[1]*self.img_dim[0]\n",
    "\n",
    "        self.scaler = nn.UpsamplingBilinear2d(size=(self.img_dim[-2], self.img_dim[-1]))\n",
    "        \n",
    "        if use1x1scale:\n",
    "            self.conv1x1 = nn.Conv2d(input_channels, self.img_dim[0], kernel_size=1, stride=1)\n",
    "            if input_channels == self.img_dim[0]:\n",
    "                self.conv1x1 = nn.Identity()\n",
    "        else:\n",
    "            #### rescale the patches (patch wise image non preserving transform, unlike bilinear interpolation)\n",
    "            self.channel_change = nn.Linear(init_dim, final_dim) ## apply after unfold\n",
    "            \n",
    "        self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "        print(f\"MLP Mixer : Channes per patch -> Initial:{init_dim} Final:{final_dim}\")\n",
    "        \n",
    "        ### after the axis are swapped\n",
    "        self.channel_dim = final_dim\n",
    "        self.patch_dim = channel_size\n",
    "        \n",
    "        self.mixer_blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            self.mixer_blocks.append(MixerBlock(self.patch_dim, self.channel_dim))\n",
    "        self.mixer_blocks = nn.Sequential(*self.mixer_blocks)\n",
    "        \n",
    "        self.linear = nn.Linear(self.patch_dim*self.channel_dim, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = self.scaler(x) ## scale to high dimension\n",
    "        x = self.conv1x1(x)\n",
    "        x = self.unfold(x).swapaxes(-1, -2).contiguous() ## convert to patches, bring channels first\n",
    "#         x = self.channel_change(x) ## change the number of channels\n",
    "        x = self.mixer_blocks(x) ## the mixer architecture\n",
    "        x = self.linear(x.view(bs, -1)) ## classify\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer = MlpMixer(3, (5, 35, 35), (5, 5), num_blocks=1, num_classes=10, use1x1scale=False)\n",
    "mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer(torch.randn(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMixerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, patch_size, num_channel):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "#         self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "        ps = None\n",
    "        if isinstance(patch_size, int):\n",
    "            ps = patch_size**2\n",
    "        else:\n",
    "            ps = patch_size[0]*patch_size[1]\n",
    "        ps = ps*num_channel\n",
    "        \n",
    "        self.ln0 = nn.LayerNorm(ps)\n",
    "        self.mlp_patch = MlpBLock(ps, [2])\n",
    "        \n",
    "#         self.fold = nn.Fold(kernel_size=patch_size, stride=patch_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## x has shape-> N, C, H, W; C=Channel\n",
    "        \n",
    "        sz = x.shape\n",
    "        \n",
    "        y = nn.functional.unfold(x, \n",
    "                                 kernel_size=self.patch_size, \n",
    "                                 stride=self.patch_size\n",
    "                                )\n",
    "        #### mix per patch\n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        y = self.ln0(y) \n",
    "        y = self.mlp_patch(y)\n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        \n",
    "        y = nn.functional.fold(y, (sz[-2], sz[-1]), \n",
    "                               kernel_size=self.patch_size, \n",
    "                               stride=self.patch_size\n",
    "                              )\n",
    "        x = x+y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmb = PatchMixerBlock(7, 5)\n",
    "pmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmb(torch.randn(1, 5, 35, 35)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factors(n):\n",
    "    facts = []\n",
    "    for i in range(2, n+1):\n",
    "        if n%i == 0:\n",
    "            facts.append(i)\n",
    "    return facts\n",
    "\n",
    "class PatchMlpMixer(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels:int, hidden_image_dim:tuple, patch_sizes:list, num_blocks:int, num_classes:int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_dim = hidden_image_dim ### must contain (C, H, W)\n",
    "        self.scaler = nn.UpsamplingBilinear2d(size=(self.img_dim[-2], self.img_dim[-1]))\n",
    "        \n",
    "        assert np.prod(patch_sizes) == hidden_image_dim[-1], \"The product of patches must equal image dimension\"\n",
    "        assert np.prod(patch_sizes) == hidden_image_dim[-2], \"The product of patches must equal image dimension\"\n",
    "        \n",
    "        ### find number of channel for input, the channel is \n",
    "        self.conv1x1 = nn.Conv2d(input_channels, self.img_dim[0], kernel_size=1, stride=1)\n",
    "        if input_channels == self.img_dim[0]:\n",
    "            self.conv1x1 = nn.Identity()\n",
    "        \n",
    "        self.mixer_blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            for ps in patch_sizes:\n",
    "                self.mixer_blocks.append(PatchMixerBlock(ps, self.img_dim[0]))\n",
    "                \n",
    "        self.mixer_blocks = nn.Sequential(*self.mixer_blocks)\n",
    "        self.linear = nn.Linear(np.prod(self.img_dim), num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = self.scaler(x)\n",
    "        x = self.conv1x1(x)\n",
    "        x = self.mixer_blocks(x)\n",
    "        x = self.linear(x.view(bs, -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_mixer = PatchMlpMixer(3, (5, 35, 35), patch_sizes=[5, 7], num_blocks=1, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_mixer(torch.randn(1, 3, 32, 32)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MlpMixer(3, (9, 32, 32), patch_size=(4, 4), num_blocks=10, num_classes=10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PatchMlpMixer(3, (3, 35, 35), patch_sizes=[5, 7], num_blocks=10, num_classes=10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters())) \n",
    "## Patch ||  1137220\n",
    "## Mixer ||  1141703"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
