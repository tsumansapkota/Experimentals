{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-374cd7ae378a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m _DEFAULT_TAGS = {\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/sklearn/utils/_joblib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# joblib imports may raise DeprecationWarning on certain Python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/joblib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnumpy_pickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompressor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_compressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmy_exceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdisk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmemstr_to_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m from ._parallel_backends import (FallbackToBackend, MultiprocessingBackend,\n\u001b[0m\u001b[1;32m     27\u001b[0m                                  \u001b[0mThreadingBackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequentialBackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                  LokyBackend)\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMemmappingPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_memmapping_executor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Compat between concurrent.futures and multiprocessing TimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/joblib/executor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdisk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdelete_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_memmapping_reducer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_memmapping_reducers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreusable_executor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_reusable_executor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/joblib/externals/loky/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_loky_pickler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreusable_executor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_reusable_executor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcloudpickle_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrap_non_picklable_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprocess_executor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBrokenProcessPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprocess_executor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEXTRA_QUEUED_CALLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueues\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleQueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_loky_pickler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_loky_pickler_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrecursive_terminate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_exitcodes_terminated_worker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/joblib/externals/loky/backend/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpsutil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import time, os\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nflib\n",
    "from nflib.flows import SequentialFlow, NormalizingFlow, ActNorm, AffineConstantFlow\n",
    "import nflib.coupling_flows as icf\n",
    "import nflib.inn_flow as inn\n",
    "import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(249)\n",
    "# xx, y = datasets.make_circles(n_samples=300, factor=0.5, noise=0.05)\n",
    "# x_ = np.random.randn(100, 2)*0.1\n",
    "# xx = np.concatenate([xx, x_], axis=0)\n",
    "# y = np.concatenate([y, np.ones(len(x_), dtype=int)*0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(249) ## 148, 249\n",
    "\n",
    "xxc, yc = datasets.make_circles(n_samples=265, factor=.5,\n",
    "                                      noise=.07)\n",
    "idx = yc==0\n",
    "xxc = xxc[idx]\n",
    "yc = yc[idx]\n",
    "\n",
    "idx = (xxc[:,0]+xxc[:,1]<1)\n",
    "xxc = xxc[idx]\n",
    "yc = yc[idx]\n",
    "\n",
    "\n",
    "xxm, ym = datasets.make_moons(n_samples=200, noise=.15)\n",
    "xxm = xxm/2 - 0.2\n",
    "\n",
    "xx = np.concatenate((xxm, xxc), axis=0)\n",
    "y = np.concatenate((ym, yc+2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MinMax Normalization\n",
    "x1 = xx[:,0]\n",
    "x2 = xx[:,1]\n",
    "# x1 = (x1-x1.min())/(x1.max()-x1.min())\n",
    "# x2 = (x2-x2.min())/(x2.max()-x2.min())\n",
    "xx = np.column_stack((x1,x2))\n",
    "\n",
    "xx = torch.Tensor(xx)\n",
    "yy = torch.Tensor(y.reshape(-1, 1))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.scatter(x1, x2, c=y, s=50, edgecolors='k', lw=0.5)\n",
    "\n",
    "# (x1min, x1max) = -0.1, 1.1\n",
    "# plt.xlim((x1min, x1max))\n",
    "# plt.ylim((x1min, x1max))\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel('X2')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_Softmax(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.linear = nn.Linear(input_dim, num_sets)\n",
    "\n",
    "        init_val = torch.randn(num_sets, output_dim)*0.1\n",
    "        for ns in range(num_sets):\n",
    "            init_val[ns, ns%output_dim] = 0.5\n",
    "        self.cls_weight = nn.Parameter(init_val)\n",
    "        \n",
    "        self.cls_confidence = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "#         self.cls_weight.data = torch.abs(self.cls_weight.data/self.cls_weight.data.sum(dim=1, keepdim=True))\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        if hard:\n",
    "            x = torch.softmax(x*1e5, dim=1)\n",
    "        else:\n",
    "            x = torch.softmax(x*self.inv_temp, dim=1)\n",
    "        self.cls_confidence = x\n",
    "        c = torch.softmax(self.cls_weight, dim=1)\n",
    "        c = self.cls_weight\n",
    "        return x@c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_SoftKMeans(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.centers = nn.Parameter(torch.rand(num_sets, input_dim)*2-1)\n",
    "        \n",
    "#         init_val = torch.ones(num_sets, output_dim)/output_dim\n",
    "\n",
    "        init_val = torch.randn(num_sets, output_dim)*0.1\n",
    "        for ns in range(num_sets):\n",
    "            init_val[ns, ns%output_dim] = 1.\n",
    "        self.cls_weight = nn.Parameter(init_val.abs())\n",
    "\n",
    "        self.cls_confidence = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "#         self.cls_weight.data.abs_()\n",
    "#         self.cls_weight.data = self.cls_weight.data/self.cls_weight.data.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        x = x[:, :self.input_dim]\n",
    "        dists = torch.cdist(x, self.centers)\n",
    "        dists = dists/np.sqrt(self.input_dim) ### correction to make diagonal of unit square 1 in nD space\n",
    "        \n",
    "        if hard:\n",
    "            x = torch.softmax(-dists*1e5, dim=1)\n",
    "        else:\n",
    "            x = torch.softmax(-dists*self.inv_temp, dim=1)\n",
    "        self.cls_confidence = x\n",
    "#         c = torch.softmax(self.cls_weight, dim=1)\n",
    "        c = self.cls_weight\n",
    "        return x@c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConnectedClassifier_SoftKMeans(nn.Module):\n",
    "    \n",
    "#     def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "#         super().__init__()\n",
    "#         self.input_dim = input_dim\n",
    "#         self.output_dim = output_dim\n",
    "#         self.num_sets = num_sets\n",
    "#         self.inv_temp = nn.Parameter(torch.ones(1, num_sets)*inv_temp)\n",
    "        \n",
    "#         self.centers = nn.Parameter(torch.rand(num_sets, input_dim)*2-1)\n",
    "        \n",
    "#         init_val = torch.randn(num_sets, output_dim)*0.1\n",
    "#         for ns in range(num_sets):\n",
    "#             init_val[ns, ns%output_dim] = 1.\n",
    "            \n",
    "#         self.cls_weight = nn.Parameter(init_val.abs())\n",
    "#         self.cls_confidence = None\n",
    "        \n",
    "        \n",
    "#     def forward(self, x, hard=False):\n",
    "# #         self.cls_weight.data.abs_()\n",
    "# #         self.cls_weight.data = self.cls_weight.data/self.cls_weight.data.sum(dim=1, keepdim=True)\n",
    "        \n",
    "#         x = x[:, :self.input_dim]\n",
    "#         dists = torch.cdist(x, self.centers)\n",
    "#         dists = dists/np.sqrt(self.input_dim) ### correction to make diagonal of unit square 1 in nD space\n",
    "        \n",
    "# #         dists = dists**2\n",
    "#         if hard:\n",
    "#             x = 1/(dists*1e5 + 1e-5)\n",
    "#         else:\n",
    "#             x = 1/(dists*self.inv_temp+1e-5)\n",
    "        \n",
    "#         x = x/x.data.sum(dim=1, keepdim=True)\n",
    "        \n",
    "#         self.cls_confidence = x\n",
    "#         c = torch.softmax(self.cls_weight, dim=1)\n",
    "# #         c = self.cls_weight\n",
    "#         return x@c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeakySignum(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x=x+0.5\n",
    "        o1x = 0.1*x\n",
    "        return torch.minimum(torch.maximum(x, o1x*0.0), o1x+0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeakyRectFilter(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x.abs()\n",
    "#         return -torch.maximum(torch.minimum(0.1*x-0.15, x-1.5), 0.1*x-1.05)\n",
    "        return -torch.maximum(torch.minimum(0.01*(x-1.5), x-1.5), 0.1*x-1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDistanceClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.centers = nn.Parameter(torch.rand(1, input_dim)*2-1)\n",
    "        self.bias = nn.Parameter(torch.ones(1)*-0.5)\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "#         self.actf = nn.Sigmoid()\n",
    "        self.actf = LeakySignum()\n",
    "#         self.actf = LeakyRectFilter()\n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "        x = torch.norm(x-self.centers, dim=1, keepdim=True) + self.bias\n",
    "        if hard:\n",
    "            x = torch.sigmoid(-x*1e5)\n",
    "        else:\n",
    "            x = self.actf(-x*self.inv_temp)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbc = BinaryDistanceClassifier(2)\n",
    "# dbc(torch.randn(3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        self.actf = nn.Sigmoid()\n",
    "#         self.actf = LeakySignum()\n",
    "#         self.actf = LeakyRectFilter()\n",
    "\n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "        x = self.linear(x)\n",
    "        if hard:\n",
    "            x = torch.sigmoid(x*1e5)\n",
    "        else:\n",
    "            x = self.actf(x*self.inv_temp)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Sequential(nn.Linear(2, 10, bias=False),\n",
    "#                       nn.BatchNorm1d(10),\n",
    "#                       nn.SELU(),\n",
    "#                       nn.Linear(10, 2, bias=False),\n",
    "#                       nn.BatchNorm1d(2),\n",
    "#                       nn.SELU(),\n",
    "#                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actf = irf.Swish\n",
    "flows = [\n",
    "    ActNorm(2),\n",
    "    irf.ResidualFlow(2, [5], activation=actf),\n",
    "    ActNorm(2),\n",
    "    irf.ResidualFlow(2, [5], activation=actf),\n",
    "    ActNorm(2),\n",
    "        ]\n",
    "\n",
    "model = SequentialFlow(flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = ConnectedClassifier_SoftKMeans(2, 10, 3)\n",
    "# classifier = LinearBinaryClassifier(2)\n",
    "classifier = BinaryDistanceClassifier(2, inv_temp=1)\n",
    "# classifier.bias.data *= 0.\n",
    "\n",
    "# classifier = nn.Sequential(nn.Linear(2,1), nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.BCELoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(list(model.parameters())+list(classifier.parameters()), lr=0.01)\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()#projection='3d')\n",
    "\n",
    "model.train()\n",
    "losses = []\n",
    "NUM = 512\n",
    "\n",
    "### for plotting in 2d grid\n",
    "ng = 400\n",
    "_a,_b,_c,_d = x1.min()-0.1, x1.max()+0.1, x2.min()-0.1, x2.max()+0.1\n",
    "xg, yg = np.linspace(_a, _b, ng), np.linspace(_c, _d, ng)\n",
    "xg, yg = np.meshgrid(xg, yg)\n",
    "xyg = np.stack([xg.reshape(-1), yg.reshape(-1)], axis=-1)\n",
    "xyg = torch.Tensor(xyg)\n",
    "\n",
    "cls = 0\n",
    "yc = (yy==cls).reshape(-1, 1).type(torch.float32)\n",
    "\n",
    "for epoch in tqdm(range(1000*4+1)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    z = model(xx)\n",
    "    yout = classifier(z)\n",
    "    \n",
    "    loss = criterion(yout, yc)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    if epoch%100 == 0:\n",
    "        acc = (yout.data>0.5).type(torch.long)\n",
    "        acc = float((acc==yc).type(torch.float32).mean())\n",
    "        losses.append(float(loss))\n",
    "        print(f\"Epoch: {epoch} Loss: {losses[-1]} Accuracy: {acc}\")\n",
    "\n",
    "        ax.clear()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            z = model(xx)\n",
    "            yout = classifier(z)\n",
    "            \n",
    "        yout_img = classifier(model(xyg))\n",
    "        model.train()\n",
    "        out = (yout_img.data.numpy()>0.5).astype(int)\n",
    "#         out = yout_img.data.numpy().astype(float)\n",
    "        cf = ax.contourf(xg, yg, out.reshape(xg.shape),# v,\n",
    "                         alpha=0.5, cmap=matplotlib.cm.bwr, antialiased=True)\n",
    "        ax.grid()\n",
    "\n",
    "        ax.scatter(x1, x2, c=yy.numpy().reshape(-1), s=80, edgecolors='k', lw=0.5)\n",
    "        ax.scatter(x1, x2, c=yout.data.numpy().reshape(-1), marker='.')\n",
    "            \n",
    "        ax.set_xlabel('X1')\n",
    "        ax.set_ylabel('X2')\n",
    "        \n",
    "        fig.canvas.draw()\n",
    "        plt.pause(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.inv_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout.min(), yout.max(), yout.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Binary classification using output change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MultiClass Classifier Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycls = yy.reshape(-1).type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actf = irf.Swish\n",
    "flows = [\n",
    "    ActNorm(2),\n",
    "    irf.ResidualFlow(2, [5], activation=actf),\n",
    "    ActNorm(2),\n",
    "    irf.ResidualFlow(2, [5], activation=actf),\n",
    "    ActNorm(2),\n",
    "        ]\n",
    "\n",
    "model = SequentialFlow(flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ConnectedClassifier_SoftKMeans(2, 6, ycls.max().item()+1, inv_temp=1)\n",
    "# classifier = ConnectedClassifier_Softmax(2, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(list(model.parameters())+list(classifier.parameters()), lr=0.01)\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()#projection='3d')\n",
    "\n",
    "model.train()\n",
    "losses = []\n",
    "NUM = 512\n",
    "\n",
    "### for plotting in 2d grid\n",
    "ng = 400\n",
    "_a,_b,_c,_d = x1.min()-0.1, x1.max()+0.1, x2.min()-0.1, x2.max()+0.1\n",
    "xg, yg = np.linspace(_a, _b, ng), np.linspace(_c, _d, ng)\n",
    "xg, yg = np.meshgrid(xg, yg)\n",
    "xyg = np.stack([xg.reshape(-1), yg.reshape(-1)], axis=-1)\n",
    "xyg = torch.Tensor(xyg)\n",
    "\n",
    "for epoch in tqdm(range(1000*4+1)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    z = model(xx)\n",
    "    yout = classifier(z)\n",
    "    \n",
    "    loss = criterion(yout, ycls)\n",
    "    loss.backward()\n",
    "    if epoch < 2000:\n",
    "        model.zero_grad()\n",
    "    \n",
    "    optimizer.step()\n",
    "        \n",
    "    if epoch%100 == 0:\n",
    "        acc = (yout.data.argmax(dim=1) == ycls)\n",
    "        acc = float(acc.type(torch.float32).mean())\n",
    "        losses.append(float(loss))\n",
    "        print(f\"Epoch: {epoch} Loss: {losses[-1]} Accuracy: {acc}\")\n",
    "\n",
    "        ax.clear()\n",
    "        with torch.no_grad():\n",
    "            z = model(xx)\n",
    "            yout = classifier(z, hard=True)\n",
    "            \n",
    "        yout_img = classifier(model(xyg), hard=True)\n",
    "#         out = (yout_img.data.numpy()>0.5).astype(int)\n",
    "        out = yout_img.data.argmax(dim=1).numpy()\n",
    "#         print(out.shape)\n",
    "#         out = yout_img.data[torch.arange(0, len(out), dtype=torch.long), out.reshape(-1)].numpy()\n",
    "#         print(out.shape)\n",
    "        cf = ax.contourf(xg, yg, out.reshape(xg.shape),# v,\n",
    "                         alpha=0.5, cmap=matplotlib.cm.bwr, antialiased=True)\n",
    "        ax.grid()\n",
    "\n",
    "        ax.scatter(x1, x2, c=ycls.numpy().reshape(-1), s=80, edgecolors='k', lw=0.5)\n",
    "        ax.scatter(x1, x2, c=yout.data.argmax(dim=1).numpy().reshape(-1), marker='.')\n",
    "            \n",
    "        ax.set_xlabel('X1')\n",
    "        ax.set_ylabel('X2')\n",
    "        \n",
    "        fig.canvas.draw()\n",
    "        plt.pause(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.inv_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "%matplotlib inline\n",
    "\n",
    "### for plotting in 2d grid\n",
    "ng = 400\n",
    "_a,_b,_c,_d = x1.min()-0.1, x1.max()+0.1, x2.min()-0.1, x2.max()+0.1\n",
    "xg, yg = np.linspace(_a, _b, ng), np.linspace(_c, _d, ng)\n",
    "xg, yg = np.meshgrid(xg, yg)\n",
    "xyg = np.stack([xg.reshape(-1), yg.reshape(-1)], axis=-1)\n",
    "xyg = torch.Tensor(xyg)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = model(xyg, False)\n",
    "    y = torch.argmax(classifier(z), dim=1)\n",
    "    \n",
    "cf = plt.contourf(xg, yg, y.reshape(xg.shape),# v,\n",
    "                     alpha=0.5, cmap=matplotlib.cm.bwr, antialiased=True)\n",
    "plt.scatter(x1, x2, marker='o', c=yy.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = torch.argmax(classifier.cls_confidence, dim=1)\n",
    "for i, u in enumerate(torch.unique(cls)):\n",
    "    cls[cls==u] = i\n",
    "\n",
    "cf = plt.contourf(xg, yg, cls.reshape(xg.shape),# v,\n",
    "                     alpha=0.5, cmap=matplotlib.cm.tab10, antialiased=True)\n",
    "plt.scatter(x1, x2, marker='o', c=yy.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.centers.data.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, non-softmax based classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### if we use same distance scaler, then same always increasing function, we get same argmax db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeakySignum(nn.Module):\n",
    "    def forward(self, x):\n",
    "        o1x = 0.1*x\n",
    "        return torch.minimum(torch.maximum(x, o1x), o1x+0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_SoftKMeans(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.centers = nn.Parameter(torch.rand(num_sets, input_dim)*2-1)\n",
    "        \n",
    "        init_val = torch.randn(num_sets, output_dim)*0.1\n",
    "        for ns in range(num_sets):\n",
    "            init_val[ns, ns%output_dim] = 1.\n",
    "            \n",
    "        self.cls_weight = nn.Parameter(init_val.abs())\n",
    "        self.cls_confidence = None\n",
    "        \n",
    "#         self.actf = LeakySignum()\n",
    "        self.actf = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "        self.cls_weight.data.abs_()\n",
    "        self.cls_weight.data = self.cls_weight.data/self.cls_weight.data.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        x = x[:, :self.input_dim]\n",
    "        dists = torch.cdist(x, self.centers)\n",
    "        dists = dists/np.sqrt(self.input_dim) ### correction to make diagonal of unit square 1 in nD space\n",
    "        \n",
    "#         dists = dists**2\n",
    "        if hard:\n",
    "            x = torch.softmax(-dists*1e5, dim=1)\n",
    "        else:\n",
    "#             x = torch.sigmoid(-dists*self.inv_temp)\n",
    "            x = self.actf(-dists*self.inv_temp)\n",
    "\n",
    "            \n",
    "        self.cls_confidence = x\n",
    "#         c = torch.softmax(self.cls_weight, dim=1)\n",
    "        c = self.cls_weight\n",
    "        return x@c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceBinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.centers = nn.Parameter(torch.rand(1, input_dim)*2-1)\n",
    "        self.bias = nn.Parameter(torch.ones(1)*-0.5)\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        self.actf = nn.Sigmoid()\n",
    "#         self.actf = LeakySignum()\n",
    "#         self.actf = LeakyRectFilter()\n",
    "        self.pos_val = nn.Parameter(torch.ones(1, output_dim)*0.5)\n",
    "        self.neg_val = nn.Parameter(torch.ones(1, output_dim)*0.5)\n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "        self.pos_val.data.abs_()\n",
    "        self.pos_val.data = self.pos_val.data/self.pos_val.data.sum()\n",
    "        self.neg_val.data.abs_()\n",
    "        self.neg_val.data = self.neg_val.data/self.neg_val.data.sum()\n",
    "        \n",
    "        x = torch.norm(x-self.centers, dim=1, keepdim=True) + self.bias\n",
    "        if hard:\n",
    "            x = torch.sigmoid(-x*1e5)\n",
    "        else:\n",
    "            x = self.actf(-x*self.inv_temp)\n",
    "        x = x*self.pos_val + (1-x)*self.neg_val\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycls = yy.reshape(-1).type(torch.long)\n",
    "\n",
    "ycls_ = torch.zeros(len(ycls), ycls.max()+1)\n",
    "ycls_[torch.arange(0, len(ycls), dtype=torch.long), ycls] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycls_, ycls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actf = irf.Swish\n",
    "flows = [\n",
    "    ActNorm(2),\n",
    "    irf.ResidualFlow(2, [5], activation=actf),\n",
    "    ActNorm(2),\n",
    "    irf.ResidualFlow(2, [5], activation=actf),\n",
    "    ActNorm(2),\n",
    "        ]\n",
    "\n",
    "model = SequentialFlow(flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = ConnectedClassifier_SoftKMeans(2, 5, ycls.max().item()+1, inv_temp=1)\n",
    "classifier = DistanceBinaryClassifier(2, ycls.max().item()+1, inv_temp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(list(model.parameters())+list(classifier.parameters()), lr=0.0031)\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()#projection='3d')\n",
    "\n",
    "model.train()\n",
    "losses = []\n",
    "NUM = 512\n",
    "\n",
    "### for plotting in 2d grid\n",
    "ng = 400\n",
    "_a,_b,_c,_d = x1.min()-0.1, x1.max()+0.1, x2.min()-0.1, x2.max()+0.1\n",
    "xg, yg = np.linspace(_a, _b, ng), np.linspace(_c, _d, ng)\n",
    "xg, yg = np.meshgrid(xg, yg)\n",
    "xyg = np.stack([xg.reshape(-1), yg.reshape(-1)], axis=-1)\n",
    "xyg = torch.Tensor(xyg)\n",
    "\n",
    "for epoch in tqdm(range(1000*4+1)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    z = model(xx)\n",
    "    yout = classifier(z)\n",
    "    \n",
    "#     loss = criterion(yout, ycls_)\n",
    "    loss = criterion(yout, ycls)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    if epoch%100 == 0:\n",
    "        acc = (yout.data.argmax(dim=1) == ycls)\n",
    "        acc = float(acc.type(torch.float32).mean())\n",
    "        losses.append(float(loss))\n",
    "        print(f\"Epoch: {epoch} Loss: {losses[-1]} Accuracy: {acc}\")\n",
    "\n",
    "        ax.clear()\n",
    "        with torch.no_grad():\n",
    "            z = model(xx)\n",
    "            yout = classifier(z)\n",
    "            \n",
    "        yout_img = classifier(model(xyg))\n",
    "        out = yout_img.data.argmax(dim=1).numpy()\n",
    "#         out = yout_img.data[torch.arange(0, len(out), dtype=torch.long), out.reshape(-1)].numpy()\n",
    "        cf = ax.contourf(xg, yg, out.reshape(xg.shape),# v,\n",
    "                         alpha=0.5, antialiased=True)\n",
    "        ax.grid()\n",
    "\n",
    "        ax.scatter(x1, x2, c=ycls.numpy().reshape(-1), s=80, edgecolors='k', lw=0.5)\n",
    "        ax.scatter(x1, x2, c=yout.data.argmax(dim=1).numpy().reshape(-1), marker='.')\n",
    "            \n",
    "        ax.set_xlabel('X1')\n",
    "        ax.set_ylabel('X2')\n",
    "        \n",
    "        fig.canvas.draw()\n",
    "        plt.pause(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "%matplotlib inline\n",
    "\n",
    "### for plotting in 2d grid\n",
    "ng = 400\n",
    "_a,_b,_c,_d = x1.min()-0.1, x1.max()+0.1, x2.min()-0.1, x2.max()+0.1\n",
    "xg, yg = np.linspace(_a, _b, ng), np.linspace(_c, _d, ng)\n",
    "xg, yg = np.meshgrid(xg, yg)\n",
    "xyg = np.stack([xg.reshape(-1), yg.reshape(-1)], axis=-1)\n",
    "xyg = torch.Tensor(xyg)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = model(xyg, False)\n",
    "    y = torch.argmax(classifier(z, hard=True), dim=1)\n",
    "    \n",
    "cf = plt.contourf(xg, yg, y.reshape(xg.shape),# v,\n",
    "                     alpha=0.5, cmap=matplotlib.cm.bwr, antialiased=True)\n",
    "plt.scatter(x1, x2, marker='o', c=yy.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(z[:,0], z[:,1], marker='.', c=y.reshape(-1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
