{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nflib\n",
    "from nflib.flows import SequentialFlow, NormalizingFlow, ActNorm, ActNorm2D, AffineConstantFlow\n",
    "import nflib.coupling_flows as icf\n",
    "import nflib.inn_flow as inn\n",
    "import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import distributions\n",
    "from torch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mylibrary.datasets as datasets\n",
    "# import mylibrary.nnlib as tnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.FashionMNIST()\n",
    "# mnist.download_mnist()\n",
    "# mnist.save_mnist()\n",
    "train_data, train_label_, test_data, test_label_ = mnist.load()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "# train_label = tnn.Logits.index_to_logit(train_label_)\n",
    "train_size = len(train_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting data to pytorch format\n",
    "train_data = torch.Tensor(train_data)\n",
    "test_data = torch.Tensor(test_data)\n",
    "train_label = torch.LongTensor(train_label_)\n",
    "test_label = torch.LongTensor(test_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data.reshape(-1, 1, 28, 28)\n",
    "        self.label = label\n",
    "        \n",
    "#         self.label = mask.type(torch.float32).reshape(-1,1)\n",
    "        self._shuffle_data_()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _shuffle_data_(self):\n",
    "        randidx = random.sample(range(len(self.data)), k=len(self.data))\n",
    "        self.data = self.data[randidx]\n",
    "        self.label = self.label[randidx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, lbl = self.data[idx], self.label[idx]\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST_Dataset(train_data, train_label)\n",
    "test_dataset = MNIST_Dataset(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_Linear(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.linear = nn.Linear(input_dim, num_sets)\n",
    "#         self.linear.bias.data *= 0\n",
    "#         self.linear.weight.data *= 0.1\n",
    "#         self.cls_weight = nn.Parameter(torch.randn(num_sets, output_dim)/output_dim)\n",
    "\n",
    "        init_val = torch.randn(num_sets, output_dim)*0.01\n",
    "        for ns in range(num_sets):\n",
    "            init_val[ns, ns%output_dim] = 0.1\n",
    "        self.cls_weight = nn.Parameter(init_val)\n",
    "        \n",
    "        self.cls_confidence = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "#         self.cls_weight.data = torch.abs(self.cls_weight.data/self.cls_weight.data.sum(dim=1, keepdim=True))\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        if hard:\n",
    "            x = torch.softmax(x*1e5, dim=1)\n",
    "        else:\n",
    "            x = torch.softmax(x*self.inv_temp, dim=1)\n",
    "        self.cls_confidence = x\n",
    "        c = torch.softmax(self.cls_weight, dim=1)\n",
    "#         c = self.cls_weight\n",
    "        return x@c ## since both are normalized, it is also normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_SoftKMeans(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.centers = nn.Parameter(torch.rand(num_sets, input_dim)*2-1)\n",
    "        \n",
    "#         self.cls_weight = nn.Parameter(torch.ones(num_sets, output_dim)/output_dim)\n",
    "\n",
    "        init_val = torch.randn(num_sets, output_dim)*0.01\n",
    "        for ns in range(num_sets):\n",
    "            init_val[ns, ns%output_dim] = 0.1\n",
    "        self.cls_weight = nn.Parameter(init_val)\n",
    "\n",
    "        self.cls_confidence = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "#         self.cls_weight.data = torch.abs(self.cls_weight.data/self.cls_weight.data.sum(dim=1, keepdim=True))\n",
    "        \n",
    "        x = x[:, :self.input_dim]\n",
    "        dists = torch.cdist(x, self.centers)\n",
    "        dists = dists/np.sqrt(self.input_dim) ### correction to make diagonal of unit square 1 in nD space\n",
    "        \n",
    "        if hard:\n",
    "            x = torch.softmax(-dists*1e5, dim=1)\n",
    "        else:\n",
    "            x = torch.softmax(-dists*self.inv_temp, dim=1)\n",
    "        self.cls_confidence = x\n",
    "        c = torch.softmax(self.cls_weight, dim=1)\n",
    "#         c = self.cls_weight\n",
    "        return x@c ## since both are normalized, it is also normalized\n",
    "#         return torch.softmax(x@self.cls_weight, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actf = irf.Swish\n",
    "# flows = [\n",
    "#     ActNorm(784),\n",
    "#     irf.ResidualFlow(784, [784], activation=actf),\n",
    "#     ActNorm(784),\n",
    "#     irf.ResidualFlow(784, [784], activation=actf),\n",
    "#     ActNorm(784),\n",
    "#         ]\n",
    "\n",
    "# model = SequentialFlow(flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "actf = irf.Swish\n",
    "flows = [\n",
    "    ActNorm2D(1),\n",
    "    irf.ConvResidualFlow(1, [16], activation=actf),\n",
    "    irf.InvertiblePooling(2),\n",
    "    ActNorm2D(4),\n",
    "    irf.ConvResidualFlow(4, [64], activation=actf),\n",
    "    irf.InvertiblePooling(2),\n",
    "    ActNorm2D(16),\n",
    "    irf.ConvResidualFlow(16, [64, 64], activation=actf),\n",
    "    irf.Flatten(img_size=(16, 7, 7))\n",
    "        ]\n",
    "\n",
    "model = SequentialFlow(flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Sequential(nn.Linear(784, 784, bias=False),\n",
    "#                       nn.BatchNorm1d(784),\n",
    "#                       nn.SELU(),\n",
    "#                       nn.Linear(784, 784, bias=False),\n",
    "#                       nn.BatchNorm1d(784),\n",
    "#                       nn.SELU(),\n",
    "#                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(torch.randn(3, 1, 28, 28)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialFlow(\n",
       "  (flows): ModuleList(\n",
       "    (0): ActNorm2D()\n",
       "    (1): ConvResidualFlow(\n",
       "      (resblock): ModuleList(\n",
       "        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Swish()\n",
       "        (2): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): InvertiblePooling()\n",
       "    (3): ActNorm2D()\n",
       "    (4): ConvResidualFlow(\n",
       "      (resblock): ModuleList(\n",
       "        (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Swish()\n",
       "        (2): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): InvertiblePooling()\n",
       "    (6): ActNorm2D()\n",
       "    (7): ConvResidualFlow(\n",
       "      (resblock): ModuleList(\n",
       "        (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Swish()\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Swish()\n",
       "        (4): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): Flatten()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ConnectedClassifier_SoftKMeans(784, 100, 10)\n",
    "# classifier = ConnectedClassifier_Softmax(784, 100, 10)\n",
    "classifier = classifier.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0003\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  60467\n"
     ]
    }
   ],
   "source": [
    "# criterion = nn.NLLLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(list(model.parameters())+list(classifier.parameters()), lr=learning_rate)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in model.parameters():\n",
    "#     print(torch.isnan(p).type(torch.float32).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(torch.randn(10, 784).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 28, 28])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = iter(test_loader).next()[0]\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:27<00:00, 13.68it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0:0,  Loss:2.2961394786834717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 30.20it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:22.61%, Test Acc:36.79%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:41<00:00, 11.87it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1:0,  Loss:2.2535247802734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 28.15it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:34.97%, Test Acc:30.67%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:42<00:00, 11.67it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2:0,  Loss:2.173365592956543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:09<00:00, 22.22it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:44.19%, Test Acc:53.90%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:50<00:00, 10.84it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3:0,  Loss:2.0923495292663574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:09<00:00, 21.92it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:54.97%, Test Acc:55.31%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:36<00:00, 12.45it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4:0,  Loss:1.961981177330017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.57it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:63.22%, Test Acc:70.89%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:32<00:00, 12.94it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5:0,  Loss:1.8263722658157349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 30.01it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:75.60%, Test Acc:77.56%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:30<00:00, 13.20it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6:0,  Loss:1.8733367919921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 30.17it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:79.44%, Test Acc:79.40%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 714/1200 [00:54<00:37, 13.07it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-27b669bf3531>\", line 10, in <module>\n",
      "    for xx, yy in tqdm(train_loader):\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/tqdm/std.py\", line 1166, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1068, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1034, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 872, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 499, in Client\n",
      "    deliver_challenge(c, authkey)\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 729, in deliver_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 386, in _recv\n",
      "    buf.write(chunk)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "EPOCHS = 50\n",
    "\n",
    "index = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "    for xx, yy in tqdm(train_loader):\n",
    "        xx, yy = xx.to(device), yy.to(device)\n",
    "#     for xx, yy in tqdm(test_loader):\n",
    "\n",
    "        yout = model(xx)\n",
    "#         print(yout)\n",
    "        yout = classifier(yout)    \n",
    "#         print(yout)\n",
    "        loss = criterion(yout, yy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(float(loss))\n",
    "\n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        train_acc += correct\n",
    "        train_count += len(outputs)\n",
    "#         break\n",
    "\n",
    "    train_accs.append(float(train_acc)/train_count*100)\n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "\n",
    "    print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "    test_count = 0\n",
    "    test_acc = 0\n",
    "    for xx, yy in tqdm(test_loader):\n",
    "        xx, yy = xx.to(device), yy.to(device)\n",
    "        with torch.no_grad():\n",
    "            yout = classifier(model(xx))    \n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        test_acc += correct\n",
    "        test_count += len(xx)\n",
    "    test_accs.append(float(test_acc)/test_count*100)\n",
    "    print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "    print()\n",
    "\n",
    "### after each class index is finished training\n",
    "print(f'\\t-> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.inv_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard test accuracy with count per classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 105.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Test Acc:88.00%\n",
      "[0, 0, 0, 0, 1029, 0, 0, 1068, 1018, 0, 0, 0, 0, 0, 0, 1000, 0, 0, 0, 0, 0, 1010, 0, 0, 0, 0, 0, 0, 0, 1010, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 972, 0, 1011, 0, 0, 0, 0, 0, 0, 0, 0, 968, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 914, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "test_acc = 0\n",
    "set_count = torch.zeros(classifier.num_sets).to(device)\n",
    "for xx, yy in tqdm(test_loader):\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    with torch.no_grad():\n",
    "        yout = classifier(model(xx), hard=True)\n",
    "        set_indx, count = torch.unique(torch.argmax(classifier.cls_confidence, dim=1), return_counts=True) \n",
    "        set_count[set_indx] += count\n",
    "    outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "    test_acc += correct\n",
    "    test_count += len(xx)\n",
    "\n",
    "print(f'Hard Test Acc:{float(test_acc)/test_count*100:.2f}%')\n",
    "print(set_count.type(torch.long).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard train accuracy with count per classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:12<00:00, 99.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Train Acc:92.36%\n",
      "[0, 0, 0, 0, 6119, 0, 0, 6266, 6018, 0, 0, 0, 0, 0, 0, 6091, 0, 0, 0, 0, 0, 6070, 0, 0, 0, 0, 0, 0, 0, 5956, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5902, 0, 6053, 0, 0, 0, 0, 0, 0, 0, 0, 5927, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5598, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "test_acc = 0\n",
    "set_count = torch.zeros(classifier.num_sets).to(device)\n",
    "for xx, yy in tqdm(train_loader):\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    with torch.no_grad():\n",
    "        yout = classifier(model(xx), hard=True)\n",
    "        set_indx, count = torch.unique(torch.argmax(classifier.cls_confidence, dim=1), return_counts=True) \n",
    "        set_count[set_indx] += count\n",
    "    outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "    test_acc += correct\n",
    "    test_count += len(xx)\n",
    "\n",
    "print(f'Hard Train Acc:{float(test_acc)/test_count*100:.2f}%')\n",
    "print(set_count.type(torch.long).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Classifiers that enclose any data\n",
    "torch.count_nonzero(set_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
       "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
       "        8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1,\n",
       "        2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,\n",
       "        6, 7, 8, 9])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### classifier with class representation\n",
    "torch.argmax(classifier.cls_weight, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class labels are same as that of initialized\n",
    "# tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
    "#         4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
    "#         8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1,\n",
    "#         2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,\n",
    "#         6, 7, 8, 9], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.0948e+01, -2.6081e-01, -4.4869e-01, -1.1516e-01, -5.1962e-01,\n",
       "         -5.4807e-01,  3.9923e-02, -5.8040e-01, -4.6139e-01, -6.0863e-01],\n",
       "        [-3.3414e-01,  1.0927e+01, -4.2983e-01, -2.9968e-01, -4.2571e-01,\n",
       "         -4.2072e-01, -4.7829e-01, -4.1128e-01, -3.7257e-01, -3.3730e-01],\n",
       "        [-3.1180e-01, -5.1346e-01,  1.0906e+01, -4.3566e-01,  1.1364e-01,\n",
       "         -4.7643e-01, -1.8677e-02, -5.7840e-01, -4.3652e-01, -5.3920e-01],\n",
       "        [-2.1061e-01, -2.8361e-01, -5.5542e-01,  1.0987e+01, -3.4030e-01,\n",
       "         -4.9548e-01, -3.5487e-01, -5.1462e-01, -4.1046e-01, -4.7260e-01],\n",
       "        [-4.8059e-01, -5.7916e-01,  1.0865e-01, -2.7176e-01,  1.0955e+01,\n",
       "         -6.9063e-01,  4.4545e-02, -6.3701e-01, -5.6656e-01, -6.5603e-01],\n",
       "        [-4.4417e-01, -4.5547e-01, -4.1456e-01, -4.8265e-01, -5.1685e-01,\n",
       "          1.0933e+01, -4.4972e-01, -1.1164e-01, -3.2782e-01, -1.9266e-01],\n",
       "        [-5.5332e-02, -5.9996e-01,  3.3389e-02, -2.3910e-01,  1.4806e-01,\n",
       "         -5.0555e-01,  1.0717e+01, -5.9555e-01, -3.4599e-01, -5.0193e-01],\n",
       "        [-5.2073e-01, -4.8838e-01, -4.6747e-01, -4.0496e-01, -4.6663e-01,\n",
       "         -2.0570e-02, -5.1408e-01,  1.0947e+01, -3.5711e-01, -1.1267e-01],\n",
       "        [-4.4006e-01, -4.5916e-01, -5.3802e-01, -4.3656e-01, -5.2514e-01,\n",
       "         -3.5106e-01, -4.0676e-01, -5.0114e-01,  1.0987e+01, -4.6063e-01],\n",
       "        [-5.4295e-01, -4.4775e-01, -5.5402e-01, -5.2921e-01, -5.2996e-01,\n",
       "         -1.9828e-01, -5.1689e-01, -1.2320e-01, -4.3508e-01,  1.0956e+01],\n",
       "        [ 1.0932e+01, -3.8285e-01, -3.1516e-01, -1.1915e-01, -4.7454e-01,\n",
       "         -5.4398e-01,  3.8695e-02, -5.3013e-01, -4.7190e-01, -5.2000e-01],\n",
       "        [-2.9392e-01,  1.0925e+01, -4.8381e-01, -2.3298e-01, -4.3430e-01,\n",
       "         -3.4566e-01, -5.0033e-01, -4.1349e-01, -3.9408e-01, -3.8953e-01],\n",
       "        [-3.6293e-01, -5.1066e-01,  1.0902e+01, -4.3768e-01,  1.3513e-01,\n",
       "         -5.3962e-01,  2.1480e-02, -5.1086e-01, -4.8196e-01, -5.7059e-01],\n",
       "        [-1.5552e-01, -2.9077e-01, -5.4308e-01,  1.0991e+01, -3.0978e-01,\n",
       "         -4.8781e-01, -3.7218e-01, -5.3092e-01, -4.2329e-01, -5.1258e-01],\n",
       "        [-5.7596e-01, -5.2855e-01,  4.5266e-02, -3.6937e-01,  1.0943e+01,\n",
       "         -5.9020e-01, -5.5494e-02, -5.4721e-01, -3.9635e-01, -5.2894e-01],\n",
       "        [-5.3055e-01, -4.5853e-01, -5.6583e-01, -4.9225e-01, -5.7045e-01,\n",
       "          1.0960e+01, -5.1710e-01,  1.9787e-02, -3.7770e-01, -1.9472e-01],\n",
       "        [-9.4623e-02, -6.9247e-01,  4.3747e-04, -3.6196e-01,  1.4623e-01,\n",
       "         -5.0191e-01,  1.0791e+01, -6.1178e-01, -3.3903e-01, -6.3671e-01],\n",
       "        [-4.9939e-01, -4.8013e-01, -5.2407e-01, -4.8853e-01, -5.0225e-01,\n",
       "         -9.4397e-02, -5.0149e-01,  1.0959e+01, -3.7762e-01, -5.6907e-02],\n",
       "        [-4.2584e-01, -4.7533e-01, -4.6840e-01, -4.7776e-01, -4.3538e-01,\n",
       "         -3.3589e-01, -3.7782e-01, -4.3822e-01,  1.0977e+01, -4.4527e-01],\n",
       "        [-5.5388e-01, -4.2535e-01, -5.9871e-01, -4.9489e-01, -5.3403e-01,\n",
       "         -1.4220e-01, -5.5110e-01, -1.4501e-01, -3.6985e-01,  1.0956e+01],\n",
       "        [ 1.0962e+01, -4.2980e-01, -3.2016e-01, -1.6157e-01, -5.5324e-01,\n",
       "         -5.2130e-01,  8.5318e-02, -6.2698e-01, -4.8872e-01, -6.0566e-01],\n",
       "        [-2.9188e-01,  1.0931e+01, -5.0170e-01, -2.1127e-01, -4.3652e-01,\n",
       "         -4.1692e-01, -4.7172e-01, -4.4645e-01, -3.9883e-01, -4.0732e-01],\n",
       "        [-3.2925e-01, -5.5004e-01,  1.0949e+01, -5.2123e-01,  1.0969e-02,\n",
       "         -5.1469e-01, -4.5683e-02, -5.7399e-01, -4.5186e-01, -5.3166e-01],\n",
       "        [-1.5235e-01, -3.2639e-01, -4.5628e-01,  1.0987e+01, -2.7080e-01,\n",
       "         -5.4109e-01, -3.1962e-01, -4.9783e-01, -4.4025e-01, -5.2786e-01],\n",
       "        [-5.8998e-01, -5.4101e-01,  1.3249e-01, -3.0329e-01,  1.0961e+01,\n",
       "         -6.0868e-01, -3.8852e-02, -6.1463e-01, -5.6822e-01, -5.8217e-01],\n",
       "        [-4.6056e-01, -4.6785e-01, -4.7719e-01, -4.8224e-01, -5.1614e-01,\n",
       "          1.0934e+01, -4.8098e-01, -4.0133e-02, -2.8410e-01, -1.7555e-01],\n",
       "        [-7.3683e-02, -6.1235e-01,  3.2516e-02, -3.2197e-01,  1.3822e-01,\n",
       "         -5.0889e-01,  1.0759e+01, -5.7667e-01, -3.7633e-01, -5.7200e-01],\n",
       "        [-5.4587e-01, -4.9449e-01, -6.0210e-01, -4.9722e-01, -5.6283e-01,\n",
       "         -5.1566e-02, -5.9442e-01,  1.0993e+01, -4.8289e-01, -9.5391e-02],\n",
       "        [-4.0541e-01, -5.2151e-01, -5.0716e-01, -4.2301e-01, -4.7512e-01,\n",
       "         -3.3608e-01, -3.9331e-01, -4.6956e-01,  1.0979e+01, -4.6600e-01],\n",
       "        [-5.3963e-01, -4.6625e-01, -5.4931e-01, -4.8844e-01, -4.8609e-01,\n",
       "         -2.0652e-01, -5.0433e-01, -7.4654e-02, -3.9036e-01,  1.0947e+01],\n",
       "        [ 1.0976e+01, -4.0038e-01, -4.3257e-01, -2.0387e-01, -6.1111e-01,\n",
       "         -5.5636e-01,  5.0004e-02, -5.9715e-01, -4.5759e-01, -5.8237e-01],\n",
       "        [-3.0129e-01,  1.0929e+01, -4.9886e-01, -2.1171e-01, -4.8382e-01,\n",
       "         -4.2862e-01, -5.0195e-01, -4.3724e-01, -2.8563e-01, -3.6406e-01],\n",
       "        [-4.1047e-01, -5.1593e-01,  1.0962e+01, -5.0116e-01,  9.9407e-02,\n",
       "         -5.7752e-01, -3.3677e-02, -5.7865e-01, -5.4627e-01, -5.5848e-01],\n",
       "        [-1.1370e-01, -3.1434e-01, -5.4598e-01,  1.0994e+01, -2.6636e-01,\n",
       "         -5.2059e-01, -3.6884e-01, -5.3482e-01, -5.0314e-01, -5.0663e-01],\n",
       "        [-5.4800e-01, -5.5229e-01,  1.4383e-01, -3.4335e-01,  1.0948e+01,\n",
       "         -6.3738e-01, -2.6913e-02, -6.3513e-01, -4.8042e-01, -5.5755e-01],\n",
       "        [-5.2159e-01, -5.4331e-01, -5.5633e-01, -5.1264e-01, -5.6571e-01,\n",
       "          1.0981e+01, -5.5621e-01, -1.0125e-01, -3.2364e-01, -2.7724e-01],\n",
       "        [ 8.2289e-02, -6.0341e-01, -3.5058e-02, -3.3782e-01,  9.9690e-02,\n",
       "         -5.6204e-01,  1.0752e+01, -6.6280e-01, -3.1157e-01, -6.0238e-01],\n",
       "        [-5.4963e-01, -4.7616e-01, -5.1130e-01, -4.7320e-01, -5.1335e-01,\n",
       "          2.8748e-02, -5.2332e-01,  1.0966e+01, -4.5943e-01, -1.5431e-01],\n",
       "        [-3.6177e-01, -4.5043e-01, -4.2826e-01, -4.1013e-01, -3.8757e-01,\n",
       "         -3.1638e-01, -3.2278e-01, -4.2584e-01,  1.0944e+01, -3.5841e-01],\n",
       "        [-5.4163e-01, -4.9829e-01, -5.1472e-01, -4.7312e-01, -4.7673e-01,\n",
       "         -2.1267e-01, -5.0753e-01, -4.3568e-02, -4.9274e-01,  1.0950e+01],\n",
       "        [ 1.0992e+01, -4.2366e-01, -4.1534e-01, -1.7137e-01, -6.4760e-01,\n",
       "         -5.5770e-01,  6.1224e-02, -6.1574e-01, -5.1247e-01, -6.0727e-01],\n",
       "        [-3.4059e-01,  1.0934e+01, -5.1354e-01, -2.2521e-01, -4.5378e-01,\n",
       "         -4.3310e-01, -5.1409e-01, -4.4750e-01, -3.8785e-01, -2.9974e-01],\n",
       "        [-3.3513e-01, -4.5303e-01,  1.0933e+01, -4.4783e-01,  5.3749e-02,\n",
       "         -5.6550e-01, -5.5929e-02, -5.6379e-01, -4.8241e-01, -5.0118e-01],\n",
       "        [-9.4017e-02, -2.8206e-01, -5.6057e-01,  1.0997e+01, -3.6044e-01,\n",
       "         -5.6665e-01, -3.3698e-01, -5.7315e-01, -4.3448e-01, -5.1472e-01],\n",
       "        [-5.2495e-01, -5.4182e-01,  6.8494e-02, -2.7879e-01,  1.0930e+01,\n",
       "         -5.7161e-01, -1.6735e-03, -6.0747e-01, -4.6969e-01, -5.2137e-01],\n",
       "        [-4.7900e-01, -4.6704e-01, -5.0529e-01, -4.9475e-01, -5.1689e-01,\n",
       "          1.0950e+01, -4.9535e-01, -8.2906e-02, -3.6665e-01, -1.6547e-01],\n",
       "        [ 6.1953e-02, -5.4924e-01,  9.7036e-03, -3.7218e-01,  5.3785e-02,\n",
       "         -4.3687e-01,  1.0711e+01, -6.0981e-01, -2.8842e-01, -5.5631e-01],\n",
       "        [-5.1988e-01, -4.3223e-01, -5.6829e-01, -4.3676e-01, -5.3476e-01,\n",
       "          2.0231e-03, -5.4261e-01,  1.0967e+01, -4.0309e-01, -1.4156e-01],\n",
       "        [-4.3765e-01, -4.1697e-01, -4.6733e-01, -4.0216e-01, -4.2925e-01,\n",
       "         -3.4273e-01, -3.7331e-01, -3.4870e-01,  1.0960e+01, -4.0058e-01],\n",
       "        [-5.6674e-01, -3.9847e-01, -5.4413e-01, -4.7344e-01, -5.1387e-01,\n",
       "         -1.8346e-01, -5.1507e-01, -8.8162e-02, -3.6624e-01,  1.0941e+01],\n",
       "        [ 1.0956e+01, -3.2570e-01, -4.3706e-01, -1.9829e-01, -5.1477e-01,\n",
       "         -4.5145e-01,  4.7251e-02, -6.3138e-01, -4.6713e-01, -5.3856e-01],\n",
       "        [-2.3807e-01,  1.0921e+01, -4.9385e-01, -1.8185e-01, -4.5259e-01,\n",
       "         -4.1885e-01, -4.6635e-01, -4.8507e-01, -3.5309e-01, -3.6444e-01],\n",
       "        [-3.5110e-01, -5.2897e-01,  1.0912e+01, -4.4421e-01,  7.0107e-02,\n",
       "         -5.3494e-01, -4.2240e-02, -4.7950e-01, -4.5032e-01, -5.3241e-01],\n",
       "        [-9.4679e-02, -2.6709e-01, -5.0440e-01,  1.0965e+01, -3.1471e-01,\n",
       "         -4.2673e-01, -2.9292e-01, -4.8881e-01, -4.2516e-01, -4.9768e-01],\n",
       "        [-6.0710e-01, -5.4842e-01,  6.5108e-02, -3.4743e-01,  1.0962e+01,\n",
       "         -5.5877e-01, -6.4200e-02, -5.9935e-01, -4.6047e-01, -5.4849e-01],\n",
       "        [-4.3649e-01, -5.1038e-01, -5.2293e-01, -5.2988e-01, -6.0224e-01,\n",
       "          1.0967e+01, -5.5374e-01, -5.1779e-02, -3.5663e-01, -2.5021e-01],\n",
       "        [ 1.1662e-01, -5.5805e-01, -2.7811e-02, -2.7093e-01,  9.7662e-03,\n",
       "         -4.5256e-01,  1.0738e+01, -6.0780e-01, -4.2182e-01, -5.4497e-01],\n",
       "        [-5.5851e-01, -4.5287e-01, -5.6481e-01, -4.5344e-01, -5.2919e-01,\n",
       "         -1.2403e-02, -5.7088e-01,  1.0968e+01, -3.7701e-01, -4.6227e-02],\n",
       "        [-3.9085e-01, -4.0280e-01, -4.8849e-01, -3.9021e-01, -3.7455e-01,\n",
       "         -3.2158e-01, -3.4633e-01, -4.9966e-01,  1.0963e+01, -4.4589e-01],\n",
       "        [-5.3275e-01, -4.4227e-01, -5.2042e-01, -4.6839e-01, -5.1669e-01,\n",
       "         -1.6136e-01, -4.6888e-01, -2.1501e-02, -3.9683e-01,  1.0934e+01],\n",
       "        [ 1.0970e+01, -4.0277e-01, -4.0110e-01, -1.3839e-01, -6.1047e-01,\n",
       "         -5.4182e-01,  2.9346e-02, -6.2155e-01, -4.6249e-01, -5.4315e-01],\n",
       "        [-3.3246e-01,  1.0935e+01, -4.9552e-01, -1.8108e-01, -4.6171e-01,\n",
       "         -3.6335e-01, -4.8278e-01, -4.5336e-01, -3.9396e-01, -4.0943e-01],\n",
       "        [-4.0195e-01, -5.3011e-01,  1.0947e+01, -5.8184e-01,  9.4132e-02,\n",
       "         -4.7460e-01, -7.7196e-02, -5.3657e-01, -4.3780e-01, -5.4549e-01],\n",
       "        [-1.1425e-01, -3.9323e-01, -5.6847e-01,  1.1005e+01, -3.0349e-01,\n",
       "         -5.7363e-01, -3.5812e-01, -5.3628e-01, -4.6792e-01, -4.7684e-01],\n",
       "        [-4.7454e-01, -5.3445e-01,  1.3667e-01, -3.4628e-01,  1.0924e+01,\n",
       "         -6.2235e-01, -2.6648e-02, -5.2074e-01, -4.4238e-01, -5.7639e-01],\n",
       "        [-3.9938e-01, -4.1835e-01, -5.6979e-01, -3.6170e-01, -6.2839e-01,\n",
       "          1.0935e+01, -5.2209e-01, -7.2596e-02, -3.1309e-01, -2.3142e-01],\n",
       "        [-2.0749e-02, -5.6304e-01, -7.5530e-02, -2.9163e-01,  1.7367e-01,\n",
       "         -5.6660e-01,  1.0731e+01, -6.1057e-01, -3.3175e-01, -5.2192e-01],\n",
       "        [-4.9342e-01, -4.3539e-01, -5.0539e-01, -4.1800e-01, -5.5300e-01,\n",
       "         -4.4621e-02, -5.5603e-01,  1.0956e+01, -4.0150e-01, -9.5771e-02],\n",
       "        [-3.9227e-01, -4.4300e-01, -4.9904e-01, -4.9124e-01, -4.4844e-01,\n",
       "         -3.5799e-01, -3.9001e-01, -4.1845e-01,  1.0967e+01, -3.7121e-01],\n",
       "        [-4.9196e-01, -3.2362e-01, -5.0343e-01, -4.5781e-01, -4.8978e-01,\n",
       "         -1.5687e-01, -5.2048e-01, -1.4525e-01, -4.2105e-01,  1.0938e+01],\n",
       "        [ 1.0932e+01, -4.2087e-01, -3.7681e-01, -1.2634e-01, -5.5663e-01,\n",
       "         -4.0838e-01,  6.0722e-02, -5.1512e-01, -4.0845e-01, -5.5051e-01],\n",
       "        [-3.0950e-01,  1.0938e+01, -5.5962e-01, -2.3534e-01, -5.2152e-01,\n",
       "         -3.5608e-01, -5.2919e-01, -4.4285e-01, -3.5600e-01, -3.0770e-01],\n",
       "        [-3.3604e-01, -5.1405e-01,  1.0915e+01, -4.6349e-01,  4.4048e-02,\n",
       "         -5.2714e-01, -4.8198e-02, -4.9950e-01, -5.0310e-01, -4.4029e-01],\n",
       "        [-8.6556e-02, -2.4106e-01, -4.7062e-01,  1.0974e+01, -3.3254e-01,\n",
       "         -5.0399e-01, -3.1953e-01, -5.1968e-01, -4.5347e-01, -5.1884e-01],\n",
       "        [-5.5510e-01, -5.2677e-01,  7.1609e-02, -2.4826e-01,  1.0935e+01,\n",
       "         -5.9197e-01, -5.1711e-02, -5.7617e-01, -4.4909e-01, -5.3650e-01],\n",
       "        [-5.1021e-01, -4.9946e-01, -6.2703e-01, -5.4056e-01, -6.8148e-01,\n",
       "          1.0994e+01, -5.6238e-01, -6.4569e-02, -4.3815e-01, -1.7797e-01],\n",
       "        [ 3.5326e-03, -5.2835e-01,  3.8667e-02, -2.9769e-01,  6.9303e-02,\n",
       "         -5.5206e-01,  1.0723e+01, -5.9279e-01, -3.4474e-01, -4.8176e-01],\n",
       "        [-5.4763e-01, -4.9649e-01, -5.1684e-01, -4.4713e-01, -4.8891e-01,\n",
       "         -4.8535e-02, -5.7850e-01,  1.0977e+01, -4.9984e-01, -1.3347e-01],\n",
       "        [-4.1983e-01, -4.0020e-01, -4.2382e-01, -3.9748e-01, -4.0935e-01,\n",
       "         -2.7415e-01, -3.2340e-01, -4.0786e-01,  1.0943e+01, -3.4750e-01],\n",
       "        [-5.7185e-01, -4.4388e-01, -5.6601e-01, -5.1908e-01, -5.3354e-01,\n",
       "         -7.6976e-02, -5.3877e-01, -1.2185e-02, -4.4992e-01,  1.0949e+01],\n",
       "        [ 1.0991e+01, -4.7230e-01, -4.4971e-01, -2.3974e-01, -6.0872e-01,\n",
       "         -5.6933e-01,  1.1001e-01, -6.4079e-01, -5.0898e-01, -5.8477e-01],\n",
       "        [-3.5417e-01,  1.0957e+01, -5.3751e-01, -2.3475e-01, -4.9030e-01,\n",
       "         -4.8389e-01, -5.3701e-01, -5.1900e-01, -3.8662e-01, -4.7025e-01],\n",
       "        [-4.0333e-01, -6.0026e-01,  1.0981e+01, -5.6080e-01,  1.1946e-01,\n",
       "         -6.1606e-01, -5.6784e-03, -6.3635e-01, -4.6145e-01, -6.3439e-01],\n",
       "        [-1.2593e-01, -2.3759e-01, -4.5251e-01,  1.0946e+01, -2.4458e-01,\n",
       "         -4.2698e-01, -3.1152e-01, -4.7299e-01, -4.3299e-01, -4.1549e-01],\n",
       "        [-5.3572e-01, -5.3820e-01,  2.6437e-02, -3.0725e-01,  1.0923e+01,\n",
       "         -5.1595e-01, -5.2002e-02, -5.6254e-01, -4.0253e-01, -5.0971e-01],\n",
       "        [-5.5496e-01, -4.6113e-01, -5.7601e-01, -5.3312e-01, -5.7972e-01,\n",
       "          1.0959e+01, -5.4925e-01, -3.2383e-02, -3.0519e-01, -1.7168e-01],\n",
       "        [ 4.0041e-02, -5.3808e-01,  2.8853e-02, -3.3652e-01,  8.9199e-02,\n",
       "         -5.4236e-01,  1.0722e+01, -5.9613e-01, -3.2436e-01, -5.3775e-01],\n",
       "        [-4.8297e-01, -5.1666e-01, -5.6357e-01, -5.0039e-01, -5.6160e-01,\n",
       "          1.2179e-02, -5.3292e-01,  1.0974e+01, -4.0942e-01, -1.0107e-01],\n",
       "        [-4.0032e-01, -3.6566e-01, -4.5452e-01, -4.5180e-01, -4.5979e-01,\n",
       "         -2.8736e-01, -3.7589e-01, -4.1366e-01,  1.0959e+01, -3.9451e-01],\n",
       "        [-5.2248e-01, -4.2376e-01, -5.8293e-01, -4.5963e-01, -5.7432e-01,\n",
       "         -2.0159e-01, -5.7708e-01, -3.9244e-02, -4.1116e-01,  1.0957e+01],\n",
       "        [ 1.0968e+01, -3.4283e-01, -4.0251e-01, -2.1335e-01, -5.5604e-01,\n",
       "         -4.9642e-01,  4.2672e-02, -5.7277e-01, -5.4988e-01, -5.5244e-01],\n",
       "        [-2.1291e-01,  1.0929e+01, -4.5244e-01, -2.2528e-01, -4.3536e-01,\n",
       "         -4.7367e-01, -4.5392e-01, -4.3381e-01, -4.3068e-01, -4.0145e-01],\n",
       "        [-3.7259e-01, -5.3080e-01,  1.0930e+01, -4.7995e-01,  1.2647e-01,\n",
       "         -5.6153e-01, -2.1767e-02, -5.2555e-01, -4.6918e-01, -5.5993e-01],\n",
       "        [-2.1591e-01, -2.7686e-01, -5.9003e-01,  1.0996e+01, -3.1091e-01,\n",
       "         -4.2084e-01, -4.3535e-01, -4.8076e-01, -4.4607e-01, -4.9116e-01],\n",
       "        [-5.0916e-01, -4.7774e-01,  9.9195e-02, -3.0540e-01,  1.0911e+01,\n",
       "         -5.8139e-01, -5.0828e-02, -5.7608e-01, -4.3177e-01, -5.2601e-01],\n",
       "        [-4.3197e-01, -5.4526e-01, -5.3143e-01, -4.7588e-01, -5.1576e-01,\n",
       "          1.0952e+01, -4.5497e-01, -6.8676e-02, -4.2971e-01, -1.6860e-01],\n",
       "        [-6.3982e-02, -6.2706e-01, -4.4224e-03, -4.1023e-01,  1.0800e-01,\n",
       "         -5.7017e-01,  1.0799e+01, -6.0272e-01, -3.8905e-01, -6.2174e-01],\n",
       "        [-5.0646e-01, -4.4196e-01, -4.4546e-01, -4.1144e-01, -5.1398e-01,\n",
       "          3.1591e-02, -5.6126e-01,  1.0951e+01, -4.1402e-01, -1.4153e-01],\n",
       "        [-4.5439e-01, -4.1490e-01, -4.9411e-01, -4.3765e-01, -4.2621e-01,\n",
       "         -3.6393e-01, -3.7009e-01, -4.5271e-01,  1.0974e+01, -4.3096e-01],\n",
       "        [-5.4502e-01, -4.1706e-01, -4.9856e-01, -4.9498e-01, -4.3099e-01,\n",
       "         -1.3921e-01, -5.1974e-01, -6.4137e-02, -4.4082e-01,  1.0933e+01]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.cls_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.unique(torch.argmax(classifier.cls_confidence, dim=1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([12.8763], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.inv_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4948e-08, 1.4584e-08, 1.4847e-08, 1.4654e-08, 1.4749e-08, 1.4790e-08,\n",
       "        1.4930e-08, 1.4765e-08, 1.0000e+00, 1.4702e-08], device='cuda:0')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### example output per classifier\n",
    "yout[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdfsdf ## to break the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyze per classifier accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:03<00:00, 338.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Train Acc:94.20%\n",
      "[1423, 8, 24, 431, 2139, 560, 200, 4761, 222, 964, 2139, 3743, 164, 776, 304, 336, 4, 0, 1404, 4, 189, 0, 791, 0, 23, 167, 1091, 0, 1267, 11, 1, 0, 64, 286, 1590, 66, 2641, 17, 6, 8, 1686, 617, 1095, 2522, 0, 67, 696, 52, 1089, 0, 138, 1283, 15, 129, 383, 2726, 714, 2, 413, 129, 233, 0, 34, 1555, 0, 1839, 22, 674, 98, 3696, 17, 6, 858, 367, 3, 28, 222, 37, 101, 39, 299, 290, 3252, 0, 65, 145, 50, 15, 574, 1167, 3, 0, 126, 137, 1043, 45, 103, 431, 830, 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "test_acc = 0\n",
    "set_count = torch.zeros(classifier.num_sets).to(device)\n",
    "set_acc = torch.zeros(classifier.num_sets).to(device)\n",
    "for xx, yy in tqdm(train_loader):\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    with torch.no_grad():\n",
    "        yout = classifier(model(xx), hard=True)\n",
    "        \n",
    "    cls_indx = torch.argmax(classifier.cls_confidence, dim=1)\n",
    "    set_indx, count = torch.unique(cls_indx, return_counts=True) \n",
    "    set_count[set_indx] += count\n",
    "    \n",
    "    outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "    correct = (outputs == yy.data.cpu().numpy()).astype(float)\n",
    "    \n",
    "    ### class_index has 100 possible values\n",
    "    for i, c in enumerate(correct):\n",
    "        set_acc[cls_indx[i]] += c\n",
    "    \n",
    "#     print(set_acc.sum(), set_count.sum())\n",
    "#     break\n",
    "    test_acc += correct.sum()\n",
    "    test_count += len(xx)\n",
    "\n",
    "print(f'Hard Train Acc:{float(test_acc)/test_count*100:.2f}%')\n",
    "print(set_count.type(torch.long).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9452, 0.8750, 0.9583, 0.9211, 0.9158, 0.9982, 0.8650, 0.9853, 0.9775,\n",
       "        0.9948, 0.8672, 0.9989, 0.8293, 0.8235, 0.9309, 0.9940, 0.7500,    nan,\n",
       "        0.9957, 1.0000, 0.9524,    nan, 0.9039,    nan, 0.9565, 1.0000, 0.7562,\n",
       "           nan, 0.9897, 0.9091, 1.0000,    nan, 0.7031, 0.9126, 0.9220, 0.9848,\n",
       "        0.9023, 0.9412, 1.0000, 1.0000, 0.9419, 0.9984, 0.9461, 0.9623,    nan,\n",
       "        1.0000, 0.9210, 1.0000, 0.9917,    nan, 0.9203, 0.9977, 0.8000, 0.8527,\n",
       "        0.9399, 0.9938, 0.8151, 1.0000, 0.9831, 0.9922, 0.9185,    nan, 0.5000,\n",
       "        0.9350,    nan, 0.9956, 0.9091, 0.9614, 1.0000, 0.9811, 0.9412, 1.0000,\n",
       "        0.7401, 0.9619, 0.3333, 1.0000, 0.9414, 1.0000, 0.9307, 1.0000, 0.8060,\n",
       "        0.9966, 0.8598,    nan, 0.9692, 1.0000, 0.7800, 0.9333, 1.0000, 0.9709,\n",
       "        1.0000,    nan, 0.7302, 0.9562, 0.8897, 1.0000, 0.8155, 0.9536, 0.9892,\n",
       "        1.0000], device='cuda:0')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_acc/set_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,\t 1423,\t 0\t 94.52%\n",
      "1,\t 8,\t 1\t 87.50%\n",
      "2,\t 24,\t 2\t 95.83%\n",
      "3,\t 431,\t 3\t 92.11%\n",
      "4,\t 2139,\t 4\t 91.58%\n",
      "5,\t 560,\t 5\t 99.82%\n",
      "6,\t 200,\t 6\t 86.50%\n",
      "7,\t 4761,\t 7\t 98.53%\n",
      "8,\t 222,\t 8\t 97.75%\n",
      "9,\t 964,\t 9\t 99.48%\n",
      "10,\t 2139,\t 0\t 86.72%\n",
      "11,\t 3743,\t 1\t 99.89%\n",
      "12,\t 164,\t 2\t 82.93%\n",
      "13,\t 776,\t 3\t 82.35%\n",
      "14,\t 304,\t 4\t 93.09%\n",
      "15,\t 336,\t 5\t 99.40%\n",
      "16,\t 4,\t 6\t 75.00%\n",
      "18,\t 1404,\t 8\t 99.57%\n",
      "19,\t 4,\t 9\t 100.00%\n",
      "20,\t 189,\t 0\t 95.24%\n",
      "22,\t 791,\t 2\t 90.39%\n",
      "24,\t 23,\t 4\t 95.65%\n",
      "25,\t 167,\t 5\t 100.00%\n",
      "26,\t 1091,\t 6\t 75.62%\n",
      "28,\t 1267,\t 8\t 98.97%\n",
      "29,\t 11,\t 9\t 90.91%\n",
      "30,\t 1,\t 0\t 100.00%\n",
      "32,\t 64,\t 2\t 70.31%\n",
      "33,\t 286,\t 3\t 91.26%\n",
      "34,\t 1590,\t 4\t 92.20%\n",
      "35,\t 66,\t 5\t 98.48%\n",
      "36,\t 2641,\t 6\t 90.23%\n",
      "37,\t 17,\t 7\t 94.12%\n",
      "38,\t 6,\t 8\t 100.00%\n",
      "39,\t 8,\t 9\t 100.00%\n",
      "40,\t 1686,\t 0\t 94.19%\n",
      "41,\t 617,\t 1\t 99.84%\n",
      "42,\t 1095,\t 2\t 94.61%\n",
      "43,\t 2522,\t 3\t 96.23%\n",
      "45,\t 67,\t 5\t 100.00%\n",
      "46,\t 696,\t 6\t 92.10%\n",
      "47,\t 52,\t 7\t 100.00%\n",
      "48,\t 1089,\t 8\t 99.17%\n",
      "50,\t 138,\t 0\t 92.03%\n",
      "51,\t 1283,\t 1\t 99.77%\n",
      "52,\t 15,\t 2\t 80.00%\n",
      "53,\t 129,\t 3\t 85.27%\n",
      "54,\t 383,\t 4\t 93.99%\n",
      "55,\t 2726,\t 5\t 99.38%\n",
      "56,\t 714,\t 6\t 81.51%\n",
      "57,\t 2,\t 7\t 100.00%\n",
      "58,\t 413,\t 8\t 98.31%\n",
      "59,\t 129,\t 9\t 99.22%\n",
      "60,\t 233,\t 0\t 91.85%\n",
      "62,\t 34,\t 2\t 50.00%\n",
      "63,\t 1555,\t 3\t 93.50%\n",
      "65,\t 1839,\t 5\t 99.56%\n",
      "66,\t 22,\t 6\t 90.91%\n",
      "67,\t 674,\t 7\t 96.14%\n",
      "68,\t 98,\t 8\t 100.00%\n",
      "69,\t 3696,\t 9\t 98.11%\n",
      "70,\t 17,\t 0\t 94.12%\n",
      "71,\t 6,\t 1\t 100.00%\n",
      "72,\t 858,\t 2\t 74.01%\n",
      "73,\t 367,\t 3\t 96.19%\n",
      "74,\t 3,\t 4\t 33.33%\n",
      "75,\t 28,\t 5\t 100.00%\n",
      "76,\t 222,\t 6\t 94.14%\n",
      "77,\t 37,\t 7\t 100.00%\n",
      "78,\t 101,\t 8\t 93.07%\n",
      "79,\t 39,\t 9\t 100.00%\n",
      "80,\t 299,\t 0\t 80.60%\n",
      "81,\t 290,\t 1\t 99.66%\n",
      "82,\t 3252,\t 2\t 85.98%\n",
      "84,\t 65,\t 4\t 96.92%\n",
      "85,\t 145,\t 5\t 100.00%\n",
      "86,\t 50,\t 6\t 78.00%\n",
      "87,\t 15,\t 7\t 93.33%\n",
      "88,\t 574,\t 8\t 100.00%\n",
      "89,\t 1167,\t 9\t 97.09%\n",
      "90,\t 3,\t 0\t 100.00%\n",
      "92,\t 126,\t 2\t 73.02%\n",
      "93,\t 137,\t 3\t 95.62%\n",
      "94,\t 1043,\t 4\t 88.97%\n",
      "95,\t 45,\t 5\t 100.00%\n",
      "96,\t 103,\t 6\t 81.55%\n",
      "97,\t 431,\t 7\t 95.36%\n",
      "98,\t 830,\t 8\t 98.92%\n",
      "99,\t 16,\t 9\t 100.00%\n"
     ]
    }
   ],
   "source": [
    "for i, (cnt, acc, cls) in enumerate(zip(set_count.type(torch.long).tolist(),\n",
    "                                   (set_acc/set_count).tolist(),\n",
    "                                   torch.argmax(classifier.cls_weight, dim=1).tolist())):\n",
    "    if cnt == 0: continue\n",
    "    print(f\"{i},\\t {cnt},\\t {cls}\\t {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
