{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d6fc5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms as T\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm\n",
    "# from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d061bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19b55932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14519961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtnnlib as dtnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25c6f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.5,],\n",
    "        std=[0.5,],\n",
    "    ),\n",
    "])\n",
    "\n",
    "# train_dataset = datasets.FashionMNIST(root=\"../../../_Datasets/\", train=True, download=True, transform=mnist_transform)\n",
    "# test_dataset = datasets.FashionMNIST(root=\"../../../_Datasets/\", train=False, download=True, transform=mnist_transform)\n",
    "train_dataset = datasets.MNIST(root=\"../../../_Datasets/\", train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = datasets.MNIST(root=\"../../../_Datasets/\", train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b83035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e5fa113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3e8ad",
   "metadata": {},
   "source": [
    "## 1 Layer epsilon Softmax MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5de8aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceTransform_Epsilon(dtnn.DistanceTransformBase):\n",
    "    \n",
    "    def __init__(self, input_dim, num_centers, p=2, bias=False, epsilon=0.1):\n",
    "        super().__init__(input_dim, num_centers, p=2)\n",
    "        \n",
    "        nc = num_centers\n",
    "        if epsilon is not None:\n",
    "            nc += 1\n",
    "        self.scaler = nn.Parameter(torch.log(torch.ones(1, 1)*1))\n",
    "        self.bias = nn.Parameter(torch.ones(1, nc)*0) if bias else None\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dists = super().forward(x)\n",
    "        \n",
    "        if self.epsilon is not None:\n",
    "            dists = torch.cat([dists, torch.ones(len(x), 1, dtype=x.dtype)*self.epsilon], dim=1)\n",
    "        \n",
    "        ### normalize similar to UMAP\n",
    "        dists = dists/torch.sqrt(dists.var(dim=1, keepdim=True)+1e-9)\n",
    "        \n",
    "        ## scale the dists\n",
    "#         dists = torch.exp(-dists + self.scaler)\n",
    "        dists = 1-dists*torch.exp(self.scaler)\n",
    "    \n",
    "        if self.bias is not None: dists = dists+self.bias\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58e39721",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalMLP_epsilonsoftmax(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, epsilon=1.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.new_hidden_dim = 0\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.layer0 = DistanceTransform_Epsilon(self.input_dim, self.hidden_dim, bias=True, epsilon=epsilon)\n",
    "        hdim = self.hidden_dim\n",
    "        if epsilon is not None:\n",
    "            hdim += 1\n",
    "            \n",
    "#         self.scale_shift = dtnn.ScaleShift(hdim, scaler_init=3, shifter_init=0, scaler_const=True, shifter_const=True)\n",
    "        self.scale_shift = dtnn.ScaleShift(hdim, scaler_init=5, shifter_init=0, scaler_const=True, shifter_const=True)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "#         self.activ = dtnn.OneActiv(hdim, mode='relu', beta_init=np.log(1.2))\n",
    "        self.activ = nn.ReLU()\n",
    "\n",
    "        self.layer1 = nn.Linear(hdim, self.output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xo = self.layer0(x)\n",
    "        xo = self.scale_shift(xo)\n",
    "        xo = self.softmax(xo)\n",
    "        \n",
    "        xo = self.activ(xo)\n",
    "        xo = self.layer1(xo)\n",
    "        return xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "477eaf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 100\n",
    "model = LocalMLP_epsilonsoftmax(784, h, 10, epsilon=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a926c463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocalMLP_epsilonsoftmax(\n",
       "  (layer0): DistanceTransform_Epsilon()\n",
       "  (scale_shift): ScaleShift()\n",
       "  (softmax): Softmax(dim=-1)\n",
       "  (activ): ReLU()\n",
       "  (layer1): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a66b7a3",
   "metadata": {},
   "source": [
    "## Randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fbf77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = model.layer0.centers.shape[0]\n",
    "new_center = []\n",
    "new_labels = []\n",
    "count = 0\n",
    "for i, (xx, yy) in enumerate(train_loader):\n",
    "    xx = xx.reshape(-1, model.layer0.input_dim).to(model.layer0.centers.device)\n",
    "    if count+xx.shape[0] < N:\n",
    "        new_center.append(xx)\n",
    "        new_labels.append(yy)\n",
    "        count += xx.shape[0]\n",
    "    elif count >= N:\n",
    "        break\n",
    "    else:\n",
    "        new_center.append(xx[:N-count])\n",
    "        new_labels.append(yy[:N-count])\n",
    "        count = N\n",
    "        break\n",
    "        \n",
    "new_center = torch.cat(new_center, dim=0)\n",
    "new_labels = torch.cat(new_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe25277e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 784]), torch.Size([100]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_center.shape, new_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56446610",
   "metadata": {},
   "source": [
    "## Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "204486be",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.zeros(len(new_labels), 10)\n",
    "for i in range(len(new_labels)):\n",
    "    weights[i, new_labels[i]] = 1.\n",
    "# weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01ba885e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e021c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer0.centers.data = new_center.to(model.layer0.centers.device)\n",
    "model.layer1.weight.data = weights.t().to(model.layer1.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b02cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch, model):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    acc = 100.*correct/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac408e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocalMLP_epsilonsoftmax(\n",
       "  (layer0): DistanceTransform_Epsilon()\n",
       "  (scale_shift): ScaleShift()\n",
       "  (softmax): Softmax(dim=-1)\n",
       "  (activ): ReLU()\n",
       "  (layer1): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78886bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a5d2531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.786 | Acc: 68.580 6858/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68.58"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = test(0, model)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05ba4f8",
   "metadata": {},
   "source": [
    "## Add new centers to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0522326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_search = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35bc0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_training_samples(N):\n",
    "    new_center = []\n",
    "    new_labels = []\n",
    "    count = 0\n",
    "    for i, (xx, yy) in enumerate(train_loader):\n",
    "        xx = xx.reshape(xx.shape[0], -1)\n",
    "        if count+xx.shape[0] < N:\n",
    "            new_center.append(xx)\n",
    "            new_labels.append(yy)\n",
    "            count += xx.shape[0]\n",
    "        elif count >= N:\n",
    "            break\n",
    "        else:\n",
    "            new_center.append(xx[:N-count])\n",
    "            new_labels.append(yy[:N-count])\n",
    "            count = N\n",
    "            break\n",
    "\n",
    "    new_center = torch.cat(new_center, dim=0)\n",
    "    new_labels = torch.cat(new_labels, dim=0)\n",
    "    \n",
    "    weights = torch.zeros(len(new_labels), 10)\n",
    "    for i in range(len(new_labels)):\n",
    "        weights[i, new_labels[i]] = 1.\n",
    "    \n",
    "    return new_center.to(device), weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bb6c925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]]),\n",
       " tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_training_samples(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c68ed586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neurons_to_model(model, centers, values):\n",
    "    c = torch.cat((model.layer0.centers.data, centers), dim=0)\n",
    "    v = torch.cat((model.layer1.weight.data, values.t()), dim=1)\n",
    "    s = torch.cat([model.layer0.bias.data, torch.ones(1, len(centers))*0], dim=1)\n",
    "\n",
    "    model.layer0.centers.data = c\n",
    "    model.layer1.weight.data = v\n",
    "    model.layer0.bias.data = s\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "934e9e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 784]), torch.Size([10, 100]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer0.centers.data.shape, model.layer1.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dd92058",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_neurons_to_model(model, *get_random_training_samples(N_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51d8b84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([130, 784]), torch.Size([10, 130]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer0.centers.data.shape, model.layer1.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd97e43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.767 | Acc: 70.250 7025/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70.25, 68.58)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc2 = test(0, model)\n",
    "test_acc2, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6f7ac5",
   "metadata": {},
   "source": [
    "## Calculate Neuron Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4eadeae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, gradients = None, None\n",
    "def capture_outputs(module, inp, out):\n",
    "    global outputs\n",
    "#     print(inp)\n",
    "    outputs = out.data.cpu()\n",
    "\n",
    "def capture_gradients(module, gradi, grado):\n",
    "    global gradients\n",
    "#     print(gradi, '\\n')\n",
    "#     print(grado)\n",
    "    gradients = grado[0].data.cpu()\n",
    "        \n",
    "forw_hook = model.softmax.register_forward_hook(capture_outputs)\n",
    "back_hook = model.softmax.register_backward_hook(capture_gradients)\n",
    "# back_hook = model[0].register_full_backward_hook(capture_gradients)\n",
    "\n",
    "\n",
    "def remove_hook():\n",
    "    back_hook.remove()\n",
    "    forw_hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79e9c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "significance = torch.zeros(model.layer0.centers.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27b9daa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device).view(-1, 28*28), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64c25f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "yout = model(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3efb4360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0.,  ..., 1., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0450,  0.0680, -0.0654, -0.0738, -0.0742, -0.0906, -0.0952, -0.0079,\n",
       "          0.0994, -0.0143], requires_grad=True)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56665d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def none_grad():\n",
    "    for p in model.parameters():\n",
    "        p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4100532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_grad()\n",
    "yout.register_hook(lambda grad: grad/torch.norm(grad, dim=1, keepdim=True))\n",
    "\n",
    "# grad = torch.randn_like(yout)\n",
    "# ### grad = grad/torch.norm(grad, dim=1, keepdim=True)\n",
    "# yout.backward(gradient=grad, retain_graph=False)\n",
    "\n",
    "criterion(yout, yy).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a8574f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_hook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a186820b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 130]), torch.Size([50, 130]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape, gradients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d747de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0843e-05, 2.7837e-06, 1.3304e-03, 7.9738e-06, 6.5565e-02, 3.9431e-02,\n",
       "        5.1774e-04, 2.4698e-08, 1.0038e-03, 1.6180e-06, 8.9945e-01, 1.4323e-02,\n",
       "        1.0667e-05, 2.9981e-02, 2.3716e-08, 3.0156e-03, 1.2143e-06, 9.4740e-03,\n",
       "        1.6931e-03, 8.9956e-01, 2.1828e-01, 8.2302e-08, 9.2242e-01, 7.5332e-04,\n",
       "        5.0646e-06, 8.3960e-02, 2.1386e-03, 6.8199e-01, 3.0051e-05, 5.3785e-05,\n",
       "        2.3041e-04, 2.4872e-01, 2.6056e-03, 5.1014e-01, 1.4312e-02, 4.5986e-05,\n",
       "        7.6161e-04, 7.5922e-03, 4.4677e-03, 3.1681e-04, 8.0149e-01, 5.0286e-03,\n",
       "        4.8214e-04, 1.3849e-02, 8.9730e-01, 7.6227e-02, 4.6019e-03, 7.4381e-06,\n",
       "        4.3657e-05, 8.0637e-01, 1.1524e-04, 8.2728e-05, 2.8509e-06, 1.8518e-04,\n",
       "        1.9607e-09, 6.0305e-08, 1.7996e-03, 3.6866e-01, 9.6218e-01, 1.1051e-02,\n",
       "        4.0418e-02, 1.5905e-04, 1.6248e-02, 3.6764e-02, 7.3153e-01, 1.5388e-03,\n",
       "        1.3211e-04, 5.9147e-01, 4.3695e-04, 1.1031e-04, 5.0696e-03, 1.6282e-01,\n",
       "        2.8402e-08, 2.5376e-03, 2.9121e-05, 7.2226e-11, 9.9022e-09, 8.1700e-01,\n",
       "        2.8139e-05, 8.6995e-01, 5.0330e-01, 1.2755e-01, 2.0093e-03, 2.4160e-08,\n",
       "        5.3732e-04, 2.2836e-07, 4.5592e-06, 7.1337e-01, 4.0672e-05, 8.9910e-01,\n",
       "        1.0145e-03, 1.3463e-02, 2.2614e-04, 2.5965e-01, 5.6155e-01, 5.1101e-01,\n",
       "        1.0344e-01, 5.1513e-04, 2.2384e-04, 6.4676e-05, 3.4498e-02, 3.0235e-03,\n",
       "        5.9337e-15, 9.6964e-01, 2.8309e-04, 5.1408e-03, 1.3737e-01, 1.2301e-02,\n",
       "        8.6215e-05, 2.1335e-01, 3.2018e-02, 2.1040e-02, 1.7186e-01, 2.4892e-09,\n",
       "        1.4598e-06, 1.5340e-02, 1.7004e-03, 1.6584e-05, 3.6199e-01, 1.2450e-02,\n",
       "        9.0918e-03, 1.0777e-06, 9.1596e-10, 1.8818e-03, 2.1845e-03, 1.5749e-04,\n",
       "        1.0518e-06, 1.2417e-03, 1.0382e+00, 9.2381e-01])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    significance += torch.sum((outputs*gradients)**2, dim=0)\n",
    "significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2cf38c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e285a0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0382e+00, 9.6964e-01, 9.6218e-01, 9.2381e-01, 9.2242e-01, 8.9956e-01,\n",
       "        8.9945e-01, 8.9910e-01, 8.9730e-01, 8.6995e-01, 8.1700e-01, 8.0637e-01,\n",
       "        8.0149e-01, 7.3153e-01, 7.1337e-01, 6.8199e-01, 5.9147e-01, 5.6155e-01,\n",
       "        5.1101e-01, 5.1014e-01, 5.0330e-01, 3.6866e-01, 3.6199e-01, 2.5965e-01,\n",
       "        2.4872e-01, 2.1828e-01, 2.1335e-01, 1.7186e-01, 1.6282e-01, 1.3737e-01,\n",
       "        1.2755e-01, 1.0344e-01, 8.3960e-02, 7.6227e-02, 6.5565e-02, 4.0418e-02,\n",
       "        3.9431e-02, 3.6764e-02, 3.4498e-02, 3.2018e-02, 2.9981e-02, 2.1040e-02,\n",
       "        1.6248e-02, 1.5340e-02, 1.4323e-02, 1.4312e-02, 1.3849e-02, 1.3463e-02,\n",
       "        1.2450e-02, 1.2301e-02, 1.1051e-02, 9.4740e-03, 9.0918e-03, 7.5922e-03,\n",
       "        5.1408e-03, 5.0696e-03, 5.0286e-03, 4.6019e-03, 4.4677e-03, 3.0235e-03,\n",
       "        3.0156e-03, 2.6056e-03, 2.5376e-03, 2.1845e-03, 2.1386e-03, 2.0093e-03,\n",
       "        1.8818e-03, 1.7996e-03, 1.7004e-03, 1.6931e-03, 1.5388e-03, 1.3304e-03,\n",
       "        1.2417e-03, 1.0145e-03, 1.0038e-03, 7.6161e-04, 7.5332e-04, 5.3732e-04,\n",
       "        5.1774e-04, 5.1513e-04, 4.8214e-04, 4.3695e-04, 3.1681e-04, 2.8309e-04,\n",
       "        2.3041e-04, 2.2614e-04, 2.2384e-04, 1.8518e-04, 1.5905e-04, 1.5749e-04,\n",
       "        1.3211e-04, 1.1524e-04, 1.1031e-04, 8.6215e-05, 8.2728e-05, 6.4676e-05,\n",
       "        5.3785e-05, 4.5986e-05, 4.3657e-05, 4.0672e-05])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(significance, k=h, sorted=True, largest=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1347aa32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([128, 103,  58, 129,  22,  19,  10,  89,  44,  79,  77,  49,  40,  64,\n",
       "         87,  27,  67,  94,  95,  33,  80,  57, 118,  93,  31,  20, 109, 112,\n",
       "         71, 106,  81,  96,  25,  45,   4,  60,   5,  63, 100, 110,  13, 111,\n",
       "         62, 115,  11,  34,  43,  91, 119, 107,  59,  17, 120,  37, 105,  70,\n",
       "         41,  46,  38, 101,  15,  32,  73, 124,  26,  82, 123,  56, 116,  18,\n",
       "         65,   2, 127,  90,   8,  36,  23,  84,   6,  97,  42,  68,  39, 104,\n",
       "         30,  92,  98,  53,  61, 125,  66,  50,  69, 108,  51,  99,  29,  35,\n",
       "         48,  88])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_idx = torch.topk(significance, k=h, sorted=True)[1]\n",
    "topk_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c15b72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_neurons_from_model(model, importance, num_prune):\n",
    "    N = model.layer0.centers.shape[0]\n",
    "    topk_idx = torch.topk(importance, k=N-num_prune, largest=True)[1]\n",
    "    \n",
    "    c = model.layer0.centers.data[topk_idx]\n",
    "    v = model.layer1.weight.data[:,topk_idx]\n",
    "    s = model.layer0.bias.data[:,topk_idx]\n",
    "    model.layer0.centers.data = c\n",
    "    model.layer1.weight.data = v\n",
    "    model.layer0.bias.data = s\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51276687",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_neurons_from_model(model, significance, N_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7431d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.794 | Acc: 67.230 6723/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(67.23, 70.25, 68.58)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc3 = test(0, model)\n",
    "\n",
    "test_acc3, test_acc2, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10e45678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 784]), torch.Size([10, 100]), torch.Size([1, 100]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer0.centers.data.shape, model.layer1.weight.data.shape, model.layer0.bias.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b76ed451",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdasd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-6ce9b5ce5154>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masdasd\u001b[0m  \u001b[0;31m### ^^ expected::: test_acc2 > test_acc3 > test_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'asdasd' is not defined"
     ]
    }
   ],
   "source": [
    "asdasd  ### ^^ expected::: test_acc2 > test_acc3 > test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea5e05",
   "metadata": {},
   "source": [
    "## Do this in Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3138b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_neurons_to_model(model, *get_random_training_samples(N_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18d8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "significance = torch.zeros(model.layer0.centers.shape[0])\n",
    "\n",
    "forw_hook = model.softmax.register_forward_hook(capture_outputs)\n",
    "back_hook = model.softmax.register_backward_hook(capture_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713908eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx = xx.to(device).view(-1, 28*28)\n",
    "    yout = model(xx)\n",
    "    \n",
    "    none_grad()\n",
    "    yout.register_hook(lambda grad: grad/torch.norm(grad, dim=1, keepdim=True))\n",
    "    \n",
    "#     grad = torch.randn_like(yout)\n",
    "#     ### grad = grad/torch.norm(grad, dim=1, keepdim=True)\n",
    "#     yout.backward(gradient=grad)\n",
    "    \n",
    "#     criterion(yout, yy).backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        significance += torch.sum((outputs*gradients)**2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cc2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac587ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1bb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_hook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc9d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_neurons_from_model(model, significance, N_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc3 = test(0, model)\n",
    "test_acc3, test_acc2, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d61aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdasd  ### ^^ expected test_acc2 > test_acc3 > test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40237304",
   "metadata": {},
   "source": [
    "## Optimize for multiple steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eaa16904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.23"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f887143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding and Pruning for STEP: 0\n",
      "[Test] 0 Loss: 1.717 | Acc: 75.450 7545/10000\n",
      "Adding and Pruning for STEP: 1\n",
      "[Test] 0 Loss: 1.702 | Acc: 77.130 7713/10000\n",
      "Adding and Pruning for STEP: 2\n",
      "[Test] 0 Loss: 1.687 | Acc: 78.540 7854/10000\n",
      "Adding and Pruning for STEP: 3\n",
      "[Test] 0 Loss: 1.673 | Acc: 79.870 7987/10000\n",
      "Adding and Pruning for STEP: 4\n",
      "[Test] 0 Loss: 1.678 | Acc: 79.710 7971/10000\n",
      "Adding and Pruning for STEP: 5\n",
      "[Test] 0 Loss: 1.676 | Acc: 79.500 7950/10000\n",
      "Adding and Pruning for STEP: 6\n",
      "[Test] 0 Loss: 1.671 | Acc: 80.110 8011/10000\n",
      "Adding and Pruning for STEP: 7\n",
      "[Test] 0 Loss: 1.669 | Acc: 80.190 8019/10000\n",
      "Adding and Pruning for STEP: 8\n",
      "[Test] 0 Loss: 1.670 | Acc: 80.130 8013/10000\n",
      "Adding and Pruning for STEP: 9\n",
      "[Test] 0 Loss: 1.665 | Acc: 80.730 8073/10000\n"
     ]
    }
   ],
   "source": [
    "## Run multiple times for convergence\n",
    "STEPS = 10\n",
    "for s in range(STEPS):\n",
    "    print(f\"Adding and Pruning for STEP: {s}\")\n",
    "    add_neurons_to_model(model, *get_random_training_samples(N_search))\n",
    "    \n",
    "    significance = torch.zeros(model.layer0.centers.shape[0])\n",
    "\n",
    "    forw_hook = model.softmax.register_forward_hook(capture_outputs)\n",
    "    back_hook = model.softmax.register_backward_hook(capture_gradients)\n",
    "    \n",
    "    for xx, yy in train_loader:\n",
    "        xx = xx.to(device).view(-1, 28*28)\n",
    "        yout = model(xx)\n",
    "\n",
    "        none_grad()\n",
    "        yout.register_hook(lambda grad: grad/torch.norm(grad, dim=1, keepdim=True))\n",
    "        ####################################\n",
    "#         grad = torch.randn_like(yout)\n",
    "#         ### grad = grad/torch.norm(grad, dim=1, keepdim=True)\n",
    "#         yout.backward(gradient=grad)\n",
    "        ###################################\n",
    "        criterion(yout, yy).backward()\n",
    "        with torch.no_grad():\n",
    "            significance += torch.sum((outputs*gradients)**2, dim=0)\n",
    "    \n",
    "    remove_hook()\n",
    "    remove_neurons_from_model(model, significance, N_search)\n",
    "    test_acc3 = test(0, model)\n",
    "#     print(f\"Accuracy: {test_acc3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d53135",
   "metadata": {},
   "source": [
    "## Noisy Selection + Finetuening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10eaf206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PROBLEM 1:The neuron that does not get pruned gets trained for longer,, \n",
    "    hence can drift largely from its initialized data point (even at lower learning rate).\n",
    "    - Can freeze the centers of the MLP and train only values.\n",
    "\n",
    "PROBLEM 2:The values of each neuron might fire at different magnitude bringing different amount of\n",
    "    importance for classification (even the distance of center with other centers reduces its magnitude).\n",
    "    - This should be carefully handeled at initialization (or normalizing the values to unit norm).\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dc7d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dbd5eaf",
   "metadata": {},
   "source": [
    "## Multilayer Noisy Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5067af77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TYPE 1: DT>eSM>DT>eSM>V\n",
    "Type 2:  /DT>eSM>S\\\n",
    "        X---------+\\>eSM>V\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd53eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
