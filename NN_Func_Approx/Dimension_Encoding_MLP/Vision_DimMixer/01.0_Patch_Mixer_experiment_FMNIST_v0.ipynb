{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os, sys, pathlib, random, time, pickle, copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=50, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=50, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## demo of train loader\n",
    "xx, yy = iter(train_loader).next()\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP-Mixer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpBLock(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_layers_ratio=[2], actf=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        #### convert hidden layers ratio to list if integer is inputted\n",
    "        if isinstance(hidden_layers_ratio, int):\n",
    "            hidden_layers_ratio = [hidden_layers_ratio]\n",
    "            \n",
    "        self.hlr = [1]+hidden_layers_ratio+[1]\n",
    "        \n",
    "        self.mlp = []\n",
    "        ### for 1 hidden layer, we iterate 2 times\n",
    "        for h in range(len(self.hlr)-1):\n",
    "            i, o = int(self.hlr[h]*self.input_dim),\\\n",
    "                    int(self.hlr[h+1]*self.input_dim)\n",
    "            self.mlp.append(nn.Linear(i, o))\n",
    "            self.mlp.append(actf())\n",
    "        self.mlp = self.mlp[:-1]\n",
    "        \n",
    "        self.mlp = nn.Sequential(*self.mlp)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpBLock(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=6, bias=True)\n",
       "    (1): GELU()\n",
       "    (2): Linear(in_features=6, out_features=8, bias=True)\n",
       "    (3): GELU()\n",
       "    (4): Linear(in_features=8, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MlpBLock(2, [3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MixerBlock(nn.Module):\n",
    "    \n",
    "#     def __init__(self, patch_dim, channel_dim):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.ln0 = nn.LayerNorm(channel_dim)\n",
    "#         self.mlp_patch = MlpBLock(patch_dim, [2])\n",
    "#         self.ln1 = nn.LayerNorm(channel_dim)\n",
    "#         self.mlp_channel = MlpBLock(channel_dim, [2])\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         ## x has shape-> N, nP, nC/hidden_dims; C=Channel, P=Patch\n",
    "        \n",
    "#         ######## !!!! Can use same mixer on shape of -> N, C, P;\n",
    "        \n",
    "#         #### mix per patch\n",
    "#         y = self.ln0(x)\n",
    "#         y = torch.swapaxes(y, -1, -2)\n",
    "#         y = self.mlp_patch(y)\n",
    "#         y = torch.swapaxes(y, -1, -2)\n",
    "#         x = x+y\n",
    "        \n",
    "#         #### mix per channel \n",
    "#         y = self.ln1(x)\n",
    "#         y = self.mlp_channel(y)\n",
    "#         x = x+y\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MlpMixer(nn.Module):\n",
    "    \n",
    "#     def __init__(self, image_dim:tuple, patch_size:tuple, hidden_expansion:float, num_blocks:int, num_classes:int):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.img_dim = image_dim ### must contain (C, H, W) or (H, W)\n",
    "        \n",
    "#         ### find patch dim\n",
    "#         d0 = int(image_dim[-2]/patch_size[0])\n",
    "#         d1 = int(image_dim[-1]/patch_size[1])\n",
    "#         assert d0*patch_size[0]==image_dim[-2], \"Image must be divisible into patch size\"\n",
    "#         assert d1*patch_size[1]==image_dim[-1], \"Image must be divisible into patch size\"\n",
    "# #         self.d0, self.d1 = d0, d1 ### number of patches in each axis\n",
    "#         __patch_size = patch_size[0]*patch_size[1]*image_dim[0] ## number of channels in each patch\n",
    "    \n",
    "#         ### find channel dim\n",
    "#         channel_size = d0*d1 ## number of patches\n",
    "        \n",
    "#         ### after the number of channels are changed\n",
    "#         init_dim = __patch_size\n",
    "#         final_dim = int(patch_size[0]*patch_size[1]*hidden_expansion)\n",
    "#         self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "#         #### rescale the patches (patch wise image non preserving transform, unlike bilinear interpolation)\n",
    "#         self.channel_change = nn.Linear(init_dim, final_dim)\n",
    "#         print(f\"MLP Mixer : Channes per patch -> Initial:{init_dim} Final:{final_dim}\")\n",
    "        \n",
    "        \n",
    "#         self.channel_dim = final_dim\n",
    "#         self.patch_dim = channel_size\n",
    "        \n",
    "#         self.mixer_blocks = []\n",
    "#         for i in range(num_blocks):\n",
    "#             self.mixer_blocks.append(MixerBlock(self.patch_dim, self.channel_dim))\n",
    "#         self.mixer_blocks = nn.Sequential(*self.mixer_blocks)\n",
    "        \n",
    "#         self.linear = nn.Linear(self.patch_dim*self.channel_dim, num_classes)\n",
    "        \n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         bs = x.shape[0]\n",
    "#         x = self.unfold(x).swapaxes(-1, -2)\n",
    "#         x = self.channel_change(x)\n",
    "#         x = self.mixer_blocks(x)\n",
    "#         x = self.linear(x.view(bs, -1))\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixer = MlpMixer((1, 28, 28), (4, 4), hidden_expansion=2, num_blocks=1, num_classes=10)\n",
    "# mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixer(torch.randn(3, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_params = dict(kernel_size=4, dilation=1, padding=0, stride=4)\n",
    "\n",
    "fold = nn.Fold(output_size=(28,28), **fold_params)\n",
    "unfold = nn.Unfold(**fold_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ones = torch.ones(3, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16, 49])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divisor = fold(unfold(input_ones))\n",
    "unfold(input_ones).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold(unfold(input_ones)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMixerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, patch_size, num_channel):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "#         self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "        ps = None\n",
    "        if isinstance(patch_size, int):\n",
    "            ps = patch_size**2\n",
    "        else:\n",
    "            ps = patch_size[0]*patch_size[1]\n",
    "        ps = ps*num_channel\n",
    "        \n",
    "        self.ln0 = nn.LayerNorm(ps)\n",
    "        self.mlp_patch = MlpBLock(ps, [2])\n",
    "        \n",
    "#         self.fold = nn.Fold(kernel_size=patch_size, stride=patch_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## x has shape-> N, C, H, W; C=Channel\n",
    "        \n",
    "        sz = x.shape\n",
    "        \n",
    "        y = nn.functional.unfold(x, \n",
    "                                 kernel_size=self.patch_size, \n",
    "                                 stride=self.patch_size\n",
    "                                )\n",
    "        #### mix per patch\n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        y = self.ln0(y) \n",
    "        y = self.mlp_patch(y)\n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        \n",
    "        y = nn.functional.fold(y, (sz[-2], sz[-1]), \n",
    "                               kernel_size=self.patch_size, \n",
    "                               stride=self.patch_size\n",
    "                              )\n",
    "        x = x+y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchMixerBlock(\n",
       "  (ln0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (mlp_patch): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmb = PatchMixerBlock(4, 2)\n",
    "pmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 28, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmb(torch.randn(1, 2, 28,28)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factors(n):\n",
    "    facts = []\n",
    "    for i in range(2, n+1):\n",
    "        if n%i == 0:\n",
    "            facts.append(i)\n",
    "    return facts\n",
    "\n",
    "class PatchMlpMixer(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_dim:tuple, patch_sizes:tuple, input_scale:float, num_blocks:int, num_classes:int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_dim = image_dim ### must contain (C, H, W)\n",
    "        \n",
    "        scaled_img_size = int(image_dim[-2]*input_scale), int(image_dim[-1]*input_scale)\n",
    "        if input_scale==1:\n",
    "            self.scaler = lambda x: x\n",
    "        else:\n",
    "            self.scaler = nn.UpsamplingBilinear2d(size=scaled_img_size)\n",
    "        \n",
    "        print(f\"Scaled Image Size: {scaled_img_size}\")\n",
    "        print(f\"Prime factors of image size\")\n",
    "        print(f\"H -> {get_factors(scaled_img_size[0])}\")\n",
    "        print(f\"W -> {get_factors(scaled_img_size[1])}\")\n",
    "        \n",
    "        ### find number of channel for input, the channel is \n",
    "        num_channel = image_dim[0]\n",
    "        \n",
    "        self.mixer_blocks = []\n",
    "        for i in range(num_blocks):\n",
    "            for ps in patch_sizes:\n",
    "                self.mixer_blocks.append(PatchMixerBlock(ps, num_channel))\n",
    "                \n",
    "        self.mixer_blocks = nn.Sequential(*self.mixer_blocks)\n",
    "        self.linear = nn.Linear(scaled_img_size[0]*scaled_img_size[1]*num_channel, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = self.scaler(x)\n",
    "        x = self.mixer_blocks(x)\n",
    "        x = self.linear(x.view(bs, -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Image Size: (28, 28)\n",
      "Prime factors of image size\n",
      "H -> [2, 4, 7, 14, 28]\n",
      "W -> [2, 4, 7, 14, 28]\n"
     ]
    }
   ],
   "source": [
    "patch_mixer = PatchMlpMixer((1, 28, 28), patch_sizes=[4, 7], input_scale=1, num_blocks=5, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_mixer(torch.randn(3, 1, 28, 28)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Image Size: (28, 28)\n",
      "Prime factors of image size\n",
      "H -> [2, 4, 7, 14, 28]\n",
      "W -> [2, 4, 7, 14, 28]\n"
     ]
    }
   ],
   "source": [
    "model = PatchMlpMixer((1, 28, 28), patch_sizes=[4, 7], input_scale=1, num_blocks=5, num_classes=10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  62615\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## debugging to find the good classifier/output distribution.\n",
    "model_name = 'patch_mixer_fmnist_v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('./models'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:19<00:00, 62.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 0 Loss: 0.404 | Acc: 85.693 51416/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 132.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 0.372 | Acc: 86.430 8643/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:17<00:00, 66.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 1 Loss: 0.292 | Acc: 89.515 53709/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 134.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 1 Loss: 0.322 | Acc: 88.570 8857/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:19<00:00, 63.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 2 Loss: 0.254 | Acc: 90.895 54537/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 126.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 2 Loss: 0.291 | Acc: 89.920 8992/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:18<00:00, 63.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 3 Loss: 0.225 | Acc: 91.807 55084/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 131.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 3 Loss: 0.288 | Acc: 89.740 8974/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:19<00:00, 62.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 4 Loss: 0.197 | Acc: 92.782 55669/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 126.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 4 Loss: 0.296 | Acc: 89.590 8959/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:18<00:00, 63.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 5 Loss: 0.172 | Acc: 93.790 56274/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 127.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 5 Loss: 0.299 | Acc: 89.940 8994/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:18<00:00, 63.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 6 Loss: 0.147 | Acc: 94.737 56842/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 126.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 6 Loss: 0.304 | Acc: 90.030 9003/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:18<00:00, 65.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 7 Loss: 0.120 | Acc: 95.738 57443/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 132.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 7 Loss: 0.320 | Acc: 90.070 9007/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:17<00:00, 66.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 8 Loss: 0.094 | Acc: 96.690 58014/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 133.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 8 Loss: 0.346 | Acc: 89.990 8999/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:18<00:00, 65.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 9 Loss: 0.067 | Acc: 97.622 58573/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 134.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 9 Loss: 0.393 | Acc: 89.390 8939/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1200/1200 [00:18<00:00, 66.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 10 Loss: 0.046 | Acc: 98.440 59064/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:01<00:00, 134.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 10 Loss: 0.412 | Acc: 89.850 8985/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████▌                                          | 182/1200 [00:02<00:15, 66.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Train the whole damn thing\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, start_epoch\u001b[38;5;241m+\u001b[39mEPOCHS): \u001b[38;5;66;03m## for 200 epochs\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     test(epoch)\n\u001b[1;32m      6\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[1;32m     11\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1207\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1173\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1173\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1175\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1014\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/multiprocessing/reductions.py:295\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[0;32m--> 295\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m         storage \u001b[38;5;241m=\u001b[39m storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/multiprocessing/resource_sharer.py:57\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_resource_sharer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction\u001b[38;5;241m.\u001b[39mrecv_handle(conn)\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/multiprocessing/resource_sharer.py:86\u001b[0m, in \u001b[0;36m_ResourceSharer.get_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m     85\u001b[0m address, key \u001b[38;5;241m=\u001b[39m ident\n\u001b[0;32m---> 86\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m c\u001b[38;5;241m.\u001b[39msend((key, os\u001b[38;5;241m.\u001b[39mgetpid()))\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/multiprocessing/connection.py:514\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m authkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    513\u001b[0m     answer_challenge(c, authkey)\n\u001b[0;32m--> 514\u001b[0m     \u001b[43mdeliver_challenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/multiprocessing/connection.py:745\u001b[0m, in \u001b[0;36mdeliver_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    743\u001b[0m connection\u001b[38;5;241m.\u001b[39msend_bytes(CHALLENGE \u001b[38;5;241m+\u001b[39m message)\n\u001b[1;32m    744\u001b[0m digest \u001b[38;5;241m=\u001b[39m hmac\u001b[38;5;241m.\u001b[39mnew(authkey, message, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmd5\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdigest()\n\u001b[0;32m--> 745\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m        \u001b[38;5;66;03m# reject large message\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;241m==\u001b[39m digest:\n\u001b[1;32m    747\u001b[0m     connection\u001b[38;5;241m.\u001b[39msend_bytes(WELCOME)\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/multiprocessing/connection.py:221\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/multiprocessing/connection.py:419\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 419\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/multiprocessing/connection.py:384\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    382\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 384\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Train the whole damn thing\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+EPOCHS): ## for 200 epochs\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.07"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90.21, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "best_acc = checkpoint['acc']\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "best_acc, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchMlpMixer(\n",
       "  (mixer_blocks): Sequential(\n",
       "    (0): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((49,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((49,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((49,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((49,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): PatchMixerBlock(\n",
       "      (ln0): LayerNorm((49,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_patch): MlpBLock(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=49, out_features=98, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=98, out_features=49, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
