{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9adde6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16e6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random, time, os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc9826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparse_nonlinear_lib as snl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9116e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43422589",
   "metadata": {},
   "source": [
    "## For FMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb3149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6203202",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=50, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=50, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3161b7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## demo of train loader\n",
    "xx, yy = iter(train_loader).next()\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1cb444",
   "metadata": {},
   "source": [
    "# Model Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad34b9b1",
   "metadata": {},
   "source": [
    "## Pair Linear Mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d17e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2patch(x, input_dim=(1, 28, 28), patch_size=(7, 4)):\n",
    "    y = nn.functional.unfold(x, \n",
    "                             kernel_size=patch_size, \n",
    "                             stride=patch_size\n",
    "                            )\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0293c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch2img(x, patch_size=(7, 4), input_dim=(1, 28, 28)):\n",
    "    y = nn.functional.fold(x, (input_dim[-2], input_dim[-1]), \n",
    "                               kernel_size=patch_size, \n",
    "                               stride=patch_size\n",
    "                              )\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22899c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2patch(torch.randn(2, 1, 28, 28)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bc1f9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch2img(torch.randn(2, 7* 4, 7*4)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7a1f13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1024)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(7*4)**2, (8*4)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b706042c",
   "metadata": {},
   "source": [
    "1. Linearize by expanding the dimension of folded image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b94d83",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9214b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMNIST_BlockMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_size=(1, 28, 28), patch_size=(7, 7)):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_linear = nn.Linear(img_size[0]*patch_size[0]*patch_size[1], 8*8)\n",
    "#         self.dim_sel = snl.DimensionSelector(8*8*4*4, 8*4*8*4)\n",
    "        self.block_mlp = snl.BlockMLP_MixerBlock(8*4*8*4, 8*4, hidden_layers_ratio=[4])\n",
    "        self.fc = nn.Linear(8*4*8*4, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = img2patch(x, input_dim=(1, 28, 28), patch_size=self.patch_size)\n",
    "#         print(x.shape)\n",
    "        x = self.patch_linear(x.transpose(-2, -1)).reshape(bs, -1)\n",
    "#         print(x.shape)\n",
    "#         x = self.dim_sel(x)\n",
    "#         print(x.shape)\n",
    "        x = self.block_mlp(x)\n",
    "#         print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0465fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMNIST_OrdMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_size=(1, 28, 28)):\n",
    "        super().__init__()\n",
    "        self.input_dim = np.prod(img_size)\n",
    "        M = 512#354 #1024\n",
    "        self.l0 = nn.Linear(self.input_dim, M)\n",
    "        self.l1 = nn.Linear(M, 10)\n",
    "        self.elu = nn.ELU()\n",
    "        self.ln = nn.LayerNorm(M)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = self.l0(x.reshape(bs, -1))\n",
    "        x = self.ln(x)\n",
    "        x = self.elu(x)\n",
    "        x = self.l1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "372527ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMNIST_PairBilinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_size=(1, 28, 28), patch_size=(7, 7)):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_linear = nn.Linear(img_size[0]*patch_size[0]*patch_size[1], 8*8)\n",
    "#         self.dim_sel = snl.DimensionSelector(8*8*4*4, 8*4*8*4)\n",
    "        self.ln = nn.LayerNorm(8*4*8*4)\n",
    "        self.bn = nn.BatchNorm1d(8*4*8*4)\n",
    "\n",
    "        self.block_func = snl.PairBilinear_MixerBlock(8*4*8*4, 8*4*8*4, grid_width=10).\n",
    "        self.fc = nn.Linear(8*4*8*4, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = img2patch(x, input_dim=(1, 28, 28), patch_size=self.patch_size)\n",
    "        x = self.patch_linear(x.transpose(-2, -1)).reshape(bs, -1)\n",
    "        x = self.ln(x)\n",
    "        x = self.block_func(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "17962814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 2]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 10, 10]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 2]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 10, 10]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 2]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 10, 10]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 2]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 10, 10]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 2]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 10, 10]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 2]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 10, 10]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 2]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 10, 10]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 2]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 10, 10]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 2]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 10, 10]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 2]) torch.float64 cuda:0\n",
      "torch.Size([512, 2, 10, 10]) torch.float64 cuda:0\n"
     ]
    }
   ],
   "source": [
    "block_func = snl.PairBilinear_MixerBlock(8*4*8*4, 8*4*8*4, grid_width=10).type(torch.double).to(device)\n",
    "# block_func.pairwise_mixing[0].pairW.dtype\n",
    "for p in block_func.parameters():\n",
    "    print(p.shape, p.dtype, p.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7e466c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mdouble()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mblock_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/HDD2/TSuman/Notebooks/_GithubSync/Experimentals/NN_Func_Approx/Dimension_Encoding_MLP/Sparse_NonLinear/sparse_nonlinear_lib.py:550\u001b[0m, in \u001b[0;36mPairBilinear_MixerBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, fn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpairwise_mixing):\n\u001b[1;32m    549\u001b[0m     _y \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m--> 550\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mi)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bs, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    551\u001b[0m     y \u001b[38;5;241m=\u001b[39m fn(y)\n\u001b[1;32m    552\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mi,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/HDD2/TSuman/Notebooks/_GithubSync/Experimentals/NN_Func_Approx/Dimension_Encoding_MLP/Sparse_NonLinear/sparse_nonlinear_lib.py:407\u001b[0m, in \u001b[0;36mPairBilinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    404\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(bs, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m#         x = BMM2x2Function.apply(x, self.pairW)\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;66;03m####################################################\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mBiLinear2x2Function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(bs, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/mnt/HDD2/TSuman/Notebooks/_GithubSync/Experimentals/NN_Func_Approx/Dimension_Encoding_MLP/Sparse_NonLinear/sparse_nonlinear_lib.py:372\u001b[0m, in \u001b[0;36mBiLinear2x2Function.forward\u001b[0;34m(ctx, inputs, weights)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, inputs, weights):\n\u001b[0;32m--> 372\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbilinear2x2_cuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m     ctx\u001b[38;5;241m.\u001b[39msave_for_backward(inputs, weights)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 1024).double().to(device)\n",
    "block_func(x)\n",
    "# x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e0ea73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = FMNIST_BlockMLP(img_size=(1, 28, 28), patch_size=(7, 7))\n",
    "# model = FMNIST_OrdMLP(img_size=(1, 28, 28))\n",
    "model = FMNIST_PairBilinear(img_size=(1, 28, 28), patch_size=(7, 7))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7587134b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FMNIST_PairBilinear(\n",
       "  (patch_linear): Linear(in_features=49, out_features=64, bias=True)\n",
       "  (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (block_func): PairBilinear_MixerBlock(\n",
       "    (selector): BiasLayer: [1024]\n",
       "    (pairwise_mixing): ModuleList(\n",
       "      (0): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (1): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (2): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (3): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (4): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (5): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (6): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (7): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (8): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "      (9): PairLinear: [1024 -> 1024] (grid: 10)\n",
       "    )\n",
       "    (reducer): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28f8ed05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(2, 1, 28, 28).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "145a10f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  1063050\n"
     ]
    }
   ],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fd8f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BLOCK MLP (1024/64) number of params:  281738\n",
    "## ORDINARY MLP (784, 1024) number of params:  814090\n",
    "## PAIR BILINEAR has 1058954"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d71b7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614656"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*784"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d531c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b373358a",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## debugging to find the good classifier/output distribution.\n",
    "# model_name = 'block_mlp_mixer_fmnist_v0'\n",
    "# model_name = 'ord_mlp_mixer_fmnist_v0'\n",
    "model_name = 'pair_bilinear_mixer_fmnist_v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b9e292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4e8858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2867980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0b5e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('./models'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf30ff1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 1200/1200 [00:06<00:00, 189.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 0 Loss: nan | Acc: 10.762 6457/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 200/200 [00:00<00:00, 411.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: nan | Acc: 10.000 1000/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████▉                                     | 291/1200 [00:01<00:05, 180.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Train the whole damn thing\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, start_epoch\u001b[38;5;241m+\u001b[39mEPOCHS): \u001b[38;5;66;03m## for 200 epochs\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     test(epoch)\n\u001b[1;32m      6\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 18\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Train the whole damn thing\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+EPOCHS): ## for 200 epochs\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee11ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "best_acc = checkpoint['acc']\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "best_acc, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ba62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dab532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
