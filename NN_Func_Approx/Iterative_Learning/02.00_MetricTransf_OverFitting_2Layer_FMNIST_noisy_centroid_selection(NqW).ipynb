{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms as T\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm\n",
    "# from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, time, sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtnnlib as dtnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.5,],\n",
    "        std=[0.5,],\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/\", train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/\", train=False, download=True, transform=mnist_transform)\n",
    "\n",
    "# train_dataset = datasets.MNIST(root=\"../../../../_Datasets/\", train=True, download=True, transform=mnist_transform)\n",
    "# test_dataset = datasets.MNIST(root=\"../../../../_Datasets/\", train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    print(xx.shape, yy.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 200\n",
    "model = nn.Sequential(\n",
    "            dtnn.DistanceTransform_MinExp(784, h),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(h, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DistanceTransform_MinExp()\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model[0].set_centroid_to_data_maxdist(train_loader)\n",
    "# model[0].set_centroid_to_data(train_loader)\n",
    "# model[0].set_centroid_to_data_randomly(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = model[0].centers.shape[0]\n",
    "new_center = []\n",
    "new_labels = []\n",
    "count = 0\n",
    "for i, (xx, yy) in enumerate(train_loader):\n",
    "    xx = xx.reshape(-1, model[0].input_dim).to(model[0].centers.device)\n",
    "    if count+xx.shape[0] < N:\n",
    "        new_center.append(xx)\n",
    "        new_labels.append(yy)\n",
    "        count += xx.shape[0]\n",
    "    elif count >= N:\n",
    "        break\n",
    "    else:\n",
    "        new_center.append(xx[:N-count])\n",
    "        new_labels.append(yy[:N-count])\n",
    "        count = N\n",
    "        break\n",
    "        \n",
    "new_center = torch.cat(new_center, dim=0)\n",
    "new_labels = torch.cat(new_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 784]), torch.Size([200]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_center.shape, new_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.zeros(len(new_labels), 10)\n",
    "for i in range(len(new_labels)):\n",
    "    weights[i, new_labels[i]] = 1.\n",
    "# weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].centers.data = new_center.to(model[0].centers.device)\n",
    "model[-1].weight.data = weights.t().to(model[-1].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch, model):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device).view(-1, 28*28), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    acc = 100.*correct/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DistanceTransform_MinExp()\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.110 | Acc: 69.350 6935/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69.35"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = test(0, model)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new centers to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_search = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_training_samples(N):\n",
    "    new_center = []\n",
    "    new_labels = []\n",
    "    count = 0\n",
    "    for i, (xx, yy) in enumerate(train_loader):\n",
    "        xx = xx.reshape(xx.shape[0], -1)\n",
    "        if count+xx.shape[0] < N:\n",
    "            new_center.append(xx)\n",
    "            new_labels.append(yy)\n",
    "            count += xx.shape[0]\n",
    "        elif count >= N:\n",
    "            break\n",
    "        else:\n",
    "            new_center.append(xx[:N-count])\n",
    "            new_labels.append(yy[:N-count])\n",
    "            count = N\n",
    "            break\n",
    "\n",
    "    new_center = torch.cat(new_center, dim=0)\n",
    "    new_labels = torch.cat(new_labels, dim=0)\n",
    "    \n",
    "    weights = torch.zeros(len(new_labels), 10)\n",
    "    for i in range(len(new_labels)):\n",
    "        weights[i, new_labels[i]] = 1.\n",
    "    \n",
    "    return new_center.to(device), weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -0.9922, -0.9843,  ..., -1.0000, -1.0000, -1.0000]]),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_training_samples(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neurons_to_model(model, centers, values):\n",
    "    c = torch.cat((model[0].centers.data, centers), dim=0)\n",
    "    v = torch.cat((model[-1].weight.data, values.t()), dim=1)\n",
    "    s = torch.cat((model[0].scaler.data, torch.ones(1, len(centers))*6/3), dim=1)\n",
    "    model[0].centers.data = c\n",
    "    model[-1].weight.data = v\n",
    "    model[0].scaler.data = s\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 784]), torch.Size([10, 200]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].centers.data.shape, model[-1].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_neurons_to_model(model, *get_random_training_samples(N_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([300, 784]), torch.Size([10, 300]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].centers.data.shape, model[-1].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.101 | Acc: 70.090 7009/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70.09, 69.35)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc2 = test(0, model)\n",
    "test_acc2, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Neuron Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, gradients = None, None\n",
    "def capture_outputs(module, inp, out):\n",
    "    global outputs\n",
    "#     print(inp)\n",
    "    outputs = out.data.cpu()\n",
    "\n",
    "def capture_gradients(module, gradi, grado):\n",
    "    global gradients\n",
    "#     print(gradi, '\\n')\n",
    "#     print(grado)\n",
    "    gradients = grado[0].data.cpu()\n",
    "        \n",
    "forw_hook = model[0].register_forward_hook(capture_outputs)\n",
    "back_hook = model[0].register_backward_hook(capture_gradients)\n",
    "# back_hook = model[0].register_full_backward_hook(capture_gradients)\n",
    "\n",
    "\n",
    "def remove_hook():\n",
    "    back_hook.remove()\n",
    "    forw_hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance = torch.zeros(model[0].centers.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    }
   ],
   "source": [
    "yout = model(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]]),\n",
       " Parameter containing:\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0059, -0.0173, -0.0311, -0.0606, -0.0492, -0.0098, -0.0139,  0.0124,\n",
       "          0.0567, -0.0322], requires_grad=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def none_grad():\n",
    "    for p in model.parameters():\n",
    "        p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "none_grad()\n",
    "# grad = torch.randn_like(yout)\n",
    "# grad = grad/torch.norm(grad, dim=1, keepdim=True)\n",
    "# yout.backward(gradient=grad, retain_graph=False)\n",
    "criterion(yout, yy).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_hook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 300]), torch.Size([50, 300]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape, gradients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.4651e-09, 5.5334e-11, 2.0848e-10, 1.8164e-10, 2.4516e-08, 4.7279e-09,\n",
       "        6.8161e-11, 6.0861e-12, 1.3654e-09, 3.2271e-09, 6.1094e-09, 4.4848e-08,\n",
       "        1.7369e-08, 7.6331e-11, 9.0758e-07, 4.7269e-08, 4.4653e-09, 4.4455e-08,\n",
       "        1.1083e-08, 1.4347e-07, 2.8366e-09, 2.4867e-07, 7.2180e-08, 1.2822e-12,\n",
       "        1.2969e-08, 1.2357e-09, 8.8349e-08, 2.0735e-10, 2.6791e-09, 4.8465e-11,\n",
       "        3.5571e-07, 1.1953e-08, 7.3189e-10, 1.8456e-11, 6.9988e-08, 4.4973e-08,\n",
       "        5.6264e-08, 7.9606e-10, 3.5879e-08, 1.8810e-12, 2.4822e-08, 5.2071e-09,\n",
       "        6.4649e-10, 2.0374e-09, 4.7842e-08, 2.8759e-10, 3.9555e-10, 4.8837e-08,\n",
       "        1.1647e-07, 7.6402e-10, 2.0775e-10, 1.5987e-08, 8.4379e-10, 1.0612e-10,\n",
       "        1.0072e-08, 4.3593e-10, 1.0037e-12, 5.3185e-11, 4.0479e-08, 1.1381e-08,\n",
       "        3.8899e-13, 2.9403e-09, 5.3745e-08, 1.5199e-07, 6.0395e-12, 3.5818e-07,\n",
       "        5.1228e-08, 2.0990e-07, 8.4953e-10, 5.3625e-10, 7.7983e-08, 3.2948e-10,\n",
       "        4.7550e-09, 4.2167e-10, 4.0250e-08, 7.6048e-11, 1.3626e-07, 2.2378e-10,\n",
       "        7.2624e-08, 8.1258e-08, 1.4168e-08, 7.0907e-08, 7.2613e-10, 3.1211e-09,\n",
       "        1.5909e-10, 8.6475e-10, 2.1443e-10, 3.2075e-13, 9.2635e-08, 2.6603e-07,\n",
       "        9.8390e-10, 1.5442e-07, 2.4480e-11, 8.1205e-08, 2.3069e-09, 3.3121e-08,\n",
       "        3.9893e-07, 1.4224e-09, 1.0098e-07, 2.0550e-07, 1.0883e-07, 6.2617e-10,\n",
       "        2.9223e-07, 2.5894e-07, 1.3747e-07, 1.5961e-08, 2.5049e-08, 1.6449e-08,\n",
       "        6.3638e-09, 6.8087e-08, 1.6916e-06, 9.3805e-12, 9.1178e-08, 1.0840e-07,\n",
       "        6.8611e-10, 3.9232e-09, 2.2104e-10, 5.5853e-10, 1.5660e-10, 6.8157e-13,\n",
       "        6.7189e-10, 6.6158e-07, 3.5608e-06, 4.5934e-08, 1.5486e-07, 4.3938e-07,\n",
       "        6.7373e-09, 6.3049e-07, 2.5437e-10, 3.2434e-09, 7.5506e-13, 2.5230e-08,\n",
       "        8.5911e-09, 1.8210e-09, 2.9936e-08, 1.8003e-10, 1.9405e-09, 2.9728e-10,\n",
       "        7.7213e-08, 2.3130e-08, 7.2501e-08, 5.7907e-09, 7.7780e-11, 1.1613e-09,\n",
       "        2.3082e-08, 5.5545e-07, 5.1977e-08, 1.6251e-10, 4.5389e-09, 1.6535e-08,\n",
       "        2.3782e-04, 2.1283e-04, 2.1911e-04, 2.3789e-04, 2.3484e-04, 2.3321e-04,\n",
       "        2.2315e-04, 2.3775e-04, 2.3477e-04, 2.3481e-04, 2.3496e-04, 2.2534e-04,\n",
       "        2.3728e-04, 2.3525e-04, 1.7792e-04, 2.2153e-04, 2.4002e-04, 2.1421e-04,\n",
       "        2.3708e-04, 2.2892e-04, 2.0268e-04, 2.0643e-04, 2.3943e-04, 2.3103e-04,\n",
       "        2.1963e-04, 2.3819e-04, 2.3403e-04, 2.3685e-04, 2.2154e-04, 2.2826e-04,\n",
       "        2.2410e-04, 2.3807e-04, 1.9352e-04, 2.0577e-04, 2.3517e-04, 2.3762e-04,\n",
       "        2.2914e-04, 2.2713e-04, 2.0969e-04, 2.3789e-04, 2.4007e-04, 2.3912e-04,\n",
       "        2.3417e-04, 1.7922e-04, 2.2687e-04, 2.2699e-04, 2.2687e-04, 2.2409e-04,\n",
       "        2.2627e-04, 2.2451e-04, 2.3419e-11, 1.8749e-10, 1.2008e-09, 1.0162e-09,\n",
       "        2.0080e-08, 8.4282e-08, 2.1670e-08, 3.5416e-09, 2.2315e-08, 6.7035e-10,\n",
       "        2.5757e-07, 6.5370e-08, 4.6797e-08, 3.7741e-09, 2.9498e-08, 2.2148e-09,\n",
       "        1.9817e-10, 5.4178e-12, 1.3315e-07, 7.4205e-09, 2.1319e-11, 1.5784e-10,\n",
       "        5.6205e-09, 5.0326e-08, 4.2926e-08, 5.6283e-10, 2.4555e-10, 3.2501e-10,\n",
       "        3.1589e-09, 3.0345e-08, 1.6197e-07, 6.2287e-10, 9.1043e-07, 5.1266e-09,\n",
       "        1.8046e-07, 1.9572e-08, 2.3131e-07, 2.5400e-10, 1.0996e-10, 8.7789e-07,\n",
       "        1.3870e-08, 1.8214e-08, 3.5906e-08, 7.7740e-08, 1.5155e-11, 2.6389e-08,\n",
       "        5.1562e-08, 1.7260e-08, 1.1710e-08, 5.0352e-09, 3.1355e-10, 3.6491e-09,\n",
       "        7.2001e-09, 1.4526e-08, 1.8901e-09, 2.9643e-10, 2.8923e-10, 2.3166e-08,\n",
       "        6.6673e-09, 2.0551e-08, 1.0324e-07, 6.7289e-09, 2.1324e-07, 8.7726e-09,\n",
       "        2.0101e-08, 7.2511e-11, 2.6418e-10, 2.4192e-07, 1.1486e-13, 6.8029e-09,\n",
       "        5.9699e-08, 2.6474e-10, 1.1244e-07, 3.1562e-08, 5.1857e-09, 2.8000e-06,\n",
       "        6.8074e-08, 7.2378e-07, 1.4229e-08, 1.7736e-08, 3.3204e-11, 2.6309e-10,\n",
       "        2.1230e-09, 4.2285e-08, 1.0610e-07, 3.0793e-07, 1.2083e-08, 5.2211e-08,\n",
       "        1.6603e-07, 1.5332e-12, 2.8070e-09, 3.0635e-10, 1.6225e-07, 6.2548e-10,\n",
       "        1.5943e-09, 1.9483e-09, 6.4940e-09, 1.3185e-08, 1.2992e-08, 8.3545e-11])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    significance += torch.sum((outputs*gradients)**2, dim=0)\n",
    "significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([190, 166, 172, 191, 175, 181, 153, 189, 150, 157, 185, 162, 168, 177,\n",
       "        163, 184, 160, 154, 159, 158, 192, 176, 155, 173, 186, 169, 179, 187,\n",
       "        195, 194, 196, 198, 161, 199, 180, 197, 156, 178, 165, 174, 152, 167,\n",
       "        151, 188, 171, 183, 170, 182, 193, 164, 122, 275, 110, 232,  14, 239,\n",
       "        277, 121, 127, 145, 125,  96,  65,  30, 285, 102,  89, 103, 210,  21,\n",
       "        267, 236, 262,  67,  99, 234, 288, 292, 230, 124,  91,  63,  19, 104,\n",
       "         76, 218,  48, 272, 100, 113, 284, 260,  98,  88, 112,  26, 205,  79,\n",
       "         93,  70, 243, 138,  78, 140,  22,  81,  34, 109, 276, 211, 270,  36,\n",
       "         62, 287, 146, 246,  66, 223,  47,  44,  15, 212, 123,  35,  11,  17,\n",
       "        224, 283,  58,  74, 242,  38,  95, 273, 229, 134, 214, 245, 131, 106,\n",
       "         40,   4, 257, 139, 144, 208, 206, 259, 264, 204, 235, 241, 279,  12,\n",
       "        247, 149, 107,  51, 105, 253, 278,  80, 240, 297, 298,  24, 286,  31,\n",
       "        248,  59,  18,  54, 263, 132, 219, 252, 269, 126, 261, 258, 296, 108,\n",
       "         10, 141, 222,  41, 274, 233, 249,  72,   5, 148,  16, 115, 213, 251,\n",
       "        207,   0, 129,   9])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_idx = torch.topk(significance, k=h)[1]\n",
    "topk_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_neurons_from_model(model, importance, num_prune):\n",
    "    N = model[0].centers.shape[0]\n",
    "    topk_idx = torch.topk(significance, k=N-num_prune, largest=True)[1]\n",
    "    \n",
    "    c = model[0].centers.data[topk_idx]\n",
    "    v = model[-1].weight.data[:,topk_idx]\n",
    "    s = model[0].scaler.data[:,topk_idx]\n",
    "    model[0].centers.data = c\n",
    "    model[-1].weight.data = v\n",
    "    model[0].scaler.data = s\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_neurons_from_model(model, significance, N_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.179 | Acc: 65.840 6584/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(65.84, 70.09, 69.35)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc3 = test(0, model)\n",
    "test_acc3, test_acc2, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do this in Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_neurons_to_model(model, *get_random_training_samples(N_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance = torch.zeros(model[0].centers.shape[0])\n",
    "\n",
    "forw_hook = model[0].register_forward_hook(capture_outputs)\n",
    "back_hook = model[0].register_backward_hook(capture_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in train_loader:\n",
    "    xx = xx.to(device).view(-1, 28*28)\n",
    "    yout = model(xx)\n",
    "    \n",
    "    none_grad()\n",
    "    \n",
    "#     grad = torch.randn_like(yout)\n",
    "#     grad = grad/torch.norm(grad, dim=1, keepdim=True)\n",
    "#     yout.backward(gradient=grad)\n",
    "    \n",
    "    criterion(yout, yy).backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        significance += torch.sum((outputs*gradients)**2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_hook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_neurons_from_model(model, significance, N_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.634 | Acc: 57.200 5720/10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57.2, 70.09, 69.35)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc3 = test(0, model)\n",
    "test_acc3, test_acc2, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdasd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-efb445db9a2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masdasd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'asdasd' is not defined"
     ]
    }
   ],
   "source": [
    "asdasd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
