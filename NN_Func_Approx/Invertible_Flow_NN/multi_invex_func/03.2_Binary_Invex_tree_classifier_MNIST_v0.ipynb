{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nflib\n",
    "from nflib.flows import SequentialFlow, NormalizingFlow, ActNorm, AffineConstantFlow\n",
    "import nflib.coupling_flows as icf\n",
    "import nflib.inn_flow as inn\n",
    "import nflib.res_flow as irf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtnnlib as dtnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mylibrary.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.FashionMNIST()\n",
    "# mnist.download_mnist()\n",
    "# mnist.save_mnist()\n",
    "train_data, train_label_, test_data, test_label_ = mnist.load()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "# train_label = tnn.Logits.index_to_logit(train_label_)\n",
    "train_size = len(train_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting data to pytorch format\n",
    "train_data = torch.Tensor(train_data)\n",
    "test_data = torch.Tensor(test_data)\n",
    "train_label = torch.LongTensor(train_label_)\n",
    "test_label = torch.LongTensor(test_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "#         self._shuffle_data_()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "#     def _shuffle_data_(self):\n",
    "#         randidx = random.sample(range(len(self.data)), k=len(self.data))\n",
    "#         self.data = self.data[randidx]\n",
    "#         self.label = self.label[randidx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, lbl = self.data[idx], self.label[idx]\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subset_Dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, index):\n",
    "        self.data = dataset.data\n",
    "        self.label = dataset.label\n",
    "        self.index = index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.index[idx]\n",
    "        img, lbl = self.data[idx], self.label[idx]\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST_Dataset(train_data, train_label)\n",
    "test_dataset = MNIST_Dataset(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0003\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(dataset=train_dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, num_workers=4, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_Softmax(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.linear = nn.Linear(input_dim, num_sets)\n",
    "        self.linear.bias.data *= 0\n",
    "        self.linear.weight.data *= 0.1\n",
    "        self.cls_weight = nn.Parameter(torch.ones(num_sets, output_dim)/output_dim)\n",
    "        self.cls_confidence = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hard=True):\n",
    "        x = self.linear(x)\n",
    "        if hard:\n",
    "            x = torch.softmax(-x*1e5, dim=1)\n",
    "        else:\n",
    "            x = torch.softmax(-x*self.inv_temp, dim=1)\n",
    "        self.cls_confidence = x\n",
    "        c = torch.softmax(self.cls_weight, dim=1)\n",
    "#         c = self.cls_weight\n",
    "        return x@c ## since both are normalized, it is also normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedClassifier_SoftKMeans(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, num_sets, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_sets = num_sets\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "        \n",
    "        self.dt = dtnn.DistanceTransformBase(784, num_sets)\n",
    "        \n",
    "        ## uniform values for all class\n",
    "        init_val = torch.ones(num_sets, output_dim)/output_dim\n",
    "\n",
    "        ## class repeat sequentially\n",
    "#         init_val = torch.randn(num_sets, output_dim)*0.01\n",
    "#         for ns in range(num_sets):\n",
    "#             init_val[ns, ns%output_dim] = 10.\n",
    "        \n",
    "        self.cls_weight = nn.Parameter(init_val)\n",
    "\n",
    "        self.cls_confidence = None\n",
    "        \n",
    "        self.move_loss = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "#         self.cls_weight.data = torch.abs(self.cls_weight.data/self.cls_weight.data.sum(dim=1, keepdim=True))\n",
    "        \n",
    "        x_ = x[:, :self.input_dim]\n",
    "        dists = self.dt(x_)\n",
    "        dists = dists/np.sqrt(self.input_dim) ### correction to make diagonal of unit square 1 in nD space\n",
    "        \n",
    "        if hard:\n",
    "            x = torch.softmax(-dists*1e5, dim=1)\n",
    "        else:\n",
    "            x = torch.softmax(-dists*self.inv_temp, dim=1)\n",
    "        \n",
    "        self.cls_confidence = x\n",
    "        c = torch.softmax(self.cls_weight, dim=1)\n",
    "#         c = self.cls_weight\n",
    "        return x@c ## since both are normalized, it is also normalized\n",
    "    \n",
    "    def set_centroid_to_data_randomly(self, data_loader, model):\n",
    "        indices = np.random.permutation(len(data_loader.dataset.data))[:self.dt.centers.shape[0]]\n",
    "        xx = data_loader.dataset.data[indices].to(self.dt.centers.device)\n",
    "        yy = data_loader.dataset.label[indices].to(self.dt.centers.device)\n",
    "        yout = model(xx)\n",
    "        self.dt.centers.data = yout\n",
    "        \n",
    "        init_val = torch.ones(self.num_sets, self.output_dim)/self.output_dim\n",
    "        for ns in range(len(indices)):\n",
    "            init_val[ns, yy[ns]] = 10.\n",
    "        self.cls_weight.data = init_val.to(self.cls_weight.device)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ST_Sigmoid(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        zz = 1/(1+torch.exp(-x))\n",
    "        ctx.save_for_backward(zz)\n",
    "        \n",
    "        output = (x>0).type(x.dtype)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        zz, = ctx.saved_tensors\n",
    "        grad_x = None\n",
    "        \n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_x = zz*(1-zz)*grad_output\n",
    "\n",
    "        return grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceBinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.centers = nn.Parameter(torch.rand(1, input_dim)*2-1)\n",
    "        self.bias = nn.Parameter(torch.ones(1)*-0.5)\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "\n",
    "#         self.actf = nn.Sigmoid()\n",
    "        self.actf = ST_Sigmoid.apply\n",
    "        self.class_val = nn.Parameter(torch.ones(2, output_dim)*0.5) ## [index: 0 = pos, 1 = neg]\n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "        self.class_val.data.abs_()\n",
    "        self.class_val.data = self.class_val.data/self.class_val.data.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        x = torch.norm(x-self.centers, dim=1, keepdim=True) + self.bias\n",
    "        if hard:\n",
    "            x = torch.sigmoid(-x*1e5)\n",
    "        else:\n",
    "            x = self.actf(-x*torch.exp(self.inv_temp))\n",
    "            \n",
    "        self.confidence = x\n",
    "        x = x*self.class_val[:1] + (1-x)*self.class_val[1:]\n",
    "        return x\n",
    "    \n",
    "    def set_centroid_to_data_randomly(self, data_loader, model):\n",
    "        index = np.random.randint(len(data_loader.dataset.data))\n",
    "        xx = data_loader.dataset.data[index:index+1].to(self.centers.device)\n",
    "        yy = data_loader.dataset.label[index:index+1].to(self.centers.device)\n",
    "        yout = model(xx)\n",
    "        \n",
    "        self.centers.data = yout\n",
    "        \n",
    "        init_val = torch.ones(self.output_dim)/self.output_dim\n",
    "        init_val[yy[0]] = 1.\n",
    "        self.class_val.data[0] = init_val.to(self.class_val.device)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtnnlib import StereographicTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StereographicBinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, inv_temp=1):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.linear = StereographicTransform(input_dim, 1, bias=True)\n",
    "        self.inv_temp = nn.Parameter(torch.ones(1)*inv_temp)\n",
    "\n",
    "#         self.actf = nn.Sigmoid()\n",
    "        self.actf = ST_Sigmoid.apply\n",
    "        self.class_val = nn.Parameter(torch.ones(2, output_dim)*0.5) ## [index: 0 = pos, 1 = neg]\n",
    "        \n",
    "    def forward(self, x, hard=False):\n",
    "        self.class_val.data.abs_()\n",
    "        self.class_val.data = self.class_val.data/self.class_val.data.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        if hard:\n",
    "            x = torch.sigmoid(x*1e5)\n",
    "        else:\n",
    "            x = self.actf(x*torch.exp(self.inv_temp))\n",
    "            \n",
    "        self.confidence = x\n",
    "        x = x*self.class_val[:1] + (1-x)*self.class_val[1:]\n",
    "        return x\n",
    "    \n",
    "    def set_centroid_to_data_randomly(self, data_loader, model):\n",
    "        index = np.random.randint(len(data_loader.dataset.data))\n",
    "        xx = data_loader.dataset.data[index:index+1].to(self.class_val.device)\n",
    "        yy = data_loader.dataset.label[index:index+1].to(self.class_val.device)\n",
    "        yout = model(xx)\n",
    "        \n",
    "        x = yout\n",
    "        x = x*self.linear.inp_scaler\n",
    "        sqnorm = (x**2).sum(dim=1, keepdim=True) ## l2 norm squared\n",
    "        x = x*2/(sqnorm+1)\n",
    "        new_dim = (sqnorm-1)/(sqnorm+1)\n",
    "        x = torch.cat((x, new_dim), dim=1)\n",
    "        \n",
    "        self.linear.linear.weight.data = x\n",
    "        \n",
    "#         init_val = torch.ones(self.output_dim)/self.output_dim\n",
    "#         init_val[yy[0]] = 1.\n",
    "#         self.class_val.data[0] = init_val.to(self.class_val.device)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = DistanceBinaryClassifier(784, 10, inv_temp=1.)\n",
    "classifier = StereographicBinaryClassifier(784, 10, inv_temp=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = iter(train_loader).next()[0][:5]\n",
    "yout = classifier(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "actf = irf.Swish\n",
    "flows = [\n",
    "    ActNorm(784),\n",
    "    irf.ResidualFlow(784, [784], activation=actf),\n",
    "    ActNorm(784),\n",
    "    irf.ResidualFlow(784, [784], activation=actf),\n",
    "    ActNorm(784),\n",
    "        ]\n",
    "\n",
    "model = SequentialFlow(flows)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Sequential(nn.Linear(784, 784, bias=False),\n",
    "#                       nn.BatchNorm1d(784),\n",
    "#                       nn.SELU(),\n",
    "#                       nn.Linear(784, 784, bias=False),\n",
    "#                       nn.BatchNorm1d(784),\n",
    "#                       nn.SELU(),\n",
    "#                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialFlow(\n",
       "  (flows): ModuleList(\n",
       "    (0): ActNorm()\n",
       "    (1): ResidualFlow(\n",
       "      (resblock): ModuleList(\n",
       "        (0): Linear(in_features=784, out_features=784, bias=True)\n",
       "        (1): Swish()\n",
       "        (2): Linear(in_features=784, out_features=784, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ActNorm()\n",
       "    (3): ResidualFlow(\n",
       "      (resblock): ModuleList(\n",
       "        (0): Linear(in_features=784, out_features=784, bias=True)\n",
       "        (1): Swish()\n",
       "        (2): Linear(in_features=784, out_features=784, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ActNorm()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = ConnectedClassifier_SoftKMeans(784, 100, 10)\n",
    "# classifier = ConnectedClassifier_Softmax(784, 10, 10)\n",
    "# classifier = DistanceBinaryClassifier(784, 10, inv_temp=1.)\n",
    "classifier = StereographicBinaryClassifier(784, 10, inv_temp=1.)\n",
    "classifier = classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.set_centroid_to_data_randomly(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSEClassificationLoss(output, target):\n",
    "    zeros = torch.zeros_like(output)\n",
    "    zeros[range(len(target)), target] = 1\n",
    "    return nn.functional.mse_loss(output, zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params:  2466466\n"
     ]
    }
   ],
   "source": [
    "# criterion = nn.NLLLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "criterion = MSEClassificationLoss\n",
    "\n",
    "optimizer = optim.Adam(list(model.parameters())+list(classifier.parameters()),\n",
    "                       lr=0.0003)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in model.parameters():\n",
    "#     print(torch.isnan(p).type(torch.float32).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 784])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = iter(test_loader).next()[0]\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1100, -0.1043,  0.0157,  ...,  0.0633,  0.0709,  0.0281],\n",
       "        [ 0.1223, -0.0137,  0.0715,  ...,  0.0541,  0.0100, -0.0355],\n",
       "        [-0.0027,  0.0780,  0.0240,  ..., -0.0418, -0.0125,  0.0831],\n",
       "        ...,\n",
       "        [-0.0391,  0.0216, -0.0194,  ..., -0.0229,  0.0148,  0.0838],\n",
       "        [ 0.0419, -0.0427, -0.0124,  ...,  0.0515,  0.0343, -0.0059],\n",
       "        [ 0.0094,  0.0329,  0.0004,  ..., -0.0092, -0.0090, -0.0079]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xx.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:08<00:00, 17.60it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0:0,  Loss:0.08264584094285965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 71.54it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:18.46%, Test Acc:19.81%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 174/1200 [00:10<01:00, 16.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-58a0b28734d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0myout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0myout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Artificial_Intelligence/Notebooks/Experimentals/NN_Func_Approx/Invertible_Flow_NN/multi_invex_func/nflib/flows.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, logDetJ)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogDetJ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_yes_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlogDetJ\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_no_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogDetJ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Artificial_Intelligence/Notebooks/Experimentals/NN_Func_Approx/Invertible_Flow_NN/multi_invex_func/nflib/flows.py\u001b[0m in \u001b[0;36m_forward_no_logDetJ\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_no_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Artificial_Intelligence/Notebooks/Experimentals/NN_Func_Approx/Invertible_Flow_NN/multi_invex_func/nflib/res_flow.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, logDetJ)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverse_yes_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlogDetJ\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverse_no_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_yes_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlogDetJ\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_no_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogDetJ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Artificial_Intelligence/Notebooks/Experimentals/NN_Func_Approx/Invertible_Flow_NN/multi_invex_func/nflib/res_flow.py\u001b[0m in \u001b[0;36m_forward_no_logDetJ\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m### if linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m### if activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 self._forward_pre_hooks.values()):\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/nn/utils/spectral_norm.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, module, inputs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_power_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_solve_v_and_rescale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/nn/utils/spectral_norm.py\u001b[0m in \u001b[0;36mcompute_weight\u001b[0;34m(self, module, do_power_iteration)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0;31m# This power iteration produces approximations of `u` and `v`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_power_iterations\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0;31m# See above on why we need to clone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "EPOCHS = 3\n",
    "\n",
    "index = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "    for xx, yy in tqdm(train_loader):\n",
    "        xx, yy = xx.to(device), yy.to(device)\n",
    "        \n",
    "        yout = model(xx)\n",
    "        yout = classifier(yout)    \n",
    "        loss = criterion(yout, yy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(float(loss))\n",
    "\n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        train_acc += correct\n",
    "        train_count += len(outputs)\n",
    "\n",
    "    train_accs.append(float(train_acc)/train_count*100)\n",
    "    train_acc = 0\n",
    "    train_count = 0\n",
    "\n",
    "    print(f'Epoch: {epoch}:{index},  Loss:{float(loss)}')\n",
    "    test_count = 0\n",
    "    test_acc = 0\n",
    "    for xx, yy in tqdm(test_loader):\n",
    "        xx, yy = xx.to(device), yy.to(device)\n",
    "        with torch.no_grad():\n",
    "            yout = classifier(model(xx))    \n",
    "        outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "        correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "        test_acc += correct\n",
    "        test_count += len(xx)\n",
    "    test_accs.append(float(test_acc)/test_count*100)\n",
    "    print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "    print()\n",
    "\n",
    "### after each class index is finished training\n",
    "print(f'\\t-> Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.5331], requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.inv_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard test accuracy with count per classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 53.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Test Acc:18.66%\n",
      "[2465, 7535]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "test_acc = 0\n",
    "set_count = torch.zeros(2).to(device)\n",
    "for xx, yy in tqdm(test_loader):\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    with torch.no_grad():\n",
    "        yout = classifier(model(xx), hard=True)\n",
    "        count = (classifier.confidence > 0.5).type(torch.long).sum()\n",
    "        set_count[0] += count\n",
    "        set_count[1] += len(classifier.confidence) - count\n",
    "        \n",
    "    outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "    test_acc += correct\n",
    "    test_count += len(xx)\n",
    "\n",
    "print(f'Hard Test Acc:{float(test_acc)/test_count*100:.2f}%')\n",
    "print(set_count.type(torch.long).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard train accuracy with count per classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:22<00:00, 54.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Test Acc:18.74%\n",
      "[14717, 45283]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "test_acc = 0\n",
    "set_count = torch.zeros(2).to(device)\n",
    "for xx, yy in tqdm(train_loader):\n",
    "    xx, yy = xx.to(device), yy.to(device)\n",
    "    with torch.no_grad():\n",
    "        yout = classifier(model(xx), hard=True)\n",
    "        count = (classifier.confidence > 0.5).type(torch.long).sum()\n",
    "        set_count[0] += count\n",
    "        set_count[1] += len(classifier.confidence) - count\n",
    "        \n",
    "    outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "    correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "    test_acc += correct\n",
    "    test_count += len(xx)\n",
    "\n",
    "print(f'Hard Test Acc:{float(test_acc)/test_count*100:.2f}%')\n",
    "print(set_count.type(torch.long).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 7])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### classifier with class representation\n",
    "torch.argmax(classifier.class_val, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdfsdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-80a679df1217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masdfsdf\u001b[0m \u001b[0;31m## to break the code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'asdfsdf' is not defined"
     ]
    }
   ],
   "source": [
    "asdfsdf ## to break the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto : Iterative Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree structure for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierTree:\n",
    "    \n",
    "    def __init__(self, train_data, test_data, device):\n",
    "        self.root = LocalClassifier(device)\n",
    "        self.root.create_network_0(784, [784, 784], 10)\n",
    "        \n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.device = device\n",
    "        pass\n",
    "    \n",
    "    def display_stats(self):\n",
    "        indexing = \"0\"\n",
    "        self.root.display_stats(indexing)\n",
    "        acc, tot = self.root.get_correct_train()\n",
    "        train_acc = acc/tot\n",
    "        acc, tot = self.root.get_correct_test()\n",
    "        test_acc = acc/tot\n",
    "        print(f\"Final Accuracy is Train: {train_acc :.5f} Test: {test_acc :.5f}\")\n",
    "            \n",
    "    def get_parent_node(self, index_list:list):\n",
    "        parent = self.root\n",
    "        index_list = index_list[1:]\n",
    "        for idx in index_list[:-1]:\n",
    "            parent = parent.children[idx]\n",
    "        return parent\n",
    "    \n",
    "    def get_node(self, index_list:list):\n",
    "        parent = self.root\n",
    "        index_list = index_list[1:]\n",
    "        for idx in index_list[:-1]:\n",
    "            parent = parent.children[idx]\n",
    "        child = parent.children[index_list[-1]]\n",
    "        return child\n",
    "    \n",
    "    def get_all_child_index(self):\n",
    "        child_list = []\n",
    "        self.root.get_all_index([0], child_list)\n",
    "        return child_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leaf node for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "    def __init__(self):\n",
    "        self.pred = None\n",
    "        self.classes = None\n",
    "        self.num_correct = None\n",
    "        self.train_indices = None\n",
    "        self.test_indices = None\n",
    "        self.test_correct = None\n",
    "        \n",
    "    def display_stats(self, indexing):\n",
    "        if len(self.train_indices)>0:\n",
    "            train_acc = self.num_correct/len(self.train_indices)\n",
    "        else:\n",
    "            train_acc = -1\n",
    "            \n",
    "        \n",
    "        print(f\"[{indexing}] : Train -> {train_acc :.4f}\", end=\" \")\n",
    "        \n",
    "        if len(self.test_indices)>0:\n",
    "            test_acc = self.test_correct/len(self.test_indices)\n",
    "        else:\n",
    "            test_acc = -1\n",
    "        print(f\"Test -> {test_acc :.4f}, NUM: {len(self.train_indices)}, classes: {self.pred}:{self.classes}\")\n",
    "\n",
    "    def get_correct_train(self):\n",
    "        return self.num_correct, len(self.train_indices)\n",
    "    \n",
    "    def get_correct_test(self):\n",
    "        return self.test_correct, len(self.test_indices)\n",
    "    \n",
    "    def get_all_index(self, indexing, indx_lst):\n",
    "        indx_lst.append(indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalClassifier:\n",
    "    \n",
    "    def __init__(self, device):\n",
    "        self.model = None\n",
    "        self.classifier = None\n",
    "        self.device = device\n",
    "        \n",
    "        ### for training purposes\n",
    "        self.train_loader = None\n",
    "        self.test_loader = None\n",
    "        self.optimizer = None\n",
    "        self.frozen = False\n",
    "        self.criterion = None\n",
    "        \n",
    "        ### after freazing the model, record stats\n",
    "        self.children = []\n",
    "    \n",
    "    def create_network_0(self, input_dim, hidden_dims:list, output_dims):\n",
    "        actf = irf.Swish\n",
    "        flows = []\n",
    "        flows.append(ActNorm(input_dim))\n",
    "        for i in range(len(hidden_dims)):\n",
    "            if isinstance(hidden_dims[i], list):\n",
    "                hdi = hidden_dims[i]\n",
    "            else:\n",
    "                hdi = [hidden_dims[i]]\n",
    "            flows.append(irf.ResidualFlow(input_dim, hdi, activation=actf))\n",
    "            flows.append(ActNorm(input_dim))\n",
    "        \n",
    "        invertible = SequentialFlow(flows)\n",
    "        \n",
    "#         actf = nn.SELU\n",
    "#         flows = []\n",
    "#         hidden_dims = [input_dim]+hidden_dims\n",
    "#         for i in range(1, len(hidden_dims)):\n",
    "#             flows.append(nn.Linear(hidden_dims[i-1], hidden_dims[i]))\n",
    "#             flows.append(actf())\n",
    "#         flows.append(nn.Linear(hidden_dims[-1], input_dim))\n",
    "#         invertible = nn.Sequential(*flows)\n",
    "\n",
    "        self.model = invertible.to(device)\n",
    "#         classifier = DistanceBinaryClassifier(input_dim, output_dims)\n",
    "        classifier = StereographicBinaryClassifier(input_dim, output_dims)\n",
    "        self.classifier = classifier.to(device)\n",
    "        \n",
    "    def create_train_loader_1(self, train_dataset, index, batch_size):\n",
    "        dataset = Subset_Dataset(train_dataset, index)\n",
    "        print(f\"Train Dataset Num: {len(index)}\")\n",
    "        self.train_loader = data.DataLoader(dataset=dataset,\n",
    "                                            num_workers=4, \n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True)\n",
    "        self.classifier.set_centroid_to_data_randomly(self.train_loader, self.model)\n",
    "    \n",
    "    def create_test_loader_2(self, test_dataset, index, batch_size):\n",
    "        dataset = Subset_Dataset(test_dataset, index)\n",
    "        print(f\"Test Dataset Num: {len(index)}\")\n",
    "        self.test_loader = data.DataLoader(dataset=dataset,\n",
    "                                            num_workers=4, \n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=False)\n",
    "        \n",
    "    def create_optimizer_3(self, lr):\n",
    "        self.optimizer = optim.Adam(list(self.model.parameters())+list(self.classifier.parameters()), \n",
    "                                    lr=lr)\n",
    "        self.criterion = MSEClassificationLoss\n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        \n",
    "        \n",
    "    def train_classifier_4(self, epochs, ):\n",
    "        if self.frozen:\n",
    "            raise ValueError(\"This classifier is frozen. Training it might cause errors in childern classifiers\")\n",
    "            \n",
    "    ############# TRAINING FUNCTIONALITY BELOW ####################    \n",
    "        train_accs, test_accs = [], []\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            classifier.train()\n",
    "            train_acc = 0\n",
    "            train_count = 0\n",
    "            for xx, yy in tqdm(self.train_loader):\n",
    "                xx, yy = xx.to(device), yy.to(device)\n",
    "\n",
    "                yout = self.model(xx)\n",
    "                yout = self.classifier(yout)    \n",
    "                loss = self.criterion(yout, yy)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "                correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "                train_acc += correct\n",
    "                train_count += len(outputs)\n",
    "\n",
    "            train_accs.append(float(train_acc)/train_count*100)\n",
    "            train_acc = 0\n",
    "            train_count = 0\n",
    "\n",
    "            print(f'Epoch: {epoch},  Loss:{float(loss)}')\n",
    "            test_count = 0\n",
    "            test_acc = 0\n",
    "            for xx, yy in tqdm(self.test_loader):\n",
    "                xx, yy = xx.to(device), yy.to(device)\n",
    "                with torch.no_grad():\n",
    "                    yout = self.classifier(self.model(xx))    \n",
    "                outputs = torch.argmax(yout, dim=1).data.cpu().numpy()\n",
    "                correct = (outputs == yy.data.cpu().numpy()).astype(float).sum()\n",
    "                test_acc += correct\n",
    "                test_count += len(xx)\n",
    "            test_accs.append(float(test_acc)/test_count*100)\n",
    "            print(f'Train Acc:{train_accs[-1]:.2f}%, Test Acc:{test_accs[-1]:.2f}%')\n",
    "            print()\n",
    "        ### after each class index is finished training\n",
    "        print(f'\\t-> MAX Train Acc {max(train_accs)} ; Test Acc {max(test_accs)}')\n",
    "        \n",
    "        \n",
    "    def freeze_and_compute_stats_5(self, MIN_POINTS):\n",
    "        assert MIN_POINTS > 0\n",
    "        if self.frozen:\n",
    "            raise ValueError(\"This classifier is frozen. The stat has already been calculated\")\n",
    "            \n",
    "#         self.frozen = True\n",
    "        ### delete optimizer, frees memory\n",
    "#         del self.optimizer\n",
    "\n",
    "        ### take classifier to eval mode\n",
    "        self.model.eval()\n",
    "        self.classifier.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "#             #### remove classifier with no data or few data.\n",
    "#             set_count = torch.zeros(2).to(device)\n",
    "#             for xx, yy in tqdm(train_loader):\n",
    "#                 xx, yy = xx.to(device), yy.to(device)\n",
    "#                 yout = classifier(model(xx), hard=True)\n",
    "#                 count = (classifier.confidence > 0.5).type(torch.long).sum()\n",
    "#                 set_count[0] += count\n",
    "#                 set_count[1] += len(classifier.confidence) - count\n",
    "\n",
    "#             #### find only the classifier having some data\n",
    "#             classifier_index = [0, 1]\n",
    "#             classifier_count = set_count.type(torch.long).tolist()\n",
    "# #             if set_count[0] < MIN_POINTS or set_count[1] < MIN_POINTS:\n",
    "# #                 ### end the freezing and ignore this training\n",
    "\n",
    "            ###### compute stats now, from pruned tree.\n",
    "            def get_Cs_Os_Ts_Zs(data_loader):\n",
    "                Cs = [] ## winning classifier\n",
    "                Os = [] ## output of winning classifier\n",
    "                Ts = [] ## target class\n",
    "                Zs = []\n",
    "\n",
    "                for xx, yy in data_loader:\n",
    "                    Ts.append(yy)\n",
    "                    xx, yy = xx.to(device), yy.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        zz = self.model(xx)\n",
    "                        Zs.append(zz.data.cpu())\n",
    "                        yout = self.classifier(zz, hard=True)\n",
    "                        Os.append(torch.argmax(yout, dim=1).data.cpu())\n",
    "\n",
    "                    cls_indx = (self.classifier.confidence > 0.5).type(torch.long).reshape(-1)\n",
    "                    Cs.append(cls_indx)\n",
    "\n",
    "                Cs = torch.cat(Cs, dim=0)\n",
    "                Ts = torch.cat(Ts, dim=0)\n",
    "                Os = torch.cat(Os, dim=0)\n",
    "                Zs = torch.cat(Zs, dim=0)\n",
    "                return Cs, Ts, Os, Zs\n",
    "\n",
    "\n",
    "            unshuffled_data = data.DataLoader(dataset=self.train_loader.dataset,\n",
    "                                                num_workers=4, \n",
    "                                                batch_size=self.train_loader.batch_size, \n",
    "                                                shuffle=False)\n",
    "            Cs, Ts, Os, Zs = get_Cs_Os_Ts_Zs(unshuffled_data)\n",
    "            _Cs, _Ts, _, _Zs = get_Cs_Os_Ts_Zs(self.test_loader)\n",
    "\n",
    "            print(\"Hard inference on the data !\")\n",
    "            self.children = []\n",
    "            acc = 0\n",
    "            for cls_idx in range(2):\n",
    "                data_idx = torch.nonzero(Cs == cls_idx)\n",
    "                Ti = Ts[data_idx]\n",
    "#                 print(Ti)\n",
    "                ### get prediction according to data\n",
    "                cls, count = torch.unique(Ti, return_counts=True, sorted=True)\n",
    "                if len(count) > 0:\n",
    "                    pred = cls[torch.argmax(count)]\n",
    "                else:\n",
    "                    pred = self.classifier.class_val[cls_idx].argmax()\n",
    "                p = (Ti==pred).type(torch.float32).sum()\n",
    "                acc += p\n",
    "\n",
    "                child = LeafNode()\n",
    "                child.pred = int(pred)\n",
    "                child.classes = cls.tolist()\n",
    "                child.num_correct = int(p)\n",
    "                child.train_indices = data_idx.cpu().reshape(-1)\n",
    "                \n",
    "                test_idx = torch.nonzero(_Cs == cls_idx)\n",
    "                test_p = (_Ts[test_idx]==pred).type(torch.float32).sum()\n",
    "                child.test_indices = test_idx.cpu().reshape(-1)\n",
    "                child.test_correct = int(test_p)\n",
    "\n",
    "                self.children.append(child)\n",
    "\n",
    "                print(f\"idx: {cls_idx}\\tout: {int(pred)} \\t acc: {p/len(Ti)*100 :.3f} \\tclasses:{cls.tolist()}\")\n",
    "            \n",
    "            accuracy = float(acc)/len(Ts)\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "        return accuracy#, (Zs, Ts, _Zs, _Ts)\n",
    "        \n",
    "        \n",
    "    def display_stats(self, indexing):\n",
    "        for i, c in enumerate(self.children):\n",
    "            c.display_stats(indexing+f\", {i}\")\n",
    "            \n",
    "    def get_all_index(self, indexing:list, indx_lst):\n",
    "        for i, c in enumerate(self.children):\n",
    "            c.get_all_index(indexing+[i], indx_lst)\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def get_correct_train(self):\n",
    "        a, b = 0, 0\n",
    "        for i, c in enumerate(self.children):\n",
    "            _a, _b = c.get_correct_train()\n",
    "            a+= _a\n",
    "            b+= _b\n",
    "        return a, b\n",
    "    \n",
    "    def get_correct_test(self):\n",
    "        a, b = 0, 0\n",
    "        for i, c in enumerate(self.children):\n",
    "            _a, _b = c.get_correct_test()\n",
    "            a+= _a\n",
    "            b+= _b\n",
    "        return a, b\n",
    "        \n",
    "    def inference_forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            zz = self.model(x)\n",
    "            yout = self.classifier(zz, hard=True)\n",
    "            return torch.argmax(classifier.cls_confidence, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ClassifierTree(train_dataset, test_dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.root.create_network_0(784, [784, 784], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialFlow(\n",
       "  (flows): ModuleList(\n",
       "    (0): ActNorm()\n",
       "    (1): ResidualFlow(\n",
       "      (resblock): ModuleList(\n",
       "        (0): Linear(in_features=784, out_features=784, bias=True)\n",
       "        (1): Swish()\n",
       "        (2): Linear(in_features=784, out_features=784, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ActNorm()\n",
       "    (3): ResidualFlow(\n",
       "      (resblock): ModuleList(\n",
       "        (0): Linear(in_features=784, out_features=784, bias=True)\n",
       "        (1): Swish()\n",
       "        (2): Linear(in_features=784, out_features=784, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ActNorm()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.root.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StereographicBinaryClassifier(\n",
       "  (linear): StereographicTransform(\n",
       "    (linear): Linear(in_features=785, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.root.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Num: 60000\n"
     ]
    }
   ],
   "source": [
    "tree.root.create_train_loader_1(train_dataset, \n",
    "                                torch.arange(0, len(train_dataset), dtype=torch.long), \n",
    "                                50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Num: 10000\n"
     ]
    }
   ],
   "source": [
    "tree.root.create_test_loader_2(test_dataset, \n",
    "                               torch.arange(0, len(test_dataset), dtype=torch.long), \n",
    "                               50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.root.create_optimizer_3(lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:12<00:00, 16.54it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0,  Loss:0.0799744725227356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 71.35it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.72%, Test Acc:19.99%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:37<00:00, 12.30it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1,  Loss:0.08179805427789688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 63.64it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.78%, Test Acc:19.98%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:12<00:00, 16.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2,  Loss:0.07908393442630768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 67.03it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:20.25%, Test Acc:19.99%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:12<00:00, 16.50it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3,  Loss:0.07965319603681564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 75.97it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:20.24%, Test Acc:20.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:08<00:00, 17.59it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4,  Loss:0.08153343200683594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 78.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.85%, Test Acc:19.99%\n",
      "\n",
      "\t-> MAX Train Acc 20.25 ; Test Acc 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tree.root.train_classifier_4(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard inference on the data !\n",
      "idx: 0\tout: 7 \t acc: 25.565 \tclasses:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "idx: 1\tout: 1 \t acc: 16.415 \tclasses:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Accuracy: 0.19993333333333332\n"
     ]
    }
   ],
   "source": [
    "acc = tree.root.freeze_and_compute_stats_5(MIN_POINTS=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] : Train -> 0.2556 Test -> 0.2562, NUM: 23466, classes: 7:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 1] : Train -> 0.1641 Test -> 0.1640, NUM: 36534, classes: 1:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Final Accuracy is Train: 0.19993 Test: 0.20000\n"
     ]
    }
   ],
   "source": [
    "tree.display_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tree.root.train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0], [0, 1]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.get_all_child_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_data = train_data.clone()\n",
    "_test_data = test_data.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Improvement over nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIN_POINTS = 10\n",
    "# batch_size = 50\n",
    "\n",
    "# ignore_nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################### SELECT WORST CLASSIFIER ##########################\n",
    "# max_incorrect = 0\n",
    "# max_inc_node = None\n",
    "# train_epoch = None\n",
    "# for ci in tree.get_all_child_index():\n",
    "#     if ci in ignore_nodes: continue\n",
    "\n",
    "#     node = tree.get_node(ci)\n",
    "#     num_data = len(node.train_indices)\n",
    "#     if num_data < MIN_POINTS: continue\n",
    "\n",
    "#     incorrect = num_data - node.num_correct\n",
    "#     if incorrect > max_incorrect:\n",
    "#         max_incorrect = incorrect\n",
    "#         max_inc_node = ci\n",
    "#         steps_in_epoch = max(num_data/batch_size, 1)\n",
    "#         train_epoch = max(int(3*1200/steps_in_epoch), 1)\n",
    "\n",
    "# print(f\"Max incorrect: {max_incorrect}, {max_inc_node}, train for: {train_epoch}\")\n",
    "\n",
    "# #################### SELECT WORST CLASSIFIER ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_POINTS = 100\n",
    "batch_size = 50\n",
    "\n",
    "priority_node_list = []\n",
    "notworking_node_list = []\n",
    "\n",
    "incorrect_attempts = 0\n",
    "global_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_epoch = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerun code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max incorrect: 3284, [0, 1, 0, 1, 1, 0], train for: 73\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### if node_list is empty, fill the list with order of incorrect elements\n",
    "## if node is found not improving, push it back in the end\n",
    "## if node is done improving, re-evaluate the priority:\n",
    "\n",
    "#################### SORT CLASSIFIER ##########################\n",
    "nodes = []\n",
    "incorrects = []\n",
    "for ci in child_indices:\n",
    "    if ci in notworking_node_list: continue\n",
    "\n",
    "    node = tree.get_node(ci)\n",
    "    num_data = len(node.train_indices)\n",
    "    if num_data < MIN_POINTS: \n",
    "        print(f\"{ci} node has num_data < MIN_POINTS ({num_data} < {MIN_POINTS})\")\n",
    "        print(f\"Ignoring !!\")\n",
    "        continue\n",
    "\n",
    "    incorrect = num_data - node.num_correct\n",
    "    nodes.append(ci)\n",
    "    incorrects.append(incorrect)\n",
    "\n",
    "incorrects, nodes = np.array(incorrects), np.array(nodes)\n",
    "max_inc_node = list(nodes[incorrects.argmax()])\n",
    "num_data = len(tree.get_node(max_inc_node).train_indices)\n",
    "#     print(num_data)\n",
    "print(f\"Max incorrect: {incorrects.max()}, {max_inc_node}, train for: {train_epoch}\")\n",
    "\n",
    "steps_in_epoch = max(num_data/batch_size, 1)\n",
    "train_epoch = max(int(global_epoch*1200/steps_in_epoch), 1)\n",
    "\n",
    "## sorting\n",
    "argsrt = np.argsort(incorrects)\n",
    "incorrects = incorrects[argsrt]\n",
    "nodes = nodes[argsrt]\n",
    "\n",
    "## setting initial value\n",
    "priority_node_list = nodes\n",
    "#################### SORT CLASSIFIER ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_inc_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0, 1, 1]), list([0, 0, 0]), list([0, 1, 0, 1, 1, 1, 1, 1]),\n",
       "       list([0, 1, 0, 1, 1, 1, 0]), list([0, 1, 0, 1, 1, 1, 1, 0]),\n",
       "       list([0, 1, 0, 1, 1, 0])], dtype=object)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] : Train -> 0.2536 Test -> 0.2401, NUM: 4400, classes: 9:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Train Dataset Num: 4400\n",
      "Test Dataset Num: 754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.63it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0,  Loss:0.08224451541900635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 34.31it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:17.73%, Test Acc:21.22%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.48it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1,  Loss:0.08102723956108093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 34.90it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.32%, Test Acc:19.36%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.95it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2,  Loss:0.08118180930614471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 35.28it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:20.80%, Test Acc:20.69%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.91it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3,  Loss:0.08030601590871811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 39.38it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:20.39%, Test Acc:19.36%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.85it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4,  Loss:0.08133258670568466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 35.83it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.73%, Test Acc:19.36%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.86it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5,  Loss:0.08049238473176956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 37.91it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.57%, Test Acc:18.30%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.83it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6,  Loss:0.08080817759037018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 38.44it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:18.89%, Test Acc:21.22%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 17.17it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7,  Loss:0.08283784985542297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 32.94it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.11%, Test Acc:21.22%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.65it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8,  Loss:0.08156988769769669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 37.35it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.18%, Test Acc:19.36%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.51it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9,  Loss:0.08060509711503983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 38.32it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:20.14%, Test Acc:18.83%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.57it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10,  Loss:0.08088590949773788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 33.52it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.07%, Test Acc:19.50%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 15.47it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11,  Loss:0.080392025411129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 34.28it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.43%, Test Acc:18.30%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 15.95it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12,  Loss:0.0832352489233017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 37.59it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.73%, Test Acc:19.36%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.08it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13,  Loss:0.07935439050197601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 36.07it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:18.89%, Test Acc:19.36%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.94it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14,  Loss:0.08050049096345901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 40.01it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.68%, Test Acc:20.95%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.91it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15,  Loss:0.07997022569179535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 39.68it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:18.77%, Test Acc:19.36%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 17.03it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16,  Loss:0.08224708586931229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 39.99it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.75%, Test Acc:19.36%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 17.11it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17,  Loss:0.08023353666067123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 35.64it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.77%, Test Acc:18.83%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 17.01it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18,  Loss:0.08237353712320328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 33.65it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.14%, Test Acc:20.69%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:05<00:00, 16.90it/s]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19,  Loss:0.0823611319065094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 36.75it/s]\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:19.89%, Test Acc:18.83%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 70/88 [00:04<00:01, 15.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-511e92d3a454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0malt_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_optimizer_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0malt_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_classifier_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-eeafb0a4eba7>\u001b[0m in \u001b[0;36mtrain_classifier_4\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0myout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0myout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Artificial_Intelligence/Notebooks/Experimentals/NN_Func_Approx/Invertible_Flow_NN/multi_invex_func/nflib/flows.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, logDetJ)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogDetJ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_yes_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlogDetJ\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_no_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogDetJ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Artificial_Intelligence/Notebooks/Experimentals/NN_Func_Approx/Invertible_Flow_NN/multi_invex_func/nflib/flows.py\u001b[0m in \u001b[0;36m_forward_no_logDetJ\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_no_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Artificial_Intelligence/Notebooks/Experimentals/NN_Func_Approx/Invertible_Flow_NN/multi_invex_func/nflib/res_flow.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, logDetJ)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverse_yes_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlogDetJ\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverse_no_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_yes_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlogDetJ\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_no_logDetJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogDetJ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Artificial_Intelligence/Notebooks/Experimentals/NN_Func_Approx/Invertible_Flow_NN/multi_invex_func/nflib/res_flow.py\u001b[0m in \u001b[0;36m_forward_no_logDetJ\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m### if linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m### if activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program_Files/Python/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#################### EXTEND SELECTED CLASSIFIER ##########################\n",
    "indx = max_inc_node\n",
    "parent = tree.get_parent_node(indx)\n",
    "node = tree.get_node(indx)\n",
    "prev_acc = node.num_correct / len(node.train_indices)\n",
    "node.display_stats(\"\")\n",
    "\n",
    "### make classifier with only available classes\n",
    "alt_node = LocalClassifier(device)\n",
    "avl_cls = node.classes\n",
    "num_cls = len(node.classes)\n",
    "output_dim = 10\n",
    "# num_sets = num_cls#*2\n",
    "# init_val = torch.randn(num_sets, output_dim)*0.01\n",
    "# for ns in range(num_sets):\n",
    "#     init_val[ns, avl_cls[ns%num_cls]] = 2.\n",
    "\n",
    "alt_node.create_network_0(784, [784, 784], output_dim)\n",
    "# alt_node.classifier.cls_weight.data = init_val.to(device)\n",
    "\n",
    "alt_node.create_train_loader_1(train_dataset, node.train_indices, batch_size=batch_size)\n",
    "alt_node.create_test_loader_2(test_dataset, node.test_indices, batch_size=batch_size)\n",
    "alt_node.create_optimizer_3(lr=0.003)\n",
    "\n",
    "alt_node.train_classifier_4(train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt_node.train_classifier_4(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard inference on the data !\n",
      "idx: 0\tout: 3 \t acc: 15.525 \tclasses:[0, 1, 2, 3, 4, 5, 6, 8]\n",
      "idx: 1\tout: 9 \t acc: 34.751 \tclasses:[5, 7, 8, 9]\n",
      "Accuracy: 0.2137796237478622\n"
     ]
    }
   ],
   "source": [
    "new_acc = alt_node.freeze_and_compute_stats_5(MIN_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_acc < prev_acc + 0.02:\n",
    "    notworking_node_list.append(max_inc_node)\n",
    "    print(\"New Node has lesser accuracy, ignoring !!!\")\n",
    "    incorrect_attempts += 1\n",
    "else:\n",
    "    ### replace the leaf node with Local Classifier Node\n",
    "    parent.children[indx[-1]] = alt_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reevaluate the importance\n",
    "child_indices = tree.get_all_child_index()\n",
    "if len(child_indices) <= len(notworking_node_list) :\n",
    "    print(\"Priority nodes all not working\")\n",
    "    ### priority nodes are all not working\n",
    "    ### reset the priority\n",
    "    notworking_node_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0] : Train -> 0.9735 Test -> 0.9722, NUM: 5477, classes: 8:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 0, 1] : Train -> 0.3331 Test -> 0.3327, NUM: 17989, classes: 9:[0, 1, 2, 3, 5, 6, 7, 8, 9]\n",
      "[0, 1, 0, 0] : Train -> 0.2582 Test -> 0.2545, NUM: 12033, classes: 5:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 1, 0, 1, 0] : Train -> 0.2510 Test -> 0.2568, NUM: 7497, classes: 7:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 1, 0, 1, 1, 0] : Train -> 0.2536 Test -> 0.2401, NUM: 4400, classes: 9:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 1, 0, 1, 1, 1, 0] : Train -> 0.2669 Test -> 0.2322, NUM: 2630, classes: 9:[0, 1, 4, 5, 6, 7, 8, 9]\n",
      "[0, 1, 0, 1, 1, 1, 1, 0] : Train -> 0.1553 Test -> 0.1241, NUM: 2847, classes: 3:[0, 1, 2, 3, 4, 5, 6, 8]\n",
      "[0, 1, 0, 1, 1, 1, 1, 1] : Train -> 0.3475 Test -> 0.3535, NUM: 1246, classes: 9:[5, 7, 8, 9]\n",
      "[0, 1, 1] : Train -> 0.9908 Test -> 0.9917, NUM: 5881, classes: 1:[0, 1, 2, 3, 4, 6, 8]\n",
      "Final Accuracy is Train: 0.41388 Test: 0.40720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## show stats of the current network\n",
    "#### After modification status\n",
    "tree.display_stats()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 0] : Train -> 0.2556 Test -> 0.2562, NUM: 23466, classes: 7:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0] : Train -> 0.1955 Test -> 0.1943, NUM: 30653, classes: 2:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 1] : Train -> 0.9908 Test -> 0.9917, NUM: 5881, classes: 1:[0, 1, 2, 3, 4, 6, 8]\n",
    "Final Accuracy is Train: 0.29698 Test: 0.29550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 0] : Train -> 0.2556 Test -> 0.2562, NUM: 23466, classes: 7:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 0] : Train -> 0.2582 Test -> 0.2545, NUM: 12033, classes: 5:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1] : Train -> 0.1665 Test -> 0.1563, NUM: 18620, classes: 6:[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "[0, 1, 1] : Train -> 0.9908 Test -> 0.9917, NUM: 5881, classes: 1:[0, 1, 2, 3, 4, 6, 8]\n",
    "Final Accuracy is Train: 0.30057 Test: 0.29550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 0, 0] : Train -> 0.9735 Test -> 0.9722, NUM: 5477, classes: 8:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 0, 1] : Train -> 0.3331 Test -> 0.3327, NUM: 17989, classes: 9:[0, 1, 2, 3, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 0] : Train -> 0.2582 Test -> 0.2545, NUM: 12033, classes: 5:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1] : Train -> 0.1665 Test -> 0.1563, NUM: 18620, classes: 6:[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "[0, 1, 1] : Train -> 0.9908 Test -> 0.9917, NUM: 5881, classes: 1:[0, 1, 2, 3, 4, 6, 8]\n",
    "Final Accuracy is Train: 0.38932 Test: 0.38290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 0, 0] : Train -> 0.9735 Test -> 0.9722, NUM: 5477, classes: 8:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 0, 1] : Train -> 0.3331 Test -> 0.3327, NUM: 17989, classes: 9:[0, 1, 2, 3, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 0] : Train -> 0.2582 Test -> 0.2545, NUM: 12033, classes: 5:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1, 0] : Train -> 0.2510 Test -> 0.2568, NUM: 7497, classes: 7:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1, 1] : Train -> 0.1703 Test -> 0.1555, NUM: 11123, classes: 6:[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "[0, 1, 1] : Train -> 0.9908 Test -> 0.9917, NUM: 5881, classes: 1:[0, 1, 2, 3, 4, 6, 8]\n",
    "Final Accuracy is Train: 0.40057 Test: 0.39490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 0, 0] : Train -> 0.9735 Test -> 0.9722, NUM: 5477, classes: 8:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 0, 1] : Train -> 0.3331 Test -> 0.3327, NUM: 17989, classes: 9:[0, 1, 2, 3, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 0] : Train -> 0.2582 Test -> 0.2545, NUM: 12033, classes: 5:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1, 0] : Train -> 0.2510 Test -> 0.2568, NUM: 7497, classes: 7:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1, 1, 0] : Train -> 0.2536 Test -> 0.2401, NUM: 4400, classes: 9:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1, 1, 1] : Train -> 0.1705 Test -> 0.1506, NUM: 6723, classes: 6:[0, 1, 2, 3, 4, 6, 8, 9]\n",
    "[0, 1, 1] : Train -> 0.9908 Test -> 0.9917, NUM: 5881, classes: 1:[0, 1, 2, 3, 4, 6, 8]\n",
    "Final Accuracy is Train: 0.40670 Test: 0.40070\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-169-427bb350984a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-169-427bb350984a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [0, 0, 0] : Train -> 0.9735 Test -> 0.9722, NUM: 5477, classes: 8:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[0, 0, 0] : Train -> 0.9735 Test -> 0.9722, NUM: 5477, classes: 8:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 0, 1] : Train -> 0.3331 Test -> 0.3327, NUM: 17989, classes: 9:[0, 1, 2, 3, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 0] : Train -> 0.2582 Test -> 0.2545, NUM: 12033, classes: 5:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1, 0] : Train -> 0.2510 Test -> 0.2568, NUM: 7497, classes: 7:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1, 1, 0] : Train -> 0.2536 Test -> 0.2401, NUM: 4400, classes: 9:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1, 1, 1, 0] : Train -> 0.2669 Test -> 0.2322, NUM: 2630, classes: 9:[0, 1, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1, 1, 1, 1] : Train -> 0.1705 Test -> 0.1526, NUM: 4093, classes: 6:[0, 1, 2, 3, 4, 6, 8]\n",
    "[0, 1, 1] : Train -> 0.9908 Test -> 0.9917, NUM: 5881, classes: 1:[0, 1, 2, 3, 4, 6, 8]\n",
    "Final Accuracy is Train: 0.41093 Test: 0.40440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 0, 0] : Train -> 0.9735 Test -> 0.9722, NUM: 5477, classes: 8:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 0, 1] : Train -> 0.3331 Test -> 0.3327, NUM: 17989, classes: 9:[0, 1, 2, 3, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 0] : Train -> 0.2582 Test -> 0.2545, NUM: 12033, classes: 5:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1, 0] : Train -> 0.2510 Test -> 0.2568, NUM: 7497, classes: 7:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1, 1, 0] : Train -> 0.2536 Test -> 0.2401, NUM: 4400, classes: 9:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1, 1, 1, 0] : Train -> 0.2669 Test -> 0.2322, NUM: 2630, classes: 9:[0, 1, 4, 5, 6, 7, 8, 9]\n",
    "[0, 1, 0, 1, 1, 1, 1, 0] : Train -> 0.1553 Test -> 0.1241, NUM: 2847, classes: 3:[0, 1, 2, 3, 4, 5, 6, 8]\n",
    "[0, 1, 0, 1, 1, 1, 1, 1] : Train -> 0.3475 Test -> 0.3535, NUM: 1246, classes: 9:[5, 7, 8, 9]\n",
    "[0, 1, 1] : Train -> 0.9908 Test -> 0.9917, NUM: 5881, classes: 1:[0, 1, 2, 3, 4, 6, 8]\n",
    "Final Accuracy is Train: 0.41388 Test: 0.40720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
