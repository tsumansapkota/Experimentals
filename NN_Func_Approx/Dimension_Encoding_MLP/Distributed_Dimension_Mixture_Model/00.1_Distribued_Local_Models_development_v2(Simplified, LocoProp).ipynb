{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os, sys, pathlib, random, time, pickle, copy, json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 147\n",
    "# SEED = 258\n",
    "# SEED = 369\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"../../../../_Datasets/FMNIST/\", train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 2000 #200\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BS, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BS, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## demo of train loader\n",
    "xx, yy = iter(train_loader).next()\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpBLock(nn.Module):\n",
    "    \n",
    "    def __init__(self, dims, actf=nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.dims = dims\n",
    "        #### convert hidden layers ratio to list if integer is inputted\n",
    "            \n",
    "        self.mlp = []\n",
    "        ### for 1 hidden layer, we iterate 2 times\n",
    "        for h in range(len(self.dims)-1):\n",
    "            i, o = int(self.dims[h]),\\\n",
    "                    int(self.dims[h+1])\n",
    "            self.mlp.append(nn.Linear(i, o))\n",
    "#             self.mlp.append(nn.BatchNorm1d(o))\n",
    "            self.mlp.append(\n",
    "                nn.Sequential(\n",
    "#                               nn.BatchNorm1d(o),\n",
    "                              nn.Dropout(p=0.1),\n",
    "                              nn.LayerNorm(o),\n",
    "                              actf(),\n",
    "                             )\n",
    "                            )\n",
    "        self.mlp = self.mlp[:-1]\n",
    "        \n",
    "        self.mlp = nn.Sequential(*self.mlp)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpBLock(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=3, bias=True)\n",
       "    (1): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2): Linear(in_features=3, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MlpBLock([2, 3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_edge(0, 1)\n",
    "G.add_edge(0, 2)\n",
    "G.add_edge(0, 3)\n",
    "G.add_edge(1, 4)\n",
    "G.add_edge(1, 5)\n",
    "G.add_edge(2, 5)\n",
    "G.add_edge(2, 6)\n",
    "G.add_edge(3, 6)\n",
    "G.add_edge(4, 7)\n",
    "G.add_edge(5, 7)\n",
    "G.add_edge(6, 7)\n",
    "G.add_edge(7, 8)\n",
    "G.add_edge(7, 9)\n",
    "G.add_edge(6, 9)\n",
    "G.add_edge(8, 10)\n",
    "G.add_edge(9, 10)\n",
    "G.add_edge(10, 11)\n",
    "\n",
    "\n",
    "# explicitly set positions\n",
    "pos = {0: (0, 1), \n",
    "       1: (1, 0), \n",
    "       2: (1, 1), \n",
    "       3: (1, 2), \n",
    "       4: (2, 0),\n",
    "       5: (2, 1),\n",
    "       6: (2.25, 2),\n",
    "       7: (3, 0.5),\n",
    "       8: (4, 0.5),\n",
    "       9: (4, 1.5),\n",
    "       10: (5, 1),\n",
    "       11: (6, 1),\n",
    "      }\n",
    "\n",
    "options = {\n",
    "    \"font_size\": 10,\n",
    "    \"node_size\": 300,\n",
    "    \"node_color\": \"white\",\n",
    "    \"edgecolors\": \"black\",\n",
    "    \"linewidths\": 2,\n",
    "    \"width\": 2,\n",
    "}\n",
    "nx.draw_networkx(G, pos, **options)\n",
    "\n",
    "# Set margins for the axes so that nodes aren't clipped\n",
    "ax = plt.gca()\n",
    "ax.margins(0.20)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeView([(0, 1), (0, 2), (0, 3), (1, 4), (1, 5), (2, 5), (2, 6), (3, 6), (4, 7), (5, 7), (6, 7), (6, 9), (7, 8), (7, 9), (8, 10), (9, 10), (10, 11)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(InDegreeView({0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 2, 6: 2, 7: 3, 8: 1, 9: 2, 10: 2, 11: 1}),\n",
       " OutDegreeView({0: 3, 1: 2, 2: 2, 3: 1, 4: 1, 5: 1, 6: 2, 7: 2, 8: 1, 9: 1, 10: 1, 11: 0}))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.in_degree(), G.out_degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutEdgeView([(0, 1), (0, 2), (0, 3), (1, 4), (1, 5), (2, 5), (2, 6), (3, 6), (4, 7), (5, 7), (6, 7), (6, 9), (7, 8), (7, 9), (8, 10), (9, 10), (10, 11)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.out_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InEdgeView([(0, 1), (0, 2), (0, 3), (1, 4), (1, 5), (2, 5), (2, 6), (3, 6), (4, 7), (5, 7), (6, 7), (7, 8), (7, 9), (6, 9), (8, 10), (9, 10), (10, 11)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.in_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Dimension-Mixer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `Local Models` are the basis for local training of models.\n",
    "2. `Local Models` have their own optimizer and communicate via low bandwidth connection.\n",
    "3. This experiment verifies if training local models reduces the number of forward and backward pass for reaching the solution.\n",
    "4. The main idea is to update local model multiple times and backproping the final gradient, rather than doing it one iteration (similar to higher order optimization ?? like 1.5-nd optimization)\n",
    "5. The optimal spectrum lies in between (Its like dynamic optimization, while doing inference with more communication between local models, far away models communicate less). There has been similar ideas otherwhere as well but not exactly. Its based on my own experiment using optimizer for find better gradient for global optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### temp herer\n",
    "xx = torch.randn(5, 3)\n",
    "dys = [torch.randn(5, 2), torch.randn(5,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedNode(abc.ABC):\n",
    "#     @abc.abstractmethod\n",
    "    def set_input_nodes(self, nodes):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "    def set_output_nodes(self, nodes):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "    def forward_local(self):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "    def backward_local(self):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "    def update_local(self):\n",
    "        pass\n",
    "    \n",
    "#     @abc.abstractmethod\n",
    "#     def train_loop(self, ):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalModel(DistributedNode):\n",
    "    \n",
    "    def __init__(self, model, lr=0.001, local_lr=0.003, local_updates=100):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "#         self.optimizer = None\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.local_lr = local_lr\n",
    "        self.local_updates = local_updates\n",
    "        \n",
    "        self.output_dim = model.dims[-1]\n",
    "        self.split_indices = None\n",
    "        \n",
    "        ### temporary state variables\n",
    "        self.input_received = []\n",
    "        self.input_shapes = []\n",
    "        self.output_shape = None\n",
    "        self.grad_received = None\n",
    "        ######## testing target\n",
    "        self.target = None\n",
    "        \n",
    "        #### For storing local variables\n",
    "        \n",
    "    def set_split_mixing_indices(self, split_sizes=None):\n",
    "        if split_sizes is None:\n",
    "            split_sizes = [self.output_dim, ]\n",
    "        ## split sizes added must be >= to input size\n",
    "        assert self.output_dim <= np.sum(split_sizes), \"split sizes are less than input dimension\"\n",
    "        for ss in split_sizes:\n",
    "            assert self.output_dim >= ss, \"split sizes are greater than input dimension\"\n",
    "            \n",
    "        \n",
    "        ## also do not use split sizes greater than input dimension\n",
    "        \n",
    "        indices = np.arange(0, self.output_dim, 1, dtype=int)\n",
    "        indices = np.random.permutation(indices)\n",
    "        \n",
    "        ## first divide input dimension into all splits\n",
    "        split_loc = split_sizes/np.sum(split_sizes)*self.output_dim\n",
    "        split_loc = split_loc.astype(int)\n",
    "        split_loc[0] += self.output_dim-split_loc.sum()\n",
    "        \n",
    "        index = np.split(indices, np.cumsum(split_loc[:-1]))\n",
    "        ## for extra input dimensions, sample randomly from remaining node indices.\n",
    "        for i in range(len(index)):\n",
    "            idx = index[i]\n",
    "            mask = np.ones(self.output_dim, dtype=bool)\n",
    "            mask[idx] = False\n",
    "            remaining = np.arange(0, self.output_dim, 1, dtype=int)[mask]\n",
    "            num_remain = split_sizes[i] - len(idx)\n",
    "            new_idx = remaining[np.random.permutation(len(remaining))[:num_remain]]\n",
    "            new_idx = np.array(new_idx)\n",
    "            \n",
    "            all_inx = np.concatenate((idx, new_idx))\n",
    "            index[i] = torch.LongTensor(all_inx)\n",
    "            pass\n",
    "        \n",
    "        self.split_indices = index\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def forward_local(self, xs):\n",
    "        ### concat received inputs\n",
    "        self.input_shapes = [xi.shape for xi in xs]\n",
    "        xs = torch.cat(xs, dim=1)\n",
    "        \n",
    "        self.input_received = xs.data\n",
    "\n",
    "        xs = self.model(xs)\n",
    "        self.output_shape = xs.shape\n",
    "        \n",
    "        ys = []\n",
    "        for si in self.split_indices:\n",
    "            ys.append(xs[:, si])\n",
    "\n",
    "#         .split([100, 100], dim=1)\n",
    "        return ys\n",
    "    \n",
    "    def backward_local(self, dys):\n",
    "        ### concat received gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            grads = torch.zeros(self.output_shape).to(dys[0].device)\n",
    "            for i, si in enumerate(self.split_indices):\n",
    "                grads[:,si] += dys[i]\n",
    "\n",
    "            self.grad_received = grads\n",
    "\n",
    "        ### Set input gradients and target\n",
    "        Xs = nn.Parameter(self.input_received, requires_grad=True)\n",
    "        ys = self.model(Xs)\n",
    "        Xgrad = torch.autograd.grad(ys, Xs, self.grad_received, only_inputs=True)[0]\n",
    "        \n",
    "        split_sz = [t[-1] for t in self.input_shapes]\n",
    "        input_grads = Xgrad.split(split_sz, dim=1)\n",
    "        \n",
    "#         self.target = ys.data - self.grad_received.data*10\n",
    "        self.target = ys.data - grads.data*100.0\n",
    "\n",
    "        ####### Train the local network\n",
    "        \n",
    "#         criterion = nn.MSELoss()\n",
    "        def criterion(y, t):\n",
    "            return (0.5*(y-t)**2).sum()\n",
    "\n",
    "#         self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001, betas=(0.9, 0.99))\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "#         self.optimizer = torch.optim.RMSprop(self.model.parameters(), lr=0.001)\n",
    "            \n",
    "        ### get model gradients different way\n",
    "        for epoch in range(100): ### Extra steps for optimizing using the same target\n",
    "            ys = self.model(self.input_received)\n",
    "            loss = criterion(ys, self.target)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return input_grads\n",
    "\n",
    "\n",
    "\n",
    "###### optimize using the same model and parameters\n",
    "##### save gradient norm, optimize copy model and gather gradient from there\n",
    "##### normalize the gradients to original gradient norm\n",
    "#     def backward_local(self, dys):\n",
    "#         ### concat received gradients\n",
    "#         with torch.no_grad():\n",
    "            \n",
    "#             grads = torch.zeros(self.output_shape).to(dys[0].device)\n",
    "#             for i, si in enumerate(self.split_indices):\n",
    "#                 grads[:,si] += dys[i]\n",
    "\n",
    "#             self.grad_received = grads\n",
    "\n",
    "# #         criterion = nn.MSELoss()\n",
    "#         def criterion(y, t):\n",
    "#             return (0.5*(y-t)**2).sum()\n",
    "\n",
    "#         Xs = nn.Parameter(self.input_received, requires_grad=True)\n",
    "#         ys = self.model(Xs)\n",
    "#         Xgrad = torch.autograd.grad(ys, Xs, self.grad_received, only_inputs=True)[0]\n",
    "#         split_sz = [t[-1] for t in self.input_shapes]\n",
    "#         input_grads = Xgrad.split(split_sz, dim=1)\n",
    "        \n",
    "#         self.target = ys.data - grads.data*10.0\n",
    "\n",
    "#         new_model = copy.deepcopy(self.model)\n",
    "#         new_model.load_state_dict(self.model.state_dict())\n",
    "#         new_optim = torch.optim.Adam(new_model.parameters(), lr=0.001)\n",
    "            \n",
    "#         ### get model gradients different way\n",
    "#         for epoch in range(40): ### Extra steps for optimizing using the same target\n",
    "#             ys = new_model(self.input_received)\n",
    "#             loss = criterion(ys, self.target)\n",
    "            \n",
    "#             new_optim.zero_grad()\n",
    "#             loss.backward()\n",
    "#             new_optim.step()\n",
    "# #             if epoch == 0:\n",
    "# #                 for parm in new_model.parameters():\n",
    "# #                     parm.grad_norm = torch.norm(parm.grad)\n",
    "            \n",
    "#        ### get unlooped optimizer\n",
    "#         for parm, new_parm in zip(self.model.parameters(), new_model.parameters()):\n",
    "# #             print(parm.grad, torch.norm(parm.grad))\n",
    "#             ## normalize the norm of the gradients according to original\n",
    "#             parm.grad = - (new_parm.data - parm.data) \n",
    "#             ### normalize it to the ratio of initial gradient magnitude\n",
    "# #             print(parm.grad, torch.norm(parm.grad), new_parm.grad_norm)\n",
    "# #             parm.grad = parm.grad/(torch.norm(parm.grad)+1e-7)*new_parm.grad_norm\n",
    "            \n",
    "# #         self.model = bkp_model\n",
    "\n",
    "#         self.optimizer.step()\n",
    "#         self.optimizer.zero_grad()\n",
    "# #         print(torch.norm(input_grads[0]), torch.norm(self.grad_received))\n",
    "#         return input_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LocalModel(MlpBLock([3, 5, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.set_split_mixing_indices([2, 2])\n",
    "# lm.set_split_mixing_indices(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 0]), tensor([2, 0])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.split_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.2331, -0.2543],\n",
       "         [ 0.0391, -0.5917],\n",
       "         [ 0.4029,  0.0740],\n",
       "         [ 0.4068,  0.1419],\n",
       "         [ 0.1493, -0.3278]]),\n",
       " tensor([[ 0.1190, -0.2543],\n",
       "         [ 0.8903, -0.5917],\n",
       "         [ 0.0491,  0.0740],\n",
       "         [-0.0637,  0.1419],\n",
       "         [-0.5916, -0.3278]])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.forward_local([xx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6.5701e-01, -7.9034e-01, -6.6066e-02],\n",
       "         [-1.0337e-01,  5.4641e-04,  6.7159e-02],\n",
       "         [-8.0819e-02, -9.5132e-02,  1.0195e-01],\n",
       "         [-7.1411e-02, -1.2860e-01,  1.7697e-01],\n",
       "         [ 5.1456e-01, -8.2910e-01, -2.1784e-01]]),)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dys = [torch.randn(2, 2), torch.randn(2,2)]\n",
    "# dys = [torch.randn(2, 3),]\n",
    "\n",
    "lm.backward_local(dys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8900, -0.5039, -0.2272],\n",
       "        [ 0.5311, -1.0748, -0.4435],\n",
       "        [ 0.5373, -0.2330, -0.4374],\n",
       "        [ 0.5096,  0.3480, -0.1747],\n",
       "        [-2.1820,  0.3810,  0.0455]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.grad_received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 168.7123,   10.1176,  100.2327],\n",
      "        [  69.5839,    2.8755,  -42.8336],\n",
      "        [ -26.8998,  -54.5045,  179.6676],\n",
      "        [ -76.6733,   70.5378, -254.7096],\n",
      "        [  12.2818,  -21.5869,    1.1647]])\n",
      "tensor([  38.0674,  -74.8231,  148.6718, -172.9162,  -33.8603])\n",
      "tensor([ -85.7599,   -5.7722,   16.8763, -173.3475,    0.0000])\n",
      "tensor([ -64.7278,  -18.6866,   11.8642, -114.1957,    0.0000])\n",
      "tensor([[  13.9507,   18.9250, -243.9871, -403.7310,    0.0000],\n",
      "        [-213.8820,   13.0969,   43.3936, -156.5489,    0.0000],\n",
      "        [-183.1409,   -6.1221,    5.1912, -135.1819,    0.0000]])\n",
      "tensor([-248.2108, -106.6114, -121.1515])\n"
     ]
    }
   ],
   "source": [
    "for p in lm.model.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1642,  0.1093,  0.4060], requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0300,  0.5263,  0.0720],\n",
       "         [ 0.1730, -0.1940, -0.4410],\n",
       "         [ 0.3676, -0.5382,  0.4060],\n",
       "         [-0.0271,  0.3004,  0.5185],\n",
       "         [ 0.3714, -0.1462,  0.3122]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.5511,  0.4164,  0.2994,  0.4824, -0.2428], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.1079, 1.0334, 0.9216, 1.0859, 0.9991], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1042,  0.0573, -0.0815,  0.0918, -0.0040], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1207, -0.4735, -0.0854,  0.4550,  0.0338],\n",
       "         [ 0.1162,  0.3133, -0.1003,  0.3583,  0.2393],\n",
       "         [ 0.4119,  0.3557, -0.4095, -0.3005,  0.1493]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1642,  0.1093,  0.4060], requires_grad=True)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.param_groups[0]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {Parameter containing:\n",
       "             tensor([[ 0.0300,  0.5263,  0.0720],\n",
       "                     [ 0.1730, -0.1940, -0.4410],\n",
       "                     [ 0.3676, -0.5382,  0.4060],\n",
       "                     [-0.0271,  0.3004,  0.5185],\n",
       "                     [ 0.3714, -0.1462,  0.3122]], requires_grad=True): {'step': 100,\n",
       "              'exp_avg': tensor([[ 1.4875e+02, -9.2698e+00,  7.5909e+01],\n",
       "                      [ 5.1134e+01, -1.7063e+01, -2.9218e+01],\n",
       "                      [-9.5448e+00, -2.6787e+01,  1.6239e+02],\n",
       "                      [-1.2883e+02,  6.2780e+01, -2.0242e+02],\n",
       "                      [-2.4303e+01, -1.4703e+01,  8.1203e-02]]),\n",
       "              'exp_avg_sq': tensor([[2316.6006,  221.5443,  605.4173],\n",
       "                      [ 221.6372,  323.3701,  121.8838],\n",
       "                      [ 238.8378,  208.8795, 3019.1292],\n",
       "                      [1913.5464,  508.2268, 5321.3804],\n",
       "                      [ 205.3705,   66.3730,   68.3708]])},\n",
       "             Parameter containing:\n",
       "             tensor([ 0.5511,  0.4164,  0.2994,  0.4824, -0.2428], requires_grad=True): {'step': 100,\n",
       "              'exp_avg': tensor([  6.4870, -78.4243, 148.4975, -89.5461,  -1.1226]),\n",
       "              'exp_avg_sq': tensor([ 387.5389,  778.7352, 2873.7144, 1898.1812,  103.8529])},\n",
       "             Parameter containing:\n",
       "             tensor([1.1079, 1.0334, 0.9216, 1.0859, 0.9991], requires_grad=True): {'step': 100,\n",
       "              'exp_avg': tensor([-7.7532e+01, -4.0757e+00,  2.3065e+01, -1.1049e+02,  4.7896e-02]),\n",
       "              'exp_avg_sq': tensor([381.5180,  12.3302, 218.0957, 684.9822,   1.3786])},\n",
       "             Parameter containing:\n",
       "             tensor([ 0.1042,  0.0573, -0.0815,  0.0918, -0.0040], requires_grad=True): {'step': 100,\n",
       "              'exp_avg': tensor([-55.2796, -26.8407,  22.8289, -85.5179,   0.0950]),\n",
       "              'exp_avg_sq': tensor([2.2095e+02, 1.1815e+02, 2.8078e+02, 6.4761e+02, 4.4445e-01])},\n",
       "             Parameter containing:\n",
       "             tensor([[-0.1207, -0.4735, -0.0854,  0.4550,  0.0338],\n",
       "                     [ 0.1162,  0.3133, -0.1003,  0.3583,  0.2393],\n",
       "                     [ 0.4119,  0.3557, -0.4095, -0.3005,  0.1493]], requires_grad=True): {'step': 100,\n",
       "              'exp_avg': tensor([[-2.2412e+01,  8.5813e+00, -2.6434e+02, -2.9426e+02, -3.2945e+00],\n",
       "                      [-2.2428e+02, -2.5657e-01,  3.9429e+01, -1.0932e+02,  5.7170e-01],\n",
       "                      [-1.7284e+02, -3.9610e+00,  3.4710e+00, -1.3954e+02,  9.3300e-02]]),\n",
       "              'exp_avg_sq': tensor([[1.3768e+03, 1.3499e+01, 1.0795e+04, 5.9568e+03, 1.6194e+02],\n",
       "                      [4.6231e+03, 2.8486e+01, 1.5813e+02, 1.0840e+03, 1.0032e+01],\n",
       "                      [2.4655e+03, 5.9665e+00, 3.5087e+00, 1.8120e+03, 1.7875e+00]])},\n",
       "             Parameter containing:\n",
       "             tensor([-0.1642,  0.1093,  0.4060], requires_grad=True): {'step': 100,\n",
       "              'exp_avg': tensor([-247.9861, -106.7174, -121.7316]),\n",
       "              'exp_avg_sq': tensor([5887.3833, 1099.5226, 1428.7043])}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.randn(5, 3)\n",
    "dys = [torch.randn(5, 2), torch.randn(5,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None\n",
    "# tensor([[-0.0216, -0.0131, -0.0257],\n",
    "#         [-0.0267, -0.0162, -0.0317],\n",
    "#         [ 2.6498,  1.6019,  3.1403],\n",
    "#         [-0.1429, -0.0864, -0.1694],\n",
    "#         [ 0.9580,  0.5792,  1.1354]])\n",
    "# None\n",
    "# tensor([ 0.0157,  0.0194, -1.9184,  0.1035, -0.6936])\n",
    "# None\n",
    "# tensor([[ 0.0912, -0.0091,  1.3586, -0.3357, -0.0134],\n",
    "#         [-0.2009,  0.0201, -2.9941,  0.7397,  0.0295],\n",
    "#         [-0.0647,  0.0065, -0.9643,  0.2382,  0.0095]])\n",
    "# None\n",
    "# tensor([ 2.4200, -5.3331, -1.7176])\n",
    "# ----------\n",
    "# tensor([[-0.0216, -0.0131, -0.0257],\n",
    "#         [-0.0267, -0.0162, -0.0317],\n",
    "#         [ 2.6498,  1.6019,  3.1403],\n",
    "#         [-0.1429, -0.0864, -0.1694],\n",
    "#         [ 0.9580,  0.5792,  1.1354]])\n",
    "# tensor([ 0.0157,  0.0194, -1.9184,  0.1035, -0.6936])\n",
    "# tensor([[ 0.0912, -0.0091,  1.3586, -0.3357, -0.0134],\n",
    "#         [-0.2009,  0.0201, -2.9941,  0.7397,  0.0295],\n",
    "#         [-0.0647,  0.0065, -0.9643,  0.2382,  0.0095]])\n",
    "# tensor([ 2.4200, -5.3331, -1.7176])\n",
    "# (tensor([[-0.6782,  0.9934,  0.2818]]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFeeder(DistributedNode):\n",
    "    \n",
    "    def __init__(self, input_dim, split_sizes = []):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.split_sizes = np.array(split_sizes, dtype=int)\n",
    "        self.split_indices = None\n",
    "\n",
    "        self.inputs = None\n",
    "        self.output_nodes = None\n",
    "        \n",
    "        ## preprocessing steps\n",
    "        self._set_split_mixing_indices_()\n",
    "        \n",
    "    def _set_split_mixing_indices_(self):\n",
    "        ## split sizes added must be >= to input size\n",
    "        assert self.input_dim <= np.sum(self.split_sizes), \"split sizes are less than input dimension\"\n",
    "        for ss in self.split_sizes:\n",
    "            assert self.input_dim >= ss, \"split sizes are greater than input dimension\"\n",
    "            \n",
    "        \n",
    "        ## also do not use split sizes greater than input dimension\n",
    "        \n",
    "        indices = np.arange(0, self.input_dim, 1, dtype=int)\n",
    "        indices = np.random.permutation(indices)\n",
    "        \n",
    "#         print(indices)\n",
    "        ## first divide input dimension into all splits\n",
    "        split_indices = self.split_sizes/np.sum(self.split_sizes)*self.input_dim\n",
    "        split_indices = split_indices.astype(int)\n",
    "        split_indices[0] += self.input_dim-split_indices.sum()\n",
    "        print(split_indices, split_indices.sum())\n",
    "        \n",
    "        index = np.split(indices, np.cumsum(split_indices[:-1]))\n",
    "#         for idx in index:\n",
    "#             print(len(idx))\n",
    "            \n",
    "        ## for extra input dimensions, sample randomly from remaining node indices.\n",
    "        for i in range(len(index)):\n",
    "            idx = index[i]\n",
    "            mask = np.ones(self.input_dim, dtype=bool)\n",
    "            mask[idx] = False\n",
    "            remaining = np.arange(0, self.input_dim, 1, dtype=int)[mask]\n",
    "            num_remain = self.split_sizes[i] - len(idx)\n",
    "            new_idx = remaining[np.random.permutation(len(remaining))[:num_remain]]\n",
    "            new_idx = np.array(new_idx)\n",
    "            \n",
    "            all_inx = np.concatenate((idx, new_idx))\n",
    "            index[i] = torch.LongTensor(all_inx)\n",
    "            \n",
    "        for idx in index:\n",
    "            print(len(idx))\n",
    "            \n",
    "        self.split_indices = index\n",
    "        pass\n",
    "\n",
    "    def set_input(self, x):\n",
    "        '''\n",
    "        x is assumed to be 2D; --> BatchSize, Dimension\n",
    "        '''\n",
    "        sz = x.shape\n",
    "        x = x.reshape(sz[0], -1)\n",
    "        self.inputs = [None for _ in range(len(self.split_indices))]\n",
    "        for i, si in enumerate(self.split_indices):\n",
    "            self.inputs[i] = x[:, si.to(x.device)]\n",
    "        return self.inputs\n",
    "    \n",
    "    def forward_local(self, x):\n",
    "        return self.set_input(x)\n",
    "    \n",
    "    def backward_local(self, ):\n",
    "        pass\n",
    "    \n",
    "    def update_local(self, ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262 261 261] 784\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "df = DataFeeder(784, [300, 300, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDimMixerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ## defining model hardcoded\n",
    "        self.m0 = DataFeeder(784, split_sizes=[300, 300, 300])\n",
    "        \n",
    "        self.m1 = MlpBLock([300, 600, 300])\n",
    "        self.m2 = MlpBLock([300, 500, 250])\n",
    "        self.m3 = MlpBLock([300, 500, 200])\n",
    "        \n",
    "        self.m4 = MlpBLock([150, 300, 100])\n",
    "        self.m5 = MlpBLock([250, 400, 100])\n",
    "        self.m6 = MlpBLock([350, 500, 200])\n",
    "        self.m7 = MlpBLock([300, 500, 200])\n",
    "        self.m8 = MlpBLock([100, 150, 50])\n",
    "        self.m9 = MlpBLock([200, 300, 100])\n",
    "        self.m10 = MlpBLock([150, 200, 10])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1, x2, x3 = self.m0.forward_local(x)\n",
    "        x1 = self.m1(x1).split([150, 150], dim=1)\n",
    "        x2 = self.m2(x2).split([100, 150], dim=1)\n",
    "        x3 = self.m3(x3)\n",
    "        \n",
    "        x4 = x1[0]\n",
    "        x5 = torch.cat([x1[1], x2[0]], dim=1)\n",
    "        x6 = torch.cat([x2[1], x3], dim=1)\n",
    "        x4 = self.m4(x4)\n",
    "        x5 = self.m5(x5)\n",
    "        x6 = self.m6(x6).split([100, 100], dim=1)\n",
    "        \n",
    "        x7 = torch.cat([x4, x5, x6[0]], dim=1)\n",
    "        x7 = self.m7(x7).split([100, 100], dim=1)\n",
    "#         print(x7[0].shape, x7[1].shape)\n",
    "        x8 = x7[0]\n",
    "        x8 = self.m8(x8)\n",
    "        x9 = torch.cat([x6[1], x7[1]], dim=1)\n",
    "        x9 = self.m9(x9)\n",
    "        \n",
    "        x10 = torch.cat([x9, x8], dim=1)\n",
    "        x10 = self.m10(x10)\n",
    "        return x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GraphDimMixerModel().to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dist_GraphDimMixerModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ## defining model hardcoded\n",
    "        self.m0 = DataFeeder(784, split_sizes=[300, 300, 300])\n",
    "        \n",
    "        self.m1 = LocalModel(MlpBLock([300, 600, 300]))\n",
    "        self.m1.set_split_mixing_indices([150, 150])\n",
    "        self.m2 = LocalModel(MlpBLock([300, 500, 250]))\n",
    "        self.m2.set_split_mixing_indices([100, 150])\n",
    "        self.m3 = LocalModel(MlpBLock([300, 500, 200]))\n",
    "        self.m3.set_split_mixing_indices(None)\n",
    "        \n",
    "        self.m4 = LocalModel(MlpBLock([150, 300, 100]))\n",
    "        self.m4.set_split_mixing_indices(None)\n",
    "        self.m5 = LocalModel(MlpBLock([250, 400, 100]))\n",
    "        self.m5.set_split_mixing_indices(None)\n",
    "        self.m6 = LocalModel(MlpBLock([350, 500, 200]))\n",
    "        self.m6.set_split_mixing_indices([100, 100])\n",
    "        self.m7 = LocalModel(MlpBLock([300, 500, 200]))\n",
    "        self.m7.set_split_mixing_indices([100, 100])\n",
    "        self.m8 = LocalModel(MlpBLock([100, 150, 50]))\n",
    "        self.m8.set_split_mixing_indices(None)\n",
    "        self.m9 = LocalModel(MlpBLock([200, 300, 100]))\n",
    "        self.m9.set_split_mixing_indices(None)\n",
    "        self.m10 = LocalModel(MlpBLock([150, 200, 10]))\n",
    "        self.m10.set_split_mixing_indices(None)\n",
    "        \n",
    "        self.model_list = [self.m1, self.m2, self.m3, self.m4, self.m5, \n",
    "                           self.m6, self.m7, self.m8, self.m9, self.m10]\n",
    "        self.module_list = nn.ModuleList([m.model for m in self.model_list])\n",
    "        \n",
    "    def set_optimizer_with_device(self, device):\n",
    "        for m in self.model_list:\n",
    "            m.model.to(device)\n",
    "#             m.optimizer = torch.optim.Adam(m.model.parameters(), lr=0.001)\n",
    "            m.optimizer = torch.optim.SGD(m.model.parameters(), lr=0.3)\n",
    "        pass\n",
    "        \n",
    "    def forward_local(self, x):\n",
    "        x1, x2, x3 = self.m0.forward_local(x)\n",
    "        x1 = self.m1.forward_local([x1])\n",
    "        x2 = self.m2.forward_local([x2])\n",
    "        x3 = self.m3.forward_local([x3])\n",
    "        \n",
    "        x4 = self.m4.forward_local([x1[0]])\n",
    "        x5 = self.m5.forward_local([x1[1], x2[0]])\n",
    "        \n",
    "        x6 = self.m6.forward_local([x2[1], x3[0]])\n",
    "        \n",
    "        x7 = self.m7.forward_local([x4[0], x5[0], x6[0]])\n",
    "        x8 = self.m8.forward_local([x7[0]])\n",
    "        x9 = self.m9.forward_local([x6[1], x7[1]])\n",
    "        \n",
    "        x10 = self.m10.forward_local([x8[0], x9[0]])\n",
    "        return x10[0]\n",
    "    \n",
    "    def backward_local(self, dy):\n",
    "        d10 = self.m10.backward_local([dy])\n",
    "        d9 = self.m9.backward_local([d10[1]])\n",
    "        d8 = self.m8.backward_local([d10[0]])\n",
    "        d7 = self.m7.backward_local([d8[0], d9[1]])\n",
    "        d6 = self.m6.backward_local([d7[2], d9[0]])\n",
    "        d5 = self.m5.backward_local([d7[1]])\n",
    "        d4 = self.m4.backward_local([d7[0]])\n",
    "        d3 = self.m3.backward_local([d6[1]])\n",
    "        d2 = self.m2.backward_local([d5[1], d6[0]])\n",
    "        d1 = self.m1.backward_local([d4[0], d5[0]])\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262 261 261] 784\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "d_dimixer = Dist_GraphDimMixerModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dist_GraphDimMixerModel(\n",
       "  (module_list): ModuleList(\n",
       "    (0): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=600, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=600, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=500, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=500, out_features=250, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=500, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=500, out_features=200, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=150, out_features=300, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=300, out_features=100, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=400, out_features=100, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (5): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=350, out_features=500, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=500, out_features=200, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (6): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=500, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=500, out_features=200, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (7): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=150, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((150,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=150, out_features=50, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (8): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=200, out_features=300, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=300, out_features=100, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (9): MlpBLock(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=150, out_features=200, bias=True)\n",
       "        (1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): Linear(in_features=200, out_features=10, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dimixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dimixer.set_optimizer_with_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1805,  0.4887, -0.1379, -0.6295,  0.2024,  0.2400,  0.2682,  0.4283,\n",
       "         -0.1800, -0.1663],\n",
       "        [-0.8595,  0.2606,  0.0802, -0.2151,  0.0765, -0.0135, -0.1285, -0.0144,\n",
       "         -0.4533, -0.0153],\n",
       "        [-0.7711, -0.2518,  0.1469, -0.1327,  0.0648, -0.0886,  0.2752,  0.2179,\n",
       "         -0.2622,  0.0588]], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dimixer.forward_local(torch.randn(3, 784).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dimixer.backward_local(torch.randn(3, 10).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdfsdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed local model training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262 261 261] 784\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "model = Dist_GraphDimMixerModel()\n",
    "model.set_optimizer_with_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'distrib_dim_mixer_fmist_s{SEED}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT ={'train_stat':[], 'test_stat':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward_local(inputs)\n",
    "        out = torch.autograd.Variable(outputs, requires_grad=True)\n",
    "        loss = criterion(out, targets)\n",
    "        loss.backward()\n",
    "            \n",
    "        model.backward_local(out.grad)\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    STAT['train_stat'].append((epoch, train_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model.forward_local(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    STAT['test_stat'].append((epoch, test_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "#         state = {\n",
    "#             'model': model.state_dict(),\n",
    "#             'acc': acc,\n",
    "#             'epoch': epoch\n",
    "#         }\n",
    "#         if not os.path.isdir('models'):\n",
    "#             os.mkdir('models')\n",
    "#         torch.save(state, f'./models/{model_name}.pth')\n",
    "#         best_acc = acc\n",
    "        \n",
    "    with open(f\"./output/{model_name}_data.json\", 'w') as f:\n",
    "        json.dump(STAT, f, indent=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('./models'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    \n",
    "    STAT = checkpoint['stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [00:36<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 0 Loss: 1.699 | Acc: 61.287 36772/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 0 Loss: 1.075 | Acc: 77.430 7743/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [00:36<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 1 Loss: 1.002 | Acc: 81.408 48845/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 1 Loss: 0.794 | Acc: 83.410 8341/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [00:36<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 2 Loss: 0.723 | Acc: 85.722 51433/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 2 Loss: 0.615 | Acc: 85.880 8588/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [00:36<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 3 Loss: 0.554 | Acc: 87.712 52627/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 3 Loss: 0.514 | Acc: 86.810 8681/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [00:36<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 4 Loss: 0.457 | Acc: 88.698 53219/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 4 Loss: 0.468 | Acc: 87.360 8736/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [00:36<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 5 Loss: 0.406 | Acc: 89.418 53651/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 5 Loss: 0.455 | Acc: 87.180 8718/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [00:36<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 6 Loss: 0.371 | Acc: 89.960 53976/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 6 Loss: 0.432 | Acc: 87.470 8747/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [00:36<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] 7 Loss: 0.346 | Acc: 90.692 54415/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] 7 Loss: 0.419 | Acc: 88.070 8807/10000\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|                        | 16/30 [00:20<00:17,  1.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Train the whole damn thing\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, start_epoch\u001b[38;5;241m+\u001b[39mEPOCHS): \u001b[38;5;66;03m## for 200 epochs\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     test(epoch)\n",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, targets)\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     22\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36mDist_GraphDimMixerModel.backward_local\u001b[0;34m(self, dy)\u001b[0m\n\u001b[1;32m     65\u001b[0m d5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm5\u001b[38;5;241m.\u001b[39mbackward_local([d7[\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m     66\u001b[0m d4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm4\u001b[38;5;241m.\u001b[39mbackward_local([d7[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m---> 67\u001b[0m d3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md6\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m d2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm2\u001b[38;5;241m.\u001b[39mbackward_local([d5[\u001b[38;5;241m1\u001b[39m], d6[\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m     69\u001b[0m d1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm1\u001b[38;5;241m.\u001b[39mbackward_local([d4[\u001b[38;5;241m0\u001b[39m], d5[\u001b[38;5;241m0\u001b[39m]])\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mLocalModel.backward_local\u001b[0;34m(self, dys)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m): \u001b[38;5;66;03m### Extra steps for optimizing using the same target\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     ys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_received)\n\u001b[0;32m--> 117\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    120\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mLocalModel.backward_local.<locals>.criterion\u001b[0;34m(y, t)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcriterion\u001b[39m(y, t):\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m)\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/All_Files/Program_Files/miniconda/lib/python3.9/site-packages/torch/_tensor.py:31\u001b[0m, in \u001b[0;36m_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Train the whole damn thing\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+EPOCHS): ## for 200 epochs\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdasdadasd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphDimMixerModel().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of params: \", sum(p.numel() for p in model.parameters())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'dim_mixer_fmist_s{SEED}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT ={'train_stat':[], 'test_stat':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following is copied from \n",
    "### https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    STAT['train_stat'].append((epoch, train_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Train] {epoch} Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = -1\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "    STAT['test_stat'].append((epoch, test_loss/(batch_idx+1), 100.*correct/total)) ### (Epochs, Loss, Acc)\n",
    "    print(f\"[Test] {epoch} Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f} {correct}/{total}\")\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f'./models/{model_name}.pth')\n",
    "        best_acc = acc\n",
    "        \n",
    "    with open(f\"./output/{model_name}_data.json\", 'w') as f:\n",
    "        json.dump(STAT, f, indent=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('./models'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    \n",
    "    STAT = checkpoint['stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the whole damn thing\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+EPOCHS): ## for 200 epochs\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f'./models/{model_name}.pth')\n",
    "best_acc = checkpoint['acc']\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "best_acc, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stat = np.array(STAT['train_stat'])\n",
    "test_stat = np.array(STAT['test_stat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_stat[:,1], label='train')\n",
    "plt.plot(test_stat[:,1], label='test')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"./output/plots/{model_name}_loss.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_stat[:,2], label='train')\n",
    "plt.plot(test_stat[:,2], label='test')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"./output/plots/{model_name}_accs.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
