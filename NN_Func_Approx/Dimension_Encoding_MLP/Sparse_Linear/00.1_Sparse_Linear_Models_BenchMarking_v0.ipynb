{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4619b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708c3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random, sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de471a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparse_linear_lib as sll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3db567",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26f0e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db9beaf",
   "metadata": {},
   "source": [
    "## Pair Linear approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8370636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = [16, 64, 256, 1024, 4096] #, 16384]\n",
    "seeds = [147, 258, 369, 321, 654, 987, 741, 852, 963, 159, 357, 951, 753]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce0f0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ns = [16384]\n",
    "# seeds = [147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39d77bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5ec7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_STEPS = 20000 #2000\n",
    "def train_model(model, optimizer, X, A):\n",
    "    for i in range(TRAIN_STEPS):\n",
    "        out = model(X)\n",
    "        loss = mse(out, A)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%1000 == 0:\n",
    "            print(f\"The MSE loss is : {float(mse(out,A))}\")\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        out = model(X)\n",
    "        tt = time.time()-start\n",
    "    return out, tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b51228a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svd_output(A, n_comp):\n",
    "    U, S, V = torch.svd(A)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _U = U[:, :n_comp]\n",
    "        _S = S[:n_comp]\n",
    "        _V = V[:, :n_comp]\n",
    "        \n",
    "        start = time.time()\n",
    "        out = torch.mm(torch.mm(_U, torch.diag(_S)), _V.t())\n",
    "        tt = time.time()-start\n",
    "    \n",
    "#     S[n_comp:] *= 0\n",
    "#     out = torch.mm(torch.mm(U, torch.diag(S)), V.t())\n",
    "    return out, tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "974d7b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_stats(df, out, A, method, seed, nparam, tim, filename):\n",
    "    diff = (out.data-A).abs()\n",
    "    \n",
    "    mean, std = float(diff.mean()), float(diff.std())\n",
    "    err = float(mse(out, A))\n",
    "\n",
    "    df = df.append({\"method\":method, \"seed\":seed, \"mse\":err,\n",
    "                    \"mean\":mean, \"std\":std, \"params\":nparam, \"time\":tim}, \n",
    "                   ignore_index=True)\n",
    "    df_ = df.copy()\n",
    "    df.to_csv(f\"./outputs/{file_name}.csv\")\n",
    "    \n",
    "    print(f\"Saving... file:{file_name} method:{method}\")\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ca4ce3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [mse, mean, std]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['mse', 'mean', 'std'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "816844b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add_PairLinears(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_adds):\n",
    "        super().__init__()\n",
    "        self.pair_mixers = []\n",
    "        self.perm_indices = []\n",
    "        for i in range(num_adds):\n",
    "            m = sll.PairLinear_MixerBlock(input_dim, input_dim)\n",
    "            self.pair_mixers.append(m)\n",
    "            if i > 0:\n",
    "                rm = torch.randperm(input_dim)\n",
    "                self.perm_indices.append(rm)\n",
    "                \n",
    "        self.pair_mixers = nn.ModuleList(self.pair_mixers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = torch.zeros_like(x)\n",
    "        for i, m in enumerate(self.pair_mixers):\n",
    "            if i > 0:\n",
    "                _x = x[:, self.perm_indices[i-1]]\n",
    "            else:\n",
    "                _x = x\n",
    "                \n",
    "            y += m(_x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dc620d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Add_PairLinears(N, 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3454c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stack_PairLinears(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_adds):\n",
    "        super().__init__()\n",
    "        self.pair_mixers = []\n",
    "        self.perm_indices = []\n",
    "        for i in range(num_adds):\n",
    "            m = sll.PairLinear_MixerBlock(input_dim, input_dim)\n",
    "            self.pair_mixers.append(m)\n",
    "            if i > 0:\n",
    "                rm = torch.randperm(input_dim)\n",
    "                self.perm_indices.append(rm)\n",
    "                \n",
    "        self.pair_mixers = nn.ModuleList(self.pair_mixers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, m in enumerate(self.pair_mixers):\n",
    "            if i == 0:\n",
    "                x = m(x)\n",
    "            else:\n",
    "                x = m(x[:, self.perm_indices[i-1]])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da14d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_base(a, base):\n",
    "    return np.log(a) / np.log(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "499149b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.append({\"mse\":1.0, \"mean\":2.0, \"std\":4.0}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2d53de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\\n  df = df.append({\"method\":method, \"seed\":seed, \"mse\":err,\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(action='once') \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "'''\n",
    "FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
    "  df = df.append({\"method\":method, \"seed\":seed, \"mse\":err,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9df26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment N=16 SEED=147\n",
      "The MSE loss is : 0.4491165280342102\n",
      "The MSE loss is : 0.20023737847805023\n",
      "The MSE loss is : 0.1958433836698532\n",
      "The MSE loss is : 0.19584333896636963\n",
      "The MSE loss is : 0.19584333896636963\n",
      "The MSE loss is : 0.19584333896636963\n",
      "The MSE loss is : 0.19584333896636963\n",
      "The MSE loss is : 0.19584333896636963\n",
      "The MSE loss is : 0.19584333896636963\n",
      "The MSE loss is : 0.19584336876869202\n",
      "The MSE loss is : 0.19584336876869202\n",
      "The MSE loss is : 0.19584335386753082\n",
      "The MSE loss is : 0.1958433985710144\n",
      "The MSE loss is : 0.19584336876869202\n",
      "The MSE loss is : 0.19584335386753082\n",
      "The MSE loss is : 0.19584335386753082\n",
      "The MSE loss is : 0.19584336876869202\n",
      "The MSE loss is : 0.19584345817565918\n",
      "The MSE loss is : 0.19584333896636963\n",
      "The MSE loss is : 0.19584335386753082\n",
      "Saving... file:record_err_16 method:pair\n",
      "The MSE loss is : 0.4491165280342102\n",
      "The MSE loss is : 0.2941505014896393\n",
      "The MSE loss is : 0.2922055125236511\n",
      "The MSE loss is : 0.2913629412651062\n",
      "The MSE loss is : 0.291361927986145\n",
      "The MSE loss is : 0.2913612127304077\n",
      "The MSE loss is : 0.29136061668395996\n",
      "The MSE loss is : 0.29136085510253906\n",
      "The MSE loss is : 0.2913600206375122\n",
      "The MSE loss is : 0.29135996103286743\n",
      "The MSE loss is : 0.2913597524166107\n",
      "The MSE loss is : 0.29135966300964355\n",
      "The MSE loss is : 0.29135963320732117\n",
      "The MSE loss is : 0.291359543800354\n",
      "The MSE loss is : 0.2913595139980316\n",
      "The MSE loss is : 0.29135948419570923\n",
      "The MSE loss is : 0.29135942459106445\n",
      "The MSE loss is : 0.29135948419570923\n",
      "The MSE loss is : 0.29135948419570923\n",
      "The MSE loss is : 0.29135948419570923\n",
      "Saving... file:record_err_16 method:block-sqrt-half\n",
      "The MSE loss is : 0.4491165280342102\n",
      "The MSE loss is : 0.172461599111557\n",
      "The MSE loss is : 0.17021699249744415\n",
      "The MSE loss is : 0.1702154576778412\n",
      "The MSE loss is : 0.17021547257900238\n",
      "The MSE loss is : 0.1702154576778412\n",
      "The MSE loss is : 0.1702154576778412\n",
      "The MSE loss is : 0.1702154576778412\n",
      "The MSE loss is : 0.1702154576778412\n",
      "The MSE loss is : 0.17021547257900238\n",
      "The MSE loss is : 0.1702154576778412\n",
      "The MSE loss is : 0.17021547257900238\n",
      "The MSE loss is : 0.1702154576778412\n",
      "The MSE loss is : 0.17021547257900238\n",
      "The MSE loss is : 0.17021548748016357\n",
      "The MSE loss is : 0.17021547257900238\n",
      "The MSE loss is : 0.17021550238132477\n",
      "The MSE loss is : 0.17021547257900238\n",
      "The MSE loss is : 0.1702154576778412\n",
      "The MSE loss is : 0.17021548748016357\n",
      "Saving... file:record_err_16 method:block-sqrt\n",
      "Saving... file:record_err_16 method:lowR-same-param\n",
      "Saving... file:record_err_16 method:lowR-samex2\n",
      "Saving... file:record_err_16 method:lowR-half\n",
      "The MSE loss is : 0.6618789434432983\n",
      "The MSE loss is : 0.002590987365692854\n",
      "The MSE loss is : 3.901618765667081e-05\n",
      "The MSE loss is : 2.0310638149112492e-07\n",
      "The MSE loss is : 4.280028276237857e-10\n",
      "The MSE loss is : 9.014432755805046e-09\n",
      "The MSE loss is : 1.5788489804435812e-07\n",
      "The MSE loss is : 2.6828137933421203e-08\n",
      "The MSE loss is : 4.115796059522836e-08\n",
      "The MSE loss is : 3.5376184204238825e-09\n",
      "The MSE loss is : 7.958369963034784e-08\n",
      "The MSE loss is : 1.9020948371917257e-08\n",
      "The MSE loss is : 3.455651267358917e-07\n",
      "The MSE loss is : 9.51467526988381e-09\n",
      "The MSE loss is : 1.5855582091717224e-07\n",
      "The MSE loss is : 2.9254636046971427e-07\n",
      "The MSE loss is : 4.711245438215883e-08\n",
      "The MSE loss is : 1.0470065703316322e-08\n",
      "The MSE loss is : 3.6227552868695057e-07\n",
      "The MSE loss is : 1.5615371466992656e-06\n",
      "Saving... file:record_err_16 method:pair-Add\n",
      "The MSE loss is : 0.4580027163028717\n",
      "The MSE loss is : 0.009526718407869339\n",
      "The MSE loss is : 0.0034545306116342545\n",
      "The MSE loss is : 0.0016621383838355541\n",
      "The MSE loss is : 0.001027722842991352\n",
      "The MSE loss is : 0.001582919736392796\n",
      "The MSE loss is : 0.0006980184698477387\n",
      "The MSE loss is : 0.0019976545590907335\n",
      "The MSE loss is : 0.0005523486761376262\n",
      "The MSE loss is : 0.0004917768528684974\n",
      "The MSE loss is : 0.00044072140008211136\n",
      "The MSE loss is : 0.00040542305214330554\n",
      "The MSE loss is : 0.0003669816069304943\n",
      "The MSE loss is : 0.0003436258411966264\n",
      "The MSE loss is : 0.00032023494713939726\n",
      "The MSE loss is : 0.00030287750996649265\n",
      "The MSE loss is : 0.0002894338103942573\n",
      "The MSE loss is : 0.00027573760598897934\n",
      "The MSE loss is : 0.00027230283012613654\n",
      "The MSE loss is : 0.0008514984510838985\n",
      "Saving... file:record_err_16 method:pair-Seq\n",
      "\n",
      "Experiment N=16 SEED=258\n",
      "The MSE loss is : 0.34958234429359436\n",
      "The MSE loss is : 0.17535558342933655\n",
      "The MSE loss is : 0.1702578067779541\n",
      "The MSE loss is : 0.1702578067779541\n",
      "The MSE loss is : 0.1702578216791153\n",
      "The MSE loss is : 0.1702578216791153\n",
      "The MSE loss is : 0.1702578216791153\n",
      "The MSE loss is : 0.1702578216791153\n",
      "The MSE loss is : 0.1702578216791153\n",
      "The MSE loss is : 0.1702578216791153\n",
      "The MSE loss is : 0.17025786638259888\n",
      "The MSE loss is : 0.17025791108608246\n",
      "The MSE loss is : 0.1702578067779541\n",
      "The MSE loss is : 0.1702578365802765\n",
      "The MSE loss is : 0.1702578067779541\n",
      "The MSE loss is : 0.1702578365802765\n",
      "The MSE loss is : 0.17025786638259888\n",
      "The MSE loss is : 0.1702578216791153\n",
      "The MSE loss is : 0.1702578365802765\n",
      "The MSE loss is : 0.17025795578956604\n",
      "Saving... file:record_err_16 method:pair\n",
      "The MSE loss is : 0.34958234429359436\n",
      "The MSE loss is : 0.24166783690452576\n",
      "The MSE loss is : 0.2405790388584137\n",
      "The MSE loss is : 0.24056130647659302\n",
      "The MSE loss is : 0.24055789411067963\n",
      "The MSE loss is : 0.24055612087249756\n",
      "The MSE loss is : 0.24055513739585876\n",
      "The MSE loss is : 0.2405545562505722\n",
      "The MSE loss is : 0.24055421352386475\n",
      "The MSE loss is : 0.2405540645122528\n",
      "The MSE loss is : 0.24055400490760803\n",
      "The MSE loss is : 0.24055388569831848\n",
      "The MSE loss is : 0.2405538558959961\n",
      "The MSE loss is : 0.2405538409948349\n",
      "The MSE loss is : 0.2405538111925125\n",
      "The MSE loss is : 0.2405538260936737\n",
      "The MSE loss is : 0.24055379629135132\n",
      "The MSE loss is : 0.24055400490760803\n",
      "The MSE loss is : 0.24055376648902893\n",
      "The MSE loss is : 0.24055376648902893\n",
      "Saving... file:record_err_16 method:block-sqrt-half\n",
      "The MSE loss is : 0.34958234429359436\n",
      "The MSE loss is : 0.12455856800079346\n",
      "The MSE loss is : 0.12451079487800598\n",
      "The MSE loss is : 0.12451079487800598\n",
      "The MSE loss is : 0.12451079487800598\n",
      "The MSE loss is : 0.12451079487800598\n",
      "The MSE loss is : 0.12451078742742538\n",
      "The MSE loss is : 0.12451078742742538\n",
      "The MSE loss is : 0.12451078742742538\n",
      "The MSE loss is : 0.12451079487800598\n",
      "The MSE loss is : 0.12451079487800598\n",
      "The MSE loss is : 0.12451079487800598\n",
      "The MSE loss is : 0.12451079487800598\n",
      "The MSE loss is : 0.12451079487800598\n",
      "The MSE loss is : 0.12451079487800598\n",
      "The MSE loss is : 0.12451080232858658\n",
      "The MSE loss is : 0.12451080232858658\n",
      "The MSE loss is : 0.12451080977916718\n",
      "The MSE loss is : 0.12451079487800598\n",
      "The MSE loss is : 0.12451079487800598\n",
      "Saving... file:record_err_16 method:block-sqrt\n",
      "Saving... file:record_err_16 method:lowR-same-param\n",
      "Saving... file:record_err_16 method:lowR-samex2\n",
      "Saving... file:record_err_16 method:lowR-half\n",
      "The MSE loss is : 0.5632895231246948\n",
      "The MSE loss is : 0.0010469575645402074\n",
      "The MSE loss is : 2.8582253435160965e-05\n",
      "The MSE loss is : 1.0255164397676708e-06\n",
      "The MSE loss is : 9.796556454944039e-09\n",
      "The MSE loss is : 1.054133225153464e-08\n",
      "The MSE loss is : 1.2198618851155807e-13\n",
      "The MSE loss is : 2.3820836414500945e-09\n",
      "The MSE loss is : 4.00815780565722e-09\n",
      "The MSE loss is : 1.0811843864644288e-08\n",
      "The MSE loss is : 2.256001288558629e-11\n",
      "The MSE loss is : 7.468842966318334e-08\n",
      "The MSE loss is : 1.527135040646499e-08\n",
      "The MSE loss is : 2.307841029391966e-08\n",
      "The MSE loss is : 1.6503260269473685e-07\n",
      "The MSE loss is : 2.8209235836129665e-08\n",
      "The MSE loss is : 1.3516150865200416e-08\n",
      "The MSE loss is : 9.720329785523063e-08\n",
      "The MSE loss is : 2.079418237599384e-08\n",
      "The MSE loss is : 4.926384349346336e-07\n",
      "Saving... file:record_err_16 method:pair-Add\n",
      "The MSE loss is : 0.3642340302467346\n",
      "The MSE loss is : 0.009270209819078445\n",
      "The MSE loss is : 0.0031049540266394615\n",
      "The MSE loss is : 0.0019052551360800862\n",
      "The MSE loss is : 0.0016382825560867786\n",
      "The MSE loss is : 0.0015796651132404804\n",
      "The MSE loss is : 0.0013922512298449874\n",
      "The MSE loss is : 0.0013000154867768288\n",
      "The MSE loss is : 0.00120765739120543\n",
      "The MSE loss is : 0.0012360555119812489\n",
      "The MSE loss is : 0.0010830324608832598\n",
      "The MSE loss is : 0.0016641308320686221\n",
      "The MSE loss is : 0.0010087392292916775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.0009753293124958873\n",
      "The MSE loss is : 0.0009567507659085095\n",
      "The MSE loss is : 0.0009172537829726934\n",
      "The MSE loss is : 0.0008938864921219647\n",
      "The MSE loss is : 0.0009341479162685573\n",
      "The MSE loss is : 0.0008734357543289661\n",
      "The MSE loss is : 0.0008408044232055545\n",
      "Saving... file:record_err_16 method:pair-Seq\n",
      "\n",
      "Experiment N=16 SEED=369\n",
      "The MSE loss is : 0.3989996910095215\n",
      "The MSE loss is : 0.1503232717514038\n",
      "The MSE loss is : 0.14614027738571167\n",
      "The MSE loss is : 0.14613927900791168\n",
      "The MSE loss is : 0.14613929390907288\n",
      "The MSE loss is : 0.14613929390907288\n",
      "The MSE loss is : 0.1461392641067505\n",
      "The MSE loss is : 0.14613929390907288\n",
      "The MSE loss is : 0.14613929390907288\n",
      "The MSE loss is : 0.14613929390907288\n",
      "The MSE loss is : 0.14613927900791168\n",
      "The MSE loss is : 0.14613929390907288\n",
      "The MSE loss is : 0.14613927900791168\n",
      "The MSE loss is : 0.14613929390907288\n",
      "The MSE loss is : 0.14613929390907288\n",
      "The MSE loss is : 0.14613929390907288\n",
      "The MSE loss is : 0.14613927900791168\n",
      "The MSE loss is : 0.14613938331604004\n",
      "The MSE loss is : 0.14613935351371765\n",
      "The MSE loss is : 0.14613929390907288\n",
      "Saving... file:record_err_16 method:pair\n",
      "The MSE loss is : 0.3989996910095215\n",
      "The MSE loss is : 0.24193182587623596\n",
      "The MSE loss is : 0.24001258611679077\n",
      "The MSE loss is : 0.23974770307540894\n",
      "The MSE loss is : 0.2397059202194214\n",
      "The MSE loss is : 0.23969843983650208\n",
      "The MSE loss is : 0.239694744348526\n",
      "The MSE loss is : 0.23969228565692902\n",
      "The MSE loss is : 0.23969115316867828\n",
      "The MSE loss is : 0.23969270288944244\n",
      "The MSE loss is : 0.23969000577926636\n",
      "The MSE loss is : 0.2396896481513977\n",
      "The MSE loss is : 0.2396893948316574\n",
      "The MSE loss is : 0.2396892011165619\n",
      "The MSE loss is : 0.23968906700611115\n",
      "The MSE loss is : 0.2396889626979828\n",
      "The MSE loss is : 0.23968884348869324\n",
      "The MSE loss is : 0.239689439535141\n",
      "The MSE loss is : 0.23968921601772308\n",
      "The MSE loss is : 0.23968864977359772\n",
      "Saving... file:record_err_16 method:block-sqrt-half\n",
      "The MSE loss is : 0.3989996910095215\n",
      "The MSE loss is : 0.10966590791940689\n",
      "The MSE loss is : 0.10937172174453735\n",
      "The MSE loss is : 0.10937171429395676\n",
      "The MSE loss is : 0.10937171429395676\n",
      "The MSE loss is : 0.10937171429395676\n",
      "The MSE loss is : 0.10937171429395676\n",
      "The MSE loss is : 0.10937171429395676\n",
      "The MSE loss is : 0.10937172174453735\n",
      "The MSE loss is : 0.10937171429395676\n",
      "The MSE loss is : 0.10937171429395676\n",
      "The MSE loss is : 0.10937171429395676\n",
      "The MSE loss is : 0.10937172174453735\n",
      "The MSE loss is : 0.10937171429395676\n",
      "The MSE loss is : 0.10937173664569855\n",
      "The MSE loss is : 0.10937172174453735\n",
      "The MSE loss is : 0.10937172919511795\n",
      "The MSE loss is : 0.10937172919511795\n",
      "The MSE loss is : 0.10937173664569855\n",
      "The MSE loss is : 0.10937173664569855\n",
      "Saving... file:record_err_16 method:block-sqrt\n",
      "Saving... file:record_err_16 method:lowR-same-param\n",
      "Saving... file:record_err_16 method:lowR-samex2\n",
      "Saving... file:record_err_16 method:lowR-half\n",
      "The MSE loss is : 0.6306746602058411\n",
      "The MSE loss is : 0.0009203090448863804\n",
      "The MSE loss is : 1.6322584997396916e-05\n",
      "The MSE loss is : 3.644676667136082e-07\n",
      "The MSE loss is : 5.670215408315471e-09\n",
      "The MSE loss is : 2.933803200377838e-11\n",
      "The MSE loss is : 9.705140163740467e-11\n",
      "The MSE loss is : 9.589302862877958e-08\n",
      "The MSE loss is : 2.359184181344176e-09\n",
      "The MSE loss is : 2.8686436337466148e-08\n",
      "The MSE loss is : 1.664860249661615e-08\n",
      "The MSE loss is : 4.012629872818252e-08\n",
      "The MSE loss is : 9.36312005705986e-08\n",
      "The MSE loss is : 4.263100095158734e-09\n",
      "The MSE loss is : 5.261910018816707e-09\n",
      "The MSE loss is : 5.247368761729376e-08\n",
      "The MSE loss is : 3.444275620267945e-08\n",
      "The MSE loss is : 1.793182775600144e-07\n",
      "The MSE loss is : 2.400598191343306e-07\n",
      "The MSE loss is : 5.0599787471128366e-08\n",
      "Saving... file:record_err_16 method:pair-Add\n",
      "The MSE loss is : 0.36468493938446045\n",
      "The MSE loss is : 0.011745410040020943\n",
      "The MSE loss is : 0.0016674945363774896\n",
      "The MSE loss is : 0.0012113930424675345\n",
      "The MSE loss is : 0.0009967493824660778\n",
      "The MSE loss is : 0.0007977324421517551\n",
      "The MSE loss is : 0.0008328063995577395\n",
      "The MSE loss is : 0.0005765958339907229\n",
      "The MSE loss is : 0.0005331370048224926\n",
      "The MSE loss is : 0.0004161888500675559\n",
      "The MSE loss is : 0.0003696875355672091\n",
      "The MSE loss is : 0.0003989558026660234\n",
      "The MSE loss is : 0.0006926521309651434\n",
      "The MSE loss is : 0.00037449796218425035\n",
      "The MSE loss is : 0.00028414418920874596\n",
      "The MSE loss is : 0.000259985972661525\n",
      "The MSE loss is : 0.0005696943262591958\n",
      "The MSE loss is : 0.00028840964660048485\n",
      "The MSE loss is : 0.0002528696204535663\n",
      "The MSE loss is : 0.00033624033676460385\n",
      "Saving... file:record_err_16 method:pair-Seq\n",
      "\n",
      "Experiment N=16 SEED=321\n",
      "The MSE loss is : 0.3957561254501343\n",
      "The MSE loss is : 0.17968115210533142\n",
      "The MSE loss is : 0.17621390521526337\n",
      "The MSE loss is : 0.1762133240699768\n",
      "The MSE loss is : 0.1762133240699768\n",
      "The MSE loss is : 0.1762133240699768\n",
      "The MSE loss is : 0.1762133240699768\n",
      "The MSE loss is : 0.1762133240699768\n",
      "The MSE loss is : 0.1762133240699768\n",
      "The MSE loss is : 0.1762133240699768\n",
      "The MSE loss is : 0.1762133240699768\n",
      "The MSE loss is : 0.1762133687734604\n",
      "The MSE loss is : 0.1762133240699768\n",
      "The MSE loss is : 0.1762133240699768\n",
      "The MSE loss is : 0.17621345818042755\n",
      "The MSE loss is : 0.1762133240699768\n",
      "The MSE loss is : 0.1762133240699768\n",
      "The MSE loss is : 0.1762133538722992\n",
      "The MSE loss is : 0.17621348798274994\n",
      "The MSE loss is : 0.1762133240699768\n",
      "Saving... file:record_err_16 method:pair\n",
      "The MSE loss is : 0.3957561254501343\n",
      "The MSE loss is : 0.24783125519752502\n",
      "The MSE loss is : 0.24712663888931274\n",
      "The MSE loss is : 0.2471122443675995\n",
      "The MSE loss is : 0.24711200594902039\n",
      "The MSE loss is : 0.24711185693740845\n",
      "The MSE loss is : 0.24711179733276367\n",
      "The MSE loss is : 0.24711176753044128\n",
      "The MSE loss is : 0.24711176753044128\n",
      "The MSE loss is : 0.24711179733276367\n",
      "The MSE loss is : 0.24711176753044128\n",
      "The MSE loss is : 0.24711179733276367\n",
      "The MSE loss is : 0.24711176753044128\n",
      "The MSE loss is : 0.24711179733276367\n",
      "The MSE loss is : 0.24711176753044128\n",
      "The MSE loss is : 0.24711178243160248\n",
      "The MSE loss is : 0.24711176753044128\n",
      "The MSE loss is : 0.24711178243160248\n",
      "The MSE loss is : 0.24711181223392487\n",
      "The MSE loss is : 0.24711178243160248\n",
      "Saving... file:record_err_16 method:block-sqrt-half\n",
      "The MSE loss is : 0.3957561254501343\n",
      "The MSE loss is : 0.14644555747509003\n",
      "The MSE loss is : 0.14456111192703247\n",
      "The MSE loss is : 0.14456091821193695\n",
      "The MSE loss is : 0.14456091821193695\n",
      "The MSE loss is : 0.14456090331077576\n",
      "The MSE loss is : 0.14456091821193695\n",
      "The MSE loss is : 0.14456090331077576\n",
      "The MSE loss is : 0.14456090331077576\n",
      "The MSE loss is : 0.14456091821193695\n",
      "The MSE loss is : 0.14456090331077576\n",
      "The MSE loss is : 0.14456090331077576\n",
      "The MSE loss is : 0.14456093311309814\n",
      "The MSE loss is : 0.14456090331077576\n",
      "The MSE loss is : 0.14456093311309814\n",
      "The MSE loss is : 0.14456090331077576\n",
      "The MSE loss is : 0.14456093311309814\n",
      "The MSE loss is : 0.14456091821193695\n",
      "The MSE loss is : 0.14456091821193695\n",
      "The MSE loss is : 0.14456093311309814\n",
      "Saving... file:record_err_16 method:block-sqrt\n",
      "Saving... file:record_err_16 method:lowR-same-param\n",
      "Saving... file:record_err_16 method:lowR-samex2\n",
      "Saving... file:record_err_16 method:lowR-half\n",
      "The MSE loss is : 0.6703342199325562\n",
      "The MSE loss is : 0.001484388718381524\n",
      "The MSE loss is : 6.970261165406555e-05\n",
      "The MSE loss is : 2.755223249550909e-06\n",
      "The MSE loss is : 2.1183719667305922e-08\n",
      "The MSE loss is : 5.9801590762686985e-12\n",
      "The MSE loss is : 1.1800955768137555e-08\n",
      "The MSE loss is : 2.533119825010033e-10\n",
      "The MSE loss is : 1.847370469931775e-07\n",
      "The MSE loss is : 2.897821219094432e-11\n",
      "The MSE loss is : 4.8572115218803447e-08\n",
      "The MSE loss is : 4.6756969140915317e-07\n",
      "The MSE loss is : 8.428984443753507e-08\n",
      "The MSE loss is : 1.794447683778344e-07\n",
      "The MSE loss is : 1.717570370374233e-07\n",
      "The MSE loss is : 8.592319886702171e-07\n",
      "The MSE loss is : 1.4746257548381436e-08\n",
      "The MSE loss is : 1.3554306121932314e-07\n",
      "The MSE loss is : 8.750059343753946e-09\n",
      "The MSE loss is : 6.721150214161753e-08\n",
      "Saving... file:record_err_16 method:pair-Add\n",
      "The MSE loss is : 0.37228405475616455\n",
      "The MSE loss is : 0.009175358340144157\n",
      "The MSE loss is : 0.005431888159364462\n",
      "The MSE loss is : 0.0044817556627094746\n",
      "The MSE loss is : 0.0042242631316185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.004094417672604322\n",
      "The MSE loss is : 0.003976179752498865\n",
      "The MSE loss is : 0.003829577937722206\n",
      "The MSE loss is : 0.0036368416622281075\n",
      "The MSE loss is : 0.0035730283707380295\n",
      "The MSE loss is : 0.003373573999851942\n",
      "The MSE loss is : 0.0033073516096919775\n",
      "The MSE loss is : 0.0032525742426514626\n",
      "The MSE loss is : 0.0032036807388067245\n",
      "The MSE loss is : 0.003156241960823536\n",
      "The MSE loss is : 0.0031450071837753057\n",
      "The MSE loss is : 0.0030307143460959196\n",
      "The MSE loss is : 0.002950448775663972\n",
      "The MSE loss is : 0.002867298200726509\n",
      "The MSE loss is : 0.002805024851113558\n",
      "Saving... file:record_err_16 method:pair-Seq\n",
      "\n",
      "Experiment N=16 SEED=654\n",
      "The MSE loss is : 0.38886141777038574\n",
      "The MSE loss is : 0.1812228560447693\n",
      "The MSE loss is : 0.17495106160640717\n",
      "The MSE loss is : 0.17494326829910278\n",
      "The MSE loss is : 0.17494329810142517\n",
      "The MSE loss is : 0.17494326829910278\n",
      "The MSE loss is : 0.17494326829910278\n",
      "The MSE loss is : 0.17494328320026398\n",
      "The MSE loss is : 0.17494328320026398\n",
      "The MSE loss is : 0.17494326829910278\n",
      "The MSE loss is : 0.17494326829910278\n",
      "The MSE loss is : 0.17494326829910278\n",
      "The MSE loss is : 0.17494326829910278\n",
      "The MSE loss is : 0.17494329810142517\n",
      "The MSE loss is : 0.17494332790374756\n",
      "The MSE loss is : 0.1749434918165207\n",
      "The MSE loss is : 0.17494334280490875\n",
      "The MSE loss is : 0.17494326829910278\n",
      "The MSE loss is : 0.17494329810142517\n",
      "The MSE loss is : 0.17494328320026398\n",
      "Saving... file:record_err_16 method:pair\n",
      "The MSE loss is : 0.38886141777038574\n",
      "The MSE loss is : 0.25749900937080383\n",
      "The MSE loss is : 0.2555408477783203\n",
      "The MSE loss is : 0.2554507255554199\n",
      "The MSE loss is : 0.25541365146636963\n",
      "The MSE loss is : 0.255389928817749\n",
      "The MSE loss is : 0.2553859353065491\n",
      "The MSE loss is : 0.2553851306438446\n",
      "The MSE loss is : 0.2553846836090088\n",
      "The MSE loss is : 0.2553843855857849\n",
      "The MSE loss is : 0.2553842067718506\n",
      "The MSE loss is : 0.25538408756256104\n",
      "The MSE loss is : 0.2553839683532715\n",
      "The MSE loss is : 0.2553839087486267\n",
      "The MSE loss is : 0.2553839087486267\n",
      "The MSE loss is : 0.25538378953933716\n",
      "The MSE loss is : 0.2553837299346924\n",
      "The MSE loss is : 0.2553844153881073\n",
      "The MSE loss is : 0.25538384914398193\n",
      "The MSE loss is : 0.25538361072540283\n",
      "Saving... file:record_err_16 method:block-sqrt-half\n",
      "The MSE loss is : 0.38886141777038574\n",
      "The MSE loss is : 0.1337663233280182\n",
      "The MSE loss is : 0.12687422335147858\n",
      "The MSE loss is : 0.12687420845031738\n",
      "The MSE loss is : 0.12687420845031738\n",
      "The MSE loss is : 0.12687420845031738\n",
      "The MSE loss is : 0.12687420845031738\n",
      "The MSE loss is : 0.12687420845031738\n",
      "The MSE loss is : 0.12687420845031738\n",
      "The MSE loss is : 0.12687420845031738\n",
      "The MSE loss is : 0.12687420845031738\n",
      "The MSE loss is : 0.12687420845031738\n",
      "The MSE loss is : 0.12687420845031738\n",
      "The MSE loss is : 0.12687423825263977\n",
      "The MSE loss is : 0.12687422335147858\n",
      "The MSE loss is : 0.12687422335147858\n",
      "The MSE loss is : 0.12687420845031738\n",
      "The MSE loss is : 0.12687420845031738\n",
      "The MSE loss is : 0.12687420845031738\n",
      "The MSE loss is : 0.12687422335147858\n",
      "Saving... file:record_err_16 method:block-sqrt\n",
      "Saving... file:record_err_16 method:lowR-same-param\n",
      "Saving... file:record_err_16 method:lowR-samex2\n",
      "Saving... file:record_err_16 method:lowR-half\n",
      "The MSE loss is : 0.635647714138031\n",
      "The MSE loss is : 0.0012920242734253407\n",
      "The MSE loss is : 1.251684625458438e-05\n",
      "The MSE loss is : 2.6810036501956347e-07\n",
      "The MSE loss is : 7.448341388105462e-10\n",
      "The MSE loss is : 1.7013228933299152e-12\n",
      "The MSE loss is : 6.411510862155967e-14\n",
      "The MSE loss is : 4.4516831193552875e-11\n",
      "The MSE loss is : 1.3268229848151236e-09\n",
      "The MSE loss is : 1.5388998964027678e-09\n",
      "The MSE loss is : 9.802536737879564e-08\n",
      "The MSE loss is : 1.4093228628553334e-07\n",
      "The MSE loss is : 1.3666255682664996e-08\n",
      "The MSE loss is : 3.1345280149253085e-08\n",
      "The MSE loss is : 1.995771157226045e-07\n",
      "The MSE loss is : 1.2262592008482898e-07\n",
      "The MSE loss is : 3.434609823216306e-07\n",
      "The MSE loss is : 7.888937858524514e-08\n",
      "The MSE loss is : 8.715831611993963e-09\n",
      "The MSE loss is : 2.3274495219993696e-08\n",
      "Saving... file:record_err_16 method:pair-Add\n",
      "The MSE loss is : 0.4229538142681122\n",
      "The MSE loss is : 0.009913933463394642\n",
      "The MSE loss is : 0.002016452606767416\n",
      "The MSE loss is : 0.0013551420997828245\n",
      "The MSE loss is : 0.0005889875465072691\n",
      "The MSE loss is : 0.0004425385850481689\n",
      "The MSE loss is : 0.0005473256460390985\n",
      "The MSE loss is : 0.0002882455592043698\n",
      "The MSE loss is : 0.00027963740285485983\n",
      "The MSE loss is : 0.00021393518545664847\n",
      "The MSE loss is : 0.0002854826161637902\n",
      "The MSE loss is : 0.00016732074436731637\n",
      "The MSE loss is : 0.00021224608644843102\n",
      "The MSE loss is : 0.0008667243528179824\n",
      "The MSE loss is : 0.00012092304677935317\n",
      "The MSE loss is : 0.00011523131979629397\n",
      "The MSE loss is : 8.599275315646082e-05\n",
      "The MSE loss is : 7.99161207396537e-05\n",
      "The MSE loss is : 7.592415931867436e-05\n",
      "The MSE loss is : 7.858954631956294e-05\n",
      "Saving... file:record_err_16 method:pair-Seq\n",
      "\n",
      "Experiment N=16 SEED=987\n",
      "The MSE loss is : 0.3883516192436218\n",
      "The MSE loss is : 0.16091707348823547\n",
      "The MSE loss is : 0.15628327429294586\n",
      "The MSE loss is : 0.15628327429294586\n",
      "The MSE loss is : 0.15628328919410706\n",
      "The MSE loss is : 0.15628327429294586\n",
      "The MSE loss is : 0.15628327429294586\n",
      "The MSE loss is : 0.15628325939178467\n",
      "The MSE loss is : 0.15628327429294586\n",
      "The MSE loss is : 0.15628328919410706\n",
      "The MSE loss is : 0.15628328919410706\n",
      "The MSE loss is : 0.15628328919410706\n",
      "The MSE loss is : 0.15628334879875183\n",
      "The MSE loss is : 0.15628331899642944\n",
      "The MSE loss is : 0.15628328919410706\n",
      "The MSE loss is : 0.1562834531068802\n",
      "The MSE loss is : 0.15628337860107422\n",
      "The MSE loss is : 0.15628327429294586\n",
      "The MSE loss is : 0.15628328919410706\n",
      "The MSE loss is : 0.15628330409526825\n",
      "Saving... file:record_err_16 method:pair\n",
      "The MSE loss is : 0.3883516192436218\n",
      "The MSE loss is : 0.24475620687007904\n",
      "The MSE loss is : 0.2447109818458557\n",
      "The MSE loss is : 0.24470239877700806\n",
      "The MSE loss is : 0.24469836056232452\n",
      "The MSE loss is : 0.24469557404518127\n",
      "The MSE loss is : 0.2446931004524231\n",
      "The MSE loss is : 0.24469177424907684\n",
      "The MSE loss is : 0.24469169974327087\n",
      "The MSE loss is : 0.24469169974327087\n",
      "The MSE loss is : 0.24469169974327087\n",
      "The MSE loss is : 0.24469169974327087\n",
      "The MSE loss is : 0.24469171464443207\n",
      "The MSE loss is : 0.24469169974327087\n",
      "The MSE loss is : 0.24469169974327087\n",
      "The MSE loss is : 0.24469169974327087\n",
      "The MSE loss is : 0.24469172954559326\n",
      "The MSE loss is : 0.24469169974327087\n",
      "The MSE loss is : 0.24469169974327087\n",
      "The MSE loss is : 0.24469169974327087\n",
      "Saving... file:record_err_16 method:block-sqrt-half\n",
      "The MSE loss is : 0.3883516192436218\n",
      "The MSE loss is : 0.12379935383796692\n",
      "The MSE loss is : 0.12311729043722153\n",
      "The MSE loss is : 0.12311729043722153\n",
      "The MSE loss is : 0.12311729043722153\n",
      "The MSE loss is : 0.12311728298664093\n",
      "The MSE loss is : 0.12311729043722153\n",
      "The MSE loss is : 0.12311729043722153\n",
      "The MSE loss is : 0.12311729043722153\n",
      "The MSE loss is : 0.12311729043722153\n",
      "The MSE loss is : 0.12311729788780212\n",
      "The MSE loss is : 0.12311728298664093\n",
      "The MSE loss is : 0.12311729043722153\n",
      "The MSE loss is : 0.12311729043722153\n",
      "The MSE loss is : 0.12311729043722153\n",
      "The MSE loss is : 0.12311729043722153\n",
      "The MSE loss is : 0.12311729788780212\n",
      "The MSE loss is : 0.12311729788780212\n",
      "The MSE loss is : 0.12311729043722153\n",
      "The MSE loss is : 0.12311730533838272\n",
      "Saving... file:record_err_16 method:block-sqrt\n",
      "Saving... file:record_err_16 method:lowR-same-param\n",
      "Saving... file:record_err_16 method:lowR-samex2\n",
      "Saving... file:record_err_16 method:lowR-half\n",
      "The MSE loss is : 0.5732505321502686\n",
      "The MSE loss is : 0.0009074890404008329\n",
      "The MSE loss is : 6.133531860541552e-05\n",
      "The MSE loss is : 2.7061150831286795e-06\n",
      "The MSE loss is : 1.2899864998416888e-07\n",
      "The MSE loss is : 4.684971344204314e-08\n",
      "The MSE loss is : 9.572338477426001e-09\n",
      "The MSE loss is : 1.2331125009978905e-09\n",
      "The MSE loss is : 3.013975629073684e-07\n",
      "The MSE loss is : 3.626174134296889e-07\n",
      "The MSE loss is : 9.297558833942787e-10\n",
      "The MSE loss is : 4.417635324216462e-08\n",
      "The MSE loss is : 9.028413217038178e-08\n",
      "The MSE loss is : 3.039553462258482e-07\n",
      "The MSE loss is : 1.453402092010947e-07\n",
      "The MSE loss is : 5.44623262044297e-08\n",
      "The MSE loss is : 4.785634644122183e-08\n",
      "The MSE loss is : 4.7410726011776205e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 7.715663059570943e-07\n",
      "The MSE loss is : 2.976347843741678e-07\n",
      "Saving... file:record_err_16 method:pair-Add\n",
      "The MSE loss is : 0.37310969829559326\n",
      "The MSE loss is : 0.008875211700797081\n",
      "The MSE loss is : 0.0027337484061717987\n",
      "The MSE loss is : 0.0016565074911341071\n",
      "The MSE loss is : 0.0007464430527761579\n",
      "The MSE loss is : 0.00032948862644843757\n",
      "The MSE loss is : 0.00021393978386186063\n",
      "The MSE loss is : 0.0001385626383125782\n",
      "The MSE loss is : 0.0001308194041484967\n",
      "The MSE loss is : 0.00014170113718137145\n",
      "The MSE loss is : 6.158198812045157e-05\n",
      "The MSE loss is : 5.1572736992966384e-05\n",
      "The MSE loss is : 9.520571620669216e-05\n",
      "The MSE loss is : 9.024006430990994e-05\n",
      "The MSE loss is : 3.377209941390902e-05\n",
      "The MSE loss is : 2.9479975637514144e-05\n",
      "The MSE loss is : 2.963114638987463e-05\n",
      "The MSE loss is : 3.390208803466521e-05\n",
      "The MSE loss is : 2.4143084374372847e-05\n",
      "The MSE loss is : 2.505116572137922e-05\n",
      "Saving... file:record_err_16 method:pair-Seq\n",
      "\n",
      "Experiment N=16 SEED=741\n",
      "The MSE loss is : 0.4133562445640564\n",
      "The MSE loss is : 0.1633908748626709\n",
      "The MSE loss is : 0.16033053398132324\n",
      "The MSE loss is : 0.16033053398132324\n",
      "The MSE loss is : 0.16033050417900085\n",
      "The MSE loss is : 0.16033053398132324\n",
      "The MSE loss is : 0.16033053398132324\n",
      "The MSE loss is : 0.16033051908016205\n",
      "The MSE loss is : 0.16033051908016205\n",
      "The MSE loss is : 0.16033053398132324\n",
      "The MSE loss is : 0.16033053398132324\n",
      "The MSE loss is : 0.16033053398132324\n",
      "The MSE loss is : 0.16033053398132324\n",
      "The MSE loss is : 0.16033053398132324\n",
      "The MSE loss is : 0.16033056378364563\n",
      "The MSE loss is : 0.16033056378364563\n",
      "The MSE loss is : 0.16033051908016205\n",
      "The MSE loss is : 0.16033056378364563\n",
      "The MSE loss is : 0.16033068299293518\n",
      "The MSE loss is : 0.16033057868480682\n",
      "Saving... file:record_err_16 method:pair\n",
      "The MSE loss is : 0.4133562445640564\n",
      "The MSE loss is : 0.23330992460250854\n",
      "The MSE loss is : 0.23319052159786224\n",
      "The MSE loss is : 0.2331523895263672\n",
      "The MSE loss is : 0.23311306536197662\n",
      "The MSE loss is : 0.23307952284812927\n",
      "The MSE loss is : 0.23306094110012054\n",
      "The MSE loss is : 0.23305359482765198\n",
      "The MSE loss is : 0.23305194079875946\n",
      "The MSE loss is : 0.23305156826972961\n",
      "The MSE loss is : 0.2330513596534729\n",
      "The MSE loss is : 0.23305124044418335\n",
      "The MSE loss is : 0.233051136136055\n",
      "The MSE loss is : 0.23305107653141022\n",
      "The MSE loss is : 0.23305128514766693\n",
      "The MSE loss is : 0.23305100202560425\n",
      "The MSE loss is : 0.23305106163024902\n",
      "The MSE loss is : 0.23305100202560425\n",
      "The MSE loss is : 0.2330508828163147\n",
      "The MSE loss is : 0.2330508828163147\n",
      "Saving... file:record_err_16 method:block-sqrt-half\n",
      "The MSE loss is : 0.4133562445640564\n",
      "The MSE loss is : 0.13657468557357788\n",
      "The MSE loss is : 0.13206414878368378\n",
      "The MSE loss is : 0.13206414878368378\n",
      "The MSE loss is : 0.13206414878368378\n",
      "The MSE loss is : 0.13206416368484497\n",
      "The MSE loss is : 0.13206416368484497\n",
      "The MSE loss is : 0.13206416368484497\n",
      "The MSE loss is : 0.13206414878368378\n",
      "The MSE loss is : 0.13206414878368378\n",
      "The MSE loss is : 0.13206414878368378\n",
      "The MSE loss is : 0.13206414878368378\n",
      "The MSE loss is : 0.13206416368484497\n",
      "The MSE loss is : 0.13206416368484497\n",
      "The MSE loss is : 0.13206416368484497\n",
      "The MSE loss is : 0.13206416368484497\n",
      "The MSE loss is : 0.13206416368484497\n",
      "The MSE loss is : 0.13206416368484497\n",
      "The MSE loss is : 0.13206416368484497\n",
      "The MSE loss is : 0.13206416368484497\n",
      "Saving... file:record_err_16 method:block-sqrt\n",
      "Saving... file:record_err_16 method:lowR-same-param\n",
      "Saving... file:record_err_16 method:lowR-samex2\n",
      "Saving... file:record_err_16 method:lowR-half\n",
      "The MSE loss is : 0.6637014746665955\n",
      "The MSE loss is : 0.0008950192714110017\n",
      "The MSE loss is : 1.8858703697333112e-05\n",
      "The MSE loss is : 1.2485733122957754e-06\n",
      "The MSE loss is : 4.620954996426008e-08\n",
      "The MSE loss is : 4.764609817797805e-10\n",
      "The MSE loss is : 1.4971322792600716e-11\n",
      "The MSE loss is : 7.344971741929385e-09\n",
      "The MSE loss is : 4.714360812840823e-08\n",
      "The MSE loss is : 1.1786482900788542e-07\n",
      "The MSE loss is : 1.692116882168193e-07\n",
      "The MSE loss is : 1.1340855508024106e-06\n",
      "The MSE loss is : 1.130705186369596e-06\n",
      "The MSE loss is : 1.7785723116503505e-08\n",
      "The MSE loss is : 5.02269728031024e-08\n",
      "The MSE loss is : 7.002429924796161e-08\n",
      "The MSE loss is : 6.195964630251183e-08\n",
      "The MSE loss is : 3.1779120490682544e-07\n",
      "The MSE loss is : 4.56592985642601e-08\n",
      "The MSE loss is : 3.660739480437769e-07\n",
      "Saving... file:record_err_16 method:pair-Add\n",
      "The MSE loss is : 0.3524753153324127\n",
      "The MSE loss is : 0.00943031907081604\n",
      "The MSE loss is : 0.0062073878943920135\n",
      "The MSE loss is : 0.004426246974617243\n",
      "The MSE loss is : 0.0038872710429131985\n",
      "The MSE loss is : 0.0037034323904663324\n",
      "The MSE loss is : 0.0030087309423834085\n",
      "The MSE loss is : 0.00271431403234601\n",
      "The MSE loss is : 0.004056895151734352\n",
      "The MSE loss is : 0.0022421828471124172\n",
      "The MSE loss is : 0.002079182770103216\n",
      "The MSE loss is : 0.0019098353805020452\n",
      "The MSE loss is : 0.001741685438901186\n",
      "The MSE loss is : 0.0016232983907684684\n",
      "The MSE loss is : 0.001550160814076662\n",
      "The MSE loss is : 0.0015105511993169785\n",
      "The MSE loss is : 0.0014762076316401362\n",
      "The MSE loss is : 0.001472722738981247\n",
      "The MSE loss is : 0.0015119987074285746\n",
      "The MSE loss is : 0.0015031739603728056\n",
      "Saving... file:record_err_16 method:pair-Seq\n",
      "\n",
      "Experiment N=16 SEED=852\n",
      "The MSE loss is : 0.34934666752815247\n",
      "The MSE loss is : 0.17059430480003357\n",
      "The MSE loss is : 0.16728739440441132\n",
      "The MSE loss is : 0.16728737950325012\n",
      "The MSE loss is : 0.1672874093055725\n",
      "The MSE loss is : 0.16728739440441132\n",
      "The MSE loss is : 0.16728737950325012\n",
      "The MSE loss is : 0.16728739440441132\n",
      "The MSE loss is : 0.16728739440441132\n",
      "The MSE loss is : 0.1672874093055725\n",
      "The MSE loss is : 0.16728739440441132\n",
      "The MSE loss is : 0.16728737950325012\n",
      "The MSE loss is : 0.1672874093055725\n",
      "The MSE loss is : 0.16728739440441132\n",
      "The MSE loss is : 0.16728739440441132\n",
      "The MSE loss is : 0.16728739440441132\n",
      "The MSE loss is : 0.1672874391078949\n",
      "The MSE loss is : 0.1672874093055725\n",
      "The MSE loss is : 0.16728739440441132\n",
      "The MSE loss is : 0.16728739440441132\n",
      "Saving... file:record_err_16 method:pair\n",
      "The MSE loss is : 0.34934666752815247\n",
      "The MSE loss is : 0.2428802251815796\n",
      "The MSE loss is : 0.24168722331523895\n",
      "The MSE loss is : 0.2415814846754074\n",
      "The MSE loss is : 0.24156610667705536\n",
      "The MSE loss is : 0.24155999720096588\n",
      "The MSE loss is : 0.2415570467710495\n",
      "The MSE loss is : 0.24155555665493011\n",
      "The MSE loss is : 0.24155476689338684\n",
      "The MSE loss is : 0.24155408143997192\n",
      "The MSE loss is : 0.24155369400978088\n",
      "The MSE loss is : 0.2415536791086197\n",
      "The MSE loss is : 0.2415531724691391\n",
      "The MSE loss is : 0.24155297875404358\n",
      "The MSE loss is : 0.2415529191493988\n",
      "The MSE loss is : 0.24155515432357788\n",
      "The MSE loss is : 0.24155263602733612\n",
      "The MSE loss is : 0.24155254662036896\n",
      "The MSE loss is : 0.2415526658296585\n",
      "The MSE loss is : 0.2415524125099182\n",
      "Saving... file:record_err_16 method:block-sqrt-half\n",
      "The MSE loss is : 0.34934666752815247\n",
      "The MSE loss is : 0.11941197514533997\n",
      "The MSE loss is : 0.1194063127040863\n",
      "The MSE loss is : 0.1194063052535057\n",
      "The MSE loss is : 0.1194063127040863\n",
      "The MSE loss is : 0.1194063052535057\n",
      "The MSE loss is : 0.1194063052535057\n",
      "The MSE loss is : 0.1194063052535057\n",
      "The MSE loss is : 0.1194063052535057\n",
      "The MSE loss is : 0.1194063052535057\n",
      "The MSE loss is : 0.11940629780292511\n",
      "The MSE loss is : 0.1194063052535057\n",
      "The MSE loss is : 0.1194063052535057\n",
      "The MSE loss is : 0.1194063127040863\n",
      "The MSE loss is : 0.1194063127040863\n",
      "The MSE loss is : 0.1194063127040863\n",
      "The MSE loss is : 0.1194063201546669\n",
      "The MSE loss is : 0.1194063052535057\n",
      "The MSE loss is : 0.1194063127040863\n",
      "The MSE loss is : 0.1194063052535057\n",
      "Saving... file:record_err_16 method:block-sqrt\n",
      "Saving... file:record_err_16 method:lowR-same-param\n",
      "Saving... file:record_err_16 method:lowR-samex2\n",
      "Saving... file:record_err_16 method:lowR-half\n",
      "The MSE loss is : 0.5837555527687073\n",
      "The MSE loss is : 0.0007611654582433403\n",
      "The MSE loss is : 2.8451642720028758e-05\n",
      "The MSE loss is : 3.0681084695061145e-07\n",
      "The MSE loss is : 7.841709503964012e-10\n",
      "The MSE loss is : 3.0440800991016204e-09\n",
      "The MSE loss is : 1.6282299952763424e-08\n",
      "The MSE loss is : 5.711250850026772e-08\n",
      "The MSE loss is : 1.8698631265579024e-07\n",
      "The MSE loss is : 7.316021424230712e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 8.353540081884603e-11\n",
      "The MSE loss is : 1.0218498047720459e-08\n",
      "The MSE loss is : 3.0711794352100696e-07\n",
      "The MSE loss is : 6.395468972186791e-07\n",
      "The MSE loss is : 3.6084564669636165e-08\n",
      "The MSE loss is : 2.0687730639679103e-08\n",
      "The MSE loss is : 8.595994245297334e-07\n",
      "The MSE loss is : 1.9105374349237536e-07\n",
      "The MSE loss is : 9.468757156128049e-08\n",
      "The MSE loss is : 1.4491222088963696e-07\n",
      "Saving... file:record_err_16 method:pair-Add\n",
      "The MSE loss is : 0.3898633122444153\n",
      "The MSE loss is : 0.010697370395064354\n",
      "The MSE loss is : 0.004760080948472023\n",
      "The MSE loss is : 0.003046631347388029\n",
      "The MSE loss is : 0.002364989835768938\n",
      "The MSE loss is : 0.0017843737732619047\n",
      "The MSE loss is : 0.001550428569316864\n",
      "The MSE loss is : 0.001423489535227418\n",
      "The MSE loss is : 0.0013357073767110705\n",
      "The MSE loss is : 0.0013378255534917116\n",
      "The MSE loss is : 0.0013657801318913698\n",
      "The MSE loss is : 0.001234433613717556\n",
      "The MSE loss is : 0.001282531302422285\n",
      "The MSE loss is : 0.0012634628219529986\n",
      "The MSE loss is : 0.001178491162136197\n",
      "The MSE loss is : 0.0017595202662050724\n",
      "The MSE loss is : 0.001170608215034008\n",
      "The MSE loss is : 0.0011853956384584308\n",
      "The MSE loss is : 0.001147485920228064\n",
      "The MSE loss is : 0.0011533037759363651\n",
      "Saving... file:record_err_16 method:pair-Seq\n",
      "\n",
      "Experiment N=16 SEED=963\n",
      "The MSE loss is : 0.41200926899909973\n",
      "The MSE loss is : 0.1737443208694458\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360085248947144\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360079288482666\n",
      "The MSE loss is : 0.17360085248947144\n",
      "The MSE loss is : 0.17360079288482666\n",
      "Saving... file:record_err_16 method:pair\n",
      "The MSE loss is : 0.41200926899909973\n",
      "The MSE loss is : 0.26853886246681213\n",
      "The MSE loss is : 0.2668330669403076\n",
      "The MSE loss is : 0.2667086124420166\n",
      "The MSE loss is : 0.26668450236320496\n",
      "The MSE loss is : 0.2666797637939453\n",
      "The MSE loss is : 0.26667776703834534\n",
      "The MSE loss is : 0.2666776180267334\n",
      "The MSE loss is : 0.26667651534080505\n",
      "The MSE loss is : 0.2666758596897125\n",
      "The MSE loss is : 0.26667535305023193\n",
      "The MSE loss is : 0.26667511463165283\n",
      "The MSE loss is : 0.2666749656200409\n",
      "The MSE loss is : 0.26667481660842896\n",
      "The MSE loss is : 0.2666763663291931\n",
      "The MSE loss is : 0.2666746973991394\n",
      "The MSE loss is : 0.2666745185852051\n",
      "The MSE loss is : 0.26667511463165283\n",
      "The MSE loss is : 0.2666744291782379\n",
      "The MSE loss is : 0.2666744589805603\n",
      "Saving... file:record_err_16 method:block-sqrt-half\n",
      "The MSE loss is : 0.41200926899909973\n",
      "The MSE loss is : 0.14638039469718933\n",
      "The MSE loss is : 0.14556796848773956\n",
      "The MSE loss is : 0.14554855227470398\n",
      "The MSE loss is : 0.14554819464683533\n",
      "The MSE loss is : 0.14554819464683533\n",
      "The MSE loss is : 0.14554819464683533\n",
      "The MSE loss is : 0.14554819464683533\n",
      "The MSE loss is : 0.14554819464683533\n",
      "The MSE loss is : 0.14554819464683533\n",
      "The MSE loss is : 0.14554819464683533\n",
      "The MSE loss is : 0.14554819464683533\n",
      "The MSE loss is : 0.14554819464683533\n",
      "The MSE loss is : 0.14554819464683533\n",
      "The MSE loss is : 0.14554819464683533\n",
      "The MSE loss is : 0.14554819464683533\n",
      "The MSE loss is : 0.14554820954799652\n",
      "The MSE loss is : 0.14554820954799652\n",
      "The MSE loss is : 0.14554820954799652\n",
      "The MSE loss is : 0.14554819464683533\n",
      "Saving... file:record_err_16 method:block-sqrt\n",
      "Saving... file:record_err_16 method:lowR-same-param\n",
      "Saving... file:record_err_16 method:lowR-samex2\n",
      "Saving... file:record_err_16 method:lowR-half\n",
      "The MSE loss is : 0.6693034172058105\n",
      "The MSE loss is : 0.001940661808475852\n",
      "The MSE loss is : 0.00015915023686829954\n",
      "The MSE loss is : 1.7666547137196176e-05\n",
      "The MSE loss is : 4.819083642360056e-06\n",
      "The MSE loss is : 1.852363311627414e-06\n",
      "The MSE loss is : 4.344236117503897e-07\n",
      "The MSE loss is : 1.1783220621452983e-08\n",
      "The MSE loss is : 3.0961423647113406e-08\n",
      "The MSE loss is : 1.5972034361766418e-07\n",
      "The MSE loss is : 1.1035930924663262e-07\n",
      "The MSE loss is : 1.936129905288908e-07\n",
      "The MSE loss is : 3.6116352131188023e-09\n",
      "The MSE loss is : 5.667443758738955e-08\n",
      "The MSE loss is : 4.109607942837101e-08\n",
      "The MSE loss is : 4.313956480928027e-08\n",
      "The MSE loss is : 1.399788374101263e-07\n",
      "The MSE loss is : 3.984436602877395e-07\n",
      "The MSE loss is : 2.1898955537835718e-07\n",
      "The MSE loss is : 2.6537364306022937e-07\n",
      "Saving... file:record_err_16 method:pair-Add\n",
      "The MSE loss is : 0.3582906424999237\n",
      "The MSE loss is : 0.00761654507368803\n",
      "The MSE loss is : 0.002994030946865678\n",
      "The MSE loss is : 0.0022461528424173594\n",
      "The MSE loss is : 0.0018238998018205166\n",
      "The MSE loss is : 0.0016027435194700956\n",
      "The MSE loss is : 0.001434149919077754\n",
      "The MSE loss is : 0.0012950743548572063\n",
      "The MSE loss is : 0.001185661181807518\n",
      "The MSE loss is : 0.001058220281265676\n",
      "The MSE loss is : 0.0010029987897723913\n",
      "The MSE loss is : 0.0008509654435329139\n",
      "The MSE loss is : 0.0032090984750539064\n",
      "The MSE loss is : 0.0006985794752836227\n",
      "The MSE loss is : 0.0007516600890085101\n",
      "The MSE loss is : 0.0006272231694310904\n",
      "The MSE loss is : 0.0005881086690351367\n",
      "The MSE loss is : 0.0005707531236112118\n",
      "The MSE loss is : 0.0005335013847798109\n",
      "The MSE loss is : 0.0005237361183390021\n",
      "Saving... file:record_err_16 method:pair-Seq\n",
      "\n",
      "Experiment N=16 SEED=159\n",
      "The MSE loss is : 0.3495132029056549\n",
      "The MSE loss is : 0.17879512906074524\n",
      "The MSE loss is : 0.17287248373031616\n",
      "The MSE loss is : 0.17287078499794006\n",
      "The MSE loss is : 0.17287078499794006\n",
      "The MSE loss is : 0.17287078499794006\n",
      "The MSE loss is : 0.17287078499794006\n",
      "The MSE loss is : 0.17287078499794006\n",
      "The MSE loss is : 0.17287079989910126\n",
      "The MSE loss is : 0.17287078499794006\n",
      "The MSE loss is : 0.17287079989910126\n",
      "The MSE loss is : 0.17287078499794006\n",
      "The MSE loss is : 0.17287090420722961\n",
      "The MSE loss is : 0.17287079989910126\n",
      "The MSE loss is : 0.17287078499794006\n",
      "The MSE loss is : 0.17287078499794006\n",
      "The MSE loss is : 0.17287078499794006\n",
      "The MSE loss is : 0.17287078499794006\n",
      "The MSE loss is : 0.17287078499794006\n",
      "The MSE loss is : 0.17287077009677887\n",
      "Saving... file:record_err_16 method:pair\n",
      "The MSE loss is : 0.3495132029056549\n",
      "The MSE loss is : 0.24886727333068848\n",
      "The MSE loss is : 0.24826033413410187\n",
      "The MSE loss is : 0.24820885062217712\n",
      "The MSE loss is : 0.2481815665960312\n",
      "The MSE loss is : 0.24815233051776886\n",
      "The MSE loss is : 0.24813905358314514\n",
      "The MSE loss is : 0.2481364905834198\n",
      "The MSE loss is : 0.24813494086265564\n",
      "The MSE loss is : 0.24813392758369446\n",
      "The MSE loss is : 0.24813328683376312\n",
      "The MSE loss is : 0.2481328248977661\n",
      "The MSE loss is : 0.24813249707221985\n",
      "The MSE loss is : 0.24813243746757507\n",
      "The MSE loss is : 0.24813199043273926\n",
      "The MSE loss is : 0.24813181161880493\n",
      "The MSE loss is : 0.2481316775083542\n",
      "The MSE loss is : 0.24813154339790344\n",
      "The MSE loss is : 0.2481314241886139\n",
      "The MSE loss is : 0.2481313794851303\n",
      "Saving... file:record_err_16 method:block-sqrt-half\n",
      "The MSE loss is : 0.3495132029056549\n",
      "The MSE loss is : 0.13489694893360138\n",
      "The MSE loss is : 0.13488967716693878\n",
      "The MSE loss is : 0.13488967716693878\n",
      "The MSE loss is : 0.13488967716693878\n",
      "The MSE loss is : 0.13488967716693878\n",
      "The MSE loss is : 0.13488967716693878\n",
      "The MSE loss is : 0.13488967716693878\n",
      "The MSE loss is : 0.13488967716693878\n",
      "The MSE loss is : 0.13488967716693878\n",
      "The MSE loss is : 0.13488967716693878\n",
      "The MSE loss is : 0.13488969206809998\n",
      "The MSE loss is : 0.13488967716693878\n",
      "The MSE loss is : 0.13488969206809998\n",
      "The MSE loss is : 0.13488970696926117\n",
      "The MSE loss is : 0.13488969206809998\n",
      "The MSE loss is : 0.13488969206809998\n",
      "The MSE loss is : 0.13488969206809998\n",
      "The MSE loss is : 0.13488969206809998\n",
      "The MSE loss is : 0.13488969206809998\n",
      "Saving... file:record_err_16 method:block-sqrt\n",
      "Saving... file:record_err_16 method:lowR-same-param\n",
      "Saving... file:record_err_16 method:lowR-samex2\n",
      "Saving... file:record_err_16 method:lowR-half\n",
      "The MSE loss is : 0.6273735165596008\n",
      "The MSE loss is : 0.0015773316845297813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 7.102359086275101e-05\n",
      "The MSE loss is : 7.855265948819579e-07\n",
      "The MSE loss is : 3.4771650003762034e-09\n",
      "The MSE loss is : 1.9450725752268028e-12\n",
      "The MSE loss is : 1.869742138893571e-09\n",
      "The MSE loss is : 6.032530031063743e-11\n",
      "The MSE loss is : 8.849185828552208e-10\n",
      "The MSE loss is : 2.4650241847723464e-09\n",
      "The MSE loss is : 5.6534229742055686e-08\n",
      "The MSE loss is : 6.429482368730532e-08\n",
      "The MSE loss is : 2.413103175058495e-07\n",
      "The MSE loss is : 2.701669465920986e-08\n",
      "The MSE loss is : 4.7910923228755564e-08\n",
      "The MSE loss is : 1.4791190494634066e-07\n",
      "The MSE loss is : 8.705831078259507e-08\n",
      "The MSE loss is : 8.492897052292392e-09\n",
      "The MSE loss is : 3.117419851150771e-07\n",
      "The MSE loss is : 2.5380546730957576e-07\n",
      "Saving... file:record_err_16 method:pair-Add\n",
      "The MSE loss is : 0.4067365527153015\n",
      "The MSE loss is : 0.00888041965663433\n",
      "The MSE loss is : 0.0030672280117869377\n",
      "The MSE loss is : 0.0018043221207335591\n",
      "The MSE loss is : 0.0013898363104090095\n",
      "The MSE loss is : 0.0015080434968695045\n",
      "The MSE loss is : 0.0008782619261182845\n",
      "The MSE loss is : 0.0007662073476240039\n",
      "The MSE loss is : 0.000704847858287394\n",
      "The MSE loss is : 0.0006576753221452236\n",
      "The MSE loss is : 0.0006147186504676938\n",
      "The MSE loss is : 0.0005775903700850904\n",
      "The MSE loss is : 0.0005285111255943775\n",
      "The MSE loss is : 0.0004754914261866361\n",
      "The MSE loss is : 0.00042632658733054996\n",
      "The MSE loss is : 0.0004244341398589313\n",
      "The MSE loss is : 0.0003630422579590231\n",
      "The MSE loss is : 0.000324562715832144\n",
      "The MSE loss is : 0.0004132299218326807\n",
      "The MSE loss is : 0.0003507126239128411\n",
      "Saving... file:record_err_16 method:pair-Seq\n",
      "\n",
      "Experiment N=16 SEED=357\n",
      "The MSE loss is : 0.434495747089386\n",
      "The MSE loss is : 0.19047927856445312\n",
      "The MSE loss is : 0.17557549476623535\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.1755743771791458\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.17557433247566223\n",
      "The MSE loss is : 0.17557445168495178\n",
      "The MSE loss is : 0.17557433247566223\n",
      "Saving... file:record_err_16 method:pair\n",
      "The MSE loss is : 0.434495747089386\n",
      "The MSE loss is : 0.26558786630630493\n",
      "The MSE loss is : 0.2652730941772461\n",
      "The MSE loss is : 0.2651562988758087\n",
      "The MSE loss is : 0.2651434540748596\n",
      "The MSE loss is : 0.26513925194740295\n",
      "The MSE loss is : 0.2651374936103821\n",
      "The MSE loss is : 0.2651365101337433\n",
      "The MSE loss is : 0.265135794878006\n",
      "The MSE loss is : 0.26513582468032837\n",
      "The MSE loss is : 0.2651350498199463\n",
      "The MSE loss is : 0.2651348114013672\n",
      "The MSE loss is : 0.26513463258743286\n",
      "The MSE loss is : 0.26513510942459106\n",
      "The MSE loss is : 0.26513463258743286\n",
      "The MSE loss is : 0.26513445377349854\n",
      "The MSE loss is : 0.26513421535491943\n",
      "The MSE loss is : 0.26513445377349854\n",
      "The MSE loss is : 0.26513418555259705\n",
      "The MSE loss is : 0.2651340365409851\n",
      "Saving... file:record_err_16 method:block-sqrt-half\n",
      "The MSE loss is : 0.434495747089386\n",
      "The MSE loss is : 0.16010785102844238\n",
      "The MSE loss is : 0.15519779920578003\n",
      "The MSE loss is : 0.15504932403564453\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "The MSE loss is : 0.1550481915473938\n",
      "Saving... file:record_err_16 method:block-sqrt\n",
      "Saving... file:record_err_16 method:lowR-same-param\n",
      "Saving... file:record_err_16 method:lowR-samex2\n",
      "Saving... file:record_err_16 method:lowR-half\n",
      "The MSE loss is : 0.6255087852478027\n",
      "The MSE loss is : 0.0019043204374611378\n",
      "The MSE loss is : 2.6326240913476795e-05\n",
      "The MSE loss is : 3.8745699271203193e-07\n",
      "The MSE loss is : 1.3492181816232574e-09\n",
      "The MSE loss is : 1.0225921671935811e-12\n",
      "The MSE loss is : 8.37783353802024e-09\n",
      "The MSE loss is : 3.5087879268758115e-08\n",
      "The MSE loss is : 1.221273498996922e-10\n",
      "The MSE loss is : 9.338849693563134e-09\n",
      "The MSE loss is : 4.313660610932857e-07\n",
      "The MSE loss is : 4.241731517140579e-07\n",
      "The MSE loss is : 2.9305402904356015e-07\n",
      "The MSE loss is : 6.766923661416513e-07\n",
      "The MSE loss is : 7.755222952710028e-08\n",
      "The MSE loss is : 4.148381194113426e-08\n",
      "The MSE loss is : 4.632428840523062e-07\n",
      "The MSE loss is : 9.51452108211015e-08\n",
      "The MSE loss is : 1.3955889244243735e-07\n",
      "The MSE loss is : 7.713225613770192e-07\n",
      "Saving... file:record_err_16 method:pair-Add\n",
      "The MSE loss is : 0.41951146721839905\n",
      "The MSE loss is : 0.01365432795137167\n",
      "The MSE loss is : 0.007032441906630993\n",
      "The MSE loss is : 0.0051468731835484505\n",
      "The MSE loss is : 0.0039739953354001045\n",
      "The MSE loss is : 0.0035461504012346268\n",
      "The MSE loss is : 0.003298189491033554\n",
      "The MSE loss is : 0.0031665475107729435\n",
      "The MSE loss is : 0.003027559956535697\n",
      "The MSE loss is : 0.0028976064641028643\n",
      "The MSE loss is : 0.002727089449763298\n",
      "The MSE loss is : 0.0026078661903738976\n",
      "The MSE loss is : 0.0032356497831642628\n",
      "The MSE loss is : 0.001819030032493174\n",
      "The MSE loss is : 0.001564770587719977\n",
      "The MSE loss is : 0.0018285127589479089\n",
      "The MSE loss is : 0.0013214170467108488\n",
      "The MSE loss is : 0.0012303321855142713\n",
      "The MSE loss is : 0.0011798373889178038\n",
      "The MSE loss is : 0.0011663957266137004\n",
      "Saving... file:record_err_16 method:pair-Seq\n",
      "\n",
      "Experiment N=16 SEED=951\n",
      "The MSE loss is : 0.3989333212375641\n",
      "The MSE loss is : 0.18452133238315582\n",
      "The MSE loss is : 0.1768490970134735\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684872448444366\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684873938560486\n",
      "The MSE loss is : 0.17684878408908844\n",
      "The MSE loss is : 0.17684878408908844\n",
      "Saving... file:record_err_16 method:pair\n",
      "The MSE loss is : 0.3989333212375641\n",
      "The MSE loss is : 0.2672269344329834\n",
      "The MSE loss is : 0.26603490114212036\n",
      "The MSE loss is : 0.26316601037979126\n",
      "The MSE loss is : 0.26302993297576904\n",
      "The MSE loss is : 0.2630206048488617\n",
      "The MSE loss is : 0.2630153000354767\n",
      "The MSE loss is : 0.2629539370536804\n",
      "The MSE loss is : 0.26275888085365295\n",
      "The MSE loss is : 0.26275843381881714\n",
      "The MSE loss is : 0.26275795698165894\n",
      "The MSE loss is : 0.26275768876075745\n",
      "The MSE loss is : 0.26275745034217834\n",
      "The MSE loss is : 0.2627592384815216\n",
      "The MSE loss is : 0.26275715231895447\n",
      "The MSE loss is : 0.26275700330734253\n",
      "The MSE loss is : 0.2627643346786499\n",
      "The MSE loss is : 0.26275700330734253\n",
      "The MSE loss is : 0.2627567648887634\n",
      "The MSE loss is : 0.26275670528411865\n",
      "Saving... file:record_err_16 method:block-sqrt-half\n",
      "The MSE loss is : 0.3989333212375641\n",
      "The MSE loss is : 0.14631271362304688\n",
      "The MSE loss is : 0.1451273262500763\n",
      "The MSE loss is : 0.14512698352336884\n",
      "The MSE loss is : 0.14512699842453003\n",
      "The MSE loss is : 0.14512698352336884\n",
      "The MSE loss is : 0.14512698352336884\n",
      "The MSE loss is : 0.14512698352336884\n",
      "The MSE loss is : 0.14512698352336884\n",
      "The MSE loss is : 0.14512699842453003\n",
      "The MSE loss is : 0.14512696862220764\n",
      "The MSE loss is : 0.14512698352336884\n",
      "The MSE loss is : 0.14512699842453003\n",
      "The MSE loss is : 0.14512699842453003\n",
      "The MSE loss is : 0.14512699842453003\n",
      "The MSE loss is : 0.14512699842453003\n",
      "The MSE loss is : 0.14512701332569122\n",
      "The MSE loss is : 0.14512698352336884\n",
      "The MSE loss is : 0.14512701332569122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.14512699842453003\n",
      "Saving... file:record_err_16 method:block-sqrt\n",
      "Saving... file:record_err_16 method:lowR-same-param\n",
      "Saving... file:record_err_16 method:lowR-samex2\n",
      "Saving... file:record_err_16 method:lowR-half\n",
      "The MSE loss is : 0.6333787441253662\n",
      "The MSE loss is : 0.0005697733722627163\n",
      "The MSE loss is : 3.007203531524283e-06\n",
      "The MSE loss is : 3.566314354941369e-09\n",
      "The MSE loss is : 1.6936201052697442e-10\n",
      "The MSE loss is : 3.9871551156187013e-13\n",
      "The MSE loss is : 5.666725769182257e-13\n",
      "The MSE loss is : 2.4735207659887237e-08\n",
      "The MSE loss is : 9.416243340609753e-10\n",
      "The MSE loss is : 3.641053325509347e-08\n",
      "The MSE loss is : 4.503828865409787e-09\n",
      "The MSE loss is : 2.84025389873932e-07\n",
      "The MSE loss is : 9.459657057675486e-09\n",
      "The MSE loss is : 1.2831371520860557e-08\n",
      "The MSE loss is : 1.203407293814962e-07\n",
      "The MSE loss is : 2.2124483578522813e-08\n",
      "The MSE loss is : 5.643590839099488e-07\n",
      "The MSE loss is : 8.069208234928738e-08\n",
      "The MSE loss is : 1.9150505181642075e-08\n",
      "The MSE loss is : 8.834300047055876e-08\n",
      "Saving... file:record_err_16 method:pair-Add\n",
      "The MSE loss is : 0.40920406579971313\n",
      "The MSE loss is : 0.005683048628270626\n",
      "The MSE loss is : 0.0027959193103015423\n",
      "The MSE loss is : 0.002225288422778249\n",
      "The MSE loss is : 0.0020270727109164\n",
      "The MSE loss is : 0.0017525951843708754\n",
      "The MSE loss is : 0.001223500701598823\n",
      "The MSE loss is : 0.0007231006165966392\n",
      "The MSE loss is : 0.0005748705007135868\n",
      "The MSE loss is : 0.0004347661742940545\n",
      "The MSE loss is : 0.0003406478790566325\n",
      "The MSE loss is : 0.000252366007771343\n",
      "The MSE loss is : 0.0001862227072706446\n",
      "The MSE loss is : 0.00014519921387545764\n",
      "The MSE loss is : 0.0001251792855327949\n",
      "The MSE loss is : 0.0001135078418883495\n",
      "The MSE loss is : 0.00010744294559117407\n",
      "The MSE loss is : 0.00010638147068675607\n",
      "The MSE loss is : 0.00010059862688649446\n",
      "The MSE loss is : 9.765999129740521e-05\n",
      "Saving... file:record_err_16 method:pair-Seq\n",
      "\n",
      "Experiment N=16 SEED=753\n",
      "The MSE loss is : 0.41001754999160767\n",
      "The MSE loss is : 0.1868484616279602\n",
      "The MSE loss is : 0.1842520833015442\n",
      "The MSE loss is : 0.18240457773208618\n",
      "The MSE loss is : 0.18240457773208618\n",
      "The MSE loss is : 0.18240457773208618\n",
      "The MSE loss is : 0.18240457773208618\n",
      "The MSE loss is : 0.18240459263324738\n",
      "The MSE loss is : 0.18240457773208618\n",
      "The MSE loss is : 0.18240457773208618\n",
      "The MSE loss is : 0.18240457773208618\n",
      "The MSE loss is : 0.18240459263324738\n",
      "The MSE loss is : 0.18240462243556976\n",
      "The MSE loss is : 0.18240463733673096\n",
      "The MSE loss is : 0.18240457773208618\n",
      "The MSE loss is : 0.18240457773208618\n",
      "The MSE loss is : 0.18240457773208618\n",
      "The MSE loss is : 0.18240457773208618\n",
      "The MSE loss is : 0.18240457773208618\n",
      "The MSE loss is : 0.18240460753440857\n",
      "Saving... file:record_err_16 method:pair\n",
      "The MSE loss is : 0.41001754999160767\n",
      "The MSE loss is : 0.2631438970565796\n",
      "The MSE loss is : 0.2625304162502289\n",
      "The MSE loss is : 0.26242589950561523\n",
      "The MSE loss is : 0.2623705565929413\n",
      "The MSE loss is : 0.2623331844806671\n",
      "The MSE loss is : 0.2623263895511627\n",
      "The MSE loss is : 0.2623206377029419\n",
      "The MSE loss is : 0.26231878995895386\n",
      "The MSE loss is : 0.26231756806373596\n",
      "The MSE loss is : 0.26231664419174194\n",
      "The MSE loss is : 0.2623160481452942\n",
      "The MSE loss is : 0.2623189091682434\n",
      "The MSE loss is : 0.26231515407562256\n",
      "The MSE loss is : 0.2623148560523987\n",
      "The MSE loss is : 0.2623145878314972\n",
      "The MSE loss is : 0.2623143792152405\n",
      "The MSE loss is : 0.2623159885406494\n",
      "The MSE loss is : 0.2623140811920166\n",
      "The MSE loss is : 0.26231399178504944\n",
      "Saving... file:record_err_16 method:block-sqrt-half\n",
      "The MSE loss is : 0.41001754999160767\n",
      "The MSE loss is : 0.14699280261993408\n",
      "The MSE loss is : 0.1463124305009842\n",
      "The MSE loss is : 0.1463121920824051\n",
      "The MSE loss is : 0.1463121920824051\n",
      "The MSE loss is : 0.1463121920824051\n",
      "The MSE loss is : 0.1463121920824051\n",
      "The MSE loss is : 0.1463121920824051\n",
      "The MSE loss is : 0.1463121920824051\n",
      "The MSE loss is : 0.1463121920824051\n",
      "The MSE loss is : 0.1463121920824051\n",
      "The MSE loss is : 0.1463121920824051\n",
      "The MSE loss is : 0.1463121920824051\n",
      "The MSE loss is : 0.1463121920824051\n",
      "The MSE loss is : 0.1463121920824051\n",
      "The MSE loss is : 0.14631220698356628\n",
      "The MSE loss is : 0.14631220698356628\n",
      "The MSE loss is : 0.14631220698356628\n",
      "The MSE loss is : 0.1463121920824051\n",
      "The MSE loss is : 0.14631220698356628\n",
      "Saving... file:record_err_16 method:block-sqrt\n",
      "Saving... file:record_err_16 method:lowR-same-param\n",
      "Saving... file:record_err_16 method:lowR-samex2\n",
      "Saving... file:record_err_16 method:lowR-half\n",
      "The MSE loss is : 0.6074973344802856\n",
      "The MSE loss is : 0.0007007077801972628\n",
      "The MSE loss is : 7.1503482104162686e-06\n",
      "The MSE loss is : 9.89508777138326e-08\n",
      "The MSE loss is : 1.989571396521228e-09\n",
      "The MSE loss is : 1.7982030087182466e-08\n",
      "The MSE loss is : 1.05598152444486e-09\n",
      "The MSE loss is : 6.190731954847095e-11\n",
      "The MSE loss is : 1.648884051519417e-07\n",
      "The MSE loss is : 7.260028578315314e-09\n",
      "The MSE loss is : 4.384851592931227e-09\n",
      "The MSE loss is : 1.5603777825390353e-08\n",
      "The MSE loss is : 3.5849657820108405e-07\n",
      "The MSE loss is : 7.640161925337452e-08\n",
      "The MSE loss is : 1.1802867305732434e-07\n",
      "The MSE loss is : 3.694730521530687e-09\n",
      "The MSE loss is : 9.788561783352634e-08\n",
      "The MSE loss is : 4.155337407496518e-08\n",
      "The MSE loss is : 8.222261840273859e-07\n",
      "The MSE loss is : 2.3298116502701305e-07\n",
      "Saving... file:record_err_16 method:pair-Add\n",
      "The MSE loss is : 0.44619596004486084\n",
      "The MSE loss is : 0.009729163721203804\n",
      "The MSE loss is : 0.0029118279926478863\n",
      "The MSE loss is : 0.0012071540113538504\n",
      "The MSE loss is : 0.0005065494333393872\n",
      "The MSE loss is : 0.00022153435565996915\n",
      "The MSE loss is : 0.00022856018040329218\n",
      "The MSE loss is : 0.00011519664258230478\n",
      "The MSE loss is : 0.00010322970047127455\n",
      "The MSE loss is : 9.880564175546169e-05\n",
      "The MSE loss is : 8.893216727301478e-05\n",
      "The MSE loss is : 8.514676301274449e-05\n",
      "The MSE loss is : 0.00011031649046344683\n",
      "The MSE loss is : 8.214810804929584e-05\n",
      "The MSE loss is : 7.641114643774927e-05\n",
      "The MSE loss is : 7.550454029114917e-05\n",
      "The MSE loss is : 7.289725181180984e-05\n",
      "The MSE loss is : 7.316148548852652e-05\n",
      "The MSE loss is : 6.931894313311204e-05\n",
      "The MSE loss is : 0.00011051924957428128\n",
      "Saving... file:record_err_16 method:pair-Seq\n",
      "\n",
      "Experiment N=64 SEED=147\n",
      "The MSE loss is : 0.35664060711860657\n",
      "The MSE loss is : 0.26728907227516174\n",
      "The MSE loss is : 0.26535332202911377\n",
      "The MSE loss is : 0.2650497257709503\n",
      "The MSE loss is : 0.26484790444374084\n",
      "The MSE loss is : 0.26484787464141846\n",
      "The MSE loss is : 0.26484787464141846\n",
      "The MSE loss is : 0.26484787464141846\n",
      "The MSE loss is : 0.26484787464141846\n",
      "The MSE loss is : 0.26484787464141846\n",
      "The MSE loss is : 0.26484793424606323\n",
      "The MSE loss is : 0.26484787464141846\n",
      "The MSE loss is : 0.26484790444374084\n",
      "The MSE loss is : 0.26484787464141846\n",
      "The MSE loss is : 0.26484787464141846\n",
      "The MSE loss is : 0.26484790444374084\n",
      "The MSE loss is : 0.26484790444374084\n",
      "The MSE loss is : 0.26484790444374084\n",
      "The MSE loss is : 0.264847993850708\n",
      "The MSE loss is : 0.26484814286231995\n",
      "Saving... file:record_err_64 method:pair\n",
      "The MSE loss is : 0.35664060711860657\n",
      "The MSE loss is : 0.2461545169353485\n",
      "The MSE loss is : 0.24390923976898193\n",
      "The MSE loss is : 0.24389325082302094\n",
      "The MSE loss is : 0.24385511875152588\n",
      "The MSE loss is : 0.24385502934455872\n",
      "The MSE loss is : 0.24385502934455872\n",
      "The MSE loss is : 0.2438550591468811\n",
      "The MSE loss is : 0.2438550442457199\n",
      "The MSE loss is : 0.2438550442457199\n",
      "The MSE loss is : 0.24385502934455872\n",
      "The MSE loss is : 0.2438550591468811\n",
      "The MSE loss is : 0.24385502934455872\n",
      "The MSE loss is : 0.2438550442457199\n",
      "The MSE loss is : 0.2438550442457199\n",
      "The MSE loss is : 0.2438550591468811\n",
      "The MSE loss is : 0.2438550442457199\n",
      "The MSE loss is : 0.2438550442457199\n",
      "The MSE loss is : 0.2438550591468811\n",
      "The MSE loss is : 0.2438550591468811\n",
      "Saving... file:record_err_64 method:block-sqrt-half\n",
      "The MSE loss is : 0.35664060711860657\n",
      "The MSE loss is : 0.26336437463760376\n",
      "The MSE loss is : 0.26335522532463074\n",
      "The MSE loss is : 0.26335519552230835\n",
      "The MSE loss is : 0.26335522532463074\n",
      "The MSE loss is : 0.26335519552230835\n",
      "The MSE loss is : 0.26335522532463074\n",
      "The MSE loss is : 0.26335522532463074\n",
      "The MSE loss is : 0.26335519552230835\n",
      "The MSE loss is : 0.26335522532463074\n",
      "The MSE loss is : 0.26335522532463074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.26335522532463074\n",
      "The MSE loss is : 0.2633552551269531\n",
      "The MSE loss is : 0.26335522532463074\n",
      "The MSE loss is : 0.26335522532463074\n",
      "The MSE loss is : 0.26335522532463074\n",
      "The MSE loss is : 0.2633552551269531\n",
      "The MSE loss is : 0.2633552551269531\n",
      "The MSE loss is : 0.26335522532463074\n",
      "The MSE loss is : 0.26335522532463074\n",
      "Saving... file:record_err_64 method:block-sqrt\n",
      "Saving... file:record_err_64 method:lowR-same-param\n",
      "Saving... file:record_err_64 method:lowR-samex2\n",
      "Saving... file:record_err_64 method:lowR-half\n",
      "The MSE loss is : 0.4341430962085724\n",
      "The MSE loss is : 0.039672158658504486\n",
      "The MSE loss is : 0.02911791205406189\n",
      "The MSE loss is : 0.026290424168109894\n",
      "The MSE loss is : 0.024562224745750427\n",
      "The MSE loss is : 0.024081993848085403\n",
      "The MSE loss is : 0.02387746423482895\n",
      "The MSE loss is : 0.023746177554130554\n",
      "The MSE loss is : 0.023495927453041077\n",
      "The MSE loss is : 0.023390216752886772\n",
      "The MSE loss is : 0.023359715938568115\n",
      "The MSE loss is : 0.02335047535598278\n",
      "The MSE loss is : 0.0233526062220335\n",
      "The MSE loss is : 0.02333318255841732\n",
      "The MSE loss is : 0.02332892455160618\n",
      "The MSE loss is : 0.023335758596658707\n",
      "The MSE loss is : 0.02332458645105362\n",
      "The MSE loss is : 0.023324742913246155\n",
      "The MSE loss is : 0.023324452340602875\n",
      "The MSE loss is : 0.023245692253112793\n",
      "Saving... file:record_err_64 method:pair-Add\n",
      "The MSE loss is : 0.3555004298686981\n",
      "The MSE loss is : 0.055825501680374146\n",
      "The MSE loss is : 0.05027725547552109\n",
      "The MSE loss is : 0.047475166618824005\n",
      "The MSE loss is : 0.04560815915465355\n",
      "The MSE loss is : 0.04462219029664993\n",
      "The MSE loss is : 0.043869905173778534\n",
      "The MSE loss is : 0.043789636343717575\n",
      "The MSE loss is : 0.04261265695095062\n",
      "The MSE loss is : 0.04205350950360298\n",
      "The MSE loss is : 0.0415622852742672\n",
      "The MSE loss is : 0.04149583354592323\n",
      "The MSE loss is : 0.04279473423957825\n",
      "The MSE loss is : 0.04110867530107498\n",
      "The MSE loss is : 0.042234912514686584\n",
      "The MSE loss is : 0.0397871658205986\n",
      "The MSE loss is : 0.04044957458972931\n",
      "The MSE loss is : 0.03945412486791611\n",
      "The MSE loss is : 0.045875415205955505\n",
      "The MSE loss is : 0.04067607596516609\n",
      "Saving... file:record_err_64 method:pair-Seq\n",
      "\n",
      "Experiment N=64 SEED=258\n",
      "The MSE loss is : 0.34387272596359253\n",
      "The MSE loss is : 0.2611415982246399\n",
      "The MSE loss is : 0.2598569989204407\n",
      "The MSE loss is : 0.2597995102405548\n",
      "The MSE loss is : 0.2597932815551758\n",
      "The MSE loss is : 0.2597932815551758\n",
      "The MSE loss is : 0.2597932815551758\n",
      "The MSE loss is : 0.2597932815551758\n",
      "The MSE loss is : 0.2597932815551758\n",
      "The MSE loss is : 0.2597932815551758\n",
      "The MSE loss is : 0.2597932815551758\n",
      "The MSE loss is : 0.25979331135749817\n",
      "The MSE loss is : 0.2597932815551758\n",
      "The MSE loss is : 0.25979331135749817\n",
      "The MSE loss is : 0.2597932815551758\n",
      "The MSE loss is : 0.2597932815551758\n",
      "The MSE loss is : 0.2597932815551758\n",
      "The MSE loss is : 0.25979340076446533\n",
      "The MSE loss is : 0.25979340076446533\n",
      "The MSE loss is : 0.25979331135749817\n",
      "Saving... file:record_err_64 method:pair\n",
      "The MSE loss is : 0.34387272596359253\n",
      "The MSE loss is : 0.24087542295455933\n",
      "The MSE loss is : 0.23948988318443298\n",
      "The MSE loss is : 0.2392214685678482\n",
      "The MSE loss is : 0.239221453666687\n",
      "The MSE loss is : 0.2392214685678482\n",
      "The MSE loss is : 0.239221453666687\n",
      "The MSE loss is : 0.2392214685678482\n",
      "The MSE loss is : 0.239221453666687\n",
      "The MSE loss is : 0.2392214685678482\n",
      "The MSE loss is : 0.2392214685678482\n",
      "The MSE loss is : 0.239221453666687\n",
      "The MSE loss is : 0.2392214685678482\n",
      "The MSE loss is : 0.2392214685678482\n",
      "The MSE loss is : 0.2392214685678482\n",
      "The MSE loss is : 0.2392214685678482\n",
      "The MSE loss is : 0.2392214685678482\n",
      "The MSE loss is : 0.2392214834690094\n",
      "The MSE loss is : 0.2392214685678482\n",
      "The MSE loss is : 0.2392214834690094\n",
      "Saving... file:record_err_64 method:block-sqrt-half\n",
      "The MSE loss is : 0.34387272596359253\n",
      "The MSE loss is : 0.25590306520462036\n",
      "The MSE loss is : 0.25589168071746826\n",
      "The MSE loss is : 0.25589168071746826\n",
      "The MSE loss is : 0.2558916509151459\n",
      "The MSE loss is : 0.2558916509151459\n",
      "The MSE loss is : 0.25589168071746826\n",
      "The MSE loss is : 0.2558916211128235\n",
      "The MSE loss is : 0.25589168071746826\n",
      "The MSE loss is : 0.25589168071746826\n",
      "The MSE loss is : 0.2558916509151459\n",
      "The MSE loss is : 0.25589168071746826\n",
      "The MSE loss is : 0.25589168071746826\n",
      "The MSE loss is : 0.2558916509151459\n",
      "The MSE loss is : 0.25589168071746826\n",
      "The MSE loss is : 0.2558916509151459\n",
      "The MSE loss is : 0.25589168071746826\n",
      "The MSE loss is : 0.2558916509151459\n",
      "The MSE loss is : 0.25589168071746826\n",
      "The MSE loss is : 0.25589168071746826\n",
      "Saving... file:record_err_64 method:block-sqrt\n",
      "Saving... file:record_err_64 method:lowR-same-param\n",
      "Saving... file:record_err_64 method:lowR-samex2\n",
      "Saving... file:record_err_64 method:lowR-half\n",
      "The MSE loss is : 0.42560988664627075\n",
      "The MSE loss is : 0.03897681087255478\n",
      "The MSE loss is : 0.02790338173508644\n",
      "The MSE loss is : 0.02523082122206688\n",
      "The MSE loss is : 0.023169569671154022\n",
      "The MSE loss is : 0.022339217364788055\n",
      "The MSE loss is : 0.022148609161376953\n",
      "The MSE loss is : 0.02170237898826599\n",
      "The MSE loss is : 0.021106364205479622\n",
      "The MSE loss is : 0.02092951163649559\n",
      "The MSE loss is : 0.02085638791322708\n",
      "The MSE loss is : 0.020831305533647537\n",
      "The MSE loss is : 0.0208213459700346\n",
      "The MSE loss is : 0.020821204409003258\n",
      "The MSE loss is : 0.02082262933254242\n",
      "The MSE loss is : 0.020818987861275673\n",
      "The MSE loss is : 0.02081778272986412\n",
      "The MSE loss is : 0.0208162572234869\n",
      "The MSE loss is : 0.02081945911049843\n",
      "The MSE loss is : 0.020822500810027122\n",
      "Saving... file:record_err_64 method:pair-Add\n",
      "The MSE loss is : 0.34689080715179443\n",
      "The MSE loss is : 0.04909305274486542\n",
      "The MSE loss is : 0.04315213859081268\n",
      "The MSE loss is : 0.040205229073762894\n",
      "The MSE loss is : 0.03864789754152298\n",
      "The MSE loss is : 0.038162559270858765\n",
      "The MSE loss is : 0.03741419315338135\n",
      "The MSE loss is : 0.03674338012933731\n",
      "The MSE loss is : 0.03647482395172119\n",
      "The MSE loss is : 0.036199819296598434\n",
      "The MSE loss is : 0.036060113459825516\n",
      "The MSE loss is : 0.03644847124814987\n",
      "The MSE loss is : 0.035446807742118835\n",
      "The MSE loss is : 0.0361451655626297\n",
      "The MSE loss is : 0.035093486309051514\n",
      "The MSE loss is : 0.03489048033952713\n",
      "The MSE loss is : 0.03470967337489128\n",
      "The MSE loss is : 0.03454214707016945\n",
      "The MSE loss is : 0.03442533314228058\n",
      "The MSE loss is : 0.0343908965587616\n",
      "Saving... file:record_err_64 method:pair-Seq\n",
      "\n",
      "Experiment N=64 SEED=369\n",
      "The MSE loss is : 0.34894853830337524\n",
      "The MSE loss is : 0.26739323139190674\n",
      "The MSE loss is : 0.26262086629867554\n",
      "The MSE loss is : 0.26171112060546875\n",
      "The MSE loss is : 0.2614787817001343\n",
      "The MSE loss is : 0.2614787817001343\n",
      "The MSE loss is : 0.2614787817001343\n",
      "The MSE loss is : 0.2614787817001343\n",
      "The MSE loss is : 0.2614787518978119\n",
      "The MSE loss is : 0.2614787518978119\n",
      "The MSE loss is : 0.2614787817001343\n",
      "The MSE loss is : 0.26147881150245667\n",
      "The MSE loss is : 0.2614787817001343\n",
      "The MSE loss is : 0.2614787817001343\n",
      "The MSE loss is : 0.2614787817001343\n",
      "The MSE loss is : 0.2614787817001343\n",
      "The MSE loss is : 0.2614787817001343\n",
      "The MSE loss is : 0.2614787817001343\n",
      "The MSE loss is : 0.2614787817001343\n",
      "The MSE loss is : 0.2614787817001343\n",
      "Saving... file:record_err_64 method:pair\n",
      "The MSE loss is : 0.34894853830337524\n",
      "The MSE loss is : 0.24703367054462433\n",
      "The MSE loss is : 0.2444879412651062\n",
      "The MSE loss is : 0.24445556104183197\n",
      "The MSE loss is : 0.24445556104183197\n",
      "The MSE loss is : 0.24445554614067078\n",
      "The MSE loss is : 0.24445554614067078\n",
      "The MSE loss is : 0.24445554614067078\n",
      "The MSE loss is : 0.24445554614067078\n",
      "The MSE loss is : 0.24445554614067078\n",
      "The MSE loss is : 0.24445556104183197\n",
      "The MSE loss is : 0.24445554614067078\n",
      "The MSE loss is : 0.24445554614067078\n",
      "The MSE loss is : 0.24445556104183197\n",
      "The MSE loss is : 0.24445557594299316\n",
      "The MSE loss is : 0.24445554614067078\n",
      "The MSE loss is : 0.24445557594299316\n",
      "The MSE loss is : 0.24445556104183197\n",
      "The MSE loss is : 0.24445557594299316\n",
      "The MSE loss is : 0.24445557594299316\n",
      "Saving... file:record_err_64 method:block-sqrt-half\n",
      "The MSE loss is : 0.34894853830337524\n",
      "The MSE loss is : 0.25922542810440063\n",
      "The MSE loss is : 0.25915977358818054\n",
      "The MSE loss is : 0.25915974378585815\n",
      "The MSE loss is : 0.25915974378585815\n",
      "The MSE loss is : 0.25915974378585815\n",
      "The MSE loss is : 0.25915977358818054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.25915977358818054\n",
      "The MSE loss is : 0.25915977358818054\n",
      "The MSE loss is : 0.25915974378585815\n",
      "The MSE loss is : 0.25915974378585815\n",
      "The MSE loss is : 0.25915977358818054\n",
      "The MSE loss is : 0.25915977358818054\n",
      "The MSE loss is : 0.25915977358818054\n",
      "The MSE loss is : 0.25915977358818054\n",
      "The MSE loss is : 0.25915974378585815\n",
      "The MSE loss is : 0.25915977358818054\n",
      "The MSE loss is : 0.25915977358818054\n",
      "The MSE loss is : 0.25915974378585815\n",
      "The MSE loss is : 0.25915974378585815\n",
      "Saving... file:record_err_64 method:block-sqrt\n",
      "Saving... file:record_err_64 method:lowR-same-param\n",
      "Saving... file:record_err_64 method:lowR-samex2\n",
      "Saving... file:record_err_64 method:lowR-half\n",
      "The MSE loss is : 0.43027782440185547\n",
      "The MSE loss is : 0.038964588195085526\n",
      "The MSE loss is : 0.027557741850614548\n",
      "The MSE loss is : 0.024395732209086418\n",
      "The MSE loss is : 0.023815451189875603\n",
      "The MSE loss is : 0.02312464453279972\n",
      "The MSE loss is : 0.02291439287364483\n",
      "The MSE loss is : 0.022665301337838173\n",
      "The MSE loss is : 0.0226436797529459\n",
      "The MSE loss is : 0.022635743021965027\n",
      "The MSE loss is : 0.02262943983078003\n",
      "The MSE loss is : 0.0226299948990345\n",
      "The MSE loss is : 0.022615570574998856\n",
      "The MSE loss is : 0.022617096081376076\n",
      "The MSE loss is : 0.022618640214204788\n",
      "The MSE loss is : 0.02260473743081093\n",
      "The MSE loss is : 0.022599708288908005\n",
      "The MSE loss is : 0.022598780691623688\n",
      "The MSE loss is : 0.02259591966867447\n",
      "The MSE loss is : 0.02260204777121544\n",
      "Saving... file:record_err_64 method:pair-Add\n",
      "The MSE loss is : 0.3461737632751465\n",
      "The MSE loss is : 0.05437115952372551\n",
      "The MSE loss is : 0.04938559979200363\n",
      "The MSE loss is : 0.046644192188978195\n",
      "The MSE loss is : 0.04583720117807388\n",
      "The MSE loss is : 0.04461091384291649\n",
      "The MSE loss is : 0.044962234795093536\n",
      "The MSE loss is : 0.0443052276968956\n",
      "The MSE loss is : 0.04336099326610565\n",
      "The MSE loss is : 0.04489469900727272\n",
      "The MSE loss is : 0.04780297726392746\n",
      "The MSE loss is : 0.04433952644467354\n",
      "The MSE loss is : 0.042119406163692474\n",
      "The MSE loss is : 0.04131995141506195\n",
      "The MSE loss is : 0.040853071957826614\n",
      "The MSE loss is : 0.04124381020665169\n",
      "The MSE loss is : 0.041519783437252045\n",
      "The MSE loss is : 0.04033106192946434\n",
      "The MSE loss is : 0.040368057787418365\n",
      "The MSE loss is : 0.03986111283302307\n",
      "Saving... file:record_err_64 method:pair-Seq\n",
      "\n",
      "Experiment N=64 SEED=321\n",
      "The MSE loss is : 0.35039860010147095\n",
      "The MSE loss is : 0.26596662402153015\n",
      "The MSE loss is : 0.26301854848861694\n",
      "The MSE loss is : 0.2623487412929535\n",
      "The MSE loss is : 0.26234865188598633\n",
      "The MSE loss is : 0.26234865188598633\n",
      "The MSE loss is : 0.26234865188598633\n",
      "The MSE loss is : 0.26234865188598633\n",
      "The MSE loss is : 0.26234862208366394\n",
      "The MSE loss is : 0.2623487114906311\n",
      "The MSE loss is : 0.26234865188598633\n",
      "The MSE loss is : 0.26234865188598633\n",
      "The MSE loss is : 0.26234865188598633\n",
      "The MSE loss is : 0.26234862208366394\n",
      "The MSE loss is : 0.2623487412929535\n",
      "The MSE loss is : 0.26234862208366394\n",
      "The MSE loss is : 0.2623486816883087\n",
      "The MSE loss is : 0.26234883069992065\n",
      "The MSE loss is : 0.2623487114906311\n",
      "The MSE loss is : 0.26234862208366394\n",
      "Saving... file:record_err_64 method:pair\n",
      "The MSE loss is : 0.35039860010147095\n",
      "The MSE loss is : 0.2415907233953476\n",
      "The MSE loss is : 0.2410798966884613\n",
      "The MSE loss is : 0.24107787013053894\n",
      "The MSE loss is : 0.24107788503170013\n",
      "The MSE loss is : 0.24107788503170013\n",
      "The MSE loss is : 0.24107789993286133\n",
      "The MSE loss is : 0.24107788503170013\n",
      "The MSE loss is : 0.24107788503170013\n",
      "The MSE loss is : 0.24107788503170013\n",
      "The MSE loss is : 0.24107788503170013\n",
      "The MSE loss is : 0.24107789993286133\n",
      "The MSE loss is : 0.24107789993286133\n",
      "The MSE loss is : 0.24107789993286133\n",
      "The MSE loss is : 0.24107789993286133\n",
      "The MSE loss is : 0.24107791483402252\n",
      "The MSE loss is : 0.24107789993286133\n",
      "The MSE loss is : 0.24107788503170013\n",
      "The MSE loss is : 0.24107789993286133\n",
      "The MSE loss is : 0.24107788503170013\n",
      "Saving... file:record_err_64 method:block-sqrt-half\n",
      "The MSE loss is : 0.35039860010147095\n",
      "The MSE loss is : 0.25887900590896606\n",
      "The MSE loss is : 0.2587288022041321\n",
      "The MSE loss is : 0.2587283253669739\n",
      "The MSE loss is : 0.25872835516929626\n",
      "The MSE loss is : 0.2587283253669739\n",
      "The MSE loss is : 0.2587283253669739\n",
      "The MSE loss is : 0.25872835516929626\n",
      "The MSE loss is : 0.25872835516929626\n",
      "The MSE loss is : 0.25872835516929626\n",
      "The MSE loss is : 0.2587283253669739\n",
      "The MSE loss is : 0.2587283253669739\n",
      "The MSE loss is : 0.2587283253669739\n",
      "The MSE loss is : 0.25872835516929626\n",
      "The MSE loss is : 0.25872838497161865\n",
      "The MSE loss is : 0.25872835516929626\n",
      "The MSE loss is : 0.25872835516929626\n",
      "The MSE loss is : 0.25872835516929626\n",
      "The MSE loss is : 0.25872838497161865\n",
      "The MSE loss is : 0.25872838497161865\n",
      "Saving... file:record_err_64 method:block-sqrt\n",
      "Saving... file:record_err_64 method:lowR-same-param\n",
      "Saving... file:record_err_64 method:lowR-samex2\n",
      "Saving... file:record_err_64 method:lowR-half\n",
      "The MSE loss is : 0.4439583420753479\n",
      "The MSE loss is : 0.03855828195810318\n",
      "The MSE loss is : 0.025915397331118584\n",
      "The MSE loss is : 0.023317866027355194\n",
      "The MSE loss is : 0.022026538848876953\n",
      "The MSE loss is : 0.021798450499773026\n",
      "The MSE loss is : 0.021618619561195374\n",
      "The MSE loss is : 0.021527990698814392\n",
      "The MSE loss is : 0.02131083607673645\n",
      "The MSE loss is : 0.02113187685608864\n",
      "The MSE loss is : 0.021035701036453247\n",
      "The MSE loss is : 0.020968208089470863\n",
      "The MSE loss is : 0.020952781662344933\n",
      "The MSE loss is : 0.020952045917510986\n",
      "The MSE loss is : 0.02094155177474022\n",
      "The MSE loss is : 0.020953580737113953\n",
      "The MSE loss is : 0.020937353372573853\n",
      "The MSE loss is : 0.020934414118528366\n",
      "The MSE loss is : 0.02093522995710373\n",
      "The MSE loss is : 0.020931867882609367\n",
      "Saving... file:record_err_64 method:pair-Add\n",
      "The MSE loss is : 0.3492546081542969\n",
      "The MSE loss is : 0.05157623440027237\n",
      "The MSE loss is : 0.047342460602521896\n",
      "The MSE loss is : 0.04522440955042839\n",
      "The MSE loss is : 0.04501901566982269\n",
      "The MSE loss is : 0.042557716369628906\n",
      "The MSE loss is : 0.04224039986729622\n",
      "The MSE loss is : 0.041753366589546204\n",
      "The MSE loss is : 0.040901608765125275\n",
      "The MSE loss is : 0.0402681902050972\n",
      "The MSE loss is : 0.03991449624300003\n",
      "The MSE loss is : 0.03959057480096817\n",
      "The MSE loss is : 0.04005468636751175\n",
      "The MSE loss is : 0.03892243281006813\n",
      "The MSE loss is : 0.038871459662914276\n",
      "The MSE loss is : 0.03837046027183533\n",
      "The MSE loss is : 0.03812022507190704\n",
      "The MSE loss is : 0.038177698850631714\n",
      "The MSE loss is : 0.03837006539106369\n",
      "The MSE loss is : 0.03830113634467125\n",
      "Saving... file:record_err_64 method:pair-Seq\n",
      "\n",
      "Experiment N=64 SEED=654\n",
      "The MSE loss is : 0.34854745864868164\n",
      "The MSE loss is : 0.26507568359375\n",
      "The MSE loss is : 0.26337987184524536\n",
      "The MSE loss is : 0.26268041133880615\n",
      "The MSE loss is : 0.2626786530017853\n",
      "The MSE loss is : 0.2626786530017853\n",
      "The MSE loss is : 0.2626786530017853\n",
      "The MSE loss is : 0.2626786530017853\n",
      "The MSE loss is : 0.2626786530017853\n",
      "The MSE loss is : 0.26267868280410767\n",
      "The MSE loss is : 0.2626786530017853\n",
      "The MSE loss is : 0.2626786530017853\n",
      "The MSE loss is : 0.26267868280410767\n",
      "The MSE loss is : 0.2626786530017853\n",
      "The MSE loss is : 0.26267871260643005\n",
      "The MSE loss is : 0.2626788020133972\n",
      "The MSE loss is : 0.26267868280410767\n",
      "The MSE loss is : 0.26267868280410767\n",
      "The MSE loss is : 0.2626788020133972\n",
      "The MSE loss is : 0.2626786530017853\n",
      "Saving... file:record_err_64 method:pair\n",
      "The MSE loss is : 0.34854745864868164\n",
      "The MSE loss is : 0.24083152413368225\n",
      "The MSE loss is : 0.2399008870124817\n",
      "The MSE loss is : 0.23939897119998932\n",
      "The MSE loss is : 0.23939897119998932\n",
      "The MSE loss is : 0.23939897119998932\n",
      "The MSE loss is : 0.23939897119998932\n",
      "The MSE loss is : 0.23939897119998932\n",
      "The MSE loss is : 0.2393989861011505\n",
      "The MSE loss is : 0.23939897119998932\n",
      "The MSE loss is : 0.2393989861011505\n",
      "The MSE loss is : 0.2393989861011505\n",
      "The MSE loss is : 0.2393989861011505\n",
      "The MSE loss is : 0.2393989861011505\n",
      "The MSE loss is : 0.2393989861011505\n",
      "The MSE loss is : 0.2393989861011505\n",
      "The MSE loss is : 0.2393990159034729\n",
      "The MSE loss is : 0.23939897119998932\n",
      "The MSE loss is : 0.2393989861011505\n",
      "The MSE loss is : 0.23939897119998932\n",
      "Saving... file:record_err_64 method:block-sqrt-half\n",
      "The MSE loss is : 0.34854745864868164\n",
      "The MSE loss is : 0.2614268660545349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.2614073157310486\n",
      "The MSE loss is : 0.2614072859287262\n",
      "The MSE loss is : 0.2614073157310486\n",
      "The MSE loss is : 0.2614073157310486\n",
      "The MSE loss is : 0.2614072859287262\n",
      "The MSE loss is : 0.2614073157310486\n",
      "The MSE loss is : 0.2614073157310486\n",
      "The MSE loss is : 0.2614073157310486\n",
      "The MSE loss is : 0.2614073157310486\n",
      "The MSE loss is : 0.2614073157310486\n",
      "The MSE loss is : 0.2614073157310486\n",
      "The MSE loss is : 0.2614073157310486\n",
      "The MSE loss is : 0.2614073157310486\n",
      "The MSE loss is : 0.2614072859287262\n",
      "The MSE loss is : 0.2614073157310486\n",
      "The MSE loss is : 0.2614072859287262\n",
      "The MSE loss is : 0.2614073157310486\n",
      "The MSE loss is : 0.2614073157310486\n",
      "Saving... file:record_err_64 method:block-sqrt\n",
      "Saving... file:record_err_64 method:lowR-same-param\n",
      "Saving... file:record_err_64 method:lowR-samex2\n",
      "Saving... file:record_err_64 method:lowR-half\n",
      "The MSE loss is : 0.43475866317749023\n",
      "The MSE loss is : 0.03876874968409538\n",
      "The MSE loss is : 0.028359610587358475\n",
      "The MSE loss is : 0.025196103379130363\n",
      "The MSE loss is : 0.023843780159950256\n",
      "The MSE loss is : 0.02291049435734749\n",
      "The MSE loss is : 0.02231145091354847\n",
      "The MSE loss is : 0.021802853792905807\n",
      "The MSE loss is : 0.021580984815955162\n",
      "The MSE loss is : 0.02153916098177433\n",
      "The MSE loss is : 0.02153090387582779\n",
      "The MSE loss is : 0.021512506529688835\n",
      "The MSE loss is : 0.02150358259677887\n",
      "The MSE loss is : 0.02148037776350975\n",
      "The MSE loss is : 0.021480735391378403\n",
      "The MSE loss is : 0.02147940918803215\n",
      "The MSE loss is : 0.02146795392036438\n",
      "The MSE loss is : 0.021460866555571556\n",
      "The MSE loss is : 0.021454470232129097\n",
      "The MSE loss is : 0.021451443433761597\n",
      "Saving... file:record_err_64 method:pair-Add\n",
      "The MSE loss is : 0.3484001159667969\n",
      "The MSE loss is : 0.05289900302886963\n",
      "The MSE loss is : 0.0477217361330986\n",
      "The MSE loss is : 0.04577101022005081\n",
      "The MSE loss is : 0.044849198311567307\n",
      "The MSE loss is : 0.045938968658447266\n",
      "The MSE loss is : 0.04312000051140785\n",
      "The MSE loss is : 0.042830146849155426\n",
      "The MSE loss is : 0.04225553572177887\n",
      "The MSE loss is : 0.042100340127944946\n",
      "The MSE loss is : 0.041879959404468536\n",
      "The MSE loss is : 0.041348896920681\n",
      "The MSE loss is : 0.04065180942416191\n",
      "The MSE loss is : 0.04036801680922508\n",
      "The MSE loss is : 0.04465563967823982\n",
      "The MSE loss is : 0.04067264497280121\n",
      "The MSE loss is : 0.039694733917713165\n",
      "The MSE loss is : 0.03936241939663887\n",
      "The MSE loss is : 0.03936002030968666\n",
      "The MSE loss is : 0.03898393362760544\n",
      "Saving... file:record_err_64 method:pair-Seq\n",
      "\n",
      "Experiment N=64 SEED=987\n",
      "The MSE loss is : 0.34683918952941895\n",
      "The MSE loss is : 0.26355060935020447\n",
      "The MSE loss is : 0.260434091091156\n",
      "The MSE loss is : 0.2604101896286011\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101598262787\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101300239563\n",
      "The MSE loss is : 0.2604101300239563\n",
      "Saving... file:record_err_64 method:pair\n",
      "The MSE loss is : 0.34683918952941895\n",
      "The MSE loss is : 0.24133622646331787\n",
      "The MSE loss is : 0.2399362027645111\n",
      "The MSE loss is : 0.2397792488336563\n",
      "The MSE loss is : 0.23974952101707458\n",
      "The MSE loss is : 0.23974944651126862\n",
      "The MSE loss is : 0.23974944651126862\n",
      "The MSE loss is : 0.23974944651126862\n",
      "The MSE loss is : 0.23974943161010742\n",
      "The MSE loss is : 0.23974944651126862\n",
      "The MSE loss is : 0.23974944651126862\n",
      "The MSE loss is : 0.2397494614124298\n",
      "The MSE loss is : 0.23974944651126862\n",
      "The MSE loss is : 0.2397494614124298\n",
      "The MSE loss is : 0.2397494614124298\n",
      "The MSE loss is : 0.239749476313591\n",
      "The MSE loss is : 0.2397494614124298\n",
      "The MSE loss is : 0.2397494614124298\n",
      "The MSE loss is : 0.23974944651126862\n",
      "The MSE loss is : 0.2397494614124298\n",
      "Saving... file:record_err_64 method:block-sqrt-half\n",
      "The MSE loss is : 0.34683918952941895\n",
      "The MSE loss is : 0.25939661264419556\n",
      "The MSE loss is : 0.25918370485305786\n",
      "The MSE loss is : 0.2591836154460907\n",
      "The MSE loss is : 0.2591836452484131\n",
      "The MSE loss is : 0.2591836452484131\n",
      "The MSE loss is : 0.2591836452484131\n",
      "The MSE loss is : 0.2591836452484131\n",
      "The MSE loss is : 0.2591836452484131\n",
      "The MSE loss is : 0.2591836154460907\n",
      "The MSE loss is : 0.2591836154460907\n",
      "The MSE loss is : 0.2591836452484131\n",
      "The MSE loss is : 0.2591836452484131\n",
      "The MSE loss is : 0.2591836452484131\n",
      "The MSE loss is : 0.2591836154460907\n",
      "The MSE loss is : 0.2591836154460907\n",
      "The MSE loss is : 0.2591836154460907\n",
      "The MSE loss is : 0.2591836452484131\n",
      "The MSE loss is : 0.2591836154460907\n",
      "The MSE loss is : 0.2591836154460907\n",
      "Saving... file:record_err_64 method:block-sqrt\n",
      "Saving... file:record_err_64 method:lowR-same-param\n",
      "Saving... file:record_err_64 method:lowR-samex2\n",
      "Saving... file:record_err_64 method:lowR-half\n",
      "The MSE loss is : 0.43305647373199463\n",
      "The MSE loss is : 0.03893869370222092\n",
      "The MSE loss is : 0.027944937348365784\n",
      "The MSE loss is : 0.024724744260311127\n",
      "The MSE loss is : 0.023166358470916748\n",
      "The MSE loss is : 0.02275894396007061\n",
      "The MSE loss is : 0.02252047508955002\n",
      "The MSE loss is : 0.022220365703105927\n",
      "The MSE loss is : 0.02193829044699669\n",
      "The MSE loss is : 0.021694373339414597\n",
      "The MSE loss is : 0.0216655395925045\n",
      "The MSE loss is : 0.021642200648784637\n",
      "The MSE loss is : 0.02163390815258026\n",
      "The MSE loss is : 0.021587632596492767\n",
      "The MSE loss is : 0.021579964086413383\n",
      "The MSE loss is : 0.02157008834183216\n",
      "The MSE loss is : 0.02151942253112793\n",
      "The MSE loss is : 0.021409722045063972\n",
      "The MSE loss is : 0.021329497918486595\n",
      "The MSE loss is : 0.021313712000846863\n",
      "Saving... file:record_err_64 method:pair-Add\n",
      "The MSE loss is : 0.3453282117843628\n",
      "The MSE loss is : 0.053321778774261475\n",
      "The MSE loss is : 0.04689410328865051\n",
      "The MSE loss is : 0.04444027692079544\n",
      "The MSE loss is : 0.0436815582215786\n",
      "The MSE loss is : 0.04410910978913307\n",
      "The MSE loss is : 0.04308079183101654\n",
      "The MSE loss is : 0.04146955907344818\n",
      "The MSE loss is : 0.040745239704847336\n",
      "The MSE loss is : 0.04074777290225029\n",
      "The MSE loss is : 0.04045218229293823\n",
      "The MSE loss is : 0.04004049301147461\n",
      "The MSE loss is : 0.04057415947318077\n",
      "The MSE loss is : 0.039577826857566833\n",
      "The MSE loss is : 0.039552148431539536\n",
      "The MSE loss is : 0.03934206813573837\n",
      "The MSE loss is : 0.03917790949344635\n",
      "The MSE loss is : 0.038936007767915726\n",
      "The MSE loss is : 0.040556278079748154\n",
      "The MSE loss is : 0.0387534573674202\n",
      "Saving... file:record_err_64 method:pair-Seq\n",
      "\n",
      "Experiment N=64 SEED=741\n",
      "The MSE loss is : 0.34601086378097534\n",
      "The MSE loss is : 0.257537305355072\n",
      "The MSE loss is : 0.2550693452358246\n",
      "The MSE loss is : 0.25506430864334106\n",
      "The MSE loss is : 0.25506430864334106\n",
      "The MSE loss is : 0.25506430864334106\n",
      "The MSE loss is : 0.25506430864334106\n",
      "The MSE loss is : 0.25506430864334106\n",
      "The MSE loss is : 0.25506430864334106\n",
      "The MSE loss is : 0.25506430864334106\n",
      "The MSE loss is : 0.25506430864334106\n",
      "The MSE loss is : 0.25506436824798584\n",
      "The MSE loss is : 0.25506430864334106\n",
      "The MSE loss is : 0.25506430864334106\n",
      "The MSE loss is : 0.255064457654953\n",
      "The MSE loss is : 0.25506430864334106\n",
      "The MSE loss is : 0.25506430864334106\n",
      "The MSE loss is : 0.25506430864334106\n",
      "The MSE loss is : 0.2550642788410187\n",
      "The MSE loss is : 0.25506430864334106\n",
      "Saving... file:record_err_64 method:pair\n",
      "The MSE loss is : 0.34601086378097534\n",
      "The MSE loss is : 0.23838266730308533\n",
      "The MSE loss is : 0.23664778470993042\n",
      "The MSE loss is : 0.23664721846580505\n",
      "The MSE loss is : 0.23664721846580505\n",
      "The MSE loss is : 0.23664721846580505\n",
      "The MSE loss is : 0.23664721846580505\n",
      "The MSE loss is : 0.23664721846580505\n",
      "The MSE loss is : 0.23664721846580505\n",
      "The MSE loss is : 0.23664721846580505\n",
      "The MSE loss is : 0.23664721846580505\n",
      "The MSE loss is : 0.23664721846580505\n",
      "The MSE loss is : 0.23664721846580505\n",
      "The MSE loss is : 0.23664721846580505\n",
      "The MSE loss is : 0.23664724826812744\n",
      "The MSE loss is : 0.23664721846580505\n",
      "The MSE loss is : 0.23664720356464386\n",
      "The MSE loss is : 0.23664721846580505\n",
      "The MSE loss is : 0.23664721846580505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.23664721846580505\n",
      "Saving... file:record_err_64 method:block-sqrt-half\n",
      "The MSE loss is : 0.34601086378097534\n",
      "The MSE loss is : 0.25728628039360046\n",
      "The MSE loss is : 0.25727134943008423\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.2572712302207947\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.25727128982543945\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.25727126002311707\n",
      "The MSE loss is : 0.25727126002311707\n",
      "Saving... file:record_err_64 method:block-sqrt\n",
      "Saving... file:record_err_64 method:lowR-same-param\n",
      "Saving... file:record_err_64 method:lowR-samex2\n",
      "Saving... file:record_err_64 method:lowR-half\n",
      "The MSE loss is : 0.431576132774353\n",
      "The MSE loss is : 0.03652732074260712\n",
      "The MSE loss is : 0.024837611243128777\n",
      "The MSE loss is : 0.022521087899804115\n",
      "The MSE loss is : 0.021332114934921265\n",
      "The MSE loss is : 0.021180124953389168\n",
      "The MSE loss is : 0.02105228416621685\n",
      "The MSE loss is : 0.02103959023952484\n",
      "The MSE loss is : 0.021023094654083252\n",
      "The MSE loss is : 0.02100951224565506\n",
      "The MSE loss is : 0.020984403789043427\n",
      "The MSE loss is : 0.02095693349838257\n",
      "The MSE loss is : 0.020917274057865143\n",
      "The MSE loss is : 0.020855549722909927\n",
      "The MSE loss is : 0.02085505612194538\n",
      "The MSE loss is : 0.020816229283809662\n",
      "The MSE loss is : 0.02081182599067688\n",
      "The MSE loss is : 0.020807772874832153\n",
      "The MSE loss is : 0.0208179522305727\n",
      "The MSE loss is : 0.020799823105335236\n",
      "Saving... file:record_err_64 method:pair-Add\n",
      "The MSE loss is : 0.3442765474319458\n",
      "The MSE loss is : 0.05348882079124451\n",
      "The MSE loss is : 0.04815889149904251\n",
      "The MSE loss is : 0.045867908746004105\n",
      "The MSE loss is : 0.04493206739425659\n",
      "The MSE loss is : 0.04370585083961487\n",
      "The MSE loss is : 0.04315944015979767\n",
      "The MSE loss is : 0.04259181022644043\n",
      "The MSE loss is : 0.041277926415205\n",
      "The MSE loss is : 0.04214312881231308\n",
      "The MSE loss is : 0.040355607867240906\n",
      "The MSE loss is : 0.04306189715862274\n",
      "The MSE loss is : 0.040487006306648254\n",
      "The MSE loss is : 0.039546698331832886\n",
      "The MSE loss is : 0.0393766313791275\n",
      "The MSE loss is : 0.03934435546398163\n",
      "The MSE loss is : 0.03939425200223923\n",
      "The MSE loss is : 0.03951554745435715\n",
      "The MSE loss is : 0.03987324237823486\n",
      "The MSE loss is : 0.038991451263427734\n",
      "Saving... file:record_err_64 method:pair-Seq\n",
      "\n",
      "Experiment N=64 SEED=852\n",
      "The MSE loss is : 0.3519335985183716\n",
      "The MSE loss is : 0.26497945189476013\n",
      "The MSE loss is : 0.2637747526168823\n",
      "The MSE loss is : 0.26345014572143555\n",
      "The MSE loss is : 0.26345008611679077\n",
      "The MSE loss is : 0.26345011591911316\n",
      "The MSE loss is : 0.26345008611679077\n",
      "The MSE loss is : 0.26345008611679077\n",
      "The MSE loss is : 0.26345008611679077\n",
      "The MSE loss is : 0.26345011591911316\n",
      "The MSE loss is : 0.26345008611679077\n",
      "The MSE loss is : 0.26345008611679077\n",
      "The MSE loss is : 0.26345014572143555\n",
      "The MSE loss is : 0.26345008611679077\n",
      "The MSE loss is : 0.26345011591911316\n",
      "The MSE loss is : 0.26345011591911316\n",
      "The MSE loss is : 0.2634503245353699\n",
      "The MSE loss is : 0.26345011591911316\n",
      "The MSE loss is : 0.26345008611679077\n",
      "The MSE loss is : 0.26345008611679077\n",
      "Saving... file:record_err_64 method:pair\n",
      "The MSE loss is : 0.3519335985183716\n",
      "The MSE loss is : 0.24446359276771545\n",
      "The MSE loss is : 0.24271604418754578\n",
      "The MSE loss is : 0.24246247112751007\n",
      "The MSE loss is : 0.24246245622634888\n",
      "The MSE loss is : 0.24246245622634888\n",
      "The MSE loss is : 0.24246245622634888\n",
      "The MSE loss is : 0.24246244132518768\n",
      "The MSE loss is : 0.24246245622634888\n",
      "The MSE loss is : 0.24246245622634888\n",
      "The MSE loss is : 0.24246245622634888\n",
      "The MSE loss is : 0.24246245622634888\n",
      "The MSE loss is : 0.24246248602867126\n",
      "The MSE loss is : 0.24246247112751007\n",
      "The MSE loss is : 0.24246245622634888\n",
      "The MSE loss is : 0.24246245622634888\n",
      "The MSE loss is : 0.24246245622634888\n",
      "The MSE loss is : 0.24246245622634888\n",
      "The MSE loss is : 0.24246248602867126\n",
      "The MSE loss is : 0.24246247112751007\n",
      "Saving... file:record_err_64 method:block-sqrt-half\n",
      "The MSE loss is : 0.3519335985183716\n",
      "The MSE loss is : 0.26518163084983826\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "The MSE loss is : 0.2651662826538086\n",
      "Saving... file:record_err_64 method:block-sqrt\n",
      "Saving... file:record_err_64 method:lowR-same-param\n",
      "Saving... file:record_err_64 method:lowR-samex2\n",
      "Saving... file:record_err_64 method:lowR-half\n",
      "The MSE loss is : 0.43665948510169983\n",
      "The MSE loss is : 0.03654857724905014\n",
      "The MSE loss is : 0.028339479118585587\n",
      "The MSE loss is : 0.024153931066393852\n",
      "The MSE loss is : 0.023464525118470192\n",
      "The MSE loss is : 0.023122958838939667\n",
      "The MSE loss is : 0.023096203804016113\n",
      "The MSE loss is : 0.023072969168424606\n",
      "The MSE loss is : 0.023069608956575394\n",
      "The MSE loss is : 0.023062633350491524\n",
      "The MSE loss is : 0.023056846112012863\n",
      "The MSE loss is : 0.023056913167238235\n",
      "The MSE loss is : 0.023052819073200226\n",
      "The MSE loss is : 0.023057738319039345\n",
      "The MSE loss is : 0.023070678114891052\n",
      "The MSE loss is : 0.023050537332892418\n",
      "The MSE loss is : 0.023051738739013672\n",
      "The MSE loss is : 0.023046929389238358\n",
      "The MSE loss is : 0.02303345873951912\n",
      "The MSE loss is : 0.02302910014986992\n",
      "Saving... file:record_err_64 method:pair-Add\n",
      "The MSE loss is : 0.35402029752731323\n",
      "The MSE loss is : 0.05145028233528137\n",
      "The MSE loss is : 0.04538138583302498\n",
      "The MSE loss is : 0.04358664155006409\n",
      "The MSE loss is : 0.042201928794384\n",
      "The MSE loss is : 0.0408492311835289\n",
      "The MSE loss is : 0.0398891419172287\n",
      "The MSE loss is : 0.04049256443977356\n",
      "The MSE loss is : 0.03873544558882713\n",
      "The MSE loss is : 0.039044082164764404\n",
      "The MSE loss is : 0.038059771060943604\n",
      "The MSE loss is : 0.03812946751713753\n",
      "The MSE loss is : 0.03776077181100845\n",
      "The MSE loss is : 0.037182096391916275\n",
      "The MSE loss is : 0.03681230545043945\n",
      "The MSE loss is : 0.03660507872700691\n",
      "The MSE loss is : 0.03660617768764496\n",
      "The MSE loss is : 0.03629102185368538\n",
      "The MSE loss is : 0.036119334399700165\n",
      "The MSE loss is : 0.03602369874715805\n",
      "Saving... file:record_err_64 method:pair-Seq\n",
      "\n",
      "Experiment N=64 SEED=963\n",
      "The MSE loss is : 0.34888964891433716\n",
      "The MSE loss is : 0.26344677805900574\n",
      "The MSE loss is : 0.2599630057811737\n",
      "The MSE loss is : 0.25958719849586487\n",
      "The MSE loss is : 0.25958719849586487\n",
      "The MSE loss is : 0.25958719849586487\n",
      "The MSE loss is : 0.25958719849586487\n",
      "The MSE loss is : 0.25958719849586487\n",
      "The MSE loss is : 0.2595871686935425\n",
      "The MSE loss is : 0.25958722829818726\n",
      "The MSE loss is : 0.25958719849586487\n",
      "The MSE loss is : 0.25958722829818726\n",
      "The MSE loss is : 0.2595871686935425\n",
      "The MSE loss is : 0.2595871686935425\n",
      "The MSE loss is : 0.25958722829818726\n",
      "The MSE loss is : 0.25958722829818726\n",
      "The MSE loss is : 0.2595871686935425\n",
      "The MSE loss is : 0.2595871686935425\n",
      "The MSE loss is : 0.25958719849586487\n",
      "The MSE loss is : 0.25958722829818726\n",
      "Saving... file:record_err_64 method:pair\n",
      "The MSE loss is : 0.34888964891433716\n",
      "The MSE loss is : 0.24391748011112213\n",
      "The MSE loss is : 0.24137434363365173\n",
      "The MSE loss is : 0.24134108424186707\n",
      "The MSE loss is : 0.24134108424186707\n",
      "The MSE loss is : 0.24134108424186707\n",
      "The MSE loss is : 0.24134108424186707\n",
      "The MSE loss is : 0.24134108424186707\n",
      "The MSE loss is : 0.24134108424186707\n",
      "The MSE loss is : 0.24134108424186707\n",
      "The MSE loss is : 0.24134108424186707\n",
      "The MSE loss is : 0.24134108424186707\n",
      "The MSE loss is : 0.24134108424186707\n",
      "The MSE loss is : 0.24134109914302826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.24134108424186707\n",
      "The MSE loss is : 0.24134108424186707\n",
      "The MSE loss is : 0.24134108424186707\n",
      "The MSE loss is : 0.24134109914302826\n",
      "The MSE loss is : 0.24134111404418945\n",
      "The MSE loss is : 0.24134108424186707\n",
      "Saving... file:record_err_64 method:block-sqrt-half\n",
      "The MSE loss is : 0.34888964891433716\n",
      "The MSE loss is : 0.26268208026885986\n",
      "The MSE loss is : 0.26264798641204834\n",
      "The MSE loss is : 0.2626456916332245\n",
      "The MSE loss is : 0.2626456320285797\n",
      "The MSE loss is : 0.2626456320285797\n",
      "The MSE loss is : 0.2626456320285797\n",
      "The MSE loss is : 0.2626456320285797\n",
      "The MSE loss is : 0.2626456618309021\n",
      "The MSE loss is : 0.2626456618309021\n",
      "The MSE loss is : 0.2626456618309021\n",
      "The MSE loss is : 0.2626456618309021\n",
      "The MSE loss is : 0.2626456618309021\n",
      "The MSE loss is : 0.2626456618309021\n",
      "The MSE loss is : 0.2626456618309021\n",
      "The MSE loss is : 0.2626456618309021\n",
      "The MSE loss is : 0.2626456618309021\n",
      "The MSE loss is : 0.2626456618309021\n",
      "The MSE loss is : 0.2626456618309021\n",
      "The MSE loss is : 0.2626456618309021\n",
      "Saving... file:record_err_64 method:block-sqrt\n",
      "Saving... file:record_err_64 method:lowR-same-param\n",
      "Saving... file:record_err_64 method:lowR-samex2\n",
      "Saving... file:record_err_64 method:lowR-half\n",
      "The MSE loss is : 0.4272056221961975\n",
      "The MSE loss is : 0.037203237414360046\n",
      "The MSE loss is : 0.025628555566072464\n",
      "The MSE loss is : 0.022853076457977295\n",
      "The MSE loss is : 0.022255070507526398\n",
      "The MSE loss is : 0.02180311270058155\n",
      "The MSE loss is : 0.02149835042655468\n",
      "The MSE loss is : 0.021305352449417114\n",
      "The MSE loss is : 0.02125713601708412\n",
      "The MSE loss is : 0.021008335053920746\n",
      "The MSE loss is : 0.020827138796448708\n",
      "The MSE loss is : 0.02061818540096283\n",
      "The MSE loss is : 0.02049880288541317\n",
      "The MSE loss is : 0.02044791355729103\n",
      "The MSE loss is : 0.020428285002708435\n",
      "The MSE loss is : 0.020401731133461\n",
      "The MSE loss is : 0.02041041851043701\n",
      "The MSE loss is : 0.02040369063615799\n",
      "The MSE loss is : 0.02038448117673397\n",
      "The MSE loss is : 0.020378831773996353\n",
      "Saving... file:record_err_64 method:pair-Add\n",
      "The MSE loss is : 0.34913694858551025\n",
      "The MSE loss is : 0.0562298521399498\n",
      "The MSE loss is : 0.04996073991060257\n",
      "The MSE loss is : 0.048173412680625916\n",
      "The MSE loss is : 0.04509600251913071\n",
      "The MSE loss is : 0.04379839822649956\n",
      "The MSE loss is : 0.04331395402550697\n",
      "The MSE loss is : 0.04305622726678848\n",
      "The MSE loss is : 0.041471321135759354\n",
      "The MSE loss is : 0.041009943932294846\n",
      "The MSE loss is : 0.04084727168083191\n",
      "The MSE loss is : 0.04037962853908539\n",
      "The MSE loss is : 0.03970927745103836\n",
      "The MSE loss is : 0.040504373610019684\n",
      "The MSE loss is : 0.039202965795993805\n",
      "The MSE loss is : 0.039910733699798584\n",
      "The MSE loss is : 0.03881007432937622\n",
      "The MSE loss is : 0.039125919342041016\n",
      "The MSE loss is : 0.03941936790943146\n",
      "The MSE loss is : 0.038280799984931946\n",
      "Saving... file:record_err_64 method:pair-Seq\n",
      "\n",
      "Experiment N=64 SEED=159\n",
      "The MSE loss is : 0.33940863609313965\n",
      "The MSE loss is : 0.2549316883087158\n",
      "The MSE loss is : 0.2525699734687805\n",
      "The MSE loss is : 0.252162367105484\n",
      "The MSE loss is : 0.25216227769851685\n",
      "The MSE loss is : 0.2515327036380768\n",
      "The MSE loss is : 0.2515326738357544\n",
      "The MSE loss is : 0.2515327036380768\n",
      "The MSE loss is : 0.2515326738357544\n",
      "The MSE loss is : 0.2515327036380768\n",
      "The MSE loss is : 0.2515326738357544\n",
      "The MSE loss is : 0.25153279304504395\n",
      "The MSE loss is : 0.2515326738357544\n",
      "The MSE loss is : 0.2515327036380768\n",
      "The MSE loss is : 0.25153273344039917\n",
      "The MSE loss is : 0.2515327036380768\n",
      "The MSE loss is : 0.25153279304504395\n",
      "The MSE loss is : 0.25153273344039917\n",
      "The MSE loss is : 0.2515328526496887\n",
      "The MSE loss is : 0.2515326738357544\n",
      "Saving... file:record_err_64 method:pair\n",
      "The MSE loss is : 0.33940863609313965\n",
      "The MSE loss is : 0.23316437005996704\n",
      "The MSE loss is : 0.2321094274520874\n",
      "The MSE loss is : 0.2321031391620636\n",
      "The MSE loss is : 0.231214702129364\n",
      "The MSE loss is : 0.2312147170305252\n",
      "The MSE loss is : 0.2312147170305252\n",
      "The MSE loss is : 0.2312147170305252\n",
      "The MSE loss is : 0.2312147170305252\n",
      "The MSE loss is : 0.2312147170305252\n",
      "The MSE loss is : 0.231214702129364\n",
      "The MSE loss is : 0.2312147170305252\n",
      "The MSE loss is : 0.2312147170305252\n",
      "The MSE loss is : 0.2312147319316864\n",
      "The MSE loss is : 0.2312147319316864\n",
      "The MSE loss is : 0.2312147319316864\n",
      "The MSE loss is : 0.2312147170305252\n",
      "The MSE loss is : 0.2312147319316864\n",
      "The MSE loss is : 0.231214702129364\n",
      "The MSE loss is : 0.2312147170305252\n",
      "Saving... file:record_err_64 method:block-sqrt-half\n",
      "The MSE loss is : 0.33940863609313965\n",
      "The MSE loss is : 0.25203821063041687\n",
      "The MSE loss is : 0.2520340085029602\n",
      "The MSE loss is : 0.2520339787006378\n",
      "The MSE loss is : 0.2520339787006378\n",
      "The MSE loss is : 0.2520340085029602\n",
      "The MSE loss is : 0.2520340085029602\n",
      "The MSE loss is : 0.2520339787006378\n",
      "The MSE loss is : 0.2520339787006378\n",
      "The MSE loss is : 0.2520339787006378\n",
      "The MSE loss is : 0.2520339787006378\n",
      "The MSE loss is : 0.2520340085029602\n",
      "The MSE loss is : 0.2520339787006378\n",
      "The MSE loss is : 0.2520339787006378\n",
      "The MSE loss is : 0.2520340085029602\n",
      "The MSE loss is : 0.2520340085029602\n",
      "The MSE loss is : 0.2520340085029602\n",
      "The MSE loss is : 0.2520340085029602\n",
      "The MSE loss is : 0.2520340085029602\n",
      "The MSE loss is : 0.2520340085029602\n",
      "Saving... file:record_err_64 method:block-sqrt\n",
      "Saving... file:record_err_64 method:lowR-same-param\n",
      "Saving... file:record_err_64 method:lowR-samex2\n",
      "Saving... file:record_err_64 method:lowR-half\n",
      "The MSE loss is : 0.4123679995536804\n",
      "The MSE loss is : 0.037059929221868515\n",
      "The MSE loss is : 0.026403550058603287\n",
      "The MSE loss is : 0.023819785565137863\n",
      "The MSE loss is : 0.02253095805644989\n",
      "The MSE loss is : 0.021763309836387634\n",
      "The MSE loss is : 0.02083675004541874\n",
      "The MSE loss is : 0.020321074873209\n",
      "The MSE loss is : 0.020219087600708008\n",
      "The MSE loss is : 0.020181309431791306\n",
      "The MSE loss is : 0.02011442929506302\n",
      "The MSE loss is : 0.02002532035112381\n",
      "The MSE loss is : 0.02000008523464203\n",
      "The MSE loss is : 0.01995985023677349\n",
      "The MSE loss is : 0.019933762028813362\n",
      "The MSE loss is : 0.019924810156226158\n",
      "The MSE loss is : 0.019923817366361618\n",
      "The MSE loss is : 0.01993608847260475\n",
      "The MSE loss is : 0.019923357293009758\n",
      "The MSE loss is : 0.019917229190468788\n",
      "Saving... file:record_err_64 method:pair-Add\n",
      "The MSE loss is : 0.33888185024261475\n",
      "The MSE loss is : 0.05179297924041748\n",
      "The MSE loss is : 0.04585687816143036\n",
      "The MSE loss is : 0.04329914599657059\n",
      "The MSE loss is : 0.04216068983078003\n",
      "The MSE loss is : 0.041378509253263474\n",
      "The MSE loss is : 0.04075334966182709\n",
      "The MSE loss is : 0.04019944369792938\n",
      "The MSE loss is : 0.04020801931619644\n",
      "The MSE loss is : 0.03942719101905823\n",
      "The MSE loss is : 0.039155397564172745\n",
      "The MSE loss is : 0.03885171189904213\n",
      "The MSE loss is : 0.03862832486629486\n",
      "The MSE loss is : 0.0391785129904747\n",
      "The MSE loss is : 0.039336685091257095\n",
      "The MSE loss is : 0.03819054737687111\n",
      "The MSE loss is : 0.03929208964109421\n",
      "The MSE loss is : 0.03798314929008484\n",
      "The MSE loss is : 0.03771785646677017\n",
      "The MSE loss is : 0.03748159855604172\n",
      "Saving... file:record_err_64 method:pair-Seq\n",
      "\n",
      "Experiment N=64 SEED=357\n",
      "The MSE loss is : 0.356806218624115\n",
      "The MSE loss is : 0.26918500661849976\n",
      "The MSE loss is : 0.26586541533470154\n",
      "The MSE loss is : 0.26467156410217285\n",
      "The MSE loss is : 0.26428231596946716\n",
      "The MSE loss is : 0.26428231596946716\n",
      "The MSE loss is : 0.26428231596946716\n",
      "The MSE loss is : 0.2642822861671448\n",
      "The MSE loss is : 0.26428231596946716\n",
      "The MSE loss is : 0.26428231596946716\n",
      "The MSE loss is : 0.2642824649810791\n",
      "The MSE loss is : 0.26428231596946716\n",
      "The MSE loss is : 0.26428231596946716\n",
      "The MSE loss is : 0.26428231596946716\n",
      "The MSE loss is : 0.2642824053764343\n",
      "The MSE loss is : 0.2642822861671448\n",
      "The MSE loss is : 0.26428231596946716\n",
      "The MSE loss is : 0.2642822861671448\n",
      "The MSE loss is : 0.26428234577178955\n",
      "The MSE loss is : 0.26428234577178955\n",
      "Saving... file:record_err_64 method:pair\n",
      "The MSE loss is : 0.356806218624115\n",
      "The MSE loss is : 0.24531465768814087\n",
      "The MSE loss is : 0.243331640958786\n",
      "The MSE loss is : 0.2433154284954071\n",
      "The MSE loss is : 0.24322235584259033\n",
      "The MSE loss is : 0.24322235584259033\n",
      "The MSE loss is : 0.24322235584259033\n",
      "The MSE loss is : 0.24322235584259033\n",
      "The MSE loss is : 0.24322235584259033\n",
      "The MSE loss is : 0.24322237074375153\n",
      "The MSE loss is : 0.24322235584259033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.24322235584259033\n",
      "The MSE loss is : 0.24322235584259033\n",
      "The MSE loss is : 0.24322237074375153\n",
      "The MSE loss is : 0.24322237074375153\n",
      "The MSE loss is : 0.24322237074375153\n",
      "The MSE loss is : 0.24322235584259033\n",
      "The MSE loss is : 0.24322237074375153\n",
      "The MSE loss is : 0.24322235584259033\n",
      "The MSE loss is : 0.24322238564491272\n",
      "Saving... file:record_err_64 method:block-sqrt-half\n",
      "The MSE loss is : 0.356806218624115\n",
      "The MSE loss is : 0.2626512050628662\n",
      "The MSE loss is : 0.26263630390167236\n",
      "The MSE loss is : 0.26263630390167236\n",
      "The MSE loss is : 0.26263630390167236\n",
      "The MSE loss is : 0.26263630390167236\n",
      "The MSE loss is : 0.26263630390167236\n",
      "The MSE loss is : 0.26263630390167236\n",
      "The MSE loss is : 0.26263627409935\n",
      "The MSE loss is : 0.26263627409935\n",
      "The MSE loss is : 0.26263630390167236\n",
      "The MSE loss is : 0.26263627409935\n",
      "The MSE loss is : 0.26263627409935\n",
      "The MSE loss is : 0.26263630390167236\n",
      "The MSE loss is : 0.26263630390167236\n",
      "The MSE loss is : 0.26263627409935\n",
      "The MSE loss is : 0.26263630390167236\n",
      "The MSE loss is : 0.26263630390167236\n",
      "The MSE loss is : 0.26263630390167236\n",
      "The MSE loss is : 0.26263630390167236\n",
      "Saving... file:record_err_64 method:block-sqrt\n",
      "Saving... file:record_err_64 method:lowR-same-param\n",
      "Saving... file:record_err_64 method:lowR-samex2\n",
      "Saving... file:record_err_64 method:lowR-half\n",
      "The MSE loss is : 0.44182270765304565\n",
      "The MSE loss is : 0.03942582383751869\n",
      "The MSE loss is : 0.027239788323640823\n",
      "The MSE loss is : 0.023849956691265106\n",
      "The MSE loss is : 0.021865615621209145\n",
      "The MSE loss is : 0.021354645490646362\n",
      "The MSE loss is : 0.02092573791742325\n",
      "The MSE loss is : 0.020479973405599594\n",
      "The MSE loss is : 0.02038458362221718\n",
      "The MSE loss is : 0.02019662968814373\n",
      "The MSE loss is : 0.020149245858192444\n",
      "The MSE loss is : 0.020099814981222153\n",
      "The MSE loss is : 0.02004821039736271\n",
      "The MSE loss is : 0.020039912313222885\n",
      "The MSE loss is : 0.0199733879417181\n",
      "The MSE loss is : 0.01994319073855877\n",
      "The MSE loss is : 0.01993514597415924\n",
      "The MSE loss is : 0.01992904767394066\n",
      "The MSE loss is : 0.019926827400922775\n",
      "The MSE loss is : 0.019924316555261612\n",
      "Saving... file:record_err_64 method:pair-Add\n",
      "The MSE loss is : 0.3527894616127014\n",
      "The MSE loss is : 0.054321274161338806\n",
      "The MSE loss is : 0.04855776205658913\n",
      "The MSE loss is : 0.04641443490982056\n",
      "The MSE loss is : 0.04512939602136612\n",
      "The MSE loss is : 0.04453347623348236\n",
      "The MSE loss is : 0.04377490282058716\n",
      "The MSE loss is : 0.04342392086982727\n",
      "The MSE loss is : 0.042931489646434784\n",
      "The MSE loss is : 0.04257998988032341\n",
      "The MSE loss is : 0.04230478033423424\n",
      "The MSE loss is : 0.04216058552265167\n",
      "The MSE loss is : 0.04190526157617569\n",
      "The MSE loss is : 0.04323440045118332\n",
      "The MSE loss is : 0.04199478402733803\n",
      "The MSE loss is : 0.04135219007730484\n",
      "The MSE loss is : 0.04112862050533295\n",
      "The MSE loss is : 0.04096926003694534\n",
      "The MSE loss is : 0.04076675325632095\n",
      "The MSE loss is : 0.04228050634264946\n",
      "Saving... file:record_err_64 method:pair-Seq\n",
      "\n",
      "Experiment N=64 SEED=951\n",
      "The MSE loss is : 0.344728022813797\n",
      "The MSE loss is : 0.26325902342796326\n",
      "The MSE loss is : 0.2607003450393677\n",
      "The MSE loss is : 0.25946080684661865\n",
      "The MSE loss is : 0.2592821419239044\n",
      "The MSE loss is : 0.2592821717262268\n",
      "The MSE loss is : 0.2592821717262268\n",
      "The MSE loss is : 0.2592821717262268\n",
      "The MSE loss is : 0.2592821717262268\n",
      "The MSE loss is : 0.2592821419239044\n",
      "The MSE loss is : 0.2592821717262268\n",
      "The MSE loss is : 0.2592821419239044\n",
      "The MSE loss is : 0.25928235054016113\n",
      "The MSE loss is : 0.2592821717262268\n",
      "The MSE loss is : 0.2592821419239044\n",
      "The MSE loss is : 0.2592821419239044\n",
      "The MSE loss is : 0.25928211212158203\n",
      "The MSE loss is : 0.2592821717262268\n",
      "The MSE loss is : 0.2592821419239044\n",
      "The MSE loss is : 0.2592821717262268\n",
      "Saving... file:record_err_64 method:pair\n",
      "The MSE loss is : 0.344728022813797\n",
      "The MSE loss is : 0.24240171909332275\n",
      "The MSE loss is : 0.240824356675148\n",
      "The MSE loss is : 0.23976737260818481\n",
      "The MSE loss is : 0.23976722359657288\n",
      "The MSE loss is : 0.23976725339889526\n",
      "The MSE loss is : 0.23976722359657288\n",
      "The MSE loss is : 0.23976722359657288\n",
      "The MSE loss is : 0.23976722359657288\n",
      "The MSE loss is : 0.23976723849773407\n",
      "The MSE loss is : 0.23976723849773407\n",
      "The MSE loss is : 0.23976723849773407\n",
      "The MSE loss is : 0.23976725339889526\n",
      "The MSE loss is : 0.23976725339889526\n",
      "The MSE loss is : 0.23976725339889526\n",
      "The MSE loss is : 0.23976725339889526\n",
      "The MSE loss is : 0.23976725339889526\n",
      "The MSE loss is : 0.23976725339889526\n",
      "The MSE loss is : 0.23976723849773407\n",
      "The MSE loss is : 0.23976725339889526\n",
      "Saving... file:record_err_64 method:block-sqrt-half\n",
      "The MSE loss is : 0.344728022813797\n",
      "The MSE loss is : 0.2539738416671753\n",
      "The MSE loss is : 0.25393176078796387\n",
      "The MSE loss is : 0.25393155217170715\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393155217170715\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393158197402954\n",
      "The MSE loss is : 0.25393158197402954\n",
      "Saving... file:record_err_64 method:block-sqrt\n",
      "Saving... file:record_err_64 method:lowR-same-param\n",
      "Saving... file:record_err_64 method:lowR-samex2\n",
      "Saving... file:record_err_64 method:lowR-half\n",
      "The MSE loss is : 0.4259845018386841\n",
      "The MSE loss is : 0.03777637332677841\n",
      "The MSE loss is : 0.027002990245819092\n",
      "The MSE loss is : 0.024406373500823975\n",
      "The MSE loss is : 0.023090217262506485\n",
      "The MSE loss is : 0.021993916481733322\n",
      "The MSE loss is : 0.02130724862217903\n",
      "The MSE loss is : 0.02121986635029316\n",
      "The MSE loss is : 0.02121615968644619\n",
      "The MSE loss is : 0.02087532728910446\n",
      "The MSE loss is : 0.020755207166075706\n",
      "The MSE loss is : 0.020748311653733253\n",
      "The MSE loss is : 0.02074437029659748\n",
      "The MSE loss is : 0.020736929029226303\n",
      "The MSE loss is : 0.020734703168272972\n",
      "The MSE loss is : 0.020732851698994637\n",
      "The MSE loss is : 0.020733051002025604\n",
      "The MSE loss is : 0.0207320898771286\n",
      "The MSE loss is : 0.020731952041387558\n",
      "The MSE loss is : 0.02072875201702118\n",
      "Saving... file:record_err_64 method:pair-Add\n",
      "The MSE loss is : 0.34559112787246704\n",
      "The MSE loss is : 0.05214862525463104\n",
      "The MSE loss is : 0.04705524444580078\n",
      "The MSE loss is : 0.043697748333215714\n",
      "The MSE loss is : 0.042146794497966766\n",
      "The MSE loss is : 0.04104996472597122\n",
      "The MSE loss is : 0.040546003729104996\n",
      "The MSE loss is : 0.03956735134124756\n",
      "The MSE loss is : 0.039956871420145035\n",
      "The MSE loss is : 0.038855843245983124\n",
      "The MSE loss is : 0.03987187147140503\n",
      "The MSE loss is : 0.038521528244018555\n",
      "The MSE loss is : 0.039124734699726105\n",
      "The MSE loss is : 0.038251399993896484\n",
      "The MSE loss is : 0.038217030465602875\n",
      "The MSE loss is : 0.03832031041383743\n",
      "The MSE loss is : 0.03772677481174469\n",
      "The MSE loss is : 0.037925273180007935\n",
      "The MSE loss is : 0.03738437592983246\n",
      "The MSE loss is : 0.03724595159292221\n",
      "Saving... file:record_err_64 method:pair-Seq\n",
      "\n",
      "Experiment N=64 SEED=753\n",
      "The MSE loss is : 0.34525519609451294\n",
      "The MSE loss is : 0.26630720496177673\n",
      "The MSE loss is : 0.261735200881958\n",
      "The MSE loss is : 0.2614709138870239\n",
      "The MSE loss is : 0.2614709138870239\n",
      "The MSE loss is : 0.26147088408470154\n",
      "The MSE loss is : 0.2614709138870239\n",
      "The MSE loss is : 0.2614709138870239\n",
      "The MSE loss is : 0.2614709138870239\n",
      "The MSE loss is : 0.2614709138870239\n",
      "The MSE loss is : 0.2614709436893463\n",
      "The MSE loss is : 0.2614709138870239\n",
      "The MSE loss is : 0.2614709138870239\n",
      "The MSE loss is : 0.2614709138870239\n",
      "The MSE loss is : 0.2614709436893463\n",
      "The MSE loss is : 0.2614709138870239\n",
      "The MSE loss is : 0.2614709138870239\n",
      "The MSE loss is : 0.26147088408470154\n",
      "The MSE loss is : 0.2614709138870239\n",
      "The MSE loss is : 0.2614709734916687\n",
      "Saving... file:record_err_64 method:pair\n",
      "The MSE loss is : 0.34525519609451294\n",
      "The MSE loss is : 0.241010844707489\n",
      "The MSE loss is : 0.2400980293750763\n",
      "The MSE loss is : 0.24009740352630615\n",
      "The MSE loss is : 0.24009738862514496\n",
      "The MSE loss is : 0.24009738862514496\n",
      "The MSE loss is : 0.24009738862514496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.24009740352630615\n",
      "The MSE loss is : 0.24009738862514496\n",
      "The MSE loss is : 0.24009740352630615\n",
      "The MSE loss is : 0.24009740352630615\n",
      "The MSE loss is : 0.24009740352630615\n",
      "The MSE loss is : 0.24009740352630615\n",
      "The MSE loss is : 0.24009740352630615\n",
      "The MSE loss is : 0.24009740352630615\n",
      "The MSE loss is : 0.24009740352630615\n",
      "The MSE loss is : 0.24009740352630615\n",
      "The MSE loss is : 0.24009740352630615\n",
      "The MSE loss is : 0.24009740352630615\n",
      "The MSE loss is : 0.24009740352630615\n",
      "Saving... file:record_err_64 method:block-sqrt-half\n",
      "The MSE loss is : 0.34525519609451294\n",
      "The MSE loss is : 0.26347702741622925\n",
      "The MSE loss is : 0.2633979022502899\n",
      "The MSE loss is : 0.26339784264564514\n",
      "The MSE loss is : 0.26339781284332275\n",
      "The MSE loss is : 0.26339781284332275\n",
      "The MSE loss is : 0.26339781284332275\n",
      "The MSE loss is : 0.26339781284332275\n",
      "The MSE loss is : 0.26339784264564514\n",
      "The MSE loss is : 0.26339781284332275\n",
      "The MSE loss is : 0.26339781284332275\n",
      "The MSE loss is : 0.26339784264564514\n",
      "The MSE loss is : 0.26339784264564514\n",
      "The MSE loss is : 0.26339784264564514\n",
      "The MSE loss is : 0.26339781284332275\n",
      "The MSE loss is : 0.26339784264564514\n",
      "The MSE loss is : 0.26339781284332275\n",
      "The MSE loss is : 0.26339784264564514\n",
      "The MSE loss is : 0.26339784264564514\n",
      "The MSE loss is : 0.26339784264564514\n",
      "Saving... file:record_err_64 method:block-sqrt\n",
      "Saving... file:record_err_64 method:lowR-same-param\n",
      "Saving... file:record_err_64 method:lowR-samex2\n",
      "Saving... file:record_err_64 method:lowR-half\n",
      "The MSE loss is : 0.4343583583831787\n",
      "The MSE loss is : 0.03708931803703308\n",
      "The MSE loss is : 0.028014227747917175\n",
      "The MSE loss is : 0.024440588429570198\n",
      "The MSE loss is : 0.022492069751024246\n",
      "The MSE loss is : 0.021979395300149918\n",
      "The MSE loss is : 0.021911701187491417\n",
      "The MSE loss is : 0.02185015007853508\n",
      "The MSE loss is : 0.021816562861204147\n",
      "The MSE loss is : 0.021798593923449516\n",
      "The MSE loss is : 0.021814174950122833\n",
      "The MSE loss is : 0.02177949994802475\n",
      "The MSE loss is : 0.021770305931568146\n",
      "The MSE loss is : 0.02178134396672249\n",
      "The MSE loss is : 0.021754123270511627\n",
      "The MSE loss is : 0.021760085597634315\n",
      "The MSE loss is : 0.02174776792526245\n",
      "The MSE loss is : 0.02175586298108101\n",
      "The MSE loss is : 0.021784720942378044\n",
      "The MSE loss is : 0.021745504811406136\n",
      "Saving... file:record_err_64 method:pair-Add\n",
      "The MSE loss is : 0.34729915857315063\n",
      "The MSE loss is : 0.05150845646858215\n",
      "The MSE loss is : 0.04654098302125931\n",
      "The MSE loss is : 0.044938236474990845\n",
      "The MSE loss is : 0.04437553137540817\n",
      "The MSE loss is : 0.04337526112794876\n",
      "The MSE loss is : 0.04305151104927063\n",
      "The MSE loss is : 0.04265156760811806\n",
      "The MSE loss is : 0.04303416982293129\n",
      "The MSE loss is : 0.04115983843803406\n",
      "The MSE loss is : 0.04118732362985611\n",
      "The MSE loss is : 0.04046279937028885\n",
      "The MSE loss is : 0.04023826867341995\n",
      "The MSE loss is : 0.04001036286354065\n",
      "The MSE loss is : 0.03974619880318642\n",
      "The MSE loss is : 0.039625585079193115\n",
      "The MSE loss is : 0.03971610218286514\n",
      "The MSE loss is : 0.03911124914884567\n",
      "The MSE loss is : 0.03890504688024521\n",
      "The MSE loss is : 0.03885562717914581\n",
      "Saving... file:record_err_64 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=147\n",
      "The MSE loss is : 0.33718395233154297\n",
      "The MSE loss is : 0.30751633644104004\n",
      "The MSE loss is : 0.3056437373161316\n",
      "The MSE loss is : 0.30491209030151367\n",
      "The MSE loss is : 0.3048853278160095\n",
      "The MSE loss is : 0.30488526821136475\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.30487051606178284\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.30487051606178284\n",
      "The MSE loss is : 0.30487051606178284\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.30487051606178284\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.3048705458641052\n",
      "The MSE loss is : 0.3048705458641052\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33718395233154297\n",
      "The MSE loss is : 0.29566365480422974\n",
      "The MSE loss is : 0.29557710886001587\n",
      "The MSE loss is : 0.2955471873283386\n",
      "The MSE loss is : 0.29554590582847595\n",
      "The MSE loss is : 0.29554036259651184\n",
      "The MSE loss is : 0.29554039239883423\n",
      "The MSE loss is : 0.29554039239883423\n",
      "The MSE loss is : 0.29554036259651184\n",
      "The MSE loss is : 0.29554036259651184\n",
      "The MSE loss is : 0.29554036259651184\n",
      "The MSE loss is : 0.29554036259651184\n",
      "The MSE loss is : 0.29554039239883423\n",
      "The MSE loss is : 0.29554039239883423\n",
      "The MSE loss is : 0.29554039239883423\n",
      "The MSE loss is : 0.29554039239883423\n",
      "The MSE loss is : 0.29554039239883423\n",
      "The MSE loss is : 0.29554036259651184\n",
      "The MSE loss is : 0.29554036259651184\n",
      "The MSE loss is : 0.29554039239883423\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33718395233154297\n",
      "The MSE loss is : 0.31248635053634644\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "The MSE loss is : 0.3124859929084778\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3663501739501953\n",
      "The MSE loss is : 0.15365439653396606\n",
      "The MSE loss is : 0.14430047571659088\n",
      "The MSE loss is : 0.14156019687652588\n",
      "The MSE loss is : 0.1403941512107849\n",
      "The MSE loss is : 0.139498770236969\n",
      "The MSE loss is : 0.13871029019355774\n",
      "The MSE loss is : 0.13802112638950348\n",
      "The MSE loss is : 0.13744062185287476\n",
      "The MSE loss is : 0.13735520839691162\n",
      "The MSE loss is : 0.13734877109527588\n",
      "The MSE loss is : 0.13734368979930878\n",
      "The MSE loss is : 0.1373402178287506\n",
      "The MSE loss is : 0.13732343912124634\n",
      "The MSE loss is : 0.13725319504737854\n",
      "The MSE loss is : 0.13724908232688904\n",
      "The MSE loss is : 0.1372503936290741\n",
      "The MSE loss is : 0.13724930584430695\n",
      "The MSE loss is : 0.13724812865257263\n",
      "The MSE loss is : 0.137248694896698\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3376785218715668\n",
      "The MSE loss is : 0.1497061401605606\n",
      "The MSE loss is : 0.14562933146953583\n",
      "The MSE loss is : 0.14402420818805695\n",
      "The MSE loss is : 0.14344534277915955\n",
      "The MSE loss is : 0.1426708996295929\n",
      "The MSE loss is : 0.1421707570552826\n",
      "The MSE loss is : 0.1417711079120636\n",
      "The MSE loss is : 0.14146360754966736\n",
      "The MSE loss is : 0.14120428264141083\n",
      "The MSE loss is : 0.14099276065826416\n",
      "The MSE loss is : 0.14085698127746582\n",
      "The MSE loss is : 0.14063599705696106\n",
      "The MSE loss is : 0.14050546288490295\n",
      "The MSE loss is : 0.14045356214046478\n",
      "The MSE loss is : 0.1405227780342102\n",
      "The MSE loss is : 0.14029887318611145\n",
      "The MSE loss is : 0.1401970088481903\n",
      "The MSE loss is : 0.14017286896705627\n",
      "The MSE loss is : 0.14008744060993195\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=258\n",
      "The MSE loss is : 0.3378857970237732\n",
      "The MSE loss is : 0.30672529339790344\n",
      "The MSE loss is : 0.3056827783584595\n",
      "The MSE loss is : 0.3052784204483032\n",
      "The MSE loss is : 0.30512136220932007\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459325313568\n",
      "The MSE loss is : 0.3050459027290344\n",
      "The MSE loss is : 0.3050459623336792\n",
      "The MSE loss is : 0.3050459027290344\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.3378857970237732\n",
      "The MSE loss is : 0.29683712124824524\n",
      "The MSE loss is : 0.296712189912796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.2967056930065155\n",
      "The MSE loss is : 0.29670560359954834\n",
      "The MSE loss is : 0.2967029809951782\n",
      "The MSE loss is : 0.2967029809951782\n",
      "The MSE loss is : 0.2967029809951782\n",
      "The MSE loss is : 0.29670295119285583\n",
      "The MSE loss is : 0.2967029809951782\n",
      "The MSE loss is : 0.2967029809951782\n",
      "The MSE loss is : 0.2967029809951782\n",
      "The MSE loss is : 0.2967029809951782\n",
      "The MSE loss is : 0.2967029809951782\n",
      "The MSE loss is : 0.2967029809951782\n",
      "The MSE loss is : 0.2967029809951782\n",
      "The MSE loss is : 0.29670295119285583\n",
      "The MSE loss is : 0.2967029809951782\n",
      "The MSE loss is : 0.2967029809951782\n",
      "The MSE loss is : 0.29670295119285583\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.3378857970237732\n",
      "The MSE loss is : 0.3131420612335205\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.31314200162887573\n",
      "The MSE loss is : 0.3131420314311981\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.36560893058776855\n",
      "The MSE loss is : 0.15356548130512238\n",
      "The MSE loss is : 0.1440727263689041\n",
      "The MSE loss is : 0.14024361968040466\n",
      "The MSE loss is : 0.1387849897146225\n",
      "The MSE loss is : 0.13810569047927856\n",
      "The MSE loss is : 0.13773900270462036\n",
      "The MSE loss is : 0.13757175207138062\n",
      "The MSE loss is : 0.13713978230953217\n",
      "The MSE loss is : 0.13653530180454254\n",
      "The MSE loss is : 0.1361689567565918\n",
      "The MSE loss is : 0.13609252870082855\n",
      "The MSE loss is : 0.1360921859741211\n",
      "The MSE loss is : 0.136092871427536\n",
      "The MSE loss is : 0.13609173893928528\n",
      "The MSE loss is : 0.1360917091369629\n",
      "The MSE loss is : 0.13609279692173004\n",
      "The MSE loss is : 0.1360917091369629\n",
      "The MSE loss is : 0.1360917091369629\n",
      "The MSE loss is : 0.13609160482883453\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.33819329738616943\n",
      "The MSE loss is : 0.15026794373989105\n",
      "The MSE loss is : 0.1466960906982422\n",
      "The MSE loss is : 0.14518249034881592\n",
      "The MSE loss is : 0.1441882848739624\n",
      "The MSE loss is : 0.1435961127281189\n",
      "The MSE loss is : 0.14328433573246002\n",
      "The MSE loss is : 0.14298737049102783\n",
      "The MSE loss is : 0.1427949070930481\n",
      "The MSE loss is : 0.14250674843788147\n",
      "The MSE loss is : 0.14251860976219177\n",
      "The MSE loss is : 0.14233535528182983\n",
      "The MSE loss is : 0.1421118974685669\n",
      "The MSE loss is : 0.1418328732252121\n",
      "The MSE loss is : 0.14164456725120544\n",
      "The MSE loss is : 0.14167127013206482\n",
      "The MSE loss is : 0.1415042281150818\n",
      "The MSE loss is : 0.14130881428718567\n",
      "The MSE loss is : 0.14135268330574036\n",
      "The MSE loss is : 0.14112523198127747\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=369\n",
      "The MSE loss is : 0.33567240834236145\n",
      "The MSE loss is : 0.30574673414230347\n",
      "The MSE loss is : 0.30459409952163696\n",
      "The MSE loss is : 0.30430498719215393\n",
      "The MSE loss is : 0.30381685495376587\n",
      "The MSE loss is : 0.30363529920578003\n",
      "The MSE loss is : 0.30363520979881287\n",
      "The MSE loss is : 0.30363520979881287\n",
      "The MSE loss is : 0.3036351799964905\n",
      "The MSE loss is : 0.30363523960113525\n",
      "The MSE loss is : 0.30363520979881287\n",
      "The MSE loss is : 0.30363523960113525\n",
      "The MSE loss is : 0.30363520979881287\n",
      "The MSE loss is : 0.30363523960113525\n",
      "The MSE loss is : 0.30363523960113525\n",
      "The MSE loss is : 0.30363523960113525\n",
      "The MSE loss is : 0.30363523960113525\n",
      "The MSE loss is : 0.3036351799964905\n",
      "The MSE loss is : 0.3036351799964905\n",
      "The MSE loss is : 0.30363523960113525\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33567240834236145\n",
      "The MSE loss is : 0.294786274433136\n",
      "The MSE loss is : 0.29469531774520874\n",
      "The MSE loss is : 0.2946752905845642\n",
      "The MSE loss is : 0.2946752607822418\n",
      "The MSE loss is : 0.29467523097991943\n",
      "The MSE loss is : 0.29467523097991943\n",
      "The MSE loss is : 0.29467523097991943\n",
      "The MSE loss is : 0.29467523097991943\n",
      "The MSE loss is : 0.2946752607822418\n",
      "The MSE loss is : 0.29467523097991943\n",
      "The MSE loss is : 0.29467523097991943\n",
      "The MSE loss is : 0.29467523097991943\n",
      "The MSE loss is : 0.29467523097991943\n",
      "The MSE loss is : 0.2946752607822418\n",
      "The MSE loss is : 0.29467523097991943\n",
      "The MSE loss is : 0.29467523097991943\n",
      "The MSE loss is : 0.2946752607822418\n",
      "The MSE loss is : 0.29467523097991943\n",
      "The MSE loss is : 0.29467523097991943\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33567240834236145\n",
      "The MSE loss is : 0.3114967942237854\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "The MSE loss is : 0.31149643659591675\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.36423587799072266\n",
      "The MSE loss is : 0.15325616300106049\n",
      "The MSE loss is : 0.1429721713066101\n",
      "The MSE loss is : 0.14066776633262634\n",
      "The MSE loss is : 0.13929486274719238\n",
      "The MSE loss is : 0.13826021552085876\n",
      "The MSE loss is : 0.13740287721157074\n",
      "The MSE loss is : 0.1368948221206665\n",
      "The MSE loss is : 0.13659454882144928\n",
      "The MSE loss is : 0.13658158481121063\n",
      "The MSE loss is : 0.1365075558423996\n",
      "The MSE loss is : 0.13645866513252258\n",
      "The MSE loss is : 0.13645637035369873\n",
      "The MSE loss is : 0.13645735383033752\n",
      "The MSE loss is : 0.136456698179245\n",
      "The MSE loss is : 0.13645505905151367\n",
      "The MSE loss is : 0.13645514845848083\n",
      "The MSE loss is : 0.136454775929451\n",
      "The MSE loss is : 0.13645505905151367\n",
      "The MSE loss is : 0.1364544928073883\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.33589643239974976\n",
      "The MSE loss is : 0.1494888812303543\n",
      "The MSE loss is : 0.14623211324214935\n",
      "The MSE loss is : 0.1446966528892517\n",
      "The MSE loss is : 0.14381307363510132\n",
      "The MSE loss is : 0.1432880163192749\n",
      "The MSE loss is : 0.1428097039461136\n",
      "The MSE loss is : 0.1425093561410904\n",
      "The MSE loss is : 0.14225398004055023\n",
      "The MSE loss is : 0.14198797941207886\n",
      "The MSE loss is : 0.14177227020263672\n",
      "The MSE loss is : 0.14160265028476715\n",
      "The MSE loss is : 0.14146552979946136\n",
      "The MSE loss is : 0.14133581519126892\n",
      "The MSE loss is : 0.14123129844665527\n",
      "The MSE loss is : 0.14111393690109253\n",
      "The MSE loss is : 0.14100904762744904\n",
      "The MSE loss is : 0.1409195065498352\n",
      "The MSE loss is : 0.1409081071615219\n",
      "The MSE loss is : 0.14100494980812073\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=321\n",
      "The MSE loss is : 0.3375713527202606\n",
      "The MSE loss is : 0.3078843355178833\n",
      "The MSE loss is : 0.3065446615219116\n",
      "The MSE loss is : 0.3059421479701996\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574461817741394\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574461817741394\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574461817741394\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574464797973633\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n",
      "The MSE loss is : 0.30574458837509155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.3375713527202606\n",
      "The MSE loss is : 0.2965623140335083\n",
      "The MSE loss is : 0.2964838445186615\n",
      "The MSE loss is : 0.2964630126953125\n",
      "The MSE loss is : 0.2964630126953125\n",
      "The MSE loss is : 0.2964573800563812\n",
      "The MSE loss is : 0.2964573800563812\n",
      "The MSE loss is : 0.2964573800563812\n",
      "The MSE loss is : 0.2964573800563812\n",
      "The MSE loss is : 0.2964573800563812\n",
      "The MSE loss is : 0.2964573800563812\n",
      "The MSE loss is : 0.2964573800563812\n",
      "The MSE loss is : 0.2964573800563812\n",
      "The MSE loss is : 0.2964573800563812\n",
      "The MSE loss is : 0.2964573800563812\n",
      "The MSE loss is : 0.2964573800563812\n",
      "The MSE loss is : 0.29645735025405884\n",
      "The MSE loss is : 0.29645735025405884\n",
      "The MSE loss is : 0.2964573800563812\n",
      "The MSE loss is : 0.2964573800563812\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.3375713527202606\n",
      "The MSE loss is : 0.31336772441864014\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "The MSE loss is : 0.3133676052093506\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3654269576072693\n",
      "The MSE loss is : 0.15317167341709137\n",
      "The MSE loss is : 0.1429278552532196\n",
      "The MSE loss is : 0.13992682099342346\n",
      "The MSE loss is : 0.13850489258766174\n",
      "The MSE loss is : 0.13762840628623962\n",
      "The MSE loss is : 0.13730940222740173\n",
      "The MSE loss is : 0.13689284026622772\n",
      "The MSE loss is : 0.13680419325828552\n",
      "The MSE loss is : 0.13679513335227966\n",
      "The MSE loss is : 0.13679146766662598\n",
      "The MSE loss is : 0.13678482174873352\n",
      "The MSE loss is : 0.13653972744941711\n",
      "The MSE loss is : 0.1363907903432846\n",
      "The MSE loss is : 0.13637816905975342\n",
      "The MSE loss is : 0.13636678457260132\n",
      "The MSE loss is : 0.13634678721427917\n",
      "The MSE loss is : 0.13633938133716583\n",
      "The MSE loss is : 0.13633999228477478\n",
      "The MSE loss is : 0.1363377571105957\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.33846840262413025\n",
      "The MSE loss is : 0.15200820565223694\n",
      "The MSE loss is : 0.14827017486095428\n",
      "The MSE loss is : 0.14666986465454102\n",
      "The MSE loss is : 0.14576295018196106\n",
      "The MSE loss is : 0.1453905999660492\n",
      "The MSE loss is : 0.1445774883031845\n",
      "The MSE loss is : 0.14414355158805847\n",
      "The MSE loss is : 0.14386090636253357\n",
      "The MSE loss is : 0.14377564191818237\n",
      "The MSE loss is : 0.14354676008224487\n",
      "The MSE loss is : 0.14354214072227478\n",
      "The MSE loss is : 0.1435222625732422\n",
      "The MSE loss is : 0.143240824341774\n",
      "The MSE loss is : 0.14325180649757385\n",
      "The MSE loss is : 0.14337050914764404\n",
      "The MSE loss is : 0.1430325210094452\n",
      "The MSE loss is : 0.1429394781589508\n",
      "The MSE loss is : 0.1429389864206314\n",
      "The MSE loss is : 0.14294520020484924\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=654\n",
      "The MSE loss is : 0.3369494080543518\n",
      "The MSE loss is : 0.30652084946632385\n",
      "The MSE loss is : 0.3048412799835205\n",
      "The MSE loss is : 0.3045271933078766\n",
      "The MSE loss is : 0.30430877208709717\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087124824524\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087124824524\n",
      "The MSE loss is : 0.30430880188941956\n",
      "The MSE loss is : 0.30430877208709717\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087124824524\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.3043087422847748\n",
      "The MSE loss is : 0.30430877208709717\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.3369494080543518\n",
      "The MSE loss is : 0.2958081364631653\n",
      "The MSE loss is : 0.29562658071517944\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955981194972992\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "The MSE loss is : 0.2955980896949768\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.3369494080543518\n",
      "The MSE loss is : 0.3117203414440155\n",
      "The MSE loss is : 0.31172001361846924\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "The MSE loss is : 0.31171998381614685\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3653230667114258\n",
      "The MSE loss is : 0.1527603566646576\n",
      "The MSE loss is : 0.14408165216445923\n",
      "The MSE loss is : 0.14142771065235138\n",
      "The MSE loss is : 0.13965588808059692\n",
      "The MSE loss is : 0.139169380068779\n",
      "The MSE loss is : 0.13845866918563843\n",
      "The MSE loss is : 0.13819459080696106\n",
      "The MSE loss is : 0.13771772384643555\n",
      "The MSE loss is : 0.13754869997501373\n",
      "The MSE loss is : 0.13754355907440186\n",
      "The MSE loss is : 0.13754048943519592\n",
      "The MSE loss is : 0.1375342309474945\n",
      "The MSE loss is : 0.13752515614032745\n",
      "The MSE loss is : 0.13746221363544464\n",
      "The MSE loss is : 0.13741916418075562\n",
      "The MSE loss is : 0.13722389936447144\n",
      "The MSE loss is : 0.13714845478534698\n",
      "The MSE loss is : 0.13709132373332977\n",
      "The MSE loss is : 0.1370777189731598\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3369959592819214\n",
      "The MSE loss is : 0.1514083743095398\n",
      "The MSE loss is : 0.1479378342628479\n",
      "The MSE loss is : 0.14639373123645782\n",
      "The MSE loss is : 0.14550690352916718\n",
      "The MSE loss is : 0.14451180398464203\n",
      "The MSE loss is : 0.1444023996591568\n",
      "The MSE loss is : 0.14381864666938782\n",
      "The MSE loss is : 0.14352962374687195\n",
      "The MSE loss is : 0.1432914435863495\n",
      "The MSE loss is : 0.14327022433280945\n",
      "The MSE loss is : 0.1429046392440796\n",
      "The MSE loss is : 0.14273065328598022\n",
      "The MSE loss is : 0.14255720376968384\n",
      "The MSE loss is : 0.1424776166677475\n",
      "The MSE loss is : 0.1423678696155548\n",
      "The MSE loss is : 0.1422690749168396\n",
      "The MSE loss is : 0.1422182321548462\n",
      "The MSE loss is : 0.14218862354755402\n",
      "The MSE loss is : 0.14189964532852173\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=987\n",
      "The MSE loss is : 0.3369542360305786\n",
      "The MSE loss is : 0.3062925934791565\n",
      "The MSE loss is : 0.3047820031642914\n",
      "The MSE loss is : 0.30450740456581116\n",
      "The MSE loss is : 0.3043172359466553\n",
      "The MSE loss is : 0.30429577827453613\n",
      "The MSE loss is : 0.30429574847221375\n",
      "The MSE loss is : 0.30429577827453613\n",
      "The MSE loss is : 0.30429577827453613\n",
      "The MSE loss is : 0.30429577827453613\n",
      "The MSE loss is : 0.30429577827453613\n",
      "The MSE loss is : 0.30429574847221375\n",
      "The MSE loss is : 0.30429574847221375\n",
      "The MSE loss is : 0.3042958676815033\n",
      "The MSE loss is : 0.3042958378791809\n",
      "The MSE loss is : 0.30429574847221375\n",
      "The MSE loss is : 0.30429577827453613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.30429574847221375\n",
      "The MSE loss is : 0.30429574847221375\n",
      "The MSE loss is : 0.30429577827453613\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.3369542360305786\n",
      "The MSE loss is : 0.29515737295150757\n",
      "The MSE loss is : 0.29500657320022583\n",
      "The MSE loss is : 0.2950037121772766\n",
      "The MSE loss is : 0.2950018346309662\n",
      "The MSE loss is : 0.2950018048286438\n",
      "The MSE loss is : 0.2950018346309662\n",
      "The MSE loss is : 0.2950018048286438\n",
      "The MSE loss is : 0.2950018346309662\n",
      "The MSE loss is : 0.2950018048286438\n",
      "The MSE loss is : 0.2950018346309662\n",
      "The MSE loss is : 0.2950018346309662\n",
      "The MSE loss is : 0.2950018346309662\n",
      "The MSE loss is : 0.2950018346309662\n",
      "The MSE loss is : 0.2950018346309662\n",
      "The MSE loss is : 0.2950018346309662\n",
      "The MSE loss is : 0.2950018346309662\n",
      "The MSE loss is : 0.2950018346309662\n",
      "The MSE loss is : 0.2950018346309662\n",
      "The MSE loss is : 0.2950018346309662\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.3369542360305786\n",
      "The MSE loss is : 0.31234443187713623\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "The MSE loss is : 0.3123434782028198\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3660483658313751\n",
      "The MSE loss is : 0.15283380448818207\n",
      "The MSE loss is : 0.14437726140022278\n",
      "The MSE loss is : 0.14162594079971313\n",
      "The MSE loss is : 0.14032846689224243\n",
      "The MSE loss is : 0.1385892927646637\n",
      "The MSE loss is : 0.13777893781661987\n",
      "The MSE loss is : 0.13732531666755676\n",
      "The MSE loss is : 0.13665035367012024\n",
      "The MSE loss is : 0.13657492399215698\n",
      "The MSE loss is : 0.13655149936676025\n",
      "The MSE loss is : 0.13652899861335754\n",
      "The MSE loss is : 0.13652890920639038\n",
      "The MSE loss is : 0.13652662932872772\n",
      "The MSE loss is : 0.1365261673927307\n",
      "The MSE loss is : 0.13652560114860535\n",
      "The MSE loss is : 0.13652655482292175\n",
      "The MSE loss is : 0.13652560114860535\n",
      "The MSE loss is : 0.13652575016021729\n",
      "The MSE loss is : 0.1365261822938919\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3367016911506653\n",
      "The MSE loss is : 0.14984706044197083\n",
      "The MSE loss is : 0.14588476717472076\n",
      "The MSE loss is : 0.14459902048110962\n",
      "The MSE loss is : 0.1438753604888916\n",
      "The MSE loss is : 0.14328256249427795\n",
      "The MSE loss is : 0.14298661053180695\n",
      "The MSE loss is : 0.14274470508098602\n",
      "The MSE loss is : 0.14239943027496338\n",
      "The MSE loss is : 0.1423318088054657\n",
      "The MSE loss is : 0.14218708872795105\n",
      "The MSE loss is : 0.14196720719337463\n",
      "The MSE loss is : 0.14169561862945557\n",
      "The MSE loss is : 0.14170658588409424\n",
      "The MSE loss is : 0.14143608510494232\n",
      "The MSE loss is : 0.14167745411396027\n",
      "The MSE loss is : 0.14127948880195618\n",
      "The MSE loss is : 0.14162319898605347\n",
      "The MSE loss is : 0.1413271129131317\n",
      "The MSE loss is : 0.14107997715473175\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=741\n",
      "The MSE loss is : 0.33608463406562805\n",
      "The MSE loss is : 0.30543357133865356\n",
      "The MSE loss is : 0.3041008710861206\n",
      "The MSE loss is : 0.3037857413291931\n",
      "The MSE loss is : 0.30368655920028687\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036806285381317\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036806285381317\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036805987358093\n",
      "The MSE loss is : 0.3036806285381317\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33608463406562805\n",
      "The MSE loss is : 0.2944648265838623\n",
      "The MSE loss is : 0.29434317350387573\n",
      "The MSE loss is : 0.2943187952041626\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "The MSE loss is : 0.29431670904159546\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33608463406562805\n",
      "The MSE loss is : 0.3115975260734558\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "The MSE loss is : 0.31159746646881104\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.36241453886032104\n",
      "The MSE loss is : 0.1523858606815338\n",
      "The MSE loss is : 0.14423419535160065\n",
      "The MSE loss is : 0.14126557111740112\n",
      "The MSE loss is : 0.13951650261878967\n",
      "The MSE loss is : 0.1385451704263687\n",
      "The MSE loss is : 0.13811565935611725\n",
      "The MSE loss is : 0.13751381635665894\n",
      "The MSE loss is : 0.13711442053318024\n",
      "The MSE loss is : 0.13685506582260132\n",
      "The MSE loss is : 0.13675647974014282\n",
      "The MSE loss is : 0.13673821091651917\n",
      "The MSE loss is : 0.13673268258571625\n",
      "The MSE loss is : 0.1367330253124237\n",
      "The MSE loss is : 0.13673369586467743\n",
      "The MSE loss is : 0.13673126697540283\n",
      "The MSE loss is : 0.1367294043302536\n",
      "The MSE loss is : 0.1367291510105133\n",
      "The MSE loss is : 0.13672983646392822\n",
      "The MSE loss is : 0.1367305964231491\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3357473611831665\n",
      "The MSE loss is : 0.14947998523712158\n",
      "The MSE loss is : 0.14605404436588287\n",
      "The MSE loss is : 0.1446247696876526\n",
      "The MSE loss is : 0.14372605085372925\n",
      "The MSE loss is : 0.14303874969482422\n",
      "The MSE loss is : 0.14257565140724182\n",
      "The MSE loss is : 0.14215686917304993\n",
      "The MSE loss is : 0.14174802601337433\n",
      "The MSE loss is : 0.1415216475725174\n",
      "The MSE loss is : 0.14146773517131805\n",
      "The MSE loss is : 0.14118504524230957\n",
      "The MSE loss is : 0.14107701182365417\n",
      "The MSE loss is : 0.14103075861930847\n",
      "The MSE loss is : 0.14106154441833496\n",
      "The MSE loss is : 0.1407681107521057\n",
      "The MSE loss is : 0.1406470686197281\n",
      "The MSE loss is : 0.1406508982181549\n",
      "The MSE loss is : 0.1403617560863495\n",
      "The MSE loss is : 0.14044560492038727\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=852\n",
      "The MSE loss is : 0.3376447558403015\n",
      "The MSE loss is : 0.3066113591194153\n",
      "The MSE loss is : 0.3049757480621338\n",
      "The MSE loss is : 0.3047933280467987\n",
      "The MSE loss is : 0.3047035336494446\n",
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.3046942353248596\n",
      "The MSE loss is : 0.30469420552253723\n",
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.3046942353248596\n",
      "The MSE loss is : 0.30469420552253723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.30469417572021484\n",
      "The MSE loss is : 0.3046942353248596\n",
      "The MSE loss is : 0.30469420552253723\n",
      "The MSE loss is : 0.30469420552253723\n",
      "The MSE loss is : 0.30469417572021484\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.3376447558403015\n",
      "The MSE loss is : 0.2955496311187744\n",
      "The MSE loss is : 0.29539135098457336\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "The MSE loss is : 0.2953650951385498\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.3376447558403015\n",
      "The MSE loss is : 0.31258490681648254\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "The MSE loss is : 0.312584787607193\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.36543694138526917\n",
      "The MSE loss is : 0.15352016687393188\n",
      "The MSE loss is : 0.14397326111793518\n",
      "The MSE loss is : 0.14050132036209106\n",
      "The MSE loss is : 0.1390429139137268\n",
      "The MSE loss is : 0.13824211061000824\n",
      "The MSE loss is : 0.13773873448371887\n",
      "The MSE loss is : 0.1375032663345337\n",
      "The MSE loss is : 0.1372348815202713\n",
      "The MSE loss is : 0.13700544834136963\n",
      "The MSE loss is : 0.13688869774341583\n",
      "The MSE loss is : 0.13688713312149048\n",
      "The MSE loss is : 0.1368858814239502\n",
      "The MSE loss is : 0.13688558340072632\n",
      "The MSE loss is : 0.136886328458786\n",
      "The MSE loss is : 0.13688689470291138\n",
      "The MSE loss is : 0.1368866264820099\n",
      "The MSE loss is : 0.13688528537750244\n",
      "The MSE loss is : 0.13688567280769348\n",
      "The MSE loss is : 0.13688530027866364\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.33829689025878906\n",
      "The MSE loss is : 0.1505243480205536\n",
      "The MSE loss is : 0.1468338519334793\n",
      "The MSE loss is : 0.14567750692367554\n",
      "The MSE loss is : 0.14483395218849182\n",
      "The MSE loss is : 0.1442808210849762\n",
      "The MSE loss is : 0.143722265958786\n",
      "The MSE loss is : 0.1434665322303772\n",
      "The MSE loss is : 0.14326542615890503\n",
      "The MSE loss is : 0.142990842461586\n",
      "The MSE loss is : 0.14292922616004944\n",
      "The MSE loss is : 0.14271283149719238\n",
      "The MSE loss is : 0.1425926834344864\n",
      "The MSE loss is : 0.14250722527503967\n",
      "The MSE loss is : 0.14250104129314423\n",
      "The MSE loss is : 0.1422724425792694\n",
      "The MSE loss is : 0.142215296626091\n",
      "The MSE loss is : 0.14239487051963806\n",
      "The MSE loss is : 0.1420397311449051\n",
      "The MSE loss is : 0.14202061295509338\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=963\n",
      "The MSE loss is : 0.33616235852241516\n",
      "The MSE loss is : 0.30603542923927307\n",
      "The MSE loss is : 0.3047929108142853\n",
      "The MSE loss is : 0.3044098913669586\n",
      "The MSE loss is : 0.3042568266391754\n",
      "The MSE loss is : 0.30419740080833435\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.30419740080833435\n",
      "The MSE loss is : 0.3041974604129791\n",
      "The MSE loss is : 0.3041974604129791\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.30419740080833435\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.3041975200176239\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.30419743061065674\n",
      "The MSE loss is : 0.3041974604129791\n",
      "The MSE loss is : 0.30419740080833435\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33616235852241516\n",
      "The MSE loss is : 0.29472702741622925\n",
      "The MSE loss is : 0.2946048378944397\n",
      "The MSE loss is : 0.2945597171783447\n",
      "The MSE loss is : 0.2945597171783447\n",
      "The MSE loss is : 0.2945597171783447\n",
      "The MSE loss is : 0.2945597171783447\n",
      "The MSE loss is : 0.2945597171783447\n",
      "The MSE loss is : 0.2945597171783447\n",
      "The MSE loss is : 0.2945597171783447\n",
      "The MSE loss is : 0.2945597171783447\n",
      "The MSE loss is : 0.2945597171783447\n",
      "The MSE loss is : 0.2945597469806671\n",
      "The MSE loss is : 0.2945597171783447\n",
      "The MSE loss is : 0.2945597171783447\n",
      "The MSE loss is : 0.2945597171783447\n",
      "The MSE loss is : 0.2945597469806671\n",
      "The MSE loss is : 0.2945597469806671\n",
      "The MSE loss is : 0.2945597171783447\n",
      "The MSE loss is : 0.2945597171783447\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33616235852241516\n",
      "The MSE loss is : 0.31154805421829224\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "The MSE loss is : 0.3115476667881012\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.36459773778915405\n",
      "The MSE loss is : 0.1528962254524231\n",
      "The MSE loss is : 0.14420902729034424\n",
      "The MSE loss is : 0.14090001583099365\n",
      "The MSE loss is : 0.1390603929758072\n",
      "The MSE loss is : 0.13844585418701172\n",
      "The MSE loss is : 0.137589693069458\n",
      "The MSE loss is : 0.13689054548740387\n",
      "The MSE loss is : 0.13674074411392212\n",
      "The MSE loss is : 0.13660335540771484\n",
      "The MSE loss is : 0.13656021654605865\n",
      "The MSE loss is : 0.13651281595230103\n",
      "The MSE loss is : 0.13638003170490265\n",
      "The MSE loss is : 0.13624721765518188\n",
      "The MSE loss is : 0.1361297219991684\n",
      "The MSE loss is : 0.1360657513141632\n",
      "The MSE loss is : 0.13604183495044708\n",
      "The MSE loss is : 0.1360383778810501\n",
      "The MSE loss is : 0.13603751361370087\n",
      "The MSE loss is : 0.1360369622707367\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3364195227622986\n",
      "The MSE loss is : 0.14970771968364716\n",
      "The MSE loss is : 0.14577624201774597\n",
      "The MSE loss is : 0.14402347803115845\n",
      "The MSE loss is : 0.14362108707427979\n",
      "The MSE loss is : 0.14319653809070587\n",
      "The MSE loss is : 0.1428612768650055\n",
      "The MSE loss is : 0.14250129461288452\n",
      "The MSE loss is : 0.14244861900806427\n",
      "The MSE loss is : 0.14208729565143585\n",
      "The MSE loss is : 0.141990527510643\n",
      "The MSE loss is : 0.14183826744556427\n",
      "The MSE loss is : 0.14177969098091125\n",
      "The MSE loss is : 0.1417538970708847\n",
      "The MSE loss is : 0.1419822871685028\n",
      "The MSE loss is : 0.1415950059890747\n",
      "The MSE loss is : 0.14149072766304016\n",
      "The MSE loss is : 0.1416921466588974\n",
      "The MSE loss is : 0.14126792550086975\n",
      "The MSE loss is : 0.14153724908828735\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=159\n",
      "The MSE loss is : 0.3379421830177307\n",
      "The MSE loss is : 0.30750611424446106\n",
      "The MSE loss is : 0.30633658170700073\n",
      "The MSE loss is : 0.30619505047798157\n",
      "The MSE loss is : 0.30615273118019104\n",
      "The MSE loss is : 0.3061524033546448\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614808201789856\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614805221557617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614811182022095\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.30614805221557617\n",
      "The MSE loss is : 0.3061481714248657\n",
      "The MSE loss is : 0.30614808201789856\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.3379421830177307\n",
      "The MSE loss is : 0.29575836658477783\n",
      "The MSE loss is : 0.2955612540245056\n",
      "The MSE loss is : 0.2955511212348938\n",
      "The MSE loss is : 0.29555076360702515\n",
      "The MSE loss is : 0.29554715752601624\n",
      "The MSE loss is : 0.2955471873283386\n",
      "The MSE loss is : 0.2955471873283386\n",
      "The MSE loss is : 0.2955471873283386\n",
      "The MSE loss is : 0.2955471873283386\n",
      "The MSE loss is : 0.29554715752601624\n",
      "The MSE loss is : 0.29554715752601624\n",
      "The MSE loss is : 0.29554715752601624\n",
      "The MSE loss is : 0.29554715752601624\n",
      "The MSE loss is : 0.29554715752601624\n",
      "The MSE loss is : 0.2955471873283386\n",
      "The MSE loss is : 0.29554715752601624\n",
      "The MSE loss is : 0.29554715752601624\n",
      "The MSE loss is : 0.2955471873283386\n",
      "The MSE loss is : 0.29554715752601624\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.3379421830177307\n",
      "The MSE loss is : 0.3131774067878723\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "The MSE loss is : 0.3131771981716156\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.36587995290756226\n",
      "The MSE loss is : 0.15370208024978638\n",
      "The MSE loss is : 0.1448940485715866\n",
      "The MSE loss is : 0.14239615201950073\n",
      "The MSE loss is : 0.14086118340492249\n",
      "The MSE loss is : 0.13961753249168396\n",
      "The MSE loss is : 0.13886019587516785\n",
      "The MSE loss is : 0.13810795545578003\n",
      "The MSE loss is : 0.13794416189193726\n",
      "The MSE loss is : 0.13784757256507874\n",
      "The MSE loss is : 0.13780046999454498\n",
      "The MSE loss is : 0.13778558373451233\n",
      "The MSE loss is : 0.13769033551216125\n",
      "The MSE loss is : 0.13749893009662628\n",
      "The MSE loss is : 0.13745637238025665\n",
      "The MSE loss is : 0.13745303452014923\n",
      "The MSE loss is : 0.13745275139808655\n",
      "The MSE loss is : 0.13744336366653442\n",
      "The MSE loss is : 0.13739079236984253\n",
      "The MSE loss is : 0.13722467422485352\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3377634286880493\n",
      "The MSE loss is : 0.15006288886070251\n",
      "The MSE loss is : 0.14635884761810303\n",
      "The MSE loss is : 0.14487984776496887\n",
      "The MSE loss is : 0.1439647078514099\n",
      "The MSE loss is : 0.14337819814682007\n",
      "The MSE loss is : 0.14295777678489685\n",
      "The MSE loss is : 0.14264194667339325\n",
      "The MSE loss is : 0.14216813445091248\n",
      "The MSE loss is : 0.14194321632385254\n",
      "The MSE loss is : 0.1417349874973297\n",
      "The MSE loss is : 0.1414845883846283\n",
      "The MSE loss is : 0.1413903534412384\n",
      "The MSE loss is : 0.14121979475021362\n",
      "The MSE loss is : 0.14133107662200928\n",
      "The MSE loss is : 0.14134010672569275\n",
      "The MSE loss is : 0.14112713932991028\n",
      "The MSE loss is : 0.14103932678699493\n",
      "The MSE loss is : 0.14107057452201843\n",
      "The MSE loss is : 0.14093273878097534\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=357\n",
      "The MSE loss is : 0.33726418018341064\n",
      "The MSE loss is : 0.3070529103279114\n",
      "The MSE loss is : 0.30571556091308594\n",
      "The MSE loss is : 0.3053184151649475\n",
      "The MSE loss is : 0.30525755882263184\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.3051893413066864\n",
      "The MSE loss is : 0.3051893413066864\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.3051893413066864\n",
      "The MSE loss is : 0.3051893413066864\n",
      "The MSE loss is : 0.3051893413066864\n",
      "The MSE loss is : 0.3051893711090088\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.3051893413066864\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.305189311504364\n",
      "The MSE loss is : 0.30518943071365356\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33726418018341064\n",
      "The MSE loss is : 0.2956993579864502\n",
      "The MSE loss is : 0.2956029176712036\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "The MSE loss is : 0.2955988347530365\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33726418018341064\n",
      "The MSE loss is : 0.3126344680786133\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "The MSE loss is : 0.3126344084739685\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3652098476886749\n",
      "The MSE loss is : 0.1526077687740326\n",
      "The MSE loss is : 0.14345614612102509\n",
      "The MSE loss is : 0.14110183715820312\n",
      "The MSE loss is : 0.13923236727714539\n",
      "The MSE loss is : 0.13836076855659485\n",
      "The MSE loss is : 0.13782891631126404\n",
      "The MSE loss is : 0.13738447427749634\n",
      "The MSE loss is : 0.1369170844554901\n",
      "The MSE loss is : 0.13677097856998444\n",
      "The MSE loss is : 0.13676407933235168\n",
      "The MSE loss is : 0.1367475986480713\n",
      "The MSE loss is : 0.13674470782279968\n",
      "The MSE loss is : 0.136738121509552\n",
      "The MSE loss is : 0.13669796288013458\n",
      "The MSE loss is : 0.13668803870677948\n",
      "The MSE loss is : 0.13659557700157166\n",
      "The MSE loss is : 0.1365307867527008\n",
      "The MSE loss is : 0.13651204109191895\n",
      "The MSE loss is : 0.13648676872253418\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.3368745744228363\n",
      "The MSE loss is : 0.14921514689922333\n",
      "The MSE loss is : 0.14554309844970703\n",
      "The MSE loss is : 0.14443045854568481\n",
      "The MSE loss is : 0.1435299962759018\n",
      "The MSE loss is : 0.14305344223976135\n",
      "The MSE loss is : 0.14253507554531097\n",
      "The MSE loss is : 0.1422518640756607\n",
      "The MSE loss is : 0.141971617937088\n",
      "The MSE loss is : 0.1416819840669632\n",
      "The MSE loss is : 0.14163532853126526\n",
      "The MSE loss is : 0.1414642035961151\n",
      "The MSE loss is : 0.14125385880470276\n",
      "The MSE loss is : 0.14104950428009033\n",
      "The MSE loss is : 0.14107970893383026\n",
      "The MSE loss is : 0.14093700051307678\n",
      "The MSE loss is : 0.14089998602867126\n",
      "The MSE loss is : 0.14080235362052917\n",
      "The MSE loss is : 0.14075154066085815\n",
      "The MSE loss is : 0.1406804919242859\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=951\n",
      "The MSE loss is : 0.33734333515167236\n",
      "The MSE loss is : 0.30579227209091187\n",
      "The MSE loss is : 0.30465805530548096\n",
      "The MSE loss is : 0.30437466502189636\n",
      "The MSE loss is : 0.3041991591453552\n",
      "The MSE loss is : 0.3041802942752838\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.30417078733444214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.3041708171367645\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.3041708767414093\n",
      "The MSE loss is : 0.3041708171367645\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.3041708171367645\n",
      "The MSE loss is : 0.30417078733444214\n",
      "The MSE loss is : 0.30417078733444214\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33734333515167236\n",
      "The MSE loss is : 0.29586702585220337\n",
      "The MSE loss is : 0.2957000732421875\n",
      "The MSE loss is : 0.2956843376159668\n",
      "The MSE loss is : 0.2956843376159668\n",
      "The MSE loss is : 0.2956843078136444\n",
      "The MSE loss is : 0.2956843078136444\n",
      "The MSE loss is : 0.2956843078136444\n",
      "The MSE loss is : 0.2956843376159668\n",
      "The MSE loss is : 0.2956843376159668\n",
      "The MSE loss is : 0.2956843376159668\n",
      "The MSE loss is : 0.2956843078136444\n",
      "The MSE loss is : 0.2956843376159668\n",
      "The MSE loss is : 0.2956843376159668\n",
      "The MSE loss is : 0.2956843376159668\n",
      "The MSE loss is : 0.2956843376159668\n",
      "The MSE loss is : 0.2956843376159668\n",
      "The MSE loss is : 0.2956843078136444\n",
      "The MSE loss is : 0.2956843376159668\n",
      "The MSE loss is : 0.2956843376159668\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33734333515167236\n",
      "The MSE loss is : 0.3124621510505676\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.3124611973762512\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "The MSE loss is : 0.31246116757392883\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3653397560119629\n",
      "The MSE loss is : 0.1517653912305832\n",
      "The MSE loss is : 0.14327676594257355\n",
      "The MSE loss is : 0.14013466238975525\n",
      "The MSE loss is : 0.13887371122837067\n",
      "The MSE loss is : 0.13778291642665863\n",
      "The MSE loss is : 0.13695302605628967\n",
      "The MSE loss is : 0.13682544231414795\n",
      "The MSE loss is : 0.13645334541797638\n",
      "The MSE loss is : 0.13620254397392273\n",
      "The MSE loss is : 0.13612355291843414\n",
      "The MSE loss is : 0.13612326979637146\n",
      "The MSE loss is : 0.13612298667430878\n",
      "The MSE loss is : 0.1361229419708252\n",
      "The MSE loss is : 0.13612273335456848\n",
      "The MSE loss is : 0.1361226886510849\n",
      "The MSE loss is : 0.13612253963947296\n",
      "The MSE loss is : 0.13612255454063416\n",
      "The MSE loss is : 0.13612274825572968\n",
      "The MSE loss is : 0.13612297177314758\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.33624088764190674\n",
      "The MSE loss is : 0.14953665435314178\n",
      "The MSE loss is : 0.14593958854675293\n",
      "The MSE loss is : 0.14463894069194794\n",
      "The MSE loss is : 0.14381062984466553\n",
      "The MSE loss is : 0.14311134815216064\n",
      "The MSE loss is : 0.14279170334339142\n",
      "The MSE loss is : 0.1423427164554596\n",
      "The MSE loss is : 0.14214764535427094\n",
      "The MSE loss is : 0.14183409512043\n",
      "The MSE loss is : 0.14172151684761047\n",
      "The MSE loss is : 0.14185956120491028\n",
      "The MSE loss is : 0.1414274126291275\n",
      "The MSE loss is : 0.1416204571723938\n",
      "The MSE loss is : 0.1411856710910797\n",
      "The MSE loss is : 0.14122214913368225\n",
      "The MSE loss is : 0.1410580277442932\n",
      "The MSE loss is : 0.14102640748023987\n",
      "The MSE loss is : 0.1406698375940323\n",
      "The MSE loss is : 0.1405748724937439\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=256 SEED=753\n",
      "The MSE loss is : 0.33508166670799255\n",
      "The MSE loss is : 0.30500614643096924\n",
      "The MSE loss is : 0.3031643033027649\n",
      "The MSE loss is : 0.30283457040786743\n",
      "The MSE loss is : 0.3027329444885254\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273279547691345\n",
      "The MSE loss is : 0.30273279547691345\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273276567459106\n",
      "The MSE loss is : 0.302732914686203\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273279547691345\n",
      "The MSE loss is : 0.30273279547691345\n",
      "The MSE loss is : 0.30273279547691345\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273282527923584\n",
      "The MSE loss is : 0.30273282527923584\n",
      "Saving... file:record_err_256 method:pair\n",
      "The MSE loss is : 0.33508166670799255\n",
      "The MSE loss is : 0.29331669211387634\n",
      "The MSE loss is : 0.2931289076805115\n",
      "The MSE loss is : 0.2931169867515564\n",
      "The MSE loss is : 0.29311642050743103\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "The MSE loss is : 0.2931159734725952\n",
      "Saving... file:record_err_256 method:block-sqrt-half\n",
      "The MSE loss is : 0.33508166670799255\n",
      "The MSE loss is : 0.3106585144996643\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "The MSE loss is : 0.31065839529037476\n",
      "Saving... file:record_err_256 method:block-sqrt\n",
      "Saving... file:record_err_256 method:lowR-same-param\n",
      "Saving... file:record_err_256 method:lowR-samex2\n",
      "Saving... file:record_err_256 method:lowR-half\n",
      "The MSE loss is : 0.3648436665534973\n",
      "The MSE loss is : 0.15143850445747375\n",
      "The MSE loss is : 0.14139261841773987\n",
      "The MSE loss is : 0.13857167959213257\n",
      "The MSE loss is : 0.1373213678598404\n",
      "The MSE loss is : 0.1366220861673355\n",
      "The MSE loss is : 0.13614721596240997\n",
      "The MSE loss is : 0.13600648939609528\n",
      "The MSE loss is : 0.13579773902893066\n",
      "The MSE loss is : 0.1353052258491516\n",
      "The MSE loss is : 0.13513946533203125\n",
      "The MSE loss is : 0.1351136863231659\n",
      "The MSE loss is : 0.13492143154144287\n",
      "The MSE loss is : 0.13491426408290863\n",
      "The MSE loss is : 0.13491247594356537\n",
      "The MSE loss is : 0.13491159677505493\n",
      "The MSE loss is : 0.13491295278072357\n",
      "The MSE loss is : 0.13491162657737732\n",
      "The MSE loss is : 0.13490989804267883\n",
      "The MSE loss is : 0.13491186499595642\n",
      "Saving... file:record_err_256 method:pair-Add\n",
      "The MSE loss is : 0.33530348539352417\n",
      "The MSE loss is : 0.15001747012138367\n",
      "The MSE loss is : 0.14635100960731506\n",
      "The MSE loss is : 0.14478614926338196\n",
      "The MSE loss is : 0.1439678966999054\n",
      "The MSE loss is : 0.14337506890296936\n",
      "The MSE loss is : 0.14366699755191803\n",
      "The MSE loss is : 0.14242824912071228\n",
      "The MSE loss is : 0.14213895797729492\n",
      "The MSE loss is : 0.1419631838798523\n",
      "The MSE loss is : 0.14162124693393707\n",
      "The MSE loss is : 0.14169782400131226\n",
      "The MSE loss is : 0.1415465772151947\n",
      "The MSE loss is : 0.1412489414215088\n",
      "The MSE loss is : 0.1409892588853836\n",
      "The MSE loss is : 0.14078325033187866\n",
      "The MSE loss is : 0.140585258603096\n",
      "The MSE loss is : 0.1408909410238266\n",
      "The MSE loss is : 0.14036762714385986\n",
      "The MSE loss is : 0.1404307782649994\n",
      "Saving... file:record_err_256 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=147\n",
      "The MSE loss is : 0.3339892029762268\n",
      "The MSE loss is : 0.3239596486091614\n",
      "The MSE loss is : 0.32336628437042236\n",
      "The MSE loss is : 0.32313302159309387\n",
      "The MSE loss is : 0.3230176866054535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.3229726552963257\n",
      "The MSE loss is : 0.3229457139968872\n",
      "The MSE loss is : 0.3229377269744873\n",
      "The MSE loss is : 0.3229323923587799\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "The MSE loss is : 0.32293111085891724\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.3339892029762268\n",
      "The MSE loss is : 0.32015591859817505\n",
      "The MSE loss is : 0.3201518654823303\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "The MSE loss is : 0.3201512098312378\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.3339892029762268\n",
      "The MSE loss is : 0.32268446683883667\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "The MSE loss is : 0.3226843476295471\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34284883737564087\n",
      "The MSE loss is : 0.2482040822505951\n",
      "The MSE loss is : 0.24320247769355774\n",
      "The MSE loss is : 0.24130788445472717\n",
      "The MSE loss is : 0.24032756686210632\n",
      "The MSE loss is : 0.23962590098381042\n",
      "The MSE loss is : 0.23913952708244324\n",
      "The MSE loss is : 0.2388308197259903\n",
      "The MSE loss is : 0.2385815978050232\n",
      "The MSE loss is : 0.23842647671699524\n",
      "The MSE loss is : 0.23830117285251617\n",
      "The MSE loss is : 0.23822930455207825\n",
      "The MSE loss is : 0.23812918365001678\n",
      "The MSE loss is : 0.23809796571731567\n",
      "The MSE loss is : 0.23806241154670715\n",
      "The MSE loss is : 0.23802369832992554\n",
      "The MSE loss is : 0.23796986043453217\n",
      "The MSE loss is : 0.23795247077941895\n",
      "The MSE loss is : 0.23793718218803406\n",
      "The MSE loss is : 0.23792965710163116\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.3339969217777252\n",
      "The MSE loss is : 0.24193991720676422\n",
      "The MSE loss is : 0.24014823138713837\n",
      "The MSE loss is : 0.2396032065153122\n",
      "The MSE loss is : 0.23929624259471893\n",
      "The MSE loss is : 0.2390793412923813\n",
      "The MSE loss is : 0.2389077991247177\n",
      "The MSE loss is : 0.23881009221076965\n",
      "The MSE loss is : 0.2386694848537445\n",
      "The MSE loss is : 0.23857775330543518\n",
      "The MSE loss is : 0.23851029574871063\n",
      "The MSE loss is : 0.23845410346984863\n",
      "The MSE loss is : 0.2384072244167328\n",
      "The MSE loss is : 0.23835551738739014\n",
      "The MSE loss is : 0.23834002017974854\n",
      "The MSE loss is : 0.23829805850982666\n",
      "The MSE loss is : 0.23827186226844788\n",
      "The MSE loss is : 0.23824262619018555\n",
      "The MSE loss is : 0.2381986826658249\n",
      "The MSE loss is : 0.23817923665046692\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=258\n",
      "The MSE loss is : 0.3342400789260864\n",
      "The MSE loss is : 0.3241846561431885\n",
      "The MSE loss is : 0.32357680797576904\n",
      "The MSE loss is : 0.3234204649925232\n",
      "The MSE loss is : 0.3233284056186676\n",
      "The MSE loss is : 0.3232693672180176\n",
      "The MSE loss is : 0.3231987953186035\n",
      "The MSE loss is : 0.32318320870399475\n",
      "The MSE loss is : 0.3231699466705322\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316890358924866\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316890358924866\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "The MSE loss is : 0.32316887378692627\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.3342400789260864\n",
      "The MSE loss is : 0.32038718461990356\n",
      "The MSE loss is : 0.320383757352829\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "The MSE loss is : 0.3203837275505066\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.3342400789260864\n",
      "The MSE loss is : 0.32282233238220215\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "The MSE loss is : 0.3228222727775574\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34287798404693604\n",
      "The MSE loss is : 0.24848487973213196\n",
      "The MSE loss is : 0.24315112829208374\n",
      "The MSE loss is : 0.24140119552612305\n",
      "The MSE loss is : 0.24051101505756378\n",
      "The MSE loss is : 0.2399352639913559\n",
      "The MSE loss is : 0.2395259141921997\n",
      "The MSE loss is : 0.23922814428806305\n",
      "The MSE loss is : 0.23895135521888733\n",
      "The MSE loss is : 0.23871871829032898\n",
      "The MSE loss is : 0.23855142295360565\n",
      "The MSE loss is : 0.23846189677715302\n",
      "The MSE loss is : 0.23841995000839233\n",
      "The MSE loss is : 0.23837855458259583\n",
      "The MSE loss is : 0.2383466362953186\n",
      "The MSE loss is : 0.23825040459632874\n",
      "The MSE loss is : 0.23818866908550262\n",
      "The MSE loss is : 0.23814024031162262\n",
      "The MSE loss is : 0.23810258507728577\n",
      "The MSE loss is : 0.23807629942893982\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.3342563211917877\n",
      "The MSE loss is : 0.24194759130477905\n",
      "The MSE loss is : 0.24022528529167175\n",
      "The MSE loss is : 0.23960821330547333\n",
      "The MSE loss is : 0.23927895724773407\n",
      "The MSE loss is : 0.23906689882278442\n",
      "The MSE loss is : 0.23891732096672058\n",
      "The MSE loss is : 0.23879624903202057\n",
      "The MSE loss is : 0.23870638012886047\n",
      "The MSE loss is : 0.23859302699565887\n",
      "The MSE loss is : 0.23851731419563293\n",
      "The MSE loss is : 0.2384510040283203\n",
      "The MSE loss is : 0.23840069770812988\n",
      "The MSE loss is : 0.23834526538848877\n",
      "The MSE loss is : 0.23829002678394318\n",
      "The MSE loss is : 0.23823688924312592\n",
      "The MSE loss is : 0.23818859457969666\n",
      "The MSE loss is : 0.2381364405155182\n",
      "The MSE loss is : 0.23813004791736603\n",
      "The MSE loss is : 0.23813046514987946\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=369\n",
      "The MSE loss is : 0.33462899923324585\n",
      "The MSE loss is : 0.3244115114212036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.32386431097984314\n",
      "The MSE loss is : 0.32367217540740967\n",
      "The MSE loss is : 0.3235931098461151\n",
      "The MSE loss is : 0.3235494792461395\n",
      "The MSE loss is : 0.3235347867012024\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235335946083069\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235335946083069\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235336244106293\n",
      "The MSE loss is : 0.3235336244106293\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.33462899923324585\n",
      "The MSE loss is : 0.3207998275756836\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "The MSE loss is : 0.3207966089248657\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.33462899923324585\n",
      "The MSE loss is : 0.32318776845932007\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "The MSE loss is : 0.3231877088546753\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34368622303009033\n",
      "The MSE loss is : 0.2487199306488037\n",
      "The MSE loss is : 0.24342918395996094\n",
      "The MSE loss is : 0.24159958958625793\n",
      "The MSE loss is : 0.2405748814344406\n",
      "The MSE loss is : 0.23999986052513123\n",
      "The MSE loss is : 0.23955048620700836\n",
      "The MSE loss is : 0.2391904890537262\n",
      "The MSE loss is : 0.23894017934799194\n",
      "The MSE loss is : 0.23881009221076965\n",
      "The MSE loss is : 0.23872342705726624\n",
      "The MSE loss is : 0.23862451314926147\n",
      "The MSE loss is : 0.2385449856519699\n",
      "The MSE loss is : 0.2384682595729828\n",
      "The MSE loss is : 0.23844021558761597\n",
      "The MSE loss is : 0.23843719065189362\n",
      "The MSE loss is : 0.23842765390872955\n",
      "The MSE loss is : 0.2383994311094284\n",
      "The MSE loss is : 0.23838704824447632\n",
      "The MSE loss is : 0.2383650839328766\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.33456528186798096\n",
      "The MSE loss is : 0.24219447374343872\n",
      "The MSE loss is : 0.24060508608818054\n",
      "The MSE loss is : 0.2400258630514145\n",
      "The MSE loss is : 0.23970486223697662\n",
      "The MSE loss is : 0.23946300148963928\n",
      "The MSE loss is : 0.23928530514240265\n",
      "The MSE loss is : 0.23916277289390564\n",
      "The MSE loss is : 0.2390400767326355\n",
      "The MSE loss is : 0.2389538437128067\n",
      "The MSE loss is : 0.23888592422008514\n",
      "The MSE loss is : 0.238836407661438\n",
      "The MSE loss is : 0.23875856399536133\n",
      "The MSE loss is : 0.23869267106056213\n",
      "The MSE loss is : 0.23866340517997742\n",
      "The MSE loss is : 0.23860295116901398\n",
      "The MSE loss is : 0.23855780065059662\n",
      "The MSE loss is : 0.23851406574249268\n",
      "The MSE loss is : 0.23847225308418274\n",
      "The MSE loss is : 0.2384553849697113\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=321\n",
      "The MSE loss is : 0.3350902795791626\n",
      "The MSE loss is : 0.32495519518852234\n",
      "The MSE loss is : 0.32437798380851746\n",
      "The MSE loss is : 0.324229896068573\n",
      "The MSE loss is : 0.3240945339202881\n",
      "The MSE loss is : 0.3240191638469696\n",
      "The MSE loss is : 0.32401567697525024\n",
      "The MSE loss is : 0.32397186756134033\n",
      "The MSE loss is : 0.32394999265670776\n",
      "The MSE loss is : 0.323948472738266\n",
      "The MSE loss is : 0.3239485025405884\n",
      "The MSE loss is : 0.3239485025405884\n",
      "The MSE loss is : 0.3239485025405884\n",
      "The MSE loss is : 0.3239485025405884\n",
      "The MSE loss is : 0.3239485025405884\n",
      "The MSE loss is : 0.3239485025405884\n",
      "The MSE loss is : 0.3239485025405884\n",
      "The MSE loss is : 0.3239485025405884\n",
      "The MSE loss is : 0.3239485025405884\n",
      "The MSE loss is : 0.323948472738266\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.3350902795791626\n",
      "The MSE loss is : 0.3211158215999603\n",
      "The MSE loss is : 0.3211122751235962\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "The MSE loss is : 0.32111215591430664\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.3350902795791626\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "The MSE loss is : 0.3235718011856079\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34382304549217224\n",
      "The MSE loss is : 0.24924811720848083\n",
      "The MSE loss is : 0.2438715547323227\n",
      "The MSE loss is : 0.24190866947174072\n",
      "The MSE loss is : 0.24090997874736786\n",
      "The MSE loss is : 0.24038165807724\n",
      "The MSE loss is : 0.23997826874256134\n",
      "The MSE loss is : 0.23969821631908417\n",
      "The MSE loss is : 0.23948633670806885\n",
      "The MSE loss is : 0.23927944898605347\n",
      "The MSE loss is : 0.2390558272600174\n",
      "The MSE loss is : 0.23897075653076172\n",
      "The MSE loss is : 0.23891189694404602\n",
      "The MSE loss is : 0.23883205652236938\n",
      "The MSE loss is : 0.2387775331735611\n",
      "The MSE loss is : 0.2387273907661438\n",
      "The MSE loss is : 0.2387142777442932\n",
      "The MSE loss is : 0.23871362209320068\n",
      "The MSE loss is : 0.2387136071920395\n",
      "The MSE loss is : 0.2387135922908783\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.33504337072372437\n",
      "The MSE loss is : 0.2426995038986206\n",
      "The MSE loss is : 0.24100519716739655\n",
      "The MSE loss is : 0.24044233560562134\n",
      "The MSE loss is : 0.24013207852840424\n",
      "The MSE loss is : 0.2399156093597412\n",
      "The MSE loss is : 0.23972633481025696\n",
      "The MSE loss is : 0.2395952194929123\n",
      "The MSE loss is : 0.23946687579154968\n",
      "The MSE loss is : 0.2393689751625061\n",
      "The MSE loss is : 0.23929180204868317\n",
      "The MSE loss is : 0.23921731114387512\n",
      "The MSE loss is : 0.2391546368598938\n",
      "The MSE loss is : 0.23907294869422913\n",
      "The MSE loss is : 0.23905396461486816\n",
      "The MSE loss is : 0.23898282647132874\n",
      "The MSE loss is : 0.23893921077251434\n",
      "The MSE loss is : 0.23888464272022247\n",
      "The MSE loss is : 0.23885822296142578\n",
      "The MSE loss is : 0.23883353173732758\n",
      "Saving... file:record_err_1024 method:pair-Seq\n",
      "\n",
      "Experiment N=1024 SEED=654\n",
      "The MSE loss is : 0.33410510420799255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is : 0.3239274322986603\n",
      "The MSE loss is : 0.32345110177993774\n",
      "The MSE loss is : 0.32324424386024475\n",
      "The MSE loss is : 0.3231106698513031\n",
      "The MSE loss is : 0.32305413484573364\n",
      "The MSE loss is : 0.32303905487060547\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "The MSE loss is : 0.32303857803344727\n",
      "Saving... file:record_err_1024 method:pair\n",
      "The MSE loss is : 0.33410510420799255\n",
      "The MSE loss is : 0.3202698230743408\n",
      "The MSE loss is : 0.3202671408653259\n",
      "The MSE loss is : 0.3202671408653259\n",
      "The MSE loss is : 0.3202671408653259\n",
      "The MSE loss is : 0.3202671408653259\n",
      "The MSE loss is : 0.3202671408653259\n",
      "The MSE loss is : 0.32026711106300354\n",
      "The MSE loss is : 0.32026711106300354\n",
      "The MSE loss is : 0.32026711106300354\n",
      "The MSE loss is : 0.32026711106300354\n",
      "The MSE loss is : 0.32026711106300354\n",
      "The MSE loss is : 0.3202671408653259\n",
      "The MSE loss is : 0.32026711106300354\n",
      "The MSE loss is : 0.3202671408653259\n",
      "The MSE loss is : 0.32026711106300354\n",
      "The MSE loss is : 0.32026711106300354\n",
      "The MSE loss is : 0.32026711106300354\n",
      "The MSE loss is : 0.3202671408653259\n",
      "The MSE loss is : 0.32026711106300354\n",
      "Saving... file:record_err_1024 method:block-sqrt-half\n",
      "The MSE loss is : 0.33410510420799255\n",
      "The MSE loss is : 0.32264983654022217\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "The MSE loss is : 0.322649747133255\n",
      "Saving... file:record_err_1024 method:block-sqrt\n",
      "Saving... file:record_err_1024 method:lowR-same-param\n",
      "Saving... file:record_err_1024 method:lowR-samex2\n",
      "Saving... file:record_err_1024 method:lowR-half\n",
      "The MSE loss is : 0.34298354387283325\n",
      "The MSE loss is : 0.2485632300376892\n",
      "The MSE loss is : 0.24333816766738892\n",
      "The MSE loss is : 0.2415049970149994\n",
      "The MSE loss is : 0.2405640184879303\n",
      "The MSE loss is : 0.23990482091903687\n",
      "The MSE loss is : 0.23945003747940063\n",
      "The MSE loss is : 0.23908020555973053\n",
      "The MSE loss is : 0.23880016803741455\n",
      "The MSE loss is : 0.23859485983848572\n",
      "The MSE loss is : 0.2384461611509323\n",
      "The MSE loss is : 0.23835237324237823\n",
      "The MSE loss is : 0.2383110225200653\n",
      "The MSE loss is : 0.2382698357105255\n",
      "The MSE loss is : 0.23822221159934998\n",
      "The MSE loss is : 0.23818041384220123\n",
      "The MSE loss is : 0.23812539875507355\n",
      "The MSE loss is : 0.23808735609054565\n",
      "The MSE loss is : 0.23806247115135193\n",
      "The MSE loss is : 0.23804980516433716\n",
      "Saving... file:record_err_1024 method:pair-Add\n",
      "The MSE loss is : 0.3341061472892761\n",
      "The MSE loss is : 0.24208979308605194\n",
      "The MSE loss is : 0.240289568901062\n",
      "The MSE loss is : 0.23963132500648499\n",
      "The MSE loss is : 0.2393037974834442\n",
      "The MSE loss is : 0.23906990885734558\n",
      "The MSE loss is : 0.2388789802789688\n",
      "The MSE loss is : 0.23875689506530762\n",
      "The MSE loss is : 0.23867303133010864\n",
      "The MSE loss is : 0.2385879009962082\n",
      "The MSE loss is : 0.238510400056839\n",
      "The MSE loss is : 0.23844921588897705\n",
      "The MSE loss is : 0.23839524388313293\n",
      "The MSE loss is : 0.23833626508712769\n",
      "The MSE loss is : 0.23832057416439056\n",
      "The MSE loss is : 0.23826369643211365\n",
      "The MSE loss is : 0.23825186491012573\n"
     ]
    }
   ],
   "source": [
    "for N in Ns:\n",
    "    X = torch.eye(N).to(device)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['method', 'seed', 'mse', 'mean', 'std', 'params', 'time'])\n",
    "    file_name = f'record_err_{N}'\n",
    "        \n",
    "    for SEED in seeds:\n",
    "        print()\n",
    "        print(f\"Experiment N={N} SEED={SEED}\")\n",
    "        \n",
    "        torch.manual_seed(SEED)\n",
    "        A = torch.rand(N, N).to(device)*2-1\n",
    "        ### For each method compute the stats\n",
    "        \n",
    "        #####################################################\n",
    "        ##### First 2x2 factorization\n",
    "        model = sll.PairLinear_MixerBlock(N, N).to(device)        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "        \n",
    "        #### Train model\n",
    "        out, tim = train_model(model, optimizer, X, A)\n",
    "        _n_params = sum(p.numel() for p in model.parameters())\n",
    "        df = save_stats(df, out, A, 'pair', SEED, _n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        del model, optimizer\n",
    "        \n",
    "        #####################################################\n",
    "        ##### First log(N) factorization\n",
    "#         _m = int(np.ceil(np.log2(N)))\n",
    "\n",
    "        #### sqrt(N)/2 \n",
    "        _m = int(np.ceil(np.sqrt(N)/2))\n",
    "        model = sll.BlockLinear_MixerBlock(N, _m).to(device)        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "        \n",
    "        #### Train model\n",
    "        out, tim = train_model(model, optimizer, X, A)\n",
    "        _n_params = sum(p.numel() for p in model.parameters())\n",
    "        df = save_stats(df, out, A, 'block-sqrt-half', SEED, _n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        del model, optimizer\n",
    "        \n",
    "        \n",
    "        #####################################################\n",
    "        ##### Second sqrt(N) factorization\n",
    "        _m = int(np.ceil(np.sqrt(N)))\n",
    "        model = sll.BlockLinear_MixerBlock(N, _m).to(device)        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "        \n",
    "        #### Train model\n",
    "        out, tim = train_model(model, optimizer, X, A)\n",
    "        _n_params = sum(p.numel() for p in model.parameters())\n",
    "        df = save_stats(df, out, A, 'block-sqrt', SEED, _n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        del model, optimizer\n",
    "        \n",
    "        \n",
    "        #####################################################\n",
    "        _m = int(np.ceil(_n_params/(N*2)))\n",
    "        out, tim = get_svd_output(A, _m)\n",
    "\n",
    "        n_params = N*_m*2\n",
    "        df = save_stats(df, out, A, 'lowR-same-param', SEED, n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        \n",
    "        #####################################################\n",
    "        _m = int(np.ceil(_n_params/N))\n",
    "        out, tim = get_svd_output(A, _m)\n",
    "\n",
    "        n_params = N*_m\n",
    "        df = save_stats(df, out, A, 'lowR-samex2', SEED, n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        \n",
    "        #####################################################\n",
    "        _m = N // 2\n",
    "        out, tim = get_svd_output(A, _m)\n",
    "\n",
    "        n_params = N*_m*2\n",
    "        df = save_stats(df, out, A, 'lowR-half', SEED, n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        \n",
    "        #####################################################\n",
    "        torch.cuda.empty_cache()\n",
    "        if N > 1024: continue\n",
    "\n",
    "        ##### Pair Linear models parallel addition\n",
    "        _m = int(np.ceil(np.log2(N)))\n",
    "        model = Add_PairLinears(N, _m).to(device)        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "        \n",
    "        #### Train model\n",
    "        out, tim = train_model(model, optimizer, X, A)\n",
    "        _n_params = sum(p.numel() for p in model.parameters())\n",
    "        df = save_stats(df, out, A, 'pair-Add', SEED, _n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        del model, optimizer\n",
    "        \n",
    "        #####################################################\n",
    "        \n",
    "        ##### Pair Linear models sequential composition\n",
    "        _m = int(np.ceil(np.log2(N)))\n",
    "        model = Stack_PairLinears(N, _m).to(device)        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "        \n",
    "        #### Train model\n",
    "        out, tim = train_model(model, optimizer, X, A)\n",
    "        _n_params = sum(p.numel() for p in model.parameters())\n",
    "        df = save_stats(df, out, A, 'pair-Seq', SEED, _n_params, tim, file_name)\n",
    "        #####################################################\n",
    "        del model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638b6b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.ceil(np.log2(64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5845c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log2(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "asfsdfasdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136ea42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
