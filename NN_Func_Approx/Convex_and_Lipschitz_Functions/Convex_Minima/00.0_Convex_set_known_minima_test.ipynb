{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# matplotlib.use(\"TkAgg\")\n",
    "%matplotlib tk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 100\n",
    "X1 = np.linspace(-2.5, 1.9, num_points)\n",
    "# X1 = np.linspace(-2.5, 2.5, num_points)\n",
    "# X2 = np.linspace(-2.5, 3, num_points)\n",
    "X2 = np.linspace(-2.2, 2.1, num_points)\n",
    "X1, X2 = np.meshgrid(X1, X2)\n",
    "Y = np.sin(np.sqrt(X1**2 + X2**2))*2-1. - 0.1*(X1)+0.02*(X2)\n",
    "\n",
    "####Scaling the data to range -1,1\n",
    "X1 = 2*(X1 - X1.min())/(X1.max() - X1.min()) -1\n",
    "X2 = 2*(X2 - X2.min())/(X2.max() - X2.min()) -1\n",
    "Y = 2*(Y - Y.min())/(Y.max() - Y.min()) -1\n",
    "Y = Y/2\n",
    "\n",
    "x1 = X1.reshape(-1)\n",
    "x2 = X2.reshape(-1)\n",
    "\n",
    "xx = torch.Tensor(np.c_[x1, x2])\n",
    "yy = torch.Tensor(Y.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: MatplotlibDeprecationWarning: Calling gca() with keyword arguments was deprecated in Matplotlib 3.4. Starting two minor releases later, gca() will take no keyword arguments. The gca() function should only be used to get the current axes, or if no axes exist, create new axes with default keyword arguments. To create a new axes with non-default arguments, use plt.axes() or plt.subplot().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(X1, X2, Y, cmap='plasma')\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convex_lib import ConvexNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvexNN_minima_v0(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, actf=nn.LeakyReLU):\n",
    "        super().__init__()\n",
    "        self.minima = nn.Parameter(torch.zeros(1, input_dim))\n",
    "        self.layer0 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.actf0 = actf()\n",
    "        self.layer1 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h = x\n",
    "        with torch.no_grad():\n",
    "            self.layer1.weight.data.abs_()\n",
    "\n",
    "#             print(torch.norm(self.layer0.weight.data, dim=1).shape, self.layer0.weight.data.shape)\n",
    "#             l0norm = torch.norm(self.layer0.weight.data, dim=1, keepdim=True)\n",
    "#             l0norm[l0norm<1] = 1.\n",
    "#             print(torch.count_nonzero(l0norm>1))\n",
    "#             self.layer0.weight.data /= l0norm\n",
    "        \n",
    "        h_lin = self.actf0(self.layer0(h))\n",
    "        h_dist = torch.norm(x-self.minima, dim=1, keepdim=True)\n",
    "#         print(h_dist.shape)\n",
    "#         print(h_lin.shape)\n",
    "\n",
    "        h = h_lin + h_dist\n",
    "        \n",
    "        h = self.layer1(h)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5994],\n",
       "        [1.5847],\n",
       "        [1.5702],\n",
       "        ...,\n",
       "        [0.9364],\n",
       "        [0.9511],\n",
       "        [0.9661]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvexNN_minima_v0(2, 5)(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This not producing the\n",
    "class ConvexNN_minima_v1(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, actf=nn.LeakyReLU):\n",
    "        super().__init__()\n",
    "        self.minima = nn.Parameter(torch.zeros(1, input_dim))\n",
    "        self.layer0 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.actf0 = actf()\n",
    "        self.layer1 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h = x\n",
    "        with torch.no_grad():\n",
    "            self.layer1.weight.data.abs_()\n",
    "#             self.layer1.weight.data /= self.layer1.weight.data.abs().sum()\n",
    "            \n",
    "#             l0norm = torch.norm(self.layer0.weight.data, dim=1, keepdim=True)\n",
    "#             self.layer0.weight.data /= l0norm\n",
    "        \n",
    "        h_lin = self.layer1(self.actf0(self.layer0(h)))\n",
    "        h_dist = torch.norm(x-self.minima, dim=1, keepdim=True)\n",
    "\n",
    "        h = h_lin + h_dist\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0184],\n",
       "        [2.0002],\n",
       "        [1.9822],\n",
       "        ...,\n",
       "        [2.1176],\n",
       "        [2.1315],\n",
       "        [2.1455]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvexNN_minima_v1(2, 5)(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa67f6b8910>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LVLs = np.linspace(sim.min(), sim.max(), 20)\n",
    "LVLs = 20\n",
    "\n",
    "cvxNet = ConvexNN_minima_v0(2, 5)\n",
    "y_ = cvxNet(xx).data.cpu().numpy().reshape(Y.shape)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.contourf(X1, X2, y_, levels=LVLs)\n",
    "cs = plt.contour(X1, X2, y_, levels=LVLs, linestyles=\"None\", colors=\"k\", linewidths=1)\n",
    "plt.clabel(cs, cs.levels, inline=True, fontsize=10, fmt=\"%1.2f\")\n",
    "minima = xx[y_.argmin()]\n",
    "plt.scatter(*minima.tolist(), s=100, edgecolors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "actf = nn.LeakyReLU\n",
    "# actf = nn.ELU\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvxNet = ConvexNN([2, 10, 1], actf)\n",
    "cvxNet = ConvexNN_minima_v0(2, 50, actf)\n",
    "# cvxNet = ConvexNN_minima_v1(2, 10, actf)\n",
    "\n",
    "optimizer = torch.optim.Adam(cvxNet.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:0.026791507378220558\n",
      "Epoch: 100, Loss:0.026388827711343765\n",
      "Epoch: 200, Loss:0.02519584819674492\n",
      "Epoch: 300, Loss:0.024125004187226295\n",
      "Epoch: 400, Loss:0.023888198658823967\n",
      "Epoch: 500, Loss:0.02335393987596035\n",
      "Epoch: 600, Loss:0.024673495441675186\n",
      "Epoch: 700, Loss:0.022621963173151016\n",
      "Epoch: 800, Loss:0.02321830578148365\n",
      "Epoch: 900, Loss:0.022515254095196724\n",
      "Epoch: 999, Loss:0.022972993552684784\n"
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    yout = -cvxNet(xx)    \n",
    "    loss = criterion(yout, yy)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100 == 0 or epoch==EPOCHS-1:\n",
    "        print(f'Epoch: {epoch}, Loss:{float(loss)}')\n",
    "        ax.clear()\n",
    "        ax.scatter(X1, X2, yy.data.numpy().reshape(-1), marker= '.')\n",
    "        ax.scatter(X1, X2, yout.data.numpy().reshape(-1), color='r', marker='.')\n",
    "        ax2.clear()\n",
    "        ax2.contourf(X1, X2, yout.data.numpy().reshape(Y.shape), levels=20)\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        plt.pause(0.01)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3958, 0.3867, 0.4709, 0.1463, 0.4385, 0.4338, 0.4098, 0.5459, 0.2794,\n",
       "        0.6009, 0.2871, 0.4855, 0.6090, 0.4902, 0.1086, 3.8824, 0.1455, 0.5257,\n",
       "        0.0280, 0.2510, 0.1976, 0.4464, 0.1144, 0.3917, 0.3422, 0.3517, 0.2032,\n",
       "        0.5200, 0.4894, 0.3625, 0.3769, 0.5733, 0.5405, 0.3550, 0.3466, 0.5240,\n",
       "        0.2835, 0.6180, 0.4909, 0.4591, 0.3017, 0.3123, 0.3099, 0.0379, 0.5466,\n",
       "        0.3884, 0.4474, 0.4902, 0.1275, 0.4245])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvxNet.layer0.weight.data.norm(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5169)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_neuron_mag = cvxNet.layer0.weight.data.norm(dim=1) * cvxNet.layer1.weight.data.squeeze()\n",
    "per_neuron_mag.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5402e-04, -3.3705e-04, -2.3886e-04, -2.5079e-04, -2.4785e-04,\n",
       "         -2.3056e-04, -2.5291e-04, -2.2721e-04, -2.4713e-04, -2.4995e-04,\n",
       "         -1.9773e-04, -1.6426e-04, -2.3448e-04, -2.1725e-04, -2.0446e-04,\n",
       "          1.3419e-01, -2.4791e-04, -2.3788e-04, -2.4779e-04, -2.4915e-04,\n",
       "         -1.9131e-04, -1.6071e-04, -2.5169e-04, -9.6318e-05, -1.0748e-04,\n",
       "         -2.4548e-04, -8.1657e-05, -2.5043e-04, -2.2578e-04, -2.3718e-04,\n",
       "         -2.4676e-04, -1.7683e-04, -2.4451e-04, -2.7423e-04, -2.0954e-04,\n",
       "         -2.4791e-04, -1.7524e-04, -2.1794e-04, -2.4795e-04, -2.4513e-04,\n",
       "         -2.4899e-04, -2.5484e-04, -2.4885e-04, -2.2049e-04, -1.8515e-04,\n",
       "         -2.2579e-04, -2.1067e-04, -2.1444e-04, -2.2881e-04, -2.5484e-05]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvxNet.layer1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0055e-04, -1.3033e-04, -1.1248e-04, -3.6694e-05, -1.0869e-04,\n",
       "        -1.0003e-04, -1.0364e-04, -1.2404e-04, -6.9038e-05, -1.5020e-04,\n",
       "        -5.6763e-05, -7.9755e-05, -1.4280e-04, -1.0649e-04, -2.2199e-05,\n",
       "         5.2096e-01, -3.6066e-05, -1.2505e-04, -6.9416e-06, -6.2526e-05,\n",
       "        -3.7809e-05, -7.1748e-05, -2.8793e-05, -3.7728e-05, -3.6782e-05,\n",
       "        -8.6329e-05, -1.6596e-05, -1.3023e-04, -1.1049e-04, -8.5987e-05,\n",
       "        -9.2995e-05, -1.0138e-04, -1.3215e-04, -9.7357e-05, -7.2627e-05,\n",
       "        -1.2991e-04, -4.9684e-05, -1.3469e-04, -1.2172e-04, -1.1253e-04,\n",
       "        -7.5117e-05, -7.9592e-05, -7.7131e-05, -8.3496e-06, -1.0120e-04,\n",
       "        -8.7699e-05, -9.4244e-05, -1.0511e-04, -2.9167e-05, -1.0819e-05])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_neuron_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_neuron_mag.abs() > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuman/Program_Files/Python/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: MatplotlibDeprecationWarning: Calling gca() with keyword arguments was deprecated in Matplotlib 3.4. Starting two minor releases later, gca() will take no keyword arguments. The gca() function should only be used to get the current axes, or if no axes exist, create new axes with default keyword arguments. To create a new axes with non-default arguments, use plt.axes() or plt.subplot().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "y_ = yout.data.cpu().numpy().reshape(Y.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.view_init(49, -71)\n",
    "ax.plot_surface(X1, X2, y_, cmap='plasma', alpha=0.9)\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('Y')\n",
    "plt.pause(1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Contour Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa67c204550>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LVLs = np.linspace(sim.min(), sim.max(), 20)\n",
    "LVLs = 20\n",
    "\n",
    "y_ = cvxNet(xx).data.cpu().numpy().reshape(Y.shape)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.contourf(X1, X2, y_, levels=LVLs)\n",
    "cs = plt.contour(X1, X2, y_, levels=LVLs, linestyles=\"None\", colors=\"k\", linewidths=1)\n",
    "plt.clabel(cs, cs.levels, inline=True, fontsize=10, fmt=\"%1.2f\")\n",
    "minima = xx[y_.argmin()]\n",
    "plt.scatter(*minima.tolist(), s=100, edgecolors=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.37873057"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val = y_.min()\n",
    "min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4949,  0.1919]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minima = xx[None, y_.argmin()]\n",
    "minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
