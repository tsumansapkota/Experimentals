{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../../Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE parameters\n",
    "num_label = 10\n",
    "label_hid1 = 5\n",
    "label_hid2 = 3\n",
    "label_hid3 = 2\n",
    "label_hid4 = 1\n",
    "\n",
    "num_image = 784 # 28*28\n",
    "image_hid1 = 392\n",
    "image_hid2 = 196\n",
    "image_hid3 = 98\n",
    "image_hid4 = 49\n",
    "image_hid5 = 25\n",
    "image_hid6 = 12\n",
    "image_hid7 = 6\n",
    "image_hid8 = 3\n",
    "image_hid9 = 2\n",
    "image_hid10 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tie_weight = tf.transpose\n",
    "act_func = lambda X:X\n",
    "initializer = tf.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLACEHOLDER DEFINATION\n",
    "X = tf.placeholder(tf.float32, shape=[None, num_image])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, num_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Encoded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMAGE COMPRESSION\n",
    "wi1 = tf.Variable(np.load('../save/weights/w1.npy'))\n",
    "wi2 = tf.Variable(np.load('../save/weights/w2.npy'))\n",
    "wi3 = tf.Variable(np.load('../save/weights/w3.npy'))\n",
    "wi4 = tf.Variable(np.load('../save/weights/w4.npy'))\n",
    "wi5 = tf.Variable(np.load('../save/weights/w5.npy'))\n",
    "wi6 = tf.Variable(np.load('../save/weights/w6.npy'))\n",
    "wi7 = tf.Variable(np.load('../save/weights/w7.npy'))\n",
    "wi8 = tf.Variable(np.load('../save/weights/w8.npy'))\n",
    "wi9 = tf.Variable(np.load('../save/weights/w9.npy'))\n",
    "wi10 = tf.Variable(np.load('../save/weights/w10.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_layer1 = act_func(tf.matmul(X, wi1))\n",
    "img_layer2 = act_func(tf.matmul(img_layer1, wi2))\n",
    "img_layer3 = act_func(tf.matmul(img_layer2, wi3))\n",
    "img_layer4 = act_func(tf.matmul(img_layer3, wi4))\n",
    "img_layer5 = act_func(tf.matmul(img_layer4, wi5))\n",
    "img_layer6 = act_func(tf.matmul(img_layer5, wi6))\n",
    "img_layer7 = act_func(tf.matmul(img_layer6, wi7))\n",
    "img_layer8 = act_func(tf.matmul(img_layer7, wi8))\n",
    "img_layer9 = act_func(tf.matmul(img_layer8, wi9))\n",
    "img_layer10 = act_func(tf.matmul(img_layer9, wi10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LABEL DECOMPRESSION\n",
    "wl1 = tf.Variable(np.load('../save/weights/lw1.npy'))\n",
    "wl2 = tf.Variable(np.load('../save/weights/lw2.npy'))\n",
    "wl3 = tf.Variable(np.load('../save/weights/lw3.npy'))\n",
    "wl4 = tf.Variable(np.load('../save/weights/lw4.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_layer1 = act_func(tf.matmul(Y, wl1))\n",
    "lbl_layer2 = act_func(tf.matmul(lbl_layer1, wl2))\n",
    "lbl_layer3 = act_func(tf.matmul(lbl_layer2, wl3))\n",
    "lbl_layer4 = act_func(tf.matmul(lbl_layer3, wl4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Parameters for activation learning\n",
    "initializer = tf.random_uniform_initializer()\n",
    "\n",
    "# input_no = image_hid8\n",
    "# output_no = label_hid3\n",
    "\n",
    "inpt = img_layer2\n",
    "yval = lbl_layer1\n",
    "\n",
    "i=98\n",
    "j=5\n",
    "\n",
    "pW1 = tf.Variable(np.load('../save/weights/slearn_parms0_{}-{}.npy'.format(i, j)))\n",
    "W1 = tf.Variable(tf.matmul(wi3,pW1))\n",
    "W2 = tf.Variable(np.load('../save/weights/slearn_parms1_{}-{}.npy'.format(i, j)))\n",
    "W3 = tf.Variable(np.load('../save/weights/slearn_parms2_{}-{}.npy'.format(i, j)))\n",
    "# W3 = tf.Variable(tf.matmul(pW3, tf.transpose(wl2)))\n",
    "\n",
    "b1 = tf.Variable(np.load('../save/weights/slearn_parms3_{}-{}.npy'.format(i, j)))\n",
    "b2 = tf.Variable(np.load('../save/weights/slearn_parms4_{}-{}.npy'.format(i, j)))\n",
    "b3 = tf.Variable(np.load('../save/weights/slearn_parms5_{}-{}.npy'.format(i, j)))\n",
    "# b3 = tf.Variable(tf.matmul(pb3,tf.transpose(wl2)))\n",
    "\n",
    "a1 = tf.nn.relu(tf.matmul(inpt, W1) + b1)\n",
    "a2 = tf.nn.relu(tf.matmul(a1, W2) + b2)\n",
    "a3 = tf.matmul(a2, W3) + b3\n",
    "\n",
    "output = a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_15:0' shape=(196, 155) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_20:0' shape=(1, 5) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "print(W1)\n",
    "print(b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Encode-Decode Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_layer1 = tf.matmul(output,tf.transpose(wl4))\n",
    "# out_layer2 = tf.matmul(output,tf.transpose(wl3))\n",
    "# out_layer3 = tf.matmul(output,tf.transpose(wl2))\n",
    "out_layer4 = tf.matmul(output,tf.transpose(wl1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS FUNCTIONS\n",
    "loss = tf.reduce_mean(tf.square(output - yval))\n",
    "# loss = tf.reduce_mean(tf.abs(output_layer - X))\n",
    "# cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=yout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "learning_rate = 0.003\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss, var_list=[W1, W2, W3, b1, b2, b3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATION\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Complete. Training Loss: 0.6114459037780762\n",
      "TEST ACCURACY: \n",
      "0.9499\n",
      "TRAIN ACCURACY: \n",
      "0.9635818\n",
      "\n",
      "Epoch 1 Complete. Training Loss: 0.6632387042045593\n",
      "TEST ACCURACY: \n",
      "0.9531\n",
      "\n",
      "Epoch 2 Complete. Training Loss: 0.15354953706264496\n",
      "TEST ACCURACY: \n",
      "0.948\n",
      "\n",
      "Epoch 3 Complete. Training Loss: 0.3472786843776703\n",
      "TEST ACCURACY: \n",
      "0.9524\n",
      "\n",
      "Epoch 4 Complete. Training Loss: 0.2761339843273163\n",
      "TEST ACCURACY: \n",
      "0.9535\n",
      "\n",
      "Epoch 5 Complete. Training Loss: 0.18551066517829895\n",
      "TEST ACCURACY: \n",
      "0.9552\n",
      "TRAIN ACCURACY: \n",
      "0.97047275\n",
      "\n",
      "Epoch 6 Complete. Training Loss: 0.18315018713474274\n",
      "TEST ACCURACY: \n",
      "0.9562\n",
      "\n",
      "Epoch 7 Complete. Training Loss: 0.40163543820381165\n",
      "TEST ACCURACY: \n",
      "0.9584\n",
      "\n",
      "Epoch 8 Complete. Training Loss: 0.1369062215089798\n",
      "TEST ACCURACY: \n",
      "0.9554\n",
      "\n",
      "Epoch 9 Complete. Training Loss: 0.2579857110977173\n",
      "TEST ACCURACY: \n",
      "0.9567\n",
      "\n",
      "Epoch 10 Complete. Training Loss: 0.287225604057312\n",
      "TEST ACCURACY: \n",
      "0.9543\n",
      "TRAIN ACCURACY: \n",
      "0.9716182\n",
      "\n",
      "Epoch 11 Complete. Training Loss: 0.10352037101984024\n",
      "TEST ACCURACY: \n",
      "0.9564\n",
      "\n",
      "Epoch 12 Complete. Training Loss: 0.22464324533939362\n",
      "TEST ACCURACY: \n",
      "0.9546\n",
      "\n",
      "Epoch 13 Complete. Training Loss: 0.17351175844669342\n",
      "TEST ACCURACY: \n",
      "0.9522\n",
      "\n",
      "Epoch 14 Complete. Training Loss: 0.12175244837999344\n",
      "TEST ACCURACY: \n",
      "0.9561\n",
      "\n",
      "Epoch 15 Complete. Training Loss: 0.26115936040878296\n",
      "TEST ACCURACY: \n",
      "0.9559\n",
      "TRAIN ACCURACY: \n",
      "0.9756727\n",
      "\n",
      "Epoch 16 Complete. Training Loss: 0.25080469250679016\n",
      "TEST ACCURACY: \n",
      "0.9582\n",
      "\n",
      "Epoch 17 Complete. Training Loss: 0.13415645062923431\n",
      "TEST ACCURACY: \n",
      "0.9581\n",
      "\n",
      "Epoch 18 Complete. Training Loss: 0.1007184386253357\n",
      "TEST ACCURACY: \n",
      "0.9554\n",
      "\n",
      "Epoch 19 Complete. Training Loss: 0.2605164349079132\n",
      "TEST ACCURACY: \n",
      "0.9545\n",
      "\n",
      "Epoch 20 Complete. Training Loss: 0.11906090378761292\n",
      "TEST ACCURACY: \n",
      "0.955\n",
      "TRAIN ACCURACY: \n",
      "0.97923636\n",
      "\n",
      "Epoch 21 Complete. Training Loss: 0.13669289648532867\n",
      "TEST ACCURACY: \n",
      "0.957\n",
      "\n",
      "Epoch 22 Complete. Training Loss: 0.10161681473255157\n",
      "TEST ACCURACY: \n",
      "0.9548\n",
      "\n",
      "Epoch 23 Complete. Training Loss: 0.15746112167835236\n",
      "TEST ACCURACY: \n",
      "0.9545\n",
      "\n",
      "Epoch 24 Complete. Training Loss: 0.30117833614349365\n",
      "TEST ACCURACY: \n",
      "0.9541\n",
      "\n",
      "Epoch 25 Complete. Training Loss: 0.16326014697551727\n",
      "TEST ACCURACY: \n",
      "0.9544\n",
      "TRAIN ACCURACY: \n",
      "0.9809273\n",
      "\n",
      "Epoch 26 Complete. Training Loss: 0.11626293510198593\n",
      "TEST ACCURACY: \n",
      "0.9572\n",
      "\n",
      "Epoch 27 Complete. Training Loss: 0.18466918170452118\n",
      "TEST ACCURACY: \n",
      "0.9537\n",
      "\n",
      "Epoch 28 Complete. Training Loss: 0.129489928483963\n",
      "TEST ACCURACY: \n",
      "0.9564\n",
      "\n",
      "Epoch 29 Complete. Training Loss: 0.24568672478199005\n",
      "TEST ACCURACY: \n",
      "0.9539\n",
      "\n",
      "Epoch 30 Complete. Training Loss: 0.1049000471830368\n",
      "TEST ACCURACY: \n",
      "0.9543\n",
      "TRAIN ACCURACY: \n",
      "0.98318183\n",
      "\n",
      "Epoch 31 Complete. Training Loss: 0.1172592043876648\n",
      "TEST ACCURACY: \n",
      "0.9543\n",
      "\n",
      "Epoch 32 Complete. Training Loss: 0.11665531992912292\n",
      "TEST ACCURACY: \n",
      "0.9541\n",
      "\n",
      "Epoch 33 Complete. Training Loss: 0.16025450825691223\n",
      "TEST ACCURACY: \n",
      "0.9533\n",
      "\n",
      "Epoch 34 Complete. Training Loss: 0.20995551347732544\n",
      "TEST ACCURACY: \n",
      "0.9538\n",
      "\n",
      "Epoch 35 Complete. Training Loss: 0.13626927137374878\n",
      "TEST ACCURACY: \n",
      "0.9529\n",
      "TRAIN ACCURACY: \n",
      "0.98358184\n",
      "\n",
      "Epoch 36 Complete. Training Loss: 0.16082614660263062\n",
      "TEST ACCURACY: \n",
      "0.9529\n",
      "\n",
      "Epoch 37 Complete. Training Loss: 0.07100221514701843\n",
      "TEST ACCURACY: \n",
      "0.954\n",
      "\n",
      "Epoch 38 Complete. Training Loss: 0.16246086359024048\n",
      "TEST ACCURACY: \n",
      "0.9545\n",
      "\n",
      "Epoch 39 Complete. Training Loss: 0.16167978942394257\n",
      "TEST ACCURACY: \n",
      "0.9528\n",
      "\n",
      "Epoch 40 Complete. Training Loss: 0.10688568651676178\n",
      "TEST ACCURACY: \n",
      "0.9532\n",
      "TRAIN ACCURACY: \n",
      "0.98532724\n",
      "\n",
      "Epoch 41 Complete. Training Loss: 0.09603376686573029\n",
      "TEST ACCURACY: \n",
      "0.9556\n",
      "\n",
      "Epoch 42 Complete. Training Loss: 0.14221346378326416\n",
      "TEST ACCURACY: \n",
      "0.9524\n",
      "\n",
      "Epoch 43 Complete. Training Loss: 0.13792096078395844\n",
      "TEST ACCURACY: \n",
      "0.9501\n",
      "\n",
      "Epoch 44 Complete. Training Loss: 0.11587425321340561\n",
      "TEST ACCURACY: \n",
      "0.9528\n",
      "\n",
      "Epoch 45 Complete. Training Loss: 0.08114573359489441\n",
      "TEST ACCURACY: \n",
      "0.9529\n",
      "TRAIN ACCURACY: \n",
      "0.9863818\n",
      "\n",
      "Epoch 46 Complete. Training Loss: 0.11672531813383102\n",
      "TEST ACCURACY: \n",
      "0.9524\n",
      "\n",
      "Epoch 47 Complete. Training Loss: 0.10306546837091446\n",
      "TEST ACCURACY: \n",
      "0.9535\n",
      "\n",
      "Epoch 48 Complete. Training Loss: 0.05380810424685478\n",
      "TEST ACCURACY: \n",
      "0.9534\n",
      "\n",
      "Epoch 49 Complete. Training Loss: 0.11775431782007217\n",
      "TEST ACCURACY: \n",
      "0.9507\n",
      "\n",
      "Epoch 50 Complete. Training Loss: 0.21590691804885864\n",
      "TEST ACCURACY: \n",
      "0.9517\n",
      "TRAIN ACCURACY: \n",
      "0.9867091\n",
      "\n",
      "Epoch 51 Complete. Training Loss: 0.14019379019737244\n",
      "TEST ACCURACY: \n",
      "0.9516\n",
      "\n",
      "Epoch 52 Complete. Training Loss: 0.13129056990146637\n",
      "TEST ACCURACY: \n",
      "0.9514\n",
      "\n",
      "Epoch 53 Complete. Training Loss: 0.07920648157596588\n",
      "TEST ACCURACY: \n",
      "0.9508\n",
      "\n",
      "Epoch 54 Complete. Training Loss: 0.15434491634368896\n",
      "TEST ACCURACY: \n",
      "0.9539\n",
      "\n",
      "Epoch 55 Complete. Training Loss: 0.11361716687679291\n",
      "TEST ACCURACY: \n",
      "0.9533\n",
      "TRAIN ACCURACY: \n",
      "0.9881091\n",
      "\n",
      "Epoch 56 Complete. Training Loss: 0.07864757627248764\n",
      "TEST ACCURACY: \n",
      "0.9524\n",
      "\n",
      "Epoch 57 Complete. Training Loss: 0.18374204635620117\n",
      "TEST ACCURACY: \n",
      "0.9527\n",
      "\n",
      "Epoch 58 Complete. Training Loss: 0.17025119066238403\n",
      "TEST ACCURACY: \n",
      "0.953\n",
      "\n",
      "Epoch 59 Complete. Training Loss: 0.10311196744441986\n",
      "TEST ACCURACY: \n",
      "0.9518\n",
      "\n",
      "Epoch 60 Complete. Training Loss: 0.08655570447444916\n",
      "TEST ACCURACY: \n",
      "0.9496\n",
      "TRAIN ACCURACY: \n",
      "0.9886364\n",
      "\n",
      "Epoch 61 Complete. Training Loss: 0.0414721742272377\n",
      "TEST ACCURACY: \n",
      "0.9523\n",
      "\n",
      "Epoch 62 Complete. Training Loss: 0.07539418339729309\n",
      "TEST ACCURACY: \n",
      "0.9508\n",
      "\n",
      "Epoch 63 Complete. Training Loss: 0.11078700423240662\n",
      "TEST ACCURACY: \n",
      "0.9509\n",
      "\n",
      "Keyboard Interrupted\n",
      "Finished Training the Model\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "try:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # Epoch == Entire Training Set\n",
    "        for epoch in range(num_epochs):\n",
    "            num_batches = mnist.train.num_examples // batch_size\n",
    "\n",
    "            # 150 batch size\n",
    "            for iteration in range(num_batches):\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size+3*epoch)\n",
    "                sess.run(train, feed_dict={X: X_batch, Y: y_batch})\n",
    "\n",
    "            training_loss = loss.eval(feed_dict={X: X_batch, Y: y_batch})   \n",
    "            print(\"Epoch {} Complete. Training Loss: {}\".format(epoch,training_loss))\n",
    "            saver.save(sess, \"../save/slearn_196-5.ckpt\")\n",
    "            \n",
    "            matches = tf.equal(tf.argmax(out_layer4, 1), tf.argmax(Y,1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "\n",
    "            print('TEST ACCURACY: ')\n",
    "            print (sess.run(acc, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n",
    "            if epoch % 5 == 0:\n",
    "                print('TRAIN ACCURACY: ')\n",
    "                print (sess.run(acc, feed_dict={X:mnist.train.images, Y:mnist.train.labels}))\n",
    "            print()\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print('Keyboard Interrupted')\n",
    "finally:\n",
    "    print('Finished Training the Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../save/slearn_196-5.ckpt\n",
      "TRAIN ACCURACY: \n",
      "0.9885455\n",
      "TEST ACCURACY: \n",
      "0.9509\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_test_labels = 10\n",
    "start_point = 15\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "#     sess.run(init)\n",
    "    saver.restore(sess,\"../save/slearn_196-5.ckpt\")\n",
    "    \n",
    "    params = sess.run([W1, W2, W3, b1, b2, b3])\n",
    "    \n",
    "    matches = tf.equal(tf.argmax(out_layer4, 1), tf.argmax(Y,1))\n",
    "    acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "    \n",
    "    print('TRAIN ACCURACY: ')\n",
    "    print (sess.run(acc, feed_dict={X:mnist.train.images, Y:mnist.train.labels}))\n",
    "\n",
    "    print('TEST ACCURACY: ')\n",
    "    print (sess.run(acc, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00792063, -0.00880351, -0.00424995, ..., -0.42170748,\n",
       "         -0.00277561, -0.00902025],\n",
       "        [-0.04102398, -0.04559678, -0.02201211, ..., -0.9462836 ,\n",
       "         -0.01437595, -0.04671935],\n",
       "        [ 0.0289632 ,  0.03219161,  0.01554068, ...,  1.2254986 ,\n",
       "          0.01014951,  0.03298415],\n",
       "        ...,\n",
       "        [-0.03514759, -0.03906534, -0.01885902, ..., -0.2134149 ,\n",
       "         -0.01231669, -0.0400271 ],\n",
       "        [ 0.00708321,  0.00787274,  0.00380061, ...,  0.53357124,\n",
       "          0.00248216,  0.00806657],\n",
       "        [-0.02135824, -0.02373895, -0.01146012, ...,  0.18062136,\n",
       "         -0.00748452, -0.0243234 ]], dtype=float32),\n",
       " array([[ 0.12928236,  0.00709345,  0.2270143 , ..., -0.11943059,\n",
       "          0.70338863,  0.65438473],\n",
       "        [ 0.5483187 ,  0.02092948,  0.75045013, ...,  0.6519301 ,\n",
       "          0.2481015 , -0.07473479],\n",
       "        [ 0.6927793 ,  0.39143902,  0.849975  , ..., -0.02917881,\n",
       "          0.7804612 ,  0.8315323 ],\n",
       "        ...,\n",
       "        [ 1.2847613 ,  0.21043186,  0.6378425 , ...,  1.0439377 ,\n",
       "          0.39896864, -0.1747307 ],\n",
       "        [ 0.40146548,  0.82552207,  0.22120453, ...,  0.37094074,\n",
       "          0.6960912 ,  0.29183385],\n",
       "        [ 0.7315277 ,  0.3760425 ,  0.20362827, ...,  0.39146245,\n",
       "          0.6885634 ,  0.46912655]], dtype=float32),\n",
       " array([[-0.19804293, -1.6085352 ,  0.525938  , -0.6276042 , -1.3901781 ],\n",
       "        [ 1.5052407 , -0.61998844, -0.9219738 ,  0.48260796, -1.080495  ],\n",
       "        [ 0.39473578,  0.53656375,  1.1670072 , -0.6904332 , -1.3985646 ],\n",
       "        [ 0.16215025, -0.8375436 ,  0.28677458, -1.2102625 ,  0.01710617],\n",
       "        [-1.2709694 ,  0.28098503,  0.5390991 , -0.83245087,  1.6701099 ],\n",
       "        [-2.4078848 ,  0.48564637, -0.6924831 ,  1.8364059 ,  2.0956256 ],\n",
       "        [-1.79923   ,  0.09321098, -0.32407108,  0.6647662 ,  1.341523  ],\n",
       "        [-2.8766673 , -5.169064  , -1.7082193 ,  0.62526965, -1.0171202 ],\n",
       "        [ 1.7933336 ,  2.7019336 , -0.2764229 ,  0.46234435,  3.7790022 ],\n",
       "        [ 1.2159891 , -0.19973272, -1.097954  ,  0.7230296 ,  3.6618152 ],\n",
       "        [ 0.7905082 , -0.3295288 ,  0.12237454, -1.081089  ,  0.30062205],\n",
       "        [ 0.12585   ,  0.42896926, -0.35884738, -1.2112435 , -1.6363564 ],\n",
       "        [ 0.48260012,  0.1287068 ,  0.5652358 , -0.2649471 , -1.2183887 ],\n",
       "        [ 2.3494155 , -0.9179705 , -0.06931831, -1.663458  , -0.53992206],\n",
       "        [ 1.1985936 ,  0.20886225,  1.040505  , -0.3369276 , -0.9281729 ],\n",
       "        [-0.15119992, -0.31006682,  1.0916318 ,  0.72068036, -0.684248  ],\n",
       "        [-1.2701288 ,  0.07521182,  1.2750496 , -0.8496027 , -1.6038836 ],\n",
       "        [ 0.3708051 ,  0.24084033, -0.21127778,  0.43799123, -0.81833154],\n",
       "        [ 0.23249999,  0.04544857, -0.02975689,  0.29004556, -0.52710575],\n",
       "        [ 0.883352  ,  0.73457605,  0.14539027, -0.10447058, -0.02818986],\n",
       "        [-0.8511919 ,  0.43441522, -0.79863966,  2.1886513 ,  3.1255202 ],\n",
       "        [ 1.5009358 ,  3.2365215 ,  2.0025887 , -0.92763305, -2.0443075 ],\n",
       "        [-1.4207445 ,  1.2267044 ,  0.32809854,  0.3456071 ,  0.90024215],\n",
       "        [-1.9726238 , -0.050198  , -0.6082368 ,  1.1205704 ,  1.0630369 ],\n",
       "        [-0.01205048,  0.6421378 ,  0.28062037, -0.25324064, -0.6757639 ],\n",
       "        [-0.03515752,  0.45715195,  0.0454716 , -0.31759855, -2.183094  ],\n",
       "        [-1.2158685 ,  0.32018274,  0.6200736 , -0.5692114 ,  1.2970537 ],\n",
       "        [ 1.4479403 , -0.31688407, -0.6011545 ,  0.95249796, -1.8959218 ],\n",
       "        [ 0.7307026 , -1.367888  ,  0.23443633, -0.9987933 ,  0.6294319 ],\n",
       "        [-0.291871  ,  1.29605   , -0.25345826,  1.7896769 , -0.29004633],\n",
       "        [ 0.59580445, -0.4763953 , -0.40816066,  0.19013764, -0.6124215 ]],\n",
       "       dtype=float32),\n",
       " array([-2.83830285e-01, -3.14585567e-01, -1.51864856e-01,  6.80624366e-01,\n",
       "        -2.66390264e-01,  8.16827491e-02, -3.32888341e+00, -3.14970165e-02,\n",
       "        -3.05841933e-03, -2.42016292e+00,  1.35417208e-01, -2.12635443e-01,\n",
       "        -6.16091602e-02, -3.12175274e-01, -1.07446745e-01,  2.81769323e+00,\n",
       "        -1.26645789e-01, -6.84211925e-02, -4.33033109e-02, -8.28335509e-02,\n",
       "        -2.38051549e-01, -1.87090799e-01, -2.37515256e-01, -3.47131312e-01,\n",
       "        -2.14897186e-01, -1.89427018e-01,  9.53839898e-01,  2.50347078e-01,\n",
       "         5.19496389e-02, -2.59649307e-02, -3.90410495e+00, -3.34351271e-01,\n",
       "        -1.59955531e-01, -2.01707944e-01, -1.42585471e-01, -1.62740294e-02,\n",
       "        -1.06223255e-01, -8.09165761e-02, -3.32744390e-01, -1.23930860e+00,\n",
       "        -6.24909438e-02, -2.03455538e-01, -1.87808543e-03, -1.01686172e-01,\n",
       "        -1.07134156e-01, -3.24131072e-01, -4.72919717e-02, -1.12508938e-01,\n",
       "        -1.99769124e-01, -2.84954667e-01, -1.74699113e-01, -3.09209347e-01,\n",
       "        -2.47551370e+00, -8.75485003e-01, -1.37419745e-01, -7.06385449e-02,\n",
       "        -1.69841364e-01, -1.87274486e-01, -3.02482277e-01, -9.55563545e-01,\n",
       "        -2.31121778e-01, -1.46016252e+00, -1.98984653e-01, -2.35728949e-01,\n",
       "        -2.36538425e-01, -2.77490556e-01, -3.36455733e-01, -8.47641647e-01,\n",
       "        -3.13719273e-01, -3.07300478e-01,  3.48350331e-02, -3.45795870e-01,\n",
       "        -2.38486812e-01, -1.86595902e-01, -9.06788707e-02, -1.84422769e-02,\n",
       "        -1.88699111e-01, -4.17425364e-01,  2.92003870e-01,  3.94372493e-01,\n",
       "        -1.92971870e-01, -1.32398710e-01, -2.45081782e+00, -1.90070435e-01,\n",
       "        -2.56040245e-01, -3.24446946e-01, -2.39385903e-01, -1.66078642e-01,\n",
       "        -1.87906057e-01, -2.47592181e-01, -1.82648487e-02, -3.19403470e-01,\n",
       "        -2.52788156e-01, -1.09489970e-01, -8.25069845e-01, -1.72850028e-01,\n",
       "        -2.64572329e-03, -1.45411715e-01, -3.16247970e-01,  3.95010002e-02,\n",
       "        -3.14214756e-03, -1.14971951e-01, -6.43066391e-02, -8.25479507e-01,\n",
       "        -1.70023069e-01,  8.16489935e-01, -4.24765125e-02, -2.60947347e-01,\n",
       "        -1.03151478e-01, -6.06596097e-02, -1.61090231e+00, -1.28042892e-01,\n",
       "        -1.70495421e-01, -1.35071859e-01, -1.31245911e-01, -1.80668175e+00,\n",
       "        -1.86944473e+00, -2.44057488e+00,  5.61805964e-01, -1.86143950e-01,\n",
       "        -2.58482844e-01, -2.17130646e-01, -6.43658400e-01,  1.28155100e+00,\n",
       "        -1.74768224e-01, -3.95139046e-02,  4.84573394e-02, -1.08957298e-01,\n",
       "        -2.11433709e-01, -2.34214827e-01, -1.54270872e-01, -1.38397068e-01,\n",
       "         1.31489992e-01, -8.27115178e-02, -4.80375253e-02, -2.96947807e-02,\n",
       "        -1.68443367e-01, -1.28414884e-01, -1.58772767e+00, -3.04109126e-01,\n",
       "        -2.00562939e-01, -2.00062528e-01, -1.82519123e-01,  1.12104878e-01,\n",
       "        -1.51214555e-01, -3.08125347e-01, -2.21346080e-01, -2.18940988e-01,\n",
       "        -1.07615006e+00, -3.15252960e-01, -8.53268132e-02, -3.39519754e-02,\n",
       "        -1.03444839e+00, -9.93057266e-02, -3.22608680e-01], dtype=float32),\n",
       " array([-0.6332385 , -0.10561334, -0.91315585,  0.8630061 ,  0.40629524,\n",
       "         0.29463506,  0.82232004, -1.1546488 , -0.57705   , -1.0337478 ,\n",
       "         0.6369324 , -0.73224425,  0.05947801,  1.7361419 ,  0.01700298,\n",
       "         1.9888891 , -0.94297284,  0.48030186,  1.0640165 ,  0.45916975,\n",
       "        -1.23337   , -0.51827437, -1.2652022 ,  0.79081047, -0.14029218,\n",
       "         0.32097164,  0.7018402 , -1.3896016 , -0.5866882 ,  0.93253034,\n",
       "         1.0394753 ], dtype=float32),\n",
       " array([[-1.2846192 ,  0.14424108, -1.5503831 ,  2.0437024 ,  2.8456304 ]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(params)):\n",
    "    np.save('../save/weights/slearn_parms{}_196-5.npy'.format(i),params[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
