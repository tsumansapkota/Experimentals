{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "import random, os, pathlib, time\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:1\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "X = torch.randn(1, N)\n",
    "### N+1 does not converge the X to exact values, but still have same scaled distance\n",
    "C = torch.randn(N+1, N) #?? Impossible to reconstruct with scaled distance\n",
    "### Normalized/scaled distance is invertible with N+2 total distances\n",
    "# C = torch.randn(N+2, N)\n",
    "dists = torch.cdist(X, C, p=2)\n",
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_inverse(C, dists):\n",
    "    A = 2*(C[1:]-C[:-1])\n",
    "    c2 = C**2\n",
    "    Z = (c2[:-1]-c2[1:]).sum(dim=1, keepdim=True)\n",
    "    invA = torch.pinverse(A)\n",
    "\n",
    "    d2 = dists**2\n",
    "    D = d2[:, :-1]-d2[:, 1:]\n",
    "\n",
    "    xrec = torch.matmul(invA, D.t()-Z).t()\n",
    "    return xrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1570, -0.2335, -1.7990, -0.2919, -0.0465]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_inverse(C, dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1570, -0.2335, -1.7990, -0.2919, -0.0465]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.8321)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists.sum() ## This should be reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4427,  0.2089, -0.3084,  0.7398, -0.8711]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_n = dists/dists.sum()\n",
    "X_n = compute_inverse(C, dists_n)\n",
    "X_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.1069, 3.1075, 3.1085, 3.1112, 3.1067, 3.1070]]),\n",
       " tensor([[3.0684, 3.3440, 3.7208, 4.5961, 2.9812, 3.1217]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(X_n, C, p=2), dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS = 9000\n",
    "# scale = torch.nn.Parameter(torch.Tensor([1.]))\n",
    "# optimizer = torch.optim.Adam([scale], lr=0.001)\n",
    "\n",
    "# for step in range(STEPS):\n",
    "# #     dists_n = dists/dists.sum()\n",
    "#     X_n = compute_inverse(C, dists_n*scale)\n",
    "#     dists_rec = torch.cdist(X_n, C, p=2)\n",
    "#     error = ((dists_rec - dists)**2).sum()\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     error.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     if (step+1)%500 == 0:\n",
    "#         print(f\"Step {step}; scale: {scale}; error:{error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 499; scale: Parameter containing:\n",
      "tensor([5.7157], requires_grad=True); error:26.895294189453125\n",
      "Step 999; scale: Parameter containing:\n",
      "tensor([9.6379], requires_grad=True); error:11.99869155883789\n",
      "Step 1499; scale: Parameter containing:\n",
      "tensor([12.6276], requires_grad=True); error:4.922844886779785\n",
      "Step 1999; scale: Parameter containing:\n",
      "tensor([14.7873], requires_grad=True); error:2.004864454269409\n",
      "Step 2499; scale: Parameter containing:\n",
      "tensor([16.3305], requires_grad=True); error:0.846184492111206\n",
      "Step 2999; scale: Parameter containing:\n",
      "tensor([17.4507], requires_grad=True); error:0.37348130345344543\n",
      "Step 3499; scale: Parameter containing:\n",
      "tensor([18.2839], requires_grad=True); error:0.17093908786773682\n",
      "Step 3999; scale: Parameter containing:\n",
      "tensor([18.9180], requires_grad=True); error:0.07995717227458954\n",
      "Step 4499; scale: Parameter containing:\n",
      "tensor([19.4090], requires_grad=True); error:0.0375974141061306\n",
      "Step 4999; scale: Parameter containing:\n",
      "tensor([19.7928], requires_grad=True); error:0.017461953684687614\n",
      "Step 5499; scale: Parameter containing:\n",
      "tensor([20.0933], requires_grad=True); error:0.007852924056351185\n",
      "Step 5999; scale: Parameter containing:\n",
      "tensor([20.3267], requires_grad=True); error:0.0033389730378985405\n",
      "Step 6499; scale: Parameter containing:\n",
      "tensor([20.5042], requires_grad=True); error:0.0013020645128563046\n",
      "Step 6999; scale: Parameter containing:\n",
      "tensor([20.6342], requires_grad=True); error:0.00044730515219271183\n",
      "Step 7499; scale: Parameter containing:\n",
      "tensor([20.7240], requires_grad=True); error:0.00012808071915060282\n",
      "Step 7999; scale: Parameter containing:\n",
      "tensor([20.7806], requires_grad=True); error:2.8359430871205404e-05\n",
      "Step 8499; scale: Parameter containing:\n",
      "tensor([20.8117], requires_grad=True); error:4.384296971693402e-06\n",
      "Step 8999; scale: Parameter containing:\n",
      "tensor([20.8258], requires_grad=True); error:4.1475834677839885e-07\n",
      "Step 9499; scale: Parameter containing:\n",
      "tensor([20.8307], requires_grad=True); error:1.961478801604244e-08\n",
      "Step 9999; scale: Parameter containing:\n",
      "tensor([20.8319], requires_grad=True); error:4.1961811803048477e-10\n"
     ]
    }
   ],
   "source": [
    "STEPS = 10000\n",
    "scale = torch.nn.Parameter(torch.Tensor([1.]))\n",
    "optimizer = torch.optim.Adam([scale], lr=0.01)\n",
    "\n",
    "for step in range(STEPS):\n",
    "#     dists_n = dists/dists.sum()\n",
    "    X_n = compute_inverse(C, dists_n*scale)\n",
    "    dists_rec = torch.cdist(X_n, C, p=2)\n",
    "    \n",
    "#     dists_rec = dists_rec/dists_rec.sum()\n",
    "#     error = ((dists_rec - dists_n)**2).sum()\n",
    "\n",
    "#     dists_rec = dists_rec/dists_rec.sum()\n",
    "    error = ((dists_rec - dists_n*scale)**2).sum()\n",
    "\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    error.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (step+1)%500 == 0:\n",
    "        print(f\"Step {step}; scale: {scale}; error:{error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.1433, 2.0812, 2.3674, 2.4449, 2.0222, 1.0560]],\n",
       "        grad_fn=<MulBackward0>),\n",
       " tensor([[3.1373, 3.0464, 3.4655, 3.5788, 2.9602, 1.5457]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_n*scale, dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2612,  0.3698, -0.4908, -0.2540,  0.2800]], grad_fn=<TBackward>)\n",
      "tensor([[0.1769, 0.1718, 0.1954, 0.2018, 0.1669, 0.0872]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X_n = compute_inverse(C, dists_n*scale)\n",
    "print(X_n)\n",
    "dists_rec = torch.cdist(X_n, C, p=2)\n",
    "dists_rec = dists_rec/dists_rec.sum()\n",
    "print(dists_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1769, 0.1718, 0.1954, 0.2018, 0.1669, 0.0872]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]]),\n",
       " tensor([[-0.2612,  0.3698, -0.4908, -0.2540,  0.2800]], grad_fn=<TBackward>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The normalized distance are same for both X and X_n which are different pints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 499; error:6.050782758393325e-06\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.20903355  0.32832682 -0.19603808 -0.27129516  0.23769674]]\n",
      "Step 999; error:2.119580955195488e-08\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.25581643  0.36677206 -0.47298455 -0.25727013  0.27943337]]\n",
      "Step 1499; error:1.587180387119247e-11\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.261079    0.369737   -0.49035275 -0.25406897  0.2799974 ]]\n",
      "Step 1999; error:2.4980018054066022e-15\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.26122996  0.3698208  -0.49083844 -0.25397566  0.28000942]]\n",
      "Step 2499; error:1.9984014443252818e-15\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.26123118  0.36982146 -0.4908421  -0.25397497  0.28000957]]\n",
      "Step 2999; error:4.218847493575595e-15\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.26123118  0.36982137 -0.4908419  -0.253975    0.28000972]]\n",
      "Step 3499; error:1.8318679906315083e-15\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.26123124  0.36982143 -0.4908421  -0.2539748   0.28000957]]\n",
      "Step 3999; error:1.3877787807814457e-15\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.26123112  0.36982137 -0.49084184 -0.25397497  0.28000963]]\n",
      "Step 4499; error:7.216449660063518e-16\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.26123106  0.36982155 -0.4908422  -0.25397494  0.2800096 ]]\n",
      "Step 4999; error:1.5543122344752192e-15\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.26123106  0.36982146 -0.49084204 -0.2539748   0.28000972]]\n",
      "Step 5499; error:6.661338147750939e-16\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.261231    0.3698215  -0.49084198 -0.253975    0.28000918]]\n",
      "Step 5999; error:8.881784197001252e-16\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.2612311   0.36982152 -0.4908418  -0.253975    0.2800099 ]]\n",
      "Step 6499; error:1.1657341758564144e-15\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.2612312   0.3698214  -0.4908418  -0.25397494  0.28001016]]\n",
      "Step 6999; error:2.0539125955565396e-15\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.26123133  0.36982146 -0.49084166 -0.25397494  0.28001007]]\n",
      "Step 7499; error:6.961098364399732e-13\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.26123127  0.36982018 -0.49084124 -0.25397414  0.28001654]]\n",
      "Step 7999; error:1.3617384997388626e-11\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.2612296   0.36982688 -0.49084038 -0.25397933  0.2799935 ]]\n",
      "Step 8499; error:2.971720425293256e-09\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.261215    0.3696643  -0.49084812 -0.2538447   0.28030214]]\n",
      "Step 8999; error:5.3213544681796066e-12\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.26122722  0.36981192 -0.49084395 -0.25396624  0.28002074]]\n",
      "Step 9499; error:1.839022090166509e-08\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.26121414  0.36974525 -0.49122748 -0.2537617   0.28014594]]\n",
      "Step 9999; error:9.459100169806334e-14\n",
      "Original:[[-1.2074946   0.54933286 -0.3855975   0.6909789  -0.74239856]]; \n",
      "Reconstructed:[[-0.26123068  0.3698204  -0.49084198 -0.25397316  0.28001136]]\n"
     ]
    }
   ],
   "source": [
    "STEPS = 10000\n",
    "X_guess = torch.nn.Parameter(torch.zeros_like(X))\n",
    "optimizer = torch.optim.Adam([X_guess], lr=0.01)\n",
    "\n",
    "for step in range(STEPS):\n",
    "    dists_g = torch.cdist(X_guess, C, p=2)\n",
    "    dists_g = dists_g/dists_g.sum()\n",
    "    error = ((dists_g - dists_n)**2).sum()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    error.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (step+1)%500 == 0:\n",
    "        print(f\"Step {step}; error:{error}\")\n",
    "        print(f\"Original:{X.numpy()}; \\nReconstructed:{X_guess.data.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cdist(X_guess, C, p=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.2612,  0.3698, -0.4908, -0.2540,  0.2800]], requires_grad=True),\n",
       " tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_guess, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1769, 0.1718, 0.1954, 0.2018, 0.1669, 0.0872]],\n",
       "        grad_fn=<DivBackward0>),\n",
       " tensor([[0.1769, 0.1718, 0.1954, 0.2018, 0.1669, 0.0872]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists_g, dists_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Again, same distance ratio but with different points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2612,  0.3698, -0.4908, -0.2540,  0.2800]], grad_fn=<TBackward>),\n",
       " Parameter containing:\n",
       " tensor([[-0.2612,  0.3698, -0.4908, -0.2540,  0.2800]], requires_grad=True),\n",
       " tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_n, X_guess, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7339)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, scaling the C similar to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 499; scale: Parameter containing:\n",
      "tensor([5.5649], requires_grad=True); error:7.854038715362549\n",
      "Step 999; scale: Parameter containing:\n",
      "tensor([8.6790], requires_grad=True); error:1.7509962320327759\n",
      "Step 1499; scale: Parameter containing:\n",
      "tensor([10.4057], requires_grad=True); error:0.3475249707698822\n",
      "Step 1999; scale: Parameter containing:\n",
      "tensor([11.3042], requires_grad=True); error:0.06650350987911224\n",
      "Step 2499; scale: Parameter containing:\n",
      "tensor([11.7627], requires_grad=True); error:0.0113601079210639\n",
      "Step 2999; scale: Parameter containing:\n",
      "tensor([11.9834], requires_grad=True); error:0.001502073835581541\n",
      "Step 3499; scale: Parameter containing:\n",
      "tensor([12.0761], requires_grad=True); error:0.00012817858078051358\n",
      "Step 3999; scale: Parameter containing:\n",
      "tensor([12.1067], requires_grad=True); error:5.690003035851987e-06\n",
      "Step 4499; scale: Parameter containing:\n",
      "tensor([12.1139], requires_grad=True); error:1.021492153086001e-07\n",
      "Step 4999; scale: Parameter containing:\n",
      "tensor([12.1149], requires_grad=True); error:4.6549075705115683e-10\n",
      "Step 5499; scale: Parameter containing:\n",
      "tensor([12.1149], requires_grad=True); error:3.589093466871418e-10\n",
      "Step 5999; scale: Parameter containing:\n",
      "tensor([12.1149], requires_grad=True); error:2.1464074961841106e-10\n",
      "Step 6499; scale: Parameter containing:\n",
      "tensor([12.1149], requires_grad=True); error:1.1749534678529017e-10\n",
      "Step 6999; scale: Parameter containing:\n",
      "tensor([12.1149], requires_grad=True); error:7.680966973566683e-11\n",
      "Step 7499; scale: Parameter containing:\n",
      "tensor([12.1149], requires_grad=True); error:3.399236447876319e-11\n",
      "Step 7999; scale: Parameter containing:\n",
      "tensor([12.1149], requires_grad=True); error:2.142996891052462e-11\n",
      "Step 8499; scale: Parameter containing:\n",
      "tensor([12.1149], requires_grad=True); error:1.2789769243681803e-11\n",
      "Step 8999; scale: Parameter containing:\n",
      "tensor([12.1149], requires_grad=True); error:6.707523425575346e-12\n",
      "Step 9499; scale: Parameter containing:\n",
      "tensor([12.1149], requires_grad=True); error:6.707523425575346e-12\n",
      "Step 9999; scale: Parameter containing:\n",
      "tensor([12.1149], requires_grad=True); error:3.524291969370097e-12\n"
     ]
    }
   ],
   "source": [
    "STEPS = 10000\n",
    "scale = torch.nn.Parameter(torch.Tensor([1.]))\n",
    "optimizer = torch.optim.Adam([scale], lr=0.01)\n",
    "\n",
    "for step in range(STEPS):\n",
    "#     dists_n = dists/dists.sum()\n",
    "    X_n = compute_inverse(C, dists_n*scale)\n",
    "    dists_rec = torch.cdist(X_n, C, p=2)\n",
    "#     dists_rec = dists_rec/dists_rec.sum()\n",
    "    error = ((dists_rec - dists_n*scale)**2).sum()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    error.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (step+1)%500 == 0:\n",
    "        print(f\"Step {step}; scale: {scale}; error:{error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2612,  0.3698, -0.4908, -0.2540,  0.2800]], grad_fn=<TBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2075,  0.5493, -0.3856,  0.6910, -0.7424]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Softmax and Layernorm also have some scaling/division .. following similar trend for reconstruction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
