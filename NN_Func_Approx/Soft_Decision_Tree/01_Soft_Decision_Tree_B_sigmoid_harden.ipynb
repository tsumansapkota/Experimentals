{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mylibrary.nnlib as tnn\n",
    "import mylibrary.datasets as datasets\n",
    "import copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST()\n",
    "train_data, train_label_, test_data, test_label_ = mnist.load()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb6f265a8d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADgdJREFUeJzt3X9sXfV5x/HPs9D8QRoIXjUTpWFpIhQUIuZOJkwoGkXM5YeCggGhWkLKRBT3j1ii0hQNZX8MNAVFg2RqBKrsqqHJ1KWZBCghqpp0CZBOTBEmhF9mKQylqi2TFAWTH/zIHD/74x53Lvh+r3Pvufdc+3m/JMv3nuecex4d5ZPz8/pr7i4A8fxJ0Q0AKAbhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1GWNXJmZ8TghUGfublOZr6Y9v5ndYWbHzex9M3ukls8C0FhW7bP9ZjZL0m8kdUgalPSqpC53H0gsw54fqLNG7PlXSHrf3T9w9wuSfi5pdQ2fB6CBagn/Akm/m/B+MJv2R8ys28z6zay/hnUByFndL/i5e5+kPonDfqCZ1LLnH5K0cML7b2bTAEwDtYT/VUnXmtm3zGy2pO9J2ptPWwDqrerDfncfNbMeSfslzZK03d3fya0zAHVV9a2+qlbGOT9Qdw15yAfA9EX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUFUP0S1JZnZC0llJFyWNunt7Hk0hP7NmzUrWr7zyyrquv6enp2zt8ssvTy67dOnSZH39+vXJ+pNPPlm21tXVlVz2888/T9Y3b96crD/22GPJejOoKfyZW939oxw+B0ADcdgPBFVr+F3SATN7zcy682gIQGPUeti/0t2HzOzPJP3KzP7b3Q9PnCH7T4H/GIAmU9Oe392Hst+nJD0vacUk8/S5ezsXA4HmUnX4zWyOmc0dfy3pu5LezqsxAPVVy2F/q6TnzWz8c/7N3X+ZS1cA6q7q8Lv7B5L+IsdeZqxrrrkmWZ89e3ayfvPNNyfrK1euLFubN29ectn77rsvWS/S4OBgsr5t27ZkvbOzs2zt7NmzyWXfeOONZP3ll19O1qcDbvUBQRF+ICjCDwRF+IGgCD8QFOEHgjJ3b9zKzBq3sgZqa2tL1g8dOpSs1/trtc1qbGwsWX/ooYeS9XPnzlW97uHh4WT9448/TtaPHz9e9brrzd1tKvOx5weCIvxAUIQfCIrwA0ERfiAowg8ERfiBoLjPn4OWlpZk/ciRI8n64sWL82wnV5V6HxkZSdZvvfXWsrULFy4kl436/EOtuM8PIInwA0ERfiAowg8ERfiBoAg/EBThB4LKY5Te8E6fPp2sb9iwIVlftWpVsv76668n65X+hHXKsWPHkvWOjo5k/fz588n69ddfX7b28MMPJ5dFfbHnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgKn6f38y2S1ol6ZS7L8+mtUjaLWmRpBOSHnD39B8618z9Pn+trrjiimS90nDSvb29ZWtr165NLvvggw8m67t27UrW0Xzy/D7/TyXd8aVpj0g66O7XSjqYvQcwjVQMv7sflvTlR9hWS9qRvd4h6Z6c+wJQZ9We87e6+/h4Rx9Kas2pHwANUvOz/e7uqXN5M+uW1F3regDkq9o9/0kzmy9J2e9T5WZ09z53b3f39irXBaAOqg3/XklrstdrJO3Jpx0AjVIx/Ga2S9J/SVpqZoNmtlbSZkkdZvaepL/J3gOYRiqe87t7V5nSbTn3EtaZM2dqWv6TTz6petl169Yl67t3707Wx8bGql43isUTfkBQhB8IivADQRF+ICjCDwRF+IGgGKJ7BpgzZ07Z2gsvvJBc9pZbbknW77zzzmT9wIEDyToajyG6ASQRfiAowg8ERfiBoAg/EBThB4Ii/EBQ3Oef4ZYsWZKsHz16NFkfGRlJ1l988cVkvb+/v2zt6aefTi7byH+bMwn3+QEkEX4gKMIPBEX4gaAIPxAU4QeCIvxAUNznD66zszNZf+aZZ5L1uXPnVr3ujRs3Jus7d+5M1oeHh5P1qLjPDyCJ8ANBEX4gKMIPBEX4gaAIPxAU4QeCqnif38y2S1ol6ZS7L8+mPSppnaTfZ7NtdPdfVFwZ9/mnneXLlyfrW7duTdZvu636kdx7e3uT9U2bNiXrQ0NDVa97OsvzPv9PJd0xyfR/cfe27Kdi8AE0l4rhd/fDkk43oBcADVTLOX+Pmb1pZtvN7KrcOgLQENWG/0eSlkhqkzQsaUu5Gc2s28z6zaz8H3MD0HBVhd/dT7r7RXcfk/RjSSsS8/a5e7u7t1fbJID8VRV+M5s/4W2npLfzaQdAo1xWaQYz2yXpO5K+YWaDkv5R0nfMrE2SSzoh6ft17BFAHfB9ftRk3rx5yfrdd99dtlbpbwWYpW9XHzp0KFnv6OhI1mcqvs8PIInwA0ERfiAowg8ERfiBoAg/EBS3+lCYL774Ilm/7LL0Yyijo6PJ+u2331629tJLLyWXnc641QcgifADQRF+ICjCDwRF+IGgCD8QFOEHgqr4fX7EdsMNNyTr999/f7J+4403lq1Vuo9fycDAQLJ++PDhmj5/pmPPDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBcZ9/hlu6dGmy3tPTk6zfe++9yfrVV199yT1N1cWLF5P14eHhZH1sbCzPdmYc9vxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFTF+/xmtlDSTkmtklxSn7v/0MxaJO2WtEjSCUkPuPvH9Ws1rkr30ru6usrWKt3HX7RoUTUt5aK/vz9Z37RpU7K+d+/ePNsJZyp7/lFJf+fuyyT9laT1ZrZM0iOSDrr7tZIOZu8BTBMVw+/uw+5+NHt9VtK7khZIWi1pRzbbDkn31KtJAPm7pHN+M1sk6duSjkhqdffx5ys/VOm0AMA0MeVn+83s65KelfQDdz9j9v/Dgbm7lxuHz8y6JXXX2iiAfE1pz29mX1Mp+D9z9+eyySfNbH5Wny/p1GTLunufu7e7e3seDQPIR8XwW2kX/xNJ77r71gmlvZLWZK/XSNqTf3sA6qXiEN1mtlLSryW9JWn8O5IbVTrv/3dJ10j6rUq3+k5X+KyQQ3S3tqYvhyxbtixZf+qpp5L166677pJ7ysuRI0eS9SeeeKJsbc+e9P6Cr+RWZ6pDdFc853f3/5RU7sNuu5SmADQPnvADgiL8QFCEHwiK8ANBEX4gKMIPBMWf7p6ilpaWsrXe3t7ksm1tbcn64sWLq+opD6+88kqyvmXLlmR9//79yfpnn312yT2hMdjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQYe7z33TTTcn6hg0bkvUVK1aUrS1YsKCqnvLy6aeflq1t27Ytuezjjz+erJ8/f76qntD82PMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFBh7vN3dnbWVK/FwMBAsr5v375kfXR0NFlPfed+ZGQkuSziYs8PBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GZu6dnMFsoaaekVkkuqc/df2hmj0paJ+n32awb3f0XFT4rvTIANXN3m8p8Uwn/fEnz3f2omc2V9JqkeyQ9IOmcuz851aYIP1B/Uw1/xSf83H1Y0nD2+qyZvSup2D9dA6Bml3TOb2aLJH1b0pFsUo+ZvWlm283sqjLLdJtZv5n119QpgFxVPOz/w4xmX5f0sqRN7v6cmbVK+kil6wD/pNKpwUMVPoPDfqDOcjvnlyQz+5qkfZL2u/vWSeqLJO1z9+UVPofwA3U21fBXPOw3M5P0E0nvTgx+diFwXKekty+1SQDFmcrV/pWSfi3pLUlj2eSNkroktal02H9C0vezi4Opz2LPD9RZrof9eSH8QP3ldtgPYGYi/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBNXoIbo/kvTbCe+/kU1rRs3aW7P2JdFbtfLs7c+nOmNDv8//lZWb9bt7e2ENJDRrb83al0Rv1SqqNw77gaAIPxBU0eHvK3j9Kc3aW7P2JdFbtQrprdBzfgDFKXrPD6AghYTfzO4ws+Nm9r6ZPVJED+WY2Qkze8vMjhU9xFg2DNopM3t7wrQWM/uVmb2X/Z50mLSCenvUzIaybXfMzO4qqLeFZvaimQ2Y2Ttm9nA2vdBtl+irkO3W8MN+M5sl6TeSOiQNSnpVUpe7DzS0kTLM7ISkdncv/J6wmf21pHOSdo6PhmRm/yzptLtvzv7jvMrd/75JentUlzhyc516Kzey9N+qwG2X54jXeShiz79C0vvu/oG7X5D0c0mrC+ij6bn7YUmnvzR5taQd2esdKv3jabgyvTUFdx9296PZ67OSxkeWLnTbJfoqRBHhXyDpdxPeD6q5hvx2SQfM7DUz6y66mUm0ThgZ6UNJrUU2M4mKIzc30pdGlm6abVfNiNd544LfV61097+UdKek9dnhbVPy0jlbM92u+ZGkJSoN4zYsaUuRzWQjSz8r6QfufmZirchtN0lfhWy3IsI/JGnhhPffzKY1BXcfyn6fkvS8SqcpzeTk+CCp2e9TBffzB+5+0t0vuvuYpB+rwG2XjSz9rKSfuftz2eTCt91kfRW13YoI/6uSrjWzb5nZbEnfk7S3gD6+wszmZBdiZGZzJH1XzTf68F5Ja7LXayTtKbCXP9IsIzeXG1laBW+7phvx2t0b/iPpLpWu+P+PpH8ooocyfS2W9Eb2807RvUnapdJh4P+qdG1kraQ/lXRQ0nuS/kNSSxP19q8qjeb8pkpBm19QbytVOqR/U9Kx7Oeuorddoq9CthtP+AFBccEPCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ/weCC5r/92q6mAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[0].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "\n",
    "learning_rate = 0.0001\n",
    "batch_size = 64#300\n",
    "EPOCHS = 10\n",
    "\n",
    "train_label = tnn.Logits.index_to_logit(train_label_)\n",
    "train_size = len(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN 0 ->  6.4271752437895735\n",
      "EPOCH =  0 accuracy =  17.988333333333333\n",
      "10793 / 60000\n",
      "   TEST   accuracy =  17.22\n",
      "1722 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.771231139757187\n",
      "EPOCH =  0 accuracy =  86.37833333333333\n",
      "51827 / 60000\n",
      "   TEST   accuracy =  87.22999999999999\n",
      "8723 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.774312290250135\n",
      "EPOCH =  0 accuracy =  87.47333333333333\n",
      "52484 / 60000\n",
      "   TEST   accuracy =  87.97\n",
      "8797 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.769567095356269\n",
      "EPOCH =  0 accuracy =  90.03166666666667\n",
      "54019 / 60000\n",
      "   TEST   accuracy =  89.96\n",
      "8996 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.815523076987942\n",
      "EPOCH =  0 accuracy =  88.03833333333333\n",
      "52823 / 60000\n",
      "   TEST   accuracy =  88.02\n",
      "8802 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.77486719547034\n",
      "EPOCH =  0 accuracy =  87.43166666666666\n",
      "52459 / 60000\n",
      "   TEST   accuracy =  87.82\n",
      "8782 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.796560758767783\n",
      "EPOCH =  0 accuracy =  86.17\n",
      "51702 / 60000\n",
      "   TEST   accuracy =  85.97\n",
      "8597 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.808956841115238\n",
      "EPOCH =  0 accuracy =  88.83166666666666\n",
      "53299 / 60000\n",
      "   TEST   accuracy =  89.09\n",
      "8909 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.89190865438618\n",
      "EPOCH =  0 accuracy =  87.90833333333333\n",
      "52745 / 60000\n",
      "   TEST   accuracy =  87.83999999999999\n",
      "8784 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.856235867275736\n",
      "EPOCH =  0 accuracy =  87.33833333333332\n",
      "52403 / 60000\n",
      "   TEST   accuracy =  87.18\n",
      "8718 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.786818988647801\n",
      "EPOCH =  1 accuracy =  85.16\n",
      "51096 / 60000\n",
      "   TEST   accuracy =  85.41\n",
      "8541 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.704837033827565\n",
      "EPOCH =  1 accuracy =  88.96833333333333\n",
      "53381 / 60000\n",
      "   TEST   accuracy =  89.21\n",
      "8921 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.747110828397097\n",
      "EPOCH =  1 accuracy =  88.58166666666666\n",
      "53149 / 60000\n",
      "   TEST   accuracy =  89.12\n",
      "8912 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.73374877275588\n",
      "EPOCH =  1 accuracy =  90.88166666666667\n",
      "54529 / 60000\n",
      "   TEST   accuracy =  90.25\n",
      "9025 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.791323103395193\n",
      "EPOCH =  1 accuracy =  88.9\n",
      "53340 / 60000\n",
      "   TEST   accuracy =  88.71\n",
      "8871 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.784786819472009\n",
      "EPOCH =  1 accuracy =  88.04666666666667\n",
      "52828 / 60000\n",
      "   TEST   accuracy =  88.02\n",
      "8802 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.763084259384344\n",
      "EPOCH =  1 accuracy =  87.42333333333333\n",
      "52454 / 60000\n",
      "   TEST   accuracy =  86.58\n",
      "8658 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.832011941637873\n",
      "EPOCH =  1 accuracy =  89.52166666666666\n",
      "53713 / 60000\n",
      "   TEST   accuracy =  89.46\n",
      "8946 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.886995002181754\n",
      "EPOCH =  1 accuracy =  88.36500000000001\n",
      "53019 / 60000\n",
      "   TEST   accuracy =  87.89\n",
      "8789 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.833778094411288\n",
      "EPOCH =  1 accuracy =  88.72666666666666\n",
      "53236 / 60000\n",
      "   TEST   accuracy =  88.53999999999999\n",
      "8854 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.781725601813136\n",
      "EPOCH =  2 accuracy =  85.76833333333333\n",
      "51461 / 60000\n",
      "   TEST   accuracy =  85.65\n",
      "8565 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.696942731027722\n",
      "EPOCH =  2 accuracy =  88.83666666666666\n",
      "53302 / 60000\n",
      "   TEST   accuracy =  89.07000000000001\n",
      "8907 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.7398188781751\n",
      "EPOCH =  2 accuracy =  88.53999999999999\n",
      "53124 / 60000\n",
      "   TEST   accuracy =  88.98\n",
      "8898 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.732923399002738\n",
      "EPOCH =  2 accuracy =  91.035\n",
      "54621 / 60000\n",
      "   TEST   accuracy =  90.58\n",
      "9058 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.789853760899817\n",
      "EPOCH =  2 accuracy =  89.26333333333332\n",
      "53558 / 60000\n",
      "   TEST   accuracy =  89.02\n",
      "8902 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.808205592545627\n",
      "EPOCH =  2 accuracy =  87.675\n",
      "52605 / 60000\n",
      "   TEST   accuracy =  87.4\n",
      "8740 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.749598878297079\n",
      "EPOCH =  2 accuracy =  87.82666666666667\n",
      "52696 / 60000\n",
      "   TEST   accuracy =  86.89\n",
      "8689 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.831550084268958\n",
      "EPOCH =  2 accuracy =  89.42333333333333\n",
      "53654 / 60000\n",
      "   TEST   accuracy =  89.41\n",
      "8941 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.89114930336873\n",
      "EPOCH =  2 accuracy =  88.445\n",
      "53067 / 60000\n",
      "   TEST   accuracy =  88.02\n",
      "8802 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.826328756014053\n",
      "EPOCH =  2 accuracy =  89.53166666666667\n",
      "53719 / 60000\n",
      "   TEST   accuracy =  89.23\n",
      "8923 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.776177226294822\n",
      "EPOCH =  3 accuracy =  86.055\n",
      "51633 / 60000\n",
      "   TEST   accuracy =  85.86\n",
      "8586 / 10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-809ca831ff4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mlinear_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tsuman/98D2644AD2642EA6/Neural_Network/Notebooks/Experimentals/NN_Func_Approx/Soft_Decision_Tree/mylibrary/nnlib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mgradients\u001b[0m  \u001b[0;31m# * learning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;31m# print(self.bias.shape, self.del_bias.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiasOpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdel_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mgradients\u001b[0m  \u001b[0;31m# * learning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tsuman/98D2644AD2642EA6/Neural_Network/Notebooks/Experimentals/NN_Func_Approx/Soft_Decision_Tree/mylibrary/nnlib.py\u001b[0m in \u001b[0;36mcompute_gradient\u001b[0;34m(self, grad, new_learning_rate)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_learning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_learning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_learning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "linear_regression = tnn.LinearLayer(input_size, output_size, optimizer=tnn.Adam())\n",
    "\n",
    "accuracy_list = []\n",
    "for epoch in range(EPOCHS):\n",
    "    for index in range(train_size // batch_size):\n",
    "        train_x = train_data[index * batch_size:(index + 1) * batch_size]\n",
    "        train_y = train_label[index * batch_size:(index + 1) * batch_size]\n",
    "        \n",
    "        yout = linear_regression.forward(train_x)\n",
    "\n",
    "        dy = tnn.SoftmaxCrossEntropy.del_loss(yout, train_y)\n",
    "        loss = tnn.SoftmaxCrossEntropy.loss(yout, train_y)\n",
    "\n",
    "        dx = linear_regression.backward(dy)\n",
    "\n",
    "        linear_regression.update()\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            \n",
    "            print('\\nTRAIN',index, '-> ', loss)\n",
    "            yout = linear_regression.forward(train_data)\n",
    "            outputs = tnn.Logits.logit_to_index(yout)\n",
    "            correct = (outputs == np.array(train_label_)).sum()\n",
    "\n",
    "            accuracy = correct / len(train_label_) * 100.\n",
    "            print('EPOCH = ',epoch,'accuracy = ', accuracy)\n",
    "            print(correct, '/', len(train_label_))\n",
    "            \n",
    "            yout = linear_regression.forward(test_data)\n",
    "            outputs = tnn.Logits.logit_to_index(yout)\n",
    "            correct = (outputs == np.array(test_label_)).sum()\n",
    "\n",
    "            accuracy = correct / len(test_label_) * 100.\n",
    "            print('   TEST  ','accuracy = ', accuracy)\n",
    "            print(correct, '/', len(test_label_))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Soft Decision Tree classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafNode(object):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, learning_rate=0.0001):\n",
    "        self.fc = tnn.LinearLayer(input_dim, output_dim, optimizer=tnn.Adam(learning_rate))\n",
    "        self.prob = None\n",
    "        self.del_outputs = None\n",
    "        self.del_prob = None\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        fc_out = self.fc.forward(inputs)\n",
    "        return fc_out\n",
    "    \n",
    "    def backward(self, del_outputs):\n",
    "        self.del_outputs = del_outputs\n",
    "        del_inputs = self.fc.backward(del_outputs)\n",
    "        return del_inputs\n",
    "    \n",
    "    def update(self):\n",
    "        self.fc.update()\n",
    "        \n",
    "\n",
    "class InnerNode(object):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, learning_rate=0.0001):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.fc = tnn.NonLinearLayer(input_dim, 1, activation=tnn.Sigmoid(), optimizer=tnn.Adam(learning_rate))\n",
    "        self.probs = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "        self.prob_left = None\n",
    "        self.prob_right = None\n",
    "        \n",
    "        self.out_left = None\n",
    "        self.out_right = None\n",
    "        return\n",
    "    \n",
    "    def create_child(self, depth):\n",
    "        if depth > 1:\n",
    "            self.left = InnerNode(self.input_dim, self.output_dim, self.learning_rate)\n",
    "            self.right = InnerNode(self.input_dim, self.output_dim, self.learning_rate)\n",
    "            self.left.create_child(depth-1)\n",
    "            self.right.create_child(depth-1)\n",
    "        else:\n",
    "            self.left = LeafNode(self.input_dim, self.output_dim, self.learning_rate)\n",
    "            self.right = LeafNode(self.input_dim, self.output_dim, self.learning_rate)\n",
    "\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.probs = self.fc.forward(inputs)\n",
    "        self.prob_left = self.probs\n",
    "        self.prob_right = (1-self.probs)        \n",
    "        \n",
    "        self.out_left = self.left.forward(inputs)\n",
    "        self.out_right = self.right.forward(inputs)\n",
    "        \n",
    "        output = self.out_left*self.prob_left + self.out_right*self.prob_right\n",
    "        return output\n",
    "    \n",
    "    def backward(self, del_outputs):\n",
    "        del_out_left = del_outputs*self.prob_left\n",
    "        del_out_right = del_outputs*self.prob_right\n",
    "\n",
    "        del_inp_left = self.left.backward(del_out_left)\n",
    "        del_inp_right = self.right.backward(del_out_right)\n",
    "        \n",
    "        del_prob_left = np.mean(self.out_left*del_outputs, axis=1, keepdims=True)\n",
    "        del_prob_right = np.mean(self.out_right*del_outputs, axis=1, keepdims=True)\n",
    "        \n",
    "        del_probs = (del_prob_left - del_prob_right)\n",
    "        del_inp_probs = self.fc.backward(del_probs)\n",
    "        \n",
    "        del_inputs = del_inp_left + del_inp_right + del_inp_probs\n",
    "        \n",
    "        return del_inputs\n",
    "        \n",
    "        \n",
    "    def update(self):\n",
    "        self.fc.update()\n",
    "        self.left.update()\n",
    "        self.right.update()\n",
    "        \n",
    "    def harden_decision(self, magnitude):\n",
    "        factor = magnitude/np.linalg.norm(self.fc.weights)\n",
    "        self.fc.weights = self.fc.weights * factor\n",
    "        self.fc.bias = self.fc.bias * factor\n",
    "        \n",
    "        if type(self.left) == InnerNode:\n",
    "            self.left.harden_decision(magnitude)\n",
    "        if type(self.right) == InnerNode:\n",
    "            self.right.harden_decision(magnitude)\n",
    "            \n",
    "    def forward_hard(self, inputs):\n",
    "        self.probs = self.fc.forward(inputs)\n",
    "        \n",
    "        self.prob_left = self.probs>0.5\n",
    "        self.prob_right = ~self.prob_left        \n",
    "        \n",
    "        if type(self.left) == InnerNode:\n",
    "            self.out_left = self.left.forward_hard(inputs)\n",
    "            self.out_right = self.right.forward_hard(inputs)\n",
    "        else:\n",
    "            self.out_left = self.left.forward(inputs)\n",
    "            self.out_right = self.right.forward(inputs)\n",
    "            \n",
    "        output = self.out_left*self.prob_left + self.out_right*self.prob_right\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Soft Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_depth = 3\n",
    "sdt = InnerNode(input_size, output_size)\n",
    "sdt.create_child(tree_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN 0 ->  6.460409913733963\n",
      "EPOCH =  0 accuracy =  12.606666666666666\n",
      "7564 / 60000\n",
      "   TEST   accuracy =  12.29\n",
      "1229 / 10000\n",
      "\n",
      "TRAIN 100 ->  6.2255978327248185\n",
      "EPOCH =  0 accuracy =  66.95166666666667\n",
      "40171 / 60000\n",
      "   TEST   accuracy =  67.19000000000001\n",
      "6719 / 10000\n",
      "\n",
      "TRAIN 200 ->  6.142939572651649\n",
      "EPOCH =  0 accuracy =  78.815\n",
      "47289 / 60000\n",
      "   TEST   accuracy =  79.22\n",
      "7922 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.9831559071003095\n",
      "EPOCH =  0 accuracy =  82.93833333333333\n",
      "49763 / 60000\n",
      "   TEST   accuracy =  83.73\n",
      "8373 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.975910216659272\n",
      "EPOCH =  0 accuracy =  85.40166666666667\n",
      "51241 / 60000\n",
      "   TEST   accuracy =  86.02\n",
      "8602 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.932855648281015\n",
      "EPOCH =  0 accuracy =  86.38333333333334\n",
      "51830 / 60000\n",
      "   TEST   accuracy =  87.39\n",
      "8739 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.933989233400958\n",
      "EPOCH =  0 accuracy =  87.32666666666667\n",
      "52396 / 60000\n",
      "   TEST   accuracy =  88.32\n",
      "8832 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.993379208189727\n",
      "EPOCH =  0 accuracy =  87.84166666666667\n",
      "52705 / 60000\n",
      "   TEST   accuracy =  88.63\n",
      "8863 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.899028508988824\n",
      "EPOCH =  0 accuracy =  88.68833333333333\n",
      "53213 / 60000\n",
      "   TEST   accuracy =  89.51\n",
      "8951 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.920091574213888\n",
      "EPOCH =  0 accuracy =  88.99833333333333\n",
      "53399 / 60000\n",
      "   TEST   accuracy =  89.61\n",
      "8961 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.799802652050204\n",
      "EPOCH =  1 accuracy =  88.24166666666666\n",
      "52945 / 60000\n",
      "   TEST   accuracy =  88.78\n",
      "8878 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.816685430250777\n",
      "EPOCH =  1 accuracy =  89.79\n",
      "53874 / 60000\n",
      "   TEST   accuracy =  90.52\n",
      "9052 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.821823341376454\n",
      "EPOCH =  1 accuracy =  90.3\n",
      "54180 / 60000\n",
      "   TEST   accuracy =  90.96\n",
      "9096 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.811394709115311\n",
      "EPOCH =  1 accuracy =  90.87833333333334\n",
      "54527 / 60000\n",
      "   TEST   accuracy =  91.59\n",
      "9159 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.7919498076189635\n",
      "EPOCH =  1 accuracy =  91.425\n",
      "54855 / 60000\n",
      "   TEST   accuracy =  91.92\n",
      "9192 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.806133537910309\n",
      "EPOCH =  1 accuracy =  91.59166666666667\n",
      "54955 / 60000\n",
      "   TEST   accuracy =  92.11\n",
      "9211 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.817408726239843\n",
      "EPOCH =  1 accuracy =  91.75666666666666\n",
      "55054 / 60000\n",
      "   TEST   accuracy =  92.25999999999999\n",
      "9226 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.8522255693122744\n",
      "EPOCH =  1 accuracy =  92.04166666666667\n",
      "55225 / 60000\n",
      "   TEST   accuracy =  92.47\n",
      "9247 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.783713193023511\n",
      "EPOCH =  1 accuracy =  92.31166666666667\n",
      "55387 / 60000\n",
      "   TEST   accuracy =  92.67999999999999\n",
      "9268 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.827421759826909\n",
      "EPOCH =  1 accuracy =  92.46\n",
      "55476 / 60000\n",
      "   TEST   accuracy =  92.77\n",
      "9277 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.730075639945101\n",
      "EPOCH =  2 accuracy =  90.15166666666666\n",
      "54091 / 60000\n",
      "   TEST   accuracy =  90.2\n",
      "9020 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.767930678846001\n",
      "EPOCH =  2 accuracy =  91.61833333333334\n",
      "54971 / 60000\n",
      "   TEST   accuracy =  91.53\n",
      "9153 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.774329657259921\n",
      "EPOCH =  2 accuracy =  91.95\n",
      "55170 / 60000\n",
      "   TEST   accuracy =  91.93\n",
      "9193 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.770302747724109\n",
      "EPOCH =  2 accuracy =  92.33833333333334\n",
      "55403 / 60000\n",
      "   TEST   accuracy =  92.41\n",
      "9241 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.736808672570652\n",
      "EPOCH =  2 accuracy =  92.525\n",
      "55515 / 60000\n",
      "   TEST   accuracy =  92.5\n",
      "9250 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.776428254804086\n",
      "EPOCH =  2 accuracy =  92.75666666666666\n",
      "55654 / 60000\n",
      "   TEST   accuracy =  92.62\n",
      "9262 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.7694365655667665\n",
      "EPOCH =  2 accuracy =  92.85333333333334\n",
      "55712 / 60000\n",
      "   TEST   accuracy =  92.96\n",
      "9296 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.794819228075575\n",
      "EPOCH =  2 accuracy =  93.03833333333333\n",
      "55823 / 60000\n",
      "   TEST   accuracy =  92.9\n",
      "9290 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.759251109309028\n",
      "EPOCH =  2 accuracy =  93.195\n",
      "55917 / 60000\n",
      "   TEST   accuracy =  93.17999999999999\n",
      "9318 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.800669316347007\n",
      "EPOCH =  2 accuracy =  93.26666666666667\n",
      "55960 / 60000\n",
      "   TEST   accuracy =  93.23\n",
      "9323 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.725215539624163\n",
      "EPOCH =  3 accuracy =  91.69166666666668\n",
      "55015 / 60000\n",
      "   TEST   accuracy =  91.52\n",
      "9152 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.764101128055297\n",
      "EPOCH =  3 accuracy =  92.09\n",
      "55254 / 60000\n",
      "   TEST   accuracy =  91.86\n",
      "9186 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.758773719077535\n",
      "EPOCH =  3 accuracy =  92.315\n",
      "55389 / 60000\n",
      "   TEST   accuracy =  91.85\n",
      "9185 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.762136459146289\n",
      "EPOCH =  3 accuracy =  92.52\n",
      "55512 / 60000\n",
      "   TEST   accuracy =  92.33\n",
      "9233 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.736548111672643\n",
      "EPOCH =  3 accuracy =  92.65333333333334\n",
      "55592 / 60000\n",
      "   TEST   accuracy =  92.32000000000001\n",
      "9232 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.77687003908874\n",
      "EPOCH =  3 accuracy =  92.79166666666666\n",
      "55675 / 60000\n",
      "   TEST   accuracy =  92.45\n",
      "9245 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.763205453146426\n",
      "EPOCH =  3 accuracy =  92.89\n",
      "55734 / 60000\n",
      "   TEST   accuracy =  92.5\n",
      "9250 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.792022978530669\n",
      "EPOCH =  3 accuracy =  93.00500000000001\n",
      "55803 / 60000\n",
      "   TEST   accuracy =  92.47999999999999\n",
      "9248 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.761079157808358\n",
      "EPOCH =  3 accuracy =  93.075\n",
      "55845 / 60000\n",
      "   TEST   accuracy =  92.66\n",
      "9266 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.803749428661931\n",
      "EPOCH =  3 accuracy =  93.22333333333333\n",
      "55934 / 60000\n",
      "   TEST   accuracy =  92.73\n",
      "9273 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.725887908001955\n",
      "EPOCH =  4 accuracy =  92.525\n",
      "55515 / 60000\n",
      "   TEST   accuracy =  92.15\n",
      "9215 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.751416659499375\n",
      "EPOCH =  4 accuracy =  92.61500000000001\n",
      "55569 / 60000\n",
      "   TEST   accuracy =  92.25999999999999\n",
      "9226 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.745020876084908\n",
      "EPOCH =  4 accuracy =  92.75\n",
      "55650 / 60000\n",
      "   TEST   accuracy =  92.25\n",
      "9225 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.7561341158638495\n",
      "EPOCH =  4 accuracy =  92.86166666666666\n",
      "55717 / 60000\n",
      "   TEST   accuracy =  92.72\n",
      "9272 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.7323733928439635\n",
      "EPOCH =  4 accuracy =  92.92833333333334\n",
      "55757 / 60000\n",
      "   TEST   accuracy =  92.67999999999999\n",
      "9268 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.778619729229298\n",
      "EPOCH =  4 accuracy =  93.08166666666666\n",
      "55849 / 60000\n",
      "   TEST   accuracy =  92.58\n",
      "9258 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.762458622461685\n",
      "EPOCH =  4 accuracy =  93.12166666666667\n",
      "55873 / 60000\n",
      "   TEST   accuracy =  92.69\n",
      "9269 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.78915039319396\n",
      "EPOCH =  4 accuracy =  93.13\n",
      "55878 / 60000\n",
      "   TEST   accuracy =  92.58999999999999\n",
      "9259 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.763368636195159\n",
      "EPOCH =  4 accuracy =  93.32833333333333\n",
      "55997 / 60000\n",
      "   TEST   accuracy =  92.88\n",
      "9288 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.8013742654500025\n",
      "EPOCH =  4 accuracy =  93.32833333333333\n",
      "55997 / 60000\n",
      "   TEST   accuracy =  92.86999999999999\n",
      "9287 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.72153104989235\n",
      "EPOCH =  5 accuracy =  93.07833333333333\n",
      "55847 / 60000\n",
      "   TEST   accuracy =  92.46\n",
      "9246 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.738182434094727\n",
      "EPOCH =  5 accuracy =  93.16333333333333\n",
      "55898 / 60000\n",
      "   TEST   accuracy =  92.69\n",
      "9269 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.7342772065362\n",
      "EPOCH =  5 accuracy =  93.24833333333333\n",
      "55949 / 60000\n",
      "   TEST   accuracy =  92.75999999999999\n",
      "9276 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.751823252200412\n",
      "EPOCH =  5 accuracy =  93.30166666666668\n",
      "55981 / 60000\n",
      "   TEST   accuracy =  92.93\n",
      "9293 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.726663980096523\n",
      "EPOCH =  5 accuracy =  93.35166666666666\n",
      "56011 / 60000\n",
      "   TEST   accuracy =  92.96\n",
      "9296 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.777151249263884\n",
      "EPOCH =  5 accuracy =  93.395\n",
      "56037 / 60000\n",
      "   TEST   accuracy =  93.02\n",
      "9302 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.758502608360375\n",
      "EPOCH =  5 accuracy =  93.44\n",
      "56064 / 60000\n",
      "   TEST   accuracy =  93.04\n",
      "9304 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.783322360991019\n",
      "EPOCH =  5 accuracy =  93.45333333333333\n",
      "56072 / 60000\n",
      "   TEST   accuracy =  92.93\n",
      "9293 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.761704225241618\n",
      "EPOCH =  5 accuracy =  93.63166666666667\n",
      "56179 / 60000\n",
      "   TEST   accuracy =  93.12\n",
      "9312 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.79518323579229\n",
      "EPOCH =  5 accuracy =  93.595\n",
      "56157 / 60000\n",
      "   TEST   accuracy =  93.06\n",
      "9306 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.716762224107002\n",
      "EPOCH =  6 accuracy =  93.50166666666667\n",
      "56101 / 60000\n",
      "   TEST   accuracy =  92.97\n",
      "9297 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.729502531802105\n",
      "EPOCH =  6 accuracy =  93.53333333333333\n",
      "56120 / 60000\n",
      "   TEST   accuracy =  93.0\n",
      "9300 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.72893482996572\n",
      "EPOCH =  6 accuracy =  93.62333333333333\n",
      "56174 / 60000\n",
      "   TEST   accuracy =  93.10000000000001\n",
      "9310 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.747110456763389\n",
      "EPOCH =  6 accuracy =  93.64666666666666\n",
      "56188 / 60000\n",
      "   TEST   accuracy =  93.37\n",
      "9337 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.723356853734721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH =  6 accuracy =  93.69833333333332\n",
      "56219 / 60000\n",
      "   TEST   accuracy =  93.42\n",
      "9342 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.772127682918013\n",
      "EPOCH =  6 accuracy =  93.72833333333334\n",
      "56237 / 60000\n",
      "   TEST   accuracy =  93.33\n",
      "9333 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.756044439651488\n",
      "EPOCH =  6 accuracy =  93.75\n",
      "56250 / 60000\n",
      "   TEST   accuracy =  93.4\n",
      "9340 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.778725978836468\n",
      "EPOCH =  6 accuracy =  93.80166666666668\n",
      "56281 / 60000\n",
      "   TEST   accuracy =  93.13\n",
      "9313 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.760138435516247\n",
      "EPOCH =  6 accuracy =  93.91833333333334\n",
      "56351 / 60000\n",
      "   TEST   accuracy =  93.4\n",
      "9340 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.78850310435516\n",
      "EPOCH =  6 accuracy =  93.88166666666666\n",
      "56329 / 60000\n",
      "   TEST   accuracy =  93.28\n",
      "9328 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.711437056787716\n",
      "EPOCH =  7 accuracy =  93.83666666666667\n",
      "56302 / 60000\n",
      "   TEST   accuracy =  93.31\n",
      "9331 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.723356541081421\n",
      "EPOCH =  7 accuracy =  93.89166666666667\n",
      "56335 / 60000\n",
      "   TEST   accuracy =  93.23\n",
      "9323 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.725439640943417\n",
      "EPOCH =  7 accuracy =  93.94500000000001\n",
      "56367 / 60000\n",
      "   TEST   accuracy =  93.4\n",
      "9340 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.742669646158106\n",
      "EPOCH =  7 accuracy =  93.96\n",
      "56376 / 60000\n",
      "   TEST   accuracy =  93.52000000000001\n",
      "9352 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.720966884033144\n",
      "EPOCH =  7 accuracy =  93.98833333333333\n",
      "56393 / 60000\n",
      "   TEST   accuracy =  93.67999999999999\n",
      "9368 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.7676496840394345\n",
      "EPOCH =  7 accuracy =  94.01\n",
      "56406 / 60000\n",
      "   TEST   accuracy =  93.51\n",
      "9351 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.752219896186685\n",
      "EPOCH =  7 accuracy =  94.03\n",
      "56418 / 60000\n",
      "   TEST   accuracy =  93.56\n",
      "9356 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.775510784110721\n",
      "EPOCH =  7 accuracy =  94.095\n",
      "56457 / 60000\n",
      "   TEST   accuracy =  93.37\n",
      "9337 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.758192383331822\n",
      "EPOCH =  7 accuracy =  94.17166666666667\n",
      "56503 / 60000\n",
      "   TEST   accuracy =  93.58999999999999\n",
      "9359 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.782973920478145\n",
      "EPOCH =  7 accuracy =  94.13666666666667\n",
      "56482 / 60000\n",
      "   TEST   accuracy =  93.47\n",
      "9347 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.707026457794607\n",
      "EPOCH =  8 accuracy =  94.10333333333334\n",
      "56462 / 60000\n",
      "   TEST   accuracy =  93.55\n",
      "9355 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.719035884183402\n",
      "EPOCH =  8 accuracy =  94.14\n",
      "56484 / 60000\n",
      "   TEST   accuracy =  93.49\n",
      "9349 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.722907725304269\n",
      "EPOCH =  8 accuracy =  94.175\n",
      "56505 / 60000\n",
      "   TEST   accuracy =  93.54\n",
      "9354 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.738822815466374\n",
      "EPOCH =  8 accuracy =  94.24\n",
      "56544 / 60000\n",
      "   TEST   accuracy =  93.7\n",
      "9370 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.718818860582255\n",
      "EPOCH =  8 accuracy =  94.235\n",
      "56541 / 60000\n",
      "   TEST   accuracy =  93.84\n",
      "9384 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.764510835322413\n",
      "EPOCH =  8 accuracy =  94.25333333333333\n",
      "56552 / 60000\n",
      "   TEST   accuracy =  93.71000000000001\n",
      "9371 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.748278816515005\n",
      "EPOCH =  8 accuracy =  94.29833333333333\n",
      "56579 / 60000\n",
      "   TEST   accuracy =  93.67\n",
      "9367 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.772956220320298\n",
      "EPOCH =  8 accuracy =  94.28666666666666\n",
      "56572 / 60000\n",
      "   TEST   accuracy =  93.64\n",
      "9364 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.756603533727675\n",
      "EPOCH =  8 accuracy =  94.38666666666666\n",
      "56632 / 60000\n",
      "   TEST   accuracy =  93.74\n",
      "9374 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.778326159432073\n",
      "EPOCH =  8 accuracy =  94.32166666666667\n",
      "56593 / 60000\n",
      "   TEST   accuracy =  93.63\n",
      "9363 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.703858342296984\n",
      "EPOCH =  9 accuracy =  94.32666666666667\n",
      "56596 / 60000\n",
      "   TEST   accuracy =  93.62\n",
      "9362 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.715849279076268\n",
      "EPOCH =  9 accuracy =  94.365\n",
      "56619 / 60000\n",
      "   TEST   accuracy =  93.63\n",
      "9363 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.720770354307531\n",
      "EPOCH =  9 accuracy =  94.38333333333333\n",
      "56630 / 60000\n",
      "   TEST   accuracy =  93.62\n",
      "9362 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.735796423710047\n",
      "EPOCH =  9 accuracy =  94.45666666666666\n",
      "56674 / 60000\n",
      "   TEST   accuracy =  93.83\n",
      "9383 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.716881891544935\n",
      "EPOCH =  9 accuracy =  94.43333333333334\n",
      "56660 / 60000\n",
      "   TEST   accuracy =  94.04\n",
      "9404 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.761893094106102\n",
      "EPOCH =  9 accuracy =  94.46833333333333\n",
      "56681 / 60000\n",
      "   TEST   accuracy =  93.82000000000001\n",
      "9382 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.744688650243955\n",
      "EPOCH =  9 accuracy =  94.50333333333333\n",
      "56702 / 60000\n",
      "   TEST   accuracy =  93.84\n",
      "9384 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.7707881435532355\n",
      "EPOCH =  9 accuracy =  94.51333333333334\n",
      "56708 / 60000\n",
      "   TEST   accuracy =  93.69\n",
      "9369 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.755329916736335\n",
      "EPOCH =  9 accuracy =  94.56666666666666\n",
      "56740 / 60000\n",
      "   TEST   accuracy =  93.87\n",
      "9387 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.774441622514319\n",
      "EPOCH =  9 accuracy =  94.51333333333334\n",
      "56708 / 60000\n",
      "   TEST   accuracy =  93.77\n",
      "9377 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.701537655522199\n",
      "EPOCH =  10 accuracy =  94.49\n",
      "56694 / 60000\n",
      "   TEST   accuracy =  93.78999999999999\n",
      "9379 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.713268856020456\n",
      "EPOCH =  10 accuracy =  94.58166666666666\n",
      "56749 / 60000\n",
      "   TEST   accuracy =  93.75\n",
      "9375 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.718995689532285\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-06c36be96c4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTRAIN'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-> '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0myout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogit_to_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-41e8633aea7a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-41e8633aea7a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_left\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_left\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_right\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-41e8633aea7a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-41e8633aea7a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mfc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfc_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tsuman/98D2644AD2642EA6/Neural_Network/Notebooks/Experimentals/NN_Func_Approx/Soft_Decision_Tree/mylibrary/nnlib.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzee\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m  \u001b[0;31m# @ == .dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzee\u001b[0m \u001b[0;31m######## useful when dont know linear or not.. general form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 64#300\n",
    "EPOCHS = 20\n",
    "\n",
    "accuracy_list = []\n",
    "# magnitude = 0.\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "#     sdt.harden_decision(np.power(10, magnitude/1000.))\n",
    "    sdt.harden_decision(np.power(10, epoch/2))\n",
    "    \n",
    "    for index in range(train_size // batch_size):\n",
    "        train_x = train_data[index * batch_size:(index + 1) * batch_size]\n",
    "        train_y = train_label[index * batch_size:(index + 1) * batch_size]\n",
    "        \n",
    "        yout = sdt.forward(train_x)\n",
    "\n",
    "        dy = tnn.SoftmaxCrossEntropy.del_loss(yout, train_y)\n",
    "        loss = tnn.SoftmaxCrossEntropy.loss(yout, train_y)\n",
    "\n",
    "        dx = sdt.backward(dy)\n",
    "\n",
    "        sdt.update()\n",
    "#         magnitude += 1.\n",
    "        if index % 100 == 0:\n",
    "                        \n",
    "            print('\\nTRAIN',index, '-> ', loss)\n",
    "            yout = sdt.forward(train_data)\n",
    "            outputs = tnn.Logits.logit_to_index(yout)\n",
    "            correct = (outputs == np.array(train_label_)).sum()\n",
    "\n",
    "            accuracy = correct / len(train_label_) * 100.\n",
    "            print('EPOCH = ',epoch,'accuracy = ', accuracy)\n",
    "            print(correct, '/', len(train_label_))\n",
    "            \n",
    "            yout = sdt.forward(test_data)\n",
    "            outputs = tnn.Logits.logit_to_index(yout)\n",
    "            correct = (outputs == np.array(test_label_)).sum()\n",
    "\n",
    "            accuracy = correct / len(test_label_) * 100.\n",
    "            print('   TEST  ','accuracy = ', accuracy)\n",
    "            print(correct, '/', len(test_label_))  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.008149207475408347, 0.008149207475408347)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.sort(np.abs(sdt.fc.bias))\n",
    "a.min(), a.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TEST   accuracy =  69.98\n",
      "6998 / 10000\n"
     ]
    }
   ],
   "source": [
    "yout = sdt.forward_hard(test_data)\n",
    "outputs = tnn.Logits.logit_to_index(yout)\n",
    "correct = (outputs == np.array(test_label_)).sum()\n",
    "\n",
    "accuracy = correct / len(test_label_) * 100.\n",
    "print('   TEST  ','accuracy = ', accuracy)\n",
    "print(correct, '/', len(test_label_))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclic hardening and softening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_depth = 3\n",
    "sdt = InnerNode(input_size, output_size)\n",
    "sdt.create_child(tree_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN 0 ->  5.725549654104375\n",
      "EPOCH =  0 accuracy =  95.70166666666667\n",
      "57421 / 60000\n",
      "   TEST   accuracy =  95.03\n",
      "9503 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.706615283101673\n",
      "EPOCH =  0 accuracy =  95.98166666666667\n",
      "57589 / 60000\n",
      "   TEST   accuracy =  95.35\n",
      "9535 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.715495697081224\n",
      "EPOCH =  0 accuracy =  96.11666666666666\n",
      "57670 / 60000\n",
      "   TEST   accuracy =  95.45\n",
      "9545 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.705844467219088\n",
      "EPOCH =  0 accuracy =  96.25166666666667\n",
      "57751 / 60000\n",
      "   TEST   accuracy =  95.50999999999999\n",
      "9551 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.690039003738425\n",
      "EPOCH =  0 accuracy =  96.34333333333333\n",
      "57806 / 60000\n",
      "   TEST   accuracy =  95.63000000000001\n",
      "9563 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.731642387069918\n",
      "EPOCH =  0 accuracy =  96.45166666666667\n",
      "57871 / 60000\n",
      "   TEST   accuracy =  95.8\n",
      "9580 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.689939288926043\n",
      "EPOCH =  0 accuracy =  96.43\n",
      "57858 / 60000\n",
      "   TEST   accuracy =  95.67999999999999\n",
      "9568 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.752874918363013\n",
      "EPOCH =  0 accuracy =  96.5\n",
      "57900 / 60000\n",
      "   TEST   accuracy =  95.78\n",
      "9578 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.721773228682208\n",
      "EPOCH =  0 accuracy =  96.54\n",
      "57924 / 60000\n",
      "   TEST   accuracy =  95.89999999999999\n",
      "9590 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.745177361622492\n",
      "EPOCH =  0 accuracy =  96.61833333333333\n",
      "57971 / 60000\n",
      "   TEST   accuracy =  95.94\n",
      "9594 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.693479465160216\n",
      "EPOCH =  1 accuracy =  96.19\n",
      "57714 / 60000\n",
      "   TEST   accuracy =  95.1\n",
      "9510 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.6832616629807795\n",
      "EPOCH =  1 accuracy =  96.53666666666668\n",
      "57922 / 60000\n",
      "   TEST   accuracy =  95.47\n",
      "9547 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.718462728729502\n",
      "EPOCH =  1 accuracy =  96.57166666666667\n",
      "57943 / 60000\n",
      "   TEST   accuracy =  95.45\n",
      "9545 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.677451107243645\n",
      "EPOCH =  1 accuracy =  96.59166666666667\n",
      "57955 / 60000\n",
      "   TEST   accuracy =  95.50999999999999\n",
      "9551 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.686503245811714\n",
      "EPOCH =  1 accuracy =  96.63000000000001\n",
      "57978 / 60000\n",
      "   TEST   accuracy =  95.50999999999999\n",
      "9551 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.718282261784175\n",
      "EPOCH =  1 accuracy =  96.655\n",
      "57993 / 60000\n",
      "   TEST   accuracy =  95.58\n",
      "9558 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.67722330667007\n",
      "EPOCH =  1 accuracy =  96.61666666666666\n",
      "57970 / 60000\n",
      "   TEST   accuracy =  95.6\n",
      "9560 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.723447082395242\n",
      "EPOCH =  1 accuracy =  96.7\n",
      "58020 / 60000\n",
      "   TEST   accuracy =  95.54\n",
      "9554 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.719285758122991\n",
      "EPOCH =  1 accuracy =  96.67\n",
      "58002 / 60000\n",
      "   TEST   accuracy =  95.53\n",
      "9553 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.7278973049989315\n",
      "EPOCH =  1 accuracy =  96.705\n",
      "58023 / 60000\n",
      "   TEST   accuracy =  95.55\n",
      "9555 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.689697160630281\n",
      "EPOCH =  2 accuracy =  96.30166666666666\n",
      "57781 / 60000\n",
      "   TEST   accuracy =  95.03\n",
      "9503 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.692044679442832\n",
      "EPOCH =  2 accuracy =  96.38666666666667\n",
      "57832 / 60000\n",
      "   TEST   accuracy =  94.99\n",
      "9499 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.721763790904269\n",
      "EPOCH =  2 accuracy =  96.38166666666666\n",
      "57829 / 60000\n",
      "   TEST   accuracy =  95.11\n",
      "9511 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.6680944846286945\n",
      "EPOCH =  2 accuracy =  96.33166666666668\n",
      "57799 / 60000\n",
      "   TEST   accuracy =  95.08\n",
      "9508 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.693024995487775\n",
      "EPOCH =  2 accuracy =  96.38333333333333\n",
      "57830 / 60000\n",
      "   TEST   accuracy =  95.05\n",
      "9505 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.715880541577404\n",
      "EPOCH =  2 accuracy =  96.43\n",
      "57858 / 60000\n",
      "   TEST   accuracy =  95.12\n",
      "9512 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.68351322302941\n",
      "EPOCH =  2 accuracy =  96.38166666666666\n",
      "57829 / 60000\n",
      "   TEST   accuracy =  95.13000000000001\n",
      "9513 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.722499969959736\n",
      "EPOCH =  2 accuracy =  96.455\n",
      "57873 / 60000\n",
      "   TEST   accuracy =  95.12\n",
      "9512 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.727329831652866\n",
      "EPOCH =  2 accuracy =  96.435\n",
      "57861 / 60000\n",
      "   TEST   accuracy =  94.97\n",
      "9497 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.729411397788633\n",
      "EPOCH =  2 accuracy =  96.475\n",
      "57885 / 60000\n",
      "   TEST   accuracy =  95.12\n",
      "9512 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.6901596756295225\n",
      "EPOCH =  3 accuracy =  96.39333333333333\n",
      "57836 / 60000\n",
      "   TEST   accuracy =  95.05\n",
      "9505 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.693362656014591\n",
      "EPOCH =  3 accuracy =  96.45\n",
      "57870 / 60000\n",
      "   TEST   accuracy =  95.12\n",
      "9512 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.724185578635526\n",
      "EPOCH =  3 accuracy =  96.45333333333333\n",
      "57872 / 60000\n",
      "   TEST   accuracy =  95.06\n",
      "9506 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.666764136587055\n",
      "EPOCH =  3 accuracy =  96.41666666666666\n",
      "57850 / 60000\n",
      "   TEST   accuracy =  95.08\n",
      "9508 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.695310582751617\n",
      "EPOCH =  3 accuracy =  96.49166666666666\n",
      "57895 / 60000\n",
      "   TEST   accuracy =  95.08\n",
      "9508 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.7140090514118125\n",
      "EPOCH =  3 accuracy =  96.49\n",
      "57894 / 60000\n",
      "   TEST   accuracy =  95.11\n",
      "9511 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.684423745269003\n",
      "EPOCH =  3 accuracy =  96.44\n",
      "57864 / 60000\n",
      "   TEST   accuracy =  95.1\n",
      "9510 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.721195368862013\n",
      "EPOCH =  3 accuracy =  96.49333333333333\n",
      "57896 / 60000\n",
      "   TEST   accuracy =  95.08\n",
      "9508 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.725813025204448\n",
      "EPOCH =  3 accuracy =  96.49166666666666\n",
      "57895 / 60000\n",
      "   TEST   accuracy =  94.98\n",
      "9498 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.72762668673969\n",
      "EPOCH =  3 accuracy =  96.52166666666666\n",
      "57913 / 60000\n",
      "   TEST   accuracy =  95.1\n",
      "9510 / 10000\n",
      "\n",
      "TRAIN 0 ->  5.68869343466992\n",
      "EPOCH =  4 accuracy =  96.46833333333333\n",
      "57881 / 60000\n",
      "   TEST   accuracy =  95.06\n",
      "9506 / 10000\n",
      "\n",
      "TRAIN 100 ->  5.692786768448192\n",
      "EPOCH =  4 accuracy =  96.53166666666667\n",
      "57919 / 60000\n",
      "   TEST   accuracy =  95.16\n",
      "9516 / 10000\n",
      "\n",
      "TRAIN 200 ->  5.722685654895068\n",
      "EPOCH =  4 accuracy =  96.52833333333334\n",
      "57917 / 60000\n",
      "   TEST   accuracy =  95.1\n",
      "9510 / 10000\n",
      "\n",
      "TRAIN 300 ->  5.668463630293309\n",
      "EPOCH =  4 accuracy =  96.53500000000001\n",
      "57921 / 60000\n",
      "   TEST   accuracy =  95.1\n",
      "9510 / 10000\n",
      "\n",
      "TRAIN 400 ->  5.694964699276774\n",
      "EPOCH =  4 accuracy =  96.54666666666667\n",
      "57928 / 60000\n",
      "   TEST   accuracy =  95.13000000000001\n",
      "9513 / 10000\n",
      "\n",
      "TRAIN 500 ->  5.713600872473759\n",
      "EPOCH =  4 accuracy =  96.56\n",
      "57936 / 60000\n",
      "   TEST   accuracy =  95.15\n",
      "9515 / 10000\n",
      "\n",
      "TRAIN 600 ->  5.6841120071823825\n",
      "EPOCH =  4 accuracy =  96.505\n",
      "57903 / 60000\n",
      "   TEST   accuracy =  95.12\n",
      "9512 / 10000\n",
      "\n",
      "TRAIN 700 ->  5.720105244174755\n",
      "EPOCH =  4 accuracy =  96.55833333333334\n",
      "57935 / 60000\n",
      "   TEST   accuracy =  95.11\n",
      "9511 / 10000\n",
      "\n",
      "TRAIN 800 ->  5.724208538384866\n",
      "EPOCH =  4 accuracy =  96.55333333333334\n",
      "57932 / 60000\n",
      "   TEST   accuracy =  95.0\n",
      "9500 / 10000\n",
      "\n",
      "TRAIN 900 ->  5.727372570328875\n",
      "EPOCH =  4 accuracy =  96.60499999999999\n",
      "57963 / 60000\n",
      "   TEST   accuracy =  95.1\n",
      "9510 / 10000\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 64#300\n",
    "EPOCHS = 20\n",
    "\n",
    "accuracy_list = []\n",
    "for epoch in range(EPOCHS):\n",
    "            \n",
    "    mag = np.power(10,epoch%5)\n",
    "    sdt.harden_decision(mag)\n",
    "    \n",
    "    for index in range(train_size // batch_size):\n",
    "        train_x = train_data[index * batch_size:(index + 1) * batch_size]\n",
    "        train_y = train_label[index * batch_size:(index + 1) * batch_size]\n",
    "        \n",
    "        yout = sdt.forward(train_x)\n",
    "\n",
    "        dy = tnn.SoftmaxCrossEntropy.del_loss(yout, train_y)\n",
    "        loss = tnn.SoftmaxCrossEntropy.loss(yout, train_y)\n",
    "\n",
    "        dx = sdt.backward(dy)\n",
    "\n",
    "        sdt.update()\n",
    "        if index % 100 == 0:\n",
    "                        \n",
    "            print('\\nTRAIN',index, '-> ', loss)\n",
    "            yout = sdt.forward(train_data)\n",
    "            outputs = tnn.Logits.logit_to_index(yout)\n",
    "            correct = (outputs == np.array(train_label_)).sum()\n",
    "\n",
    "            accuracy = correct / len(train_label_) * 100.\n",
    "            print('EPOCH = ',epoch,'accuracy = ', accuracy)\n",
    "            print(correct, '/', len(train_label_))\n",
    "            \n",
    "            yout = sdt.forward(test_data)\n",
    "            outputs = tnn.Logits.logit_to_index(yout)\n",
    "            correct = (outputs == np.array(test_label_)).sum()\n",
    "\n",
    "            accuracy = correct / len(test_label_) * 100.\n",
    "            print('   TEST  ','accuracy = ', accuracy)\n",
    "            print(correct, '/', len(test_label_))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.000000124475"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(sdt.fc.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
