{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os, sys, pathlib, random, time, pickle, copy, json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED = 147\n",
    "# SEED = 258\n",
    "SEED = 369\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "la1 = None\n",
    "class MlpBLock(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_layers_ratio=[2], actf=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        #### convert hidden layers ratio to list if integer is inputted\n",
    "        if isinstance(hidden_layers_ratio, int):\n",
    "            hidden_layers_ratio = [hidden_layers_ratio]\n",
    "            \n",
    "        self.hlr = [1]+hidden_layers_ratio+[1]\n",
    "        \n",
    "        self.mlp = []\n",
    "        ### for 1 hidden layer, we iterate 2 times\n",
    "        for h in range(len(self.hlr)-1):\n",
    "            i, o = int(self.hlr[h]*self.input_dim),\\\n",
    "                    int(self.hlr[h+1]*self.input_dim)\n",
    "            self.mlp.append(nn.Linear(i, o))\n",
    "            self.mlp.append(actf())\n",
    "        self.mlp = self.mlp[:-1]\n",
    "        \n",
    "        self.mlp = nn.Sequential(*self.mlp)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        global la1\n",
    "#         return self.mlp(x)\n",
    "        for i, layer in enumerate(self.mlp):\n",
    "            x = layer(x)\n",
    "            if i == 0:\n",
    "                la1 = x\n",
    "#                 print(x.shape)\n",
    "#                 print(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MlpBLock(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=6, bias=True)\n",
       "    (1): GELU()\n",
       "    (2): Linear(in_features=6, out_features=8, bias=True)\n",
       "    (3): GELU()\n",
       "    (4): Linear(in_features=8, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MlpBLock(2, [3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMixerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, patch_size, num_channel):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "#         self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "        ps = None\n",
    "        if isinstance(patch_size, int):\n",
    "            ps = patch_size**2\n",
    "        else:\n",
    "            ps = patch_size[0]*patch_size[1]\n",
    "        ps = ps*num_channel\n",
    "        \n",
    "        self.mlp_patch = MlpBLock(ps, [2])\n",
    "        \n",
    "#         self.fold = nn.Fold(kernel_size=patch_size, stride=patch_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## x has shape-> N, C, H, W; C=Channel\n",
    "        \n",
    "        sz = x.shape\n",
    "        \n",
    "        y = nn.functional.unfold(x, \n",
    "                                 kernel_size=self.patch_size, \n",
    "                                 stride=self.patch_size\n",
    "                                )\n",
    "#         print(\"unfolded shape\", y.shape)\n",
    "        #### mix per patch\n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        y = self.mlp_patch(y)\n",
    "        y = torch.swapaxes(y, -1, -2)\n",
    "        \n",
    "        y = nn.functional.fold(y, (sz[-2], sz[-1]), \n",
    "                               kernel_size=self.patch_size, \n",
    "                               stride=self.patch_size\n",
    "                              )\n",
    "        x = x+y\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchMixerBlock(\n",
       "  (mlp_patch): MlpBLock(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=192, out_features=384, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Linear(in_features=384, out_features=192, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmb = PatchMixerBlock(8, 3)\n",
    "pmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 16, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmb(torch.randn(5, 3, 16, 16)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Unfold+Linear+Fold to conv2d+reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 2\n",
    "conv2d = nn.Conv2d(3, 3*8*8*h, kernel_size=8, stride=8, groups=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 3, 8, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_1x1 = nn.Conv2d(3*8*8*h, 3*8*8, kernel_size=1, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 384, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(torch.randn(5, 3, 16, 16)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 192, 2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = conv2d_1x1(conv2d(torch.randn(5, 3, 16, 16)))\n",
    "yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 8, 8, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.view(-1, 3, 8, 8, 2, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 16, 16])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.view(-1, 3, 8, 8, 2, 2).permute(0,1,2,4,3,5).reshape(-1, 3, 16, 16).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear(in_features=192, out_features=384, bias=True),\n",
       " Linear(in_features=384, out_features=192, bias=True))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmb.mlp_patch.mlp[0], pmb.mlp_patch.mlp[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d.weight.data = pmb.mlp_patch.mlp[0].weight.data.reshape(-1, 3, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d.bias.data = pmb.mlp_patch.mlp[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 3, 16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0938e-01,  3.0875e-01,  1.1378e-01,  ..., -3.9103e-01,\n",
      "           3.8987e-02, -2.9499e-01],\n",
      "         [-3.6289e-02,  4.2033e-01, -1.5503e+00,  ..., -5.1576e-01,\n",
      "          -8.1168e-01,  4.0114e-02],\n",
      "         [-4.7239e-01,  3.5274e-02,  1.0130e+00,  ...,  8.1015e-03,\n",
      "           6.5814e-01,  5.3013e-01],\n",
      "         [ 1.1671e+00, -5.4763e-01,  4.2892e-01,  ..., -9.5840e-01,\n",
      "           1.0319e+00,  4.3571e-01]],\n",
      "\n",
      "        [[-4.6715e-02, -2.4464e-01,  3.8992e-01,  ...,  4.6404e-01,\n",
      "          -1.0017e-01,  4.0540e-01],\n",
      "         [ 1.8285e-01,  2.9831e-01, -3.1520e-01,  ..., -6.1594e-01,\n",
      "          -7.1937e-01,  5.7502e-01],\n",
      "         [ 7.9037e-01, -1.4237e+00, -9.7666e-02,  ..., -1.0188e+00,\n",
      "          -5.3295e-01,  6.5312e-02],\n",
      "         [-6.1959e-01,  8.4910e-01,  8.8066e-02,  ..., -4.1976e-02,\n",
      "          -1.3695e+00, -1.4766e-01]],\n",
      "\n",
      "        [[ 8.5568e-02,  3.6752e-01,  3.7391e-01,  ..., -9.2734e-02,\n",
      "          -5.8245e-01, -4.6754e-01],\n",
      "         [-6.9989e-01,  1.2125e-01, -4.1096e-01,  ..., -5.5445e-02,\n",
      "          -5.9076e-01, -1.0959e+00],\n",
      "         [ 9.0892e-01, -2.8391e-01,  8.8242e-03,  ...,  1.1582e+00,\n",
      "          -5.1349e-01,  4.3379e-01],\n",
      "         [ 9.6159e-01, -4.4120e-01,  6.6179e-01,  ..., -2.0513e-01,\n",
      "          -6.9365e-01,  6.1343e-01]],\n",
      "\n",
      "        [[ 1.8842e-01,  3.4338e-01,  2.4356e-01,  ...,  1.0517e-01,\n",
      "          -1.9072e-01, -1.5809e-01],\n",
      "         [-1.7079e+00, -3.1207e-01,  9.6793e-01,  ...,  8.9106e-01,\n",
      "           5.2706e-01, -6.9316e-01],\n",
      "         [ 1.1990e-01, -1.3755e+00,  9.3170e-01,  ..., -3.1800e-01,\n",
      "          -4.5009e-01, -1.1889e-03],\n",
      "         [-7.2323e-01,  1.7991e-01,  3.3891e-01,  ...,  5.3592e-01,\n",
      "           3.7689e-01, -6.2940e-02]],\n",
      "\n",
      "        [[-2.0338e-01,  1.6020e+00,  1.2050e-01,  ..., -1.5531e+00,\n",
      "           1.5867e-01,  3.6964e-01],\n",
      "         [ 1.7355e+00, -3.8833e-01,  6.5525e-01,  ...,  6.3949e-01,\n",
      "          -4.2394e-01,  5.2868e-01],\n",
      "         [ 7.7290e-01,  3.3881e-01,  1.0627e+00,  ..., -1.0294e+00,\n",
      "           9.4102e-01,  2.6800e-01],\n",
      "         [ 4.0504e-01,  1.7651e-01, -2.0346e-01,  ...,  1.4968e+00,\n",
      "           3.3025e-01, -5.8974e-01]]], grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 384])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = conv2d(x).reshape(5, 3*8*8*h, -1).transpose(1,2)\n",
    "print(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pmb(x)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(la1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.2817e-07), tensor(1.2062e-07), tensor(0.), tensor(1.1921e-06))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = (la1-y).abs().data\n",
    "diff.mean(), diff.std(), diff.min(), diff.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Putting it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([192, 384, 1, 1]), torch.Size([192, 384]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_1x1.weight.data.shape, pmb.mlp_patch.mlp[-1].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([192]), torch.Size([192]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_1x1.bias.shape, pmb.mlp_patch.mlp[-1].bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_1x1.weight.data = pmb.mlp_patch.mlp[-1].weight.data.reshape(192, 384, 1, 1)\n",
    "conv2d_1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_1x1.bias.data = pmb.mlp_patch.mlp[-1].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([384, 3, 8, 8]), torch.Size([384, 192]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### for first layer\n",
    "conv2d.weight.data.shape, pmb.mlp_patch.mlp[0].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([384]), torch.Size([384]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.bias.shape, pmb.mlp_patch.mlp[0].bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d.weight.data = pmb.mlp_patch.mlp[0].weight.data.reshape(-1, 3, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d.bias.data = pmb.mlp_patch.mlp[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test\n",
    "x = torch.randn(5, 3, 16, 16)\n",
    "actf = nn.GELU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425 µs ± 26.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit x + conv2d_1x1(actf(conv2d(x))).view(-1, 3, 8, 8, 2, 2).permute(0,1,4,2,5,3).reshape(-1, 3, 16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388 µs ± 3.04 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pmb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x + conv2d_1x1(actf(conv2d(x))).view(-1, 3, 8, 8, 2, 2).permute(0,1,4,2,5,3).reshape(-1, 3, 16, 16)\n",
    "b = pmb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.1437e-08), tensor(6.7618e-08), tensor(0.), tensor(4.7684e-07))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = (a-b).abs().data\n",
    "diff.mean(), diff.std(), diff.min(), diff.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
